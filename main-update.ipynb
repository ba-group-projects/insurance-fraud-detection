{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "### Question\n",
    "Briefly discuss why it is more difficult to find a good classifier on such a dataset than on one where, for example, 5,000 claims are fraudulent, and 5,000 are not. In particular, consider what happens when undetected fraudulent claims are very costly to the insurance company.\n",
    "\n",
    "### Answer\n",
    "When the dataset in highly unbalanced, like what in the car-insurance case, the machine learning algorithm can predict well in the majority class and predict poorly in minority class. Since most of machine learning algorithm always pursue to decrease error rate, thus they tend to predict the all the label to majority class one. In our scenario, the algorithm tends to predict all the claims non-fraudulent. However, the wrong prediction will increase the False-negative rate, which will increase the cost of fraudulent claims.\n",
    "Another issue related to the scarce minority data is that we might miss some key combination of variables that has high probability to be fraudulent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check how much NaN values in each column when the claim is frandulent.\n",
    "We can find when the claim is frandulent, most of the numerical variables are not missing, which means we could directly drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the range of all variables and drop unreasonable numbers\n",
    "# split first and scale with smote code\n",
    "# check scale first or smote first\n",
    "# validation loss and trainning loss\n",
    "# the batch size is 32\n",
    "# TODO train test validation\n",
    "# check the roc curve\n",
    "# hidden layer number\n",
    "# TODO smote oversampling issue(why the number is float)\n",
    "# claim involved cover\n",
    "# TODO clear session andv set seeds #FIXME\n",
    "# TODO sensebility_at_spec\n",
    "# TODO set seeds before \n",
    "# TODO model summary\n",
    "# TODO save model \n",
    "\n",
    "# TO ASK\n",
    "# How to select the best model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "\n",
    "### TODO    \n",
    "calculate the number of policyholdersnumber and vehicle number\n",
    "\n",
    "### Question\n",
    "Load the dataset \"Insurance_claims.csv\" and clean it as appropriate for use with machine learning algorithms. A description of the features can be found at the end of this document.\n",
    "\n",
    "### Principle\n",
    "1. Since the dataset is highly unbalanced, and the fraudulent dataset is very scarce, we don't want to drop the data label with 'fradulent'.\n",
    "2. When the variables is categorical varibles, we tend to keep the Nah value as a classificaiton value rather than drop it.\n",
    "3. When the variables is numerical variables, we will check how many NaN values is related to the fraudulent case. If few of them, we will drop the variable. Otherwise, we will find a way to fill in the NaN values.\n",
    "\n",
    "### Proprocess procedure\n",
    "1. load data and select useful columns\n",
    "2. drop duplicates\n",
    "3. drop unreasonable rows\n",
    "4. deal with nan data\n",
    "    - deal with the categorical nan data\n",
    "    - deal with the numerical nan data\n",
    "5. deal with date data\n",
    "6. get an insight of the distribution of dataset\n",
    "    - check whether there is a signicicant distribution difference in every column in fraud data and non-fraud data\n",
    "7. clean features\n",
    "    - dummy\n",
    "      - PolicyholderOccupation\n",
    "      - ClaimCause\n",
    "      - ClaimInvolvedCovers\n",
    "      - DamageImportance\n",
    "      - FirstPartyVehicleType \n",
    "      - ConnectionBetweenParties\n",
    "      - PolicyWasSubscribedOnInternet\n",
    "    - extract features in 'ClaimInvolvedCovers'\n",
    "    - outlier # TODO\n",
    "8. split data and scale\n",
    "9.  show the data structure after preprocess\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import imblearn\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score,roc_auc_score,roc_curve\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Load data and select useful columns\n",
    "We are going to use the following features to predict the fraud cases:\n",
    "1. PolicyholderOccupation\n",
    "2. LossDate\n",
    "3. FirstPolicySubscriptionDate\n",
    "4. ClainType\n",
    "5. ClaimInvolvedCovers\n",
    "6. DamageImportance\n",
    "7. FirstPartyVehicleType\n",
    "8. ConnectionBetweenParties\n",
    "9. PolicyWasSubscribedOnInternet\n",
    "10. NumberOfPoliciesOfPolicyholder\n",
    "11. FpVehicleAgeMonths\n",
    "12. EasinessToStage\n",
    "13. ClaimWihoutIdentifiedThirdParty\n",
    "14. ClaimAmount\n",
    "15. LossHour\n",
    "16. PolicyHolderAge\n",
    "17. NumberOfBodilyInjuries\n",
    "18. FirstPartyLiability\n",
    "19. LossAndHolderPostCodeSame\n",
    "\n",
    "And we also need label:\n",
    "1. Fraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data sample:\n",
      "  PolicyholderOccupation  LossDate FirstPolicySubscriptionDate  \\\n",
      "0           CivilServant  02.01.19                    18.06.18   \n",
      "1                 Worker  02.01.19                    29.06.17   \n",
      "2                 Worker  02.01.19                    05.02.17   \n",
      "3           CivilServant  02.01.19                    21.01.17   \n",
      "4                 Farmer  02.01.19                    13.01.18   \n",
      "\n",
      "                         ClaimCause  \\\n",
      "0               CollisionWithAnimal   \n",
      "1                     LossOfControl   \n",
      "2  AccidentWithIdentifiedThirdParty   \n",
      "3  AccidentWithIdentifiedThirdParty   \n",
      "4  AccidentWithIdentifiedThirdParty   \n",
      "\n",
      "                               ClaimInvolvedCovers DamageImportance  \\\n",
      "0                     MaterialDamages ActLiability              NaN   \n",
      "1                     MaterialDamages ActLiability              NaN   \n",
      "2                     MaterialDamages ActLiability              NaN   \n",
      "3  MaterialDamages ActLiability ReplacementVehicle              NaN   \n",
      "4                                     ActLiability              NaN   \n",
      "\n",
      "  FirstPartyVehicleType ConnectionBetweenParties  \\\n",
      "0                   Car                      NaN   \n",
      "1                   Car                      NaN   \n",
      "2                   Car                      NaN   \n",
      "3                   Car                      NaN   \n",
      "4                   Car                      NaN   \n",
      "\n",
      "   PolicyWasSubscribedOnInternet  NumberOfPoliciesOfPolicyholder  \\\n",
      "0                              1                               1   \n",
      "1                              0                               3   \n",
      "2                              0                               9   \n",
      "3                              0                               2   \n",
      "4                              0                               4   \n",
      "\n",
      "   FpVehicleAgeMonths  EasinessToStage  ClaimWihoutIdentifiedThirdParty  \\\n",
      "0               104.0             0.25                                1   \n",
      "1               230.0             0.50                                1   \n",
      "2                93.0             0.25                                0   \n",
      "3                56.0             0.25                                0   \n",
      "4               110.0             0.25                                0   \n",
      "\n",
      "   ClaimAmount  LossHour  PolicyHolderAge  NumberOfBodilyInjuries  \\\n",
      "0      4624.73       8.0             45.0                       0   \n",
      "1      1606.81      11.0             20.0                       0   \n",
      "2       998.20      18.0             32.0                       0   \n",
      "3      2506.92      11.0             46.0                       0   \n",
      "4        12.00      12.0             28.0                       0   \n",
      "\n",
      "   FirstPartyLiability  LossAndHolderPostCodeSame  Fraud  \n",
      "0                  1.0                          1      0  \n",
      "1                  1.0                          0      0  \n",
      "2                  0.5                          1      0  \n",
      "3                  0.5                          1      0  \n",
      "4                  0.0                          0      0  \n",
      "-----------------------------------------------------\n",
      "Data Columns:\n",
      "Index(['PolicyholderOccupation', 'LossDate', 'FirstPolicySubscriptionDate',\n",
      "       'ClaimCause', 'ClaimInvolvedCovers', 'DamageImportance',\n",
      "       'FirstPartyVehicleType', 'ConnectionBetweenParties',\n",
      "       'PolicyWasSubscribedOnInternet', 'NumberOfPoliciesOfPolicyholder',\n",
      "       'FpVehicleAgeMonths', 'EasinessToStage',\n",
      "       'ClaimWihoutIdentifiedThirdParty', 'ClaimAmount', 'LossHour',\n",
      "       'PolicyHolderAge', 'NumberOfBodilyInjuries', 'FirstPartyLiability',\n",
      "       'LossAndHolderPostCodeSame', 'Fraud'],\n",
      "      dtype='object')\n",
      "-----------------------------------------------------\n",
      "Data description:\n",
      "       PolicyWasSubscribedOnInternet  NumberOfPoliciesOfPolicyholder  \\\n",
      "count                   11530.000000                    11530.000000   \n",
      "mean                        0.205551                        2.231830   \n",
      "std                         0.404121                        1.690804   \n",
      "min                         0.000000                        1.000000   \n",
      "25%                         0.000000                        1.000000   \n",
      "50%                         0.000000                        2.000000   \n",
      "75%                         0.000000                        3.000000   \n",
      "max                         1.000000                       18.000000   \n",
      "\n",
      "       FpVehicleAgeMonths  EasinessToStage  ClaimWihoutIdentifiedThirdParty  \\\n",
      "count        11518.000000     11530.000000                     11530.000000   \n",
      "mean           113.445390         0.377593                         0.685863   \n",
      "std             73.622026         0.139479                         0.464191   \n",
      "min             -4.000000         0.000000                         0.000000   \n",
      "25%             52.000000         0.250000                         0.000000   \n",
      "50%            108.000000         0.500000                         1.000000   \n",
      "75%            162.000000         0.500000                         1.000000   \n",
      "max            652.000000         0.500000                         1.000000   \n",
      "\n",
      "        ClaimAmount      LossHour  PolicyHolderAge  NumberOfBodilyInjuries  \\\n",
      "count  11530.000000  11436.000000     11494.000000            11530.000000   \n",
      "mean    1409.463023      8.265128        44.575083                0.028187   \n",
      "std     2672.349310      7.407462        15.218107                0.200147   \n",
      "min        0.000000      0.000000        18.000000                0.000000   \n",
      "25%      288.085000      0.000000        32.000000                0.000000   \n",
      "50%      755.900000      9.000000        43.000000                0.000000   \n",
      "75%     1500.000000     15.000000        56.000000                0.000000   \n",
      "max    64696.000000     23.000000        90.000000                5.000000   \n",
      "\n",
      "       FirstPartyLiability  LossAndHolderPostCodeSame         Fraud  \n",
      "count         11530.000000               11530.000000  11530.000000  \n",
      "mean              0.208066                   0.566609      0.009974  \n",
      "std               0.402509                   0.495565      0.099375  \n",
      "min               0.000000                   0.000000      0.000000  \n",
      "25%               0.000000                   0.000000      0.000000  \n",
      "50%               0.000000                   1.000000      0.000000  \n",
      "75%               0.000000                   1.000000      0.000000  \n",
      "max               1.000000                   1.000000      1.000000  \n",
      "-----------------------------------------------------\n",
      "Data duplicated rows:\n",
      "14\n",
      "-----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# read data and get a brief idea of the data\n",
    "df = pd.read_csv('./materials/Insurance_claims.csv')\n",
    "# get useful features that needed in the machine learning model\n",
    "# TODO using nlp to insurer notes data\n",
    "needed_columns = [ 'PolicyholderOccupation',\n",
    "       'LossDate', 'FirstPolicySubscriptionDate', 'ClaimCause',\n",
    "       'ClaimInvolvedCovers', 'DamageImportance', 'FirstPartyVehicleType',\n",
    "       'ConnectionBetweenParties', 'PolicyWasSubscribedOnInternet',\n",
    "       'NumberOfPoliciesOfPolicyholder', 'FpVehicleAgeMonths',\n",
    "       'EasinessToStage', 'ClaimWihoutIdentifiedThirdParty', 'ClaimAmount',\n",
    "       'LossHour', 'PolicyHolderAge', 'NumberOfBodilyInjuries',\n",
    "       'FirstPartyLiability', 'LossAndHolderPostCodeSame','Fraud']\n",
    "df = df[needed_columns]\n",
    "\n",
    "# show the first 5 rows, get some idea of the data structure\n",
    "print(f'Data sample:')\n",
    "print(df.head(5)) #TODO use sentiment analysis \n",
    "print('-----------------------------------------------------')\n",
    "\n",
    "# get the columns name\n",
    "print('Data Columns:')\n",
    "print(str(df.columns))\n",
    "print('-----------------------------------------------------')\n",
    "\n",
    "# get some basic information about the data, and we found that the min number \n",
    "# of FpVehicleAgeMonths is less than 0, which does't make sense. We are going \n",
    "# to detect whether these rows are fraud cases or not. If they are all non-fraud,\n",
    "# we can drop the rows with negative FpVehicleAgeMonths value. Otherwise, we will \n",
    "# create a new feature that record these abnormal rows since these unreasonable \n",
    "# values might be evidence of fraud cases.\n",
    "print('Data description:')\n",
    "print(df.describe())\n",
    "print('-----------------------------------------------------')\n",
    "\n",
    "# check whether there are any duplicated rows and we found there are 8 duplicated rows,\n",
    "# which we are going to drop.\n",
    "print('Data duplicated rows:')\n",
    "print(df.duplicated().sum())\n",
    "print('-----------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Drop the duplicated rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the data before dropping duplicated rows:\n",
      "(11530, 20)\n",
      "-----------------------------------------------------\n",
      "The shape of the data after dropping duplicated rows:\n",
      "(11516, 20)\n",
      "-----------------------------------------------------\n",
      "The number of rows that are dropped: 14\n"
     ]
    }
   ],
   "source": [
    "print('The shape of the data before dropping duplicated rows:')\n",
    "df_shape_before_drop = df.shape\n",
    "print(df.shape)\n",
    "print('-----------------------------------------------------')\n",
    "\n",
    "# drop the duplicated rows\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "print('The shape of the data after dropping duplicated rows:')\n",
    "df_shape_after_drop = df.shape\n",
    "print(df.shape)\n",
    "print('-----------------------------------------------------')\n",
    "\n",
    "print(f'The number of rows that are dropped: {df_shape_before_drop[0]-df_shape_after_drop[0]}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Drop unreasonable values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     PolicyholderOccupation  LossDate FirstPolicySubscriptionDate  \\\n",
      "8019                Retired  24.06.20                    22.10.19   \n",
      "8446                Retired  21.07.20                    26.02.20   \n",
      "8529                Retired  17.07.20                    26.02.20   \n",
      "\n",
      "            ClaimCause           ClaimInvolvedCovers DamageImportance  \\\n",
      "8019     LossOfControl  MaterialDamages ActLiability              NaN   \n",
      "8446     LossOfControl  MaterialDamages ActLiability              NaN   \n",
      "8529  WindscreenDamage                    Windscreen              NaN   \n",
      "\n",
      "     FirstPartyVehicleType ConnectionBetweenParties  \\\n",
      "8019                   Car                      NaN   \n",
      "8446                   Car                      NaN   \n",
      "8529                   Car                      NaN   \n",
      "\n",
      "      PolicyWasSubscribedOnInternet  NumberOfPoliciesOfPolicyholder  \\\n",
      "8019                              0                               2   \n",
      "8446                              0                               4   \n",
      "8529                              0                               4   \n",
      "\n",
      "      FpVehicleAgeMonths  EasinessToStage  ClaimWihoutIdentifiedThirdParty  \\\n",
      "8019                -1.0              0.5                                1   \n",
      "8446                -4.0              0.5                                1   \n",
      "8529                -4.0              0.5                                1   \n",
      "\n",
      "      ClaimAmount  LossHour  PolicyHolderAge  NumberOfBodilyInjuries  \\\n",
      "8019      3806.61      14.0             71.0                       0   \n",
      "8446      2819.11      14.0             72.0                       0   \n",
      "8529      1323.53       0.0             72.0                       0   \n",
      "\n",
      "      FirstPartyLiability  LossAndHolderPostCodeSame  Fraud  \n",
      "8019                  1.0                          1      0  \n",
      "8446                  1.0                          1      0  \n",
      "8529                  0.0                          1      0  \n",
      "-----------------------------------------------------\n",
      "The number of rows that are dropped: 3\n"
     ]
    }
   ],
   "source": [
    "# check whether unreasonable rows contain fraud cases\n",
    "df_unreasonable_rows = df[df['FpVehicleAgeMonths'] < 0]\n",
    "df_shape_before_drop = df_unreasonable_rows.shape\n",
    "print(df_unreasonable_rows)\n",
    "print('-----------------------------------------------------')\n",
    "# we can find that these three rows are not fraud cases. \n",
    "# Since we have enough non-fraud data, we can drop these rows.\n",
    "df_shape_before_drop = df.shape\n",
    "df.drop(df_unreasonable_rows.index, inplace=True)\n",
    "df_shape_after_drop = df.shape\n",
    "\n",
    "print(f'The number of rows that are dropped: {df_shape_before_drop[0]-df_shape_after_drop[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Deal with nan data\n",
    "Check how much NaN values in each column.\n",
    "\n",
    "We can find that except for 'FirstPartyVehicleNumber', 'ThirdPartyVehicleNumber', 'InsurerNotes', which we might not use in our models, most the NaN values are concentrated in the 'PolicyholderOccupation', 'ClaimCause',etc which are mainly categorical variables. In this case, we could turn these NaN values into a category value in order to take account the influence of missing variables, no mather what reason they are missing.\n",
    "\n",
    "In terms of the numeric variables, we will furtherly check how many of them are missing when the claim is fraudulent or not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaN values in each column:\n",
      "PolicyholderOccupation               340\n",
      "LossDate                               0\n",
      "FirstPolicySubscriptionDate            0\n",
      "ClaimCause                           191\n",
      "ClaimInvolvedCovers                  189\n",
      "DamageImportance                   10775\n",
      "FirstPartyVehicleType                 12\n",
      "ConnectionBetweenParties           11415\n",
      "PolicyWasSubscribedOnInternet          0\n",
      "NumberOfPoliciesOfPolicyholder         0\n",
      "FpVehicleAgeMonths                    12\n",
      "EasinessToStage                        0\n",
      "ClaimWihoutIdentifiedThirdParty        0\n",
      "ClaimAmount                            0\n",
      "LossHour                              94\n",
      "PolicyHolderAge                       36\n",
      "NumberOfBodilyInjuries                 0\n",
      "FirstPartyLiability                    0\n",
      "LossAndHolderPostCodeSame              0\n",
      "Fraud                                  0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check how much NaN values in each column.\n",
    "print(f'Number of NaN values in each column:') \n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can find that in the Fraud case, there are a lot of data missing in categorical columns, but few in numerical columns.\n",
    "\n",
    "Thus, we can set NaN as a category of categorical data and generate dummy variables. And we can drop the rows that contains NaN values in numerical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaN values in each column when Frand is True:\n",
      "PolicyholderOccupation               4\n",
      "LossDate                             0\n",
      "FirstPolicySubscriptionDate          0\n",
      "ClaimCause                           0\n",
      "ClaimInvolvedCovers                  0\n",
      "DamageImportance                    96\n",
      "FirstPartyVehicleType                2\n",
      "ConnectionBetweenParties           102\n",
      "PolicyWasSubscribedOnInternet        0\n",
      "NumberOfPoliciesOfPolicyholder       0\n",
      "FpVehicleAgeMonths                   2\n",
      "EasinessToStage                      0\n",
      "ClaimWihoutIdentifiedThirdParty      0\n",
      "ClaimAmount                          0\n",
      "LossHour                             1\n",
      "PolicyHolderAge                      0\n",
      "NumberOfBodilyInjuries               0\n",
      "FirstPartyLiability                  0\n",
      "LossAndHolderPostCodeSame            0\n",
      "Fraud                                0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check the number of missing data when Frand is True\n",
    "df_fraud = df[df[\"Fraud\"]==1]\n",
    "print(f'Number of NaN values in each column when Frand is True:')\n",
    "print(df_fraud.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaN values in each column when Frand is False:\n",
      "PolicyholderOccupation               336\n",
      "LossDate                               0\n",
      "FirstPolicySubscriptionDate            0\n",
      "ClaimCause                           191\n",
      "ClaimInvolvedCovers                  189\n",
      "DamageImportance                   10679\n",
      "FirstPartyVehicleType                 10\n",
      "ConnectionBetweenParties           11313\n",
      "PolicyWasSubscribedOnInternet          0\n",
      "NumberOfPoliciesOfPolicyholder         0\n",
      "FpVehicleAgeMonths                    10\n",
      "EasinessToStage                        0\n",
      "ClaimWihoutIdentifiedThirdParty        0\n",
      "ClaimAmount                            0\n",
      "LossHour                              93\n",
      "PolicyHolderAge                       36\n",
      "NumberOfBodilyInjuries                 0\n",
      "FirstPartyLiability                    0\n",
      "LossAndHolderPostCodeSame              0\n",
      "Fraud                                  0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_non_frand = df[df[\"Fraud\"]==0]\n",
    "print(f'Number of NaN values in each column when Frand is False:')\n",
    "print(df_non_frand.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill the missing data in categorical columns with string NaN and make it a category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_columns = ['PolicyholderOccupation', 'ClaimCause','ClaimInvolvedCovers', 'DamageImportance', 'FirstPartyVehicleType','ConnectionBetweenParties', 'PolicyWasSubscribedOnInternet']\n",
    "df[dummy_columns] = df[dummy_columns].fillna('NaN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop the missing data in numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of rows that are dropped: 142\n",
      "The number of rows that are dropped when Frand is True: 3\n"
     ]
    }
   ],
   "source": [
    "df_shape_before_drop = df.shape\n",
    "df_fraud_shape_before_drop = df[df[\"Fraud\"]==1].shape\n",
    "df.dropna(subset=[\"LossHour\",\"PolicyHolderAge\",\"FpVehicleAgeMonths\"],inplace=True)\n",
    "df_shape_after_drop = df.shape\n",
    "df_fraud_shape_after_drop = df[df[\"Fraud\"]==1].shape\n",
    "print(f'The number of rows that are dropped: {df_shape_before_drop[0]-df_shape_after_drop[0]}')\n",
    "print(f'The number of rows that are dropped when Frand is True: {df_fraud_shape_before_drop[0]-df_fraud_shape_after_drop[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After these steps, we don't have any missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of NaN values in each column:\n",
      "-----------------------------------------------------\n",
      "The shape of final datasets:\n",
      "(11371, 20)\n",
      "-----------------------------------------------------\n",
      "Data sample:\n",
      "  PolicyholderOccupation  LossDate FirstPolicySubscriptionDate  \\\n",
      "0           CivilServant  02.01.19                    18.06.18   \n",
      "1                 Worker  02.01.19                    29.06.17   \n",
      "2                 Worker  02.01.19                    05.02.17   \n",
      "3           CivilServant  02.01.19                    21.01.17   \n",
      "4                 Farmer  02.01.19                    13.01.18   \n",
      "\n",
      "                         ClaimCause  \\\n",
      "0               CollisionWithAnimal   \n",
      "1                     LossOfControl   \n",
      "2  AccidentWithIdentifiedThirdParty   \n",
      "3  AccidentWithIdentifiedThirdParty   \n",
      "4  AccidentWithIdentifiedThirdParty   \n",
      "\n",
      "                               ClaimInvolvedCovers DamageImportance  \\\n",
      "0                     MaterialDamages ActLiability              NaN   \n",
      "1                     MaterialDamages ActLiability              NaN   \n",
      "2                     MaterialDamages ActLiability              NaN   \n",
      "3  MaterialDamages ActLiability ReplacementVehicle              NaN   \n",
      "4                                     ActLiability              NaN   \n",
      "\n",
      "  FirstPartyVehicleType ConnectionBetweenParties  \\\n",
      "0                   Car                      NaN   \n",
      "1                   Car                      NaN   \n",
      "2                   Car                      NaN   \n",
      "3                   Car                      NaN   \n",
      "4                   Car                      NaN   \n",
      "\n",
      "   PolicyWasSubscribedOnInternet  NumberOfPoliciesOfPolicyholder  \\\n",
      "0                              1                               1   \n",
      "1                              0                               3   \n",
      "2                              0                               9   \n",
      "3                              0                               2   \n",
      "4                              0                               4   \n",
      "\n",
      "   FpVehicleAgeMonths  EasinessToStage  ClaimWihoutIdentifiedThirdParty  \\\n",
      "0               104.0             0.25                                1   \n",
      "1               230.0             0.50                                1   \n",
      "2                93.0             0.25                                0   \n",
      "3                56.0             0.25                                0   \n",
      "4               110.0             0.25                                0   \n",
      "\n",
      "   ClaimAmount  LossHour  PolicyHolderAge  NumberOfBodilyInjuries  \\\n",
      "0      4624.73       8.0             45.0                       0   \n",
      "1      1606.81      11.0             20.0                       0   \n",
      "2       998.20      18.0             32.0                       0   \n",
      "3      2506.92      11.0             46.0                       0   \n",
      "4        12.00      12.0             28.0                       0   \n",
      "\n",
      "   FirstPartyLiability  LossAndHolderPostCodeSame  Fraud  \n",
      "0                  1.0                          1      0  \n",
      "1                  1.0                          0      0  \n",
      "2                  0.5                          1      0  \n",
      "3                  0.5                          1      0  \n",
      "4                  0.0                          0      0  \n",
      "-----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('The number of NaN values in each column:')\n",
    "df.isna().sum()\n",
    "print('-----------------------------------------------------')\n",
    "\n",
    "print('The shape of final datasets:')\n",
    "print(df.shape)\n",
    "print('-----------------------------------------------------')\n",
    "\n",
    "print(\"Data sample:\")\n",
    "print(df.head(5))\n",
    "print('-----------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Deal with date data\n",
    "We tend to consider the date data as important features. Because we consider that in different time period, people might have different tendency to defraud. And this argument is supported by Pascal Blanque(2002), who asserted that the economic crisis is an important reason for the defraud.\n",
    "\n",
    "However, our date data is datetime format, which cannot be used in machine learning model. In hence, we will convert the date data into timestamp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn the date into timestamp\n",
    "df['LossDate'] = df['LossDate'].apply(lambda x:datetime.datetime.strptime(x,'%d.%M.%y').timestamp())\n",
    "df['FirstPolicySubscriptionDate'] = df['FirstPolicySubscriptionDate'].apply(lambda x:datetime.datetime.strptime(x,'%d.%M.%y').timestamp())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 Get an insight of the distribution of dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the distribution of the numerical data, we can see that there are some diffenece between the fraud and non-fraud cases, especially in the distribution of 'FpVehicleAgeMonths' and 'claimAmount'. In the fraud cases, they usually have a more disperse distribution in 'FpVehicleAgeMonths' and higher value in 'claimAmount'. \n",
    "\n",
    "And in the categorical data, we can find some interesting patterns. For example, in the fraud cases, the percentage of 'TotalLoss' is much higher than the non-fraud cases, which is understandable. And in the fraud cases, the fraud cases tend to be same address between two parties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the datasets that are fraud cases and non-fraud cases\n",
    "df_fraud = df[df['Fraud'] == 1]\n",
    "df_non_fraud = df[df['Fraud'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean of fraud datasets:\n",
      "-----------------------------------------------------\n",
      "LossDate                           1.557971e+09\n",
      "FirstPolicySubscriptionDate        1.546519e+09\n",
      "PolicyWasSubscribedOnInternet      2.857143e-01\n",
      "NumberOfPoliciesOfPolicyholder     1.625000e+00\n",
      "FpVehicleAgeMonths                 1.177143e+02\n",
      "EasinessToStage                    3.464286e-01\n",
      "ClaimWihoutIdentifiedThirdParty    5.625000e-01\n",
      "ClaimAmount                        3.647878e+03\n",
      "LossHour                           1.292857e+01\n",
      "PolicyHolderAge                    4.104464e+01\n",
      "NumberOfBodilyInjuries             3.571429e-02\n",
      "FirstPartyLiability                4.910714e-01\n",
      "LossAndHolderPostCodeSame          6.160714e-01\n",
      "Fraud                              1.000000e+00\n",
      "dtype: float64\n",
      "-----------------------------------------------------\n",
      "The mean of non-fraud datasets:\n",
      "-----------------------------------------------------\n",
      "LossDate                           1.564733e+09\n",
      "FirstPolicySubscriptionDate        1.523620e+09\n",
      "PolicyWasSubscribedOnInternet      2.037481e-01\n",
      "NumberOfPoliciesOfPolicyholder     2.242828e+00\n",
      "FpVehicleAgeMonths                 1.136111e+02\n",
      "EasinessToStage                    3.780842e-01\n",
      "ClaimWihoutIdentifiedThirdParty    6.861178e-01\n",
      "ClaimAmount                        1.383297e+03\n",
      "LossHour                           8.231815e+00\n",
      "PolicyHolderAge                    4.461249e+01\n",
      "NumberOfBodilyInjuries             2.788880e-02\n",
      "FirstPartyLiability                2.040146e-01\n",
      "LossAndHolderPostCodeSame          5.652367e-01\n",
      "Fraud                              0.000000e+00\n",
      "dtype: float64\n",
      "-----------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_63917/1158699191.py:4: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  df_fraud_mean = df_fraud.mean()\n",
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_63917/1158699191.py:10: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  df_non_fraud_mean = df_non_fraud.mean()\n"
     ]
    }
   ],
   "source": [
    "# get the mean of both datasets\n",
    "print('The mean of fraud datasets:')\n",
    "print('-----------------------------------------------------')\n",
    "df_fraud_mean = df_fraud.mean()\n",
    "print(df_fraud_mean)\n",
    "print('-----------------------------------------------------')\n",
    "\n",
    "print('The mean of non-fraud datasets:')\n",
    "print('-----------------------------------------------------')\n",
    "df_non_fraud_mean = df_non_fraud.mean()\n",
    "print(df_non_fraud_mean)\n",
    "print('-----------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The distribution numerical data of fraud datasets:\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x1080 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------\n",
      "The distribution numerical data of non-fraud datasets:\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x1080 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the distribution of fraud datasets\n",
    "print('The distribution numerical data of fraud datasets:')\n",
    "df_fraud.iloc[:,:-1].hist(bins=50, figsize=(20,15),density=True, xlabelsize=10, ylabelsize=10) #TODO add title\n",
    "plt.show()\n",
    "print('-----------------------------------------------------')\n",
    "\n",
    "# plot the distribution of non-fraud datasets\n",
    "print('The distribution numerical data of non-fraud datasets:')\n",
    "df_non_fraud.iloc[:,:-1].hist(bins=50, figsize=(20,15),density=True, xlabelsize=10, ylabelsize=10)\n",
    "plt.show()\n",
    "\n",
    "# TODO show the classification of categorical data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x1440 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABIEAAAJZCAYAAAA+iyW5AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAoeElEQVR4nO3dfZCfZX3v8c/VhBgRIRRSjQQMVAxJYLOSBAMo4VRFzFEeiu0RKRAQUyigZaZTMmOreHSs7ekZbAYk0jOICBI61AcOIp4DllNDQEgwiYQHSWMk4UEglIgghYTr/JGwXZY8bJJfsiHX6zWzw/7u+9p7v5vkj/Xtdd+/UmsNAAAAADu33xnoAQAAAADY9kQgAAAAgAaIQAAAAAANEIEAAAAAGiACAQAAADRABAIAAABogAgEAJCklPKbUsoBAz0HAMC2IgIBAE0ppSwrpfx2XfR55eNttdbdaq1Lt/Cag0opXyylPFpKebaU8tNSyrAOjw4AsFUGD/QAAAAD4CO11ls6eL3PJzkiyeFJHk4yLskLHbw+AMBWsxMIACBJKaWWUt6x7vO9Sin/u5Ty61LK3et2+czZwNftmeTPk3yy1vrLuta9tVYRCADYoYhAAACvdWmS55K8Ncnp6z425JAkq5N8tJTyeCnl56WUc7fDjAAAm8XtYABAi75bSlm97vPbaq0nvHKilDIoyUlJDq61Pp/kvlLKN5IcvYFrjUyyR5J3Jtk/yYFJbi2l/LzW+n+30fwAAJvNTiAAoEUn1FqHrfs4oc+54Vn7f5Qt73VseTbst+v++99rrb+ttS5KMjvJ1I5NCwDQASIQAMCrPZm1t3eN7HVs342sX7Tuv3WbTQQA0AEiEABAL7XWNUm+neSiUsqupZSDkpy2kfX/luTHST5TSnlDKWVMkv+W5MbtMjAAQD+JQAAAr3Ve1j7n5/Ek30xybZL/2Mj6k5O8PcnKJN9P8te11lu39ZAAAJuj1GrnMgDAxpRS/jbJW2utG3uXMACAHZqdQAAAfZRSDiqldJW1DkvyiSTfGei5AAC2hreIBwB4rTdn7S1gb0vyRJL/meR7AzoRAMBWcjsYAAAAQAPcDgYAAADQABEIAAAAoAED9kygvffeu44aNWqgvj0AAADATmf+/PlP1VqHr+/cgEWgUaNGZd68eQP17QEAAAB2OqWUX27onNvBAAAAABogAgEAAAA0QAQCAAAAaIAIBAAAANAAEQgAAACgASIQAAAAQANEIAAAAIAGiEAAAAAADRCBAAAAABogAgEAAAA0QAQCAAAAaIAIBAAAANAAEQgAAACgASIQAAAAQANEIAAAAIAGiEAAAAAADRCBAAAAABogAgEAAAA0QAQCAAAAaIAIBAAAANCATUagUsoVpZQnSin3buB8KaXMLKUsKaUsKqUc2vkxAQAAANga/dkJdGWSYzdy/kNJDlz3MT3JZVs/FgAAAACdtMkIVGv91yRPb2TJ8UmuqmvdmWRYKWVEpwYEAAAAYOt14plA+yRZ3uv1inXHAAAAANhBDO7ANcp6jtX1LixletbeMpb99tuvA9+aZly0x0BPAOyMLlo10BMAOyO/twDbgt9b6IBO7ARakWTfXq9HJnl0fQtrrZfXWifWWicOHz68A98aAAAAgP7oRAS6Iclp694lbHKSVbXWxzpwXQAAAAA6ZJO3g5VSrk1ydJK9SykrknwuyS5JUmudleSmJFOTLEnyfJIzttWwAAAAAGyZTUagWuvJmzhfk5zbsYkAAAAA6LhO3A4GAAAAwA5OBAIAAABogAgEAAAA0AARCAAAAKABIhAAAABAA0QgAAAAgAaIQAAAAAANEIEAAAAAGiACAQAAADRABAIAAABogAgEAAAA0AARCAAAAKABIhAAAABAA0QgAAAAgAaIQAAAAAANEIEAAAAAGiACAQAAADRABAIAAABogAgEAAAA0AARCAAAAKABIhAAAABAA0QgAAAAgAaIQAAAAAANEIEAAAAAGiACAQAAADRABAIAAABogAgEAAAA0AARCAAAAKABIhAAAABAA0QgAAAAgAaIQAAAAAANEIEAAAAAGiACAQAAADRABAIAAABogAgEAAAA0AARCAAAAKABIhAAAABAA0QgAAAAgAaIQAAAAAANEIEAAAAAGiACAQAAADRABAIAAABogAgEAAAA0AARCAAAAKABIhAAAABAA0QgAAAAgAaIQAAAAAANEIEAAAAAGiACAQAAADRABAIAAABogAgEAAAA0AARCAAAAKABIhAAAABAA0QgAAAAgAaIQAAAAAANEIEAAAAAGiACAQAAADRABAIAAABogAgEAAAA0AARCAAAAKABIhAAAABAA0QgAAAAgAaIQAAAAAANEIEAAAAAGiACAQAAADRABAIAAABogAgEAAAA0AARCAAAAKABIhAAAABAA0QgAAAAgAaIQAAAAAANEIEAAAAAGiACAQAAADRABAIAAABogAgEAAAA0AARCAAAAKABIhAAAABAA0QgAAAAgAaIQAAAAAANEIEAAAAAGiACAQAAADRABAIAAABogAgEAAAA0AARCAAAAKABIhAAAABAA0QgAAAAgAaIQAAAAAANEIEAAAAAGiACAQAAADRABAIAAABogAgEAAAA0AARCAAAAKABIhAAAABAA0QgAAAAgAaIQAAAAAAN6FcEKqUcW0p5sJSypJQyYz3n9yil/O9SysJSyuJSyhmdHxUAAACALbXJCFRKGZTk0iQfSjI2ycmllLF9lp2b5L5a6/gkRyf5n6WUIR2eFQAAAIAt1J+dQIclWVJrXVprfTHJ7CTH91lTk7y5lFKS7Jbk6SSrOzopAAAAAFusPxFonyTLe71ese5Yb5ckGZPk0SQ/S/LpWuvLfS9USpleSplXSpn35JNPbuHIAAAAAGyu/kSgsp5jtc/rDyZZkORtSbqTXFJK2f01X1Tr5bXWibXWicOHD9/MUQEAAADYUoP7sWZFkn17vR6ZtTt+ejsjyZdrrTXJklLKL5IclOSujkxJ80a98K2BHgHYCS0b6AEAAGA76s9OoLuTHFhK2X/dw54/luSGPmseTvK+JCmlvCXJ6CRLOzkoAAAAAFtukzuBaq2rSynnJflhkkFJrqi1Li6lnL3u/KwkX0hyZSnlZ1l7+9iFtdantuHcAAAAAGyG/twOllrrTUlu6nNsVq/PH01yTGdHAwAAAKBT+nM7GAAAAACvcyIQAAAAQANEIAAAAIAGiEAAAAAADRCBAAAAABogAgEAAAA0QAQCAAAAaIAIBAAAANAAEQgAAACgASIQAAAAQANEIAAAAIAGiEAAAAAADRCBAAAAABogAgEAAAA0QAQCAAAAaIAIBAAAANAAEQgAAACgASIQAAAAQANEIAAAAIAGiEAAAAAADRCBAAAAABogAgEAAAA0QAQCAAAAaIAIBAAAANAAEQgAAACgASIQAAAAQANEIAAAAIAGiEAAAAAADRCBAAAAABogAgEAAAA0QAQCAAAAaIAIBAAAANAAEQgAAACgASIQAAAAQANEIAAAAIAGiEAAAAAADRCBAAAAABogAgEAAAA0QAQCAAAAaMDggR4AAAB2JqNe+NZAjwDshJYN9ADsFOwEAgAAAGiACAQAAADQABEIAAAAoAEiEAAAAEADRCAAAACABohAAAAAAA0QgQAAAAAaIAIBAAAANEAEAgAAAGiACAQAAADQABEIAAAAoAEiEAAAAEADRCAAAACABohAAAAAAA0QgQAAAAAaIAIBAAAANEAEAgAAAGiACAQAAADQABEIAAAAoAEiEAAAAEADRCAAAACABohAAAAAAA0QgQAAAAAaIAIBAAAANEAEAgAAAGiACAQAAADQABEIAAAAoAEiEAAAAEADRCAAAACABohAAAAAAA0QgQAAAAAaIAIBAAAANEAEAgAAAGiACAQAAADQABEIAAAAoAEiEAAAAEADRCAAAACABohAAAAAAA0QgQAAAAAaIAIBAAAANEAEAgAAAGiACAQAAADQABEIAAAAoAEiEAAAAEADRCAAAACABohAAAAAAA0QgQAAAAAaIAIBAAAANEAEAgAAAGiACAQAAADQABEIAAAAoAEiEAAAAEADRCAAAACABohAAAAAAA3oVwQqpRxbSnmwlLKklDJjA2uOLqUsKKUsLqX8v86OCQAAAMDWGLypBaWUQUkuTfKBJCuS3F1KuaHWel+vNcOSfDXJsbXWh0spv7eN5gUAAABgC/RnJ9BhSZbUWpfWWl9MMjvJ8X3WfDzJt2utDydJrfWJzo4JAAAAwNboTwTaJ8nyXq9XrDvW2zuT7FlKua2UMr+UclqnBgQAAABg623ydrAkZT3H6nquMyHJ+5K8MckdpZQ7a60/f9WFSpmeZHqS7Lfffps/LQAAAABbpD87gVYk2bfX65FJHl3Pmptrrc/VWp9K8q9Jxve9UK318lrrxFrrxOHDh2/pzAAAAABspv5EoLuTHFhK2b+UMiTJx5Lc0GfN95K8t5QyuJSya5J3J7m/s6MCAAAAsKU2eTtYrXV1KeW8JD9MMijJFbXWxaWUs9edn1Vrvb+UcnOSRUleTvK/aq33bsvBAQAAAOi//jwTKLXWm5Lc1OfYrD6v/0eS/9G50QAAAADolP7cDgYAAADA65wIBAAAANAAEQgAAACgASIQAAAAQANEIAAAAIAGiEAAAAAADRCBAAAAABogAgEAAAA0QAQCAAAAaIAIBAAAANAAEQgAAACgASIQAAAAQANEIAAAAIAGiEAAAAAADRCBAAAAABogAgEAAAA0QAQCAAAAaIAIBAAAANAAEQgAAACgASIQAAAAQANEIAAAAIAGiEAAAAAADRCBAAAAABogAgEAAAA0QAQCAAAAaIAIBAAAANAAEQgAAACgASIQAAAAQANEIAAAAIAGiEAAAAAADRCBAAAAABogAgEAAAA0QAQCAAAAaIAIBAAAANAAEQgAAACgASIQAAAAQANEIAAAAIAGiEAAAAAADRCBAAAAABogAgEAAAA0QAQCAAAAaIAIBAAAANAAEQgAAACgASIQAAAAQANEIAAAAIAGiEAAAAAADRCBAAAAABogAgEAAAA0QAQCAAAAaIAIBAAAANAAEQgAAACgASIQAAAAQANEIAAAAIAGiEAAAAAADRCBAAAAABogAgEAAAA0QAQCAAAAaIAIBAAAANAAEQgAAACgASIQAAAAQANEIAAAAIAGiEAAAAAADRCBAAAAABogAgEAAAA0QAQCAAAAaIAIBAAAANAAEQgAAACgASIQAAAAQANEIAAAAIAGiEAAAAAADRCBAAAAABogAgEAAAA0QAQCAAAAaIAIBAAAANAAEQgAAACgASIQAAAAQANEIAAAAIAGiEAAAAAADRCBAAAAABogAgEAAAA0QAQCAAAAaIAIBAAAANAAEQgAAACgASIQAAAAQANEIAAAAIAGiEAAAAAADRCBAAAAABogAgEAAAA0QAQCAAAAaIAIBAAAANAAEQgAAACgASIQAAAAQANEIAAAAIAGiEAAAAAADRCBAAAAABrQrwhUSjm2lPJgKWVJKWXGRtZNKqWsKaV8tHMjAgAAALC1NhmBSimDklya5ENJxiY5uZQydgPr/jbJDzs9JAAAAABbpz87gQ5LsqTWurTW+mKS2UmOX8+685P8c5InOjgfAAAAAB3Qnwi0T5LlvV6vWHesRyllnyQnJpm1sQuVUqaXUuaVUuY9+eSTmzsrAAAAAFuoPxGorOdY7fP6K0kurLWu2diFaq2X11on1lonDh8+vJ8jAgAAALC1BvdjzYok+/Z6PTLJo33WTEwyu5SSJHsnmVpKWV1r/W4nhgQAAABg6/QnAt2d5MBSyv5JHknysSQf772g1rr/K5+XUq5McqMABAAAALDj2GQEqrWuLqWcl7Xv+jUoyRW11sWllLPXnd/oc4AAAAAAGHj92QmUWutNSW7qc2y98afWOm3rxwIAAACgk/rzYGgAAAAAXudEIAAAAIAGiEAAAAAADRCBAAAAABogAgEAAAA0QAQCAAAAaIAIBAAAANAAEQgAAACgASIQAAAAQANEIAAAAIAGiEAAAAAADRCBAAAAABogAgEAAAA0QAQCAAAAaIAIBAAAANAAEQgAAACgASIQAAAAQANEIAAAAIAGiEAAAAAADRCBAAAAABogAgEAAAA0QAQCAAAAaIAIBAAAANAAEQgAAACgASIQAAAAQANEIAAAAIAGiEAAAAAADRCBAAAAABogAgEAAAA0QAQCAAAAaIAIBAAAANAAEQgAAACgASIQAAAAQANEIAAAAIAGiEAAAAAADRCBAAAAABogAgEAAAA0QAQCAAAAaIAIBAAAANAAEQgAAACgASIQAAAAQANEIAAAAIAGiEAAAAAADRCBAAAAABogAgEAAAA0QAQCAAAAaIAIBAAAANAAEQgAAACgASIQAAAAQANEIAAAAIAGiEAAAAAADRCBAAAAABogAgEAAAA0QAQCAAAAaIAIBAAAANAAEQgAAACgASIQAAAAQANEIAAAAIAGiEAAAAAADRCBAAAAABogAgEAAAA0QAQCAAAAaIAIBAAAANAAEQgAAACgASIQAAAAQANEIAAAAIAGiEAAAAAADRCBAAAAABogAgEAAAA0QAQCAAAAaIAIBAAAANAAEQgAAACgASIQAAAAQANEIAAAAIAGiEAAAAAADRCBAAAAABogAgEAAAA0QAQCAAAAaIAIBAAAANAAEQgAAACgASIQAAAAQANEIAAAAIAGiEAAAAAADRCBAAAAABogAgEAAAA0QAQCAAAAaIAIBAAAANAAEQgAAACgASIQAAAAQANEIAAAAIAGiEAAAAAADRCBAAAAABogAgEAAAA0QAQCAAAAaEC/IlAp5dhSyoOllCWllBnrOX9KKWXRuo+5pZTxnR8VAAAAgC21yQhUShmU5NIkH0oyNsnJpZSxfZb9IsmUWmtXki8kubzTgwIAAACw5fqzE+iwJEtqrUtrrS8mmZ3k+N4Laq1za63/vu7lnUlGdnZMAAAAALZGfyLQPkmW93q9Yt2xDflEkh9szVAAAAAAdNbgfqwp6zlW17uwlP+StRHoPRs4Pz3J9CTZb7/9+jkiAAAAAFurPzuBViTZt9frkUke7buolNKV5H8lOb7WunJ9F6q1Xl5rnVhrnTh8+PAtmRcAAACALdCfCHR3kgNLKfuXUoYk+ViSG3ovKKXsl+TbSU6ttf6882MCAAAAsDU2eTtYrXV1KeW8JD9MMijJFbXWxaWUs9edn5Xks0n2SvLVUkqSrK61Ttx2YwMAAACwOfrzTKDUWm9KclOfY7N6fX5WkrM6OxoAAAAAndKf28EAAAAAeJ0TgQAAAAAaIAIBAAAANEAEAgAAAGiACAQAAADQABEIAAAAoAEiEAAAAEADRCAAAACABohAAAAAAA0QgQAAAAAaIAIBAAAANEAEAgAAAGiACAQAAADQABEIAAAAoAEiEAAAAEADRCAAAACABohAAAAAAA0QgQAAAAAaIAIBAAAANEAEAgAAAGiACAQAAADQABEIAAAAoAEiEAAAAEADRCAAAACABohAAAAAAA0QgQAAAAAaIAIBAAAANEAEAgAAAGiACAQAAADQABEIAAAAoAEiEAAAAEADRCAAAACABohAAAAAAA0QgQAAAAAaIAIBAAAANEAEAgAAAGiACAQAAADQABEIAAAAoAEiEAAAAEADRCAAAACABohAAAAAAA0QgQAAAAAaIAIBAAAANEAEAgAAAGiACAQAAADQgMEDPQAAsG289NJLWbFiRV544YWBHgWSJEOHDs3IkSOzyy67DPQoANAkEQgAdlIrVqzIm9/85owaNSqllIEeh8bVWrNy5cqsWLEi+++//0CPAwBNcjsYAOykXnjhhey1114CEDuEUkr22msvO9MAYACJQACwExOA2JH49wgAA0sEAgAAAGiACAQADRk0aFC6u7tz8MEH54/+6I/y/PPPb3DtlVdemfPOOy9JMmvWrFx11VWb/f3e9a53ZcGCBUmS1atX501velOuvvrqnvMTJkzIPffcs1nXvPPOO/Pud7873d3dGTNmTC666KKNrl+2bFkOPvjgzR19k6ZOnZpnnnlmq6/f9+vnzJmTww47LAcddFAOOuigXH755Zt9jQ350pe+tMVzbo7bbrstc+fO3S7fCwDoPxEIABryxje+MQsWLMi9996bIUOGZNasWf36urPPPjunnXbaZn+/I444oicGLFy4MKNHj+55/dxzz2Xp0qUZP378Zl3z9NNPz+WXX97zc/zxH//xZs+1NWqtefnll3PTTTdl2LBhHb32448/no9//OOZNWtWHnjggcyZMydf+9rX8v3vf78j19+SCLRmzZrN/hoRCAB2TCIQADTqve99b5YsWZKnn346J5xwQrq6ujJ58uQsWrToNWsvuuii/P3f/32SZMmSJXn/+9+f8ePH59BDD82//du/5dRTT833vve9nvWnnHJKbrjhhhx55JE9MWDu3Lk5++yze3YG3XXXXTn00EMzaNCgnHDCCZkwYULGjRvXs/NlzZo1mTZtWg4++OAccsghufjii5MkTzzxREaMGJFk7c6msWPHvmbGJDn44IOzbNmyJGt3IZ1++unp6urKRz/60Z4dUDNmzMjYsWPT1dWVv/iLv0iS/OpXv8qJJ56Y8ePHZ/z48Zk7d26WLVuWMWPG5M/+7M9y6KGHZvny5Rk1alSeeuqpjV5//vz5mTJlSiZMmJAPfvCDeeyxx3qOjx8/PocffnguvfTSnpkvvfTSTJs2LYceemiSZO+9987f/d3f5ctf/nKSZNq0afnUpz6VI444IgcccECuv/761/xdXXnllfnDP/zDHHvssTnwwAPzl3/5lz0/629/+9t0d3fnlFNOSZJcffXVOeyww9Ld3Z0//dM/7Qk+u+22Wz772c/m3e9+d+64447stttu+cxnPpPx48dn8uTJ+dWvfpUkefLJJ3PSSSdl0qRJmTRpUm6//fYsW7Yss2bNysUXX5zu7u78+Mc/Xt8/PwBgAIhAANCg1atX5wc/+EEOOeSQfO5zn8u73vWuLFq0KF/60pc2uePnlFNOybnnnpuFCxdm7ty5GTFiRM4666x8/etfT5KsWrUqc+fOzdSpU1+1E2ju3Lk56qij8oY3vCHPPvts5s6dmyOPPDJJcsUVV2T+/PmZN29eZs6cmZUrV2bBggV55JFHcu+99+ZnP/tZzjjjjCTJBRdckNGjR+fEE0/M1772tX6929SDDz6Y6dOnZ9GiRdl9993z1a9+NU8//XS+853vZPHixVm0aFH+6q/+KknyqU99KlOmTMnChQtzzz33ZNy4cT3XOO200/LTn/40b3/72zd5/Zdeeinnn39+rr/++syfPz9nnnlmPvOZzyRJzjjjjMycOTN33HHHq66zePHiTJgw4VXHJk6cmMWLF/e8fuyxxzJnzpzceOONmTFjxnp/3gULFuS6667Lz372s1x33XVZvnx5vvzlL/fsBLvmmmty//3357rrrsvtt9+eBQsWZNCgQbnmmmuSrN2ldfDBB+cnP/lJ3vOe9+S5557L5MmTs3Dhwhx11FH5x3/8xyTJpz/96VxwwQW5++6788///M8566yzMmrUqJx99tm54IILsmDBgrz3ve/d5N8PALB9iEAA0JBXdoJMnDgx++23Xz7xiU9kzpw5OfXUU5Mkf/AHf5CVK1dm1apV6/36Z599No888khOPPHEJMnQoUOz6667ZsqUKVmyZEmeeOKJXHvttTnppJMyePDgjBo1Ki+++GIef/zxPPDAAxk9enQmTZqUn/zkJ5k7d26OOOKIJMnMmTN7dpksX748Dz30UA444IAsXbo0559/fm6++ebsvvvuSZLPfvazmTdvXo455ph861vfyrHHHrvJn3vfffftCU5/8id/kjlz5mT33XfP0KFDc9ZZZ+Xb3/52dt111yTJj370o5xzzjlJ1u402mOPPZIkb3/72zN58uR+X//BBx/Mvffemw984APp7u7OF7/4xaxYsSKrVq3KM888kylTpiRJz599svZWs/W9g1bvYyeccEJ+53d+J2PHju3ZkdPX+973vuyxxx4ZOnRoxo4dm1/+8pevWXPrrbdm/vz5mTRpUrq7u3Prrbdm6dKlPT/3SSed1LN2yJAh+fCHP5xk7XOcXtlhdcstt+S8885Ld3d3jjvuuPz617/Os88+u96ZAICBN3igBwAAtp9XdoL0Vmt9zboNvZX3+ta+4tRTT80111yT2bNn54orrug5fvjhh+f666/PiBEjUkrJ5MmTc/vtt+euu+7K5MmTc9ttt+WWW27JHXfckV133TVHH310Xnjhhey5555ZuHBhfvjDH+bSSy/NP/3TP/Vc9/d///dzzjnn5JOf/GSGDx+elStXZvDgwXn55Zd7vm/vHUJ9f55SSgYPHpy77rort956a2bPnp1LLrkkP/rRjzb4873pTW/a4Ln1Xb/WmnHjxr1mt88zzzyzwT/fcePGZd68eTnuuON6js2fP7/nlrckecMb3tDz+Yb+PnqvGTRoUFavXv2aNbXWnH766fmbv/mb15wbOnRoBg0a1PN6l1126Zm59/Vefvnl3HHHHXnjG9+43jkAgB2LnUAA0Lijjjqq5zag2267LXvvvXfPrpu+dt9994wcOTLf/e53kyT/8R//0fP8m2nTpuUrX/lKkvTcQpUkRx55ZC6++OIcfvjhSdZGoauuuipvfetbM2zYsKxatSp77rlndt111zzwwAO58847kyRPPfVUXn755Zx00kn5whe+0PMuYt///vd74sdDDz2UQYMGZdiwYRk1alTPmnvuuSe/+MUvemZ4+OGHe2LMtddem/e85z35zW9+k1WrVmXq1Kn5yle+0hPH3ve+9+Wyyy5Lsva5RL/+9a83+We4vuuPHj06Tz75ZM/xl156KYsXL86wYcOyxx57ZM6cOUnS82efJOeee26uvPLKnllWrlyZCy+8sOe5Pltrl112yUsvvdTzc15//fV54oknkiRPP/30encMbcwxxxyTSy65pOf1K3O/+c1vtiMIAHZAIhAANO6iiy7KvHnz0tXVlRkzZuQb3/jGRtd/85vfzMyZM9PV1ZUjjjgijz/+eJLkLW95S8aMGdPz7J5XHHnkkVm6dGlPBBoxYkTWrFnTcyvYsccem9WrV6erqyt//dd/3XPL1SOPPJKjjz463d3dmTZtWs+OlW9+85sZPXp0uru7e3YfvXL70tNPP53u7u5cdtlleec739kzw5gxY/KNb3wjXV1defrpp3POOefk2WefzYc//OF0dXVlypQpPQ+e/od/+If8y7/8Sw455JBMmDDhVc/j2ZD1XX/IkCG5/vrrc+GFF2b8+PHp7u7ueT7S17/+9Zx77rk5/PDDX7WLZsSIEbn66qvzyU9+MgcddFCOOOKInHnmmfnIRz6yyRn6Y/r06enq6sopp5ySsWPH5otf/GKOOeaYdHV15QMf+EDPg6v7a+bMmT3/dsaOHdvzbnMf+chH8p3vfMeDoQFgB1M2tq17W5o4cWKdN2/egHxvXn9GzejMW+MC9Lbsy/91oEfYpu6///6MGTNmu32/559/PoccckjuueeenufoQF/b+9/lQPB7C7At7Oy/t9A5pZT5tdaJ6ztnJxAAsNVuueWWHHTQQTn//PMFIACAHZQHQwMAW+39739/Hn744YEeAwCAjbATCAAAAKABIhAAAABAA0QgAAAAgAaIQAAAAAAN8GBoAGCn1um36+7vW/TefPPN+fSnP501a9bkrLPOyowZMzo6BwDA5rITCACgw9asWZNzzz03P/jBD3Lffffl2muvzX333TfQYwEAjROBAAA67K677so73vGOHHDAARkyZEg+9rGP5Xvf+95AjwUANE4EAgDosEceeST77rtvz+uRI0fmkUceGcCJAABEIACAjqu1vuZYKWUAJgEA+E8iEABAh40cOTLLly/veb1ixYq87W1vG8CJAABEIACAjps0aVIeeuih/OIXv8iLL76Y2bNn57jjjhvosQCAxnmLeABgp9bft3TvpMGDB+eSSy7JBz/4waxZsyZnnnlmxo0bt93nAADoTQQCANgGpk6dmqlTpw70GAAAPdwOBgAAANAAEQgAAACgASIQAAAAQANEIAAAAIAGiEAAAAAADRCBAAAAABrgLeIBgJ3bRXt0+HqrNrnkzDPPzI033pjf+73fy7333tvZ7w8AsIXsBAIA6LBp06bl5ptvHugxAABeRQQCAOiwo446Kr/7u7870GMAALyKCAQAAADQABEIAAAAoAEiEAAAAEADRCAAAACABniLeABg59aPt3TvtJNPPjm33XZbnnrqqYwcOTKf//zn84lPfGK7zwEA0JsIBADQYddee+1AjwAA8BpuBwMAAABogAgEAAAA0AARCAB2YrXWgR4Bevj3CAADSwQCgJ3U0KFDs3LlSv/Dmx1CrTUrV67M0KFDB3oUAGiWB0MDwE5q5MiRWbFiRZ588smBHgWSrA2TI0eOHOgxAKBZIhAA7KR22WWX7L///gM9BgAAO4h+3Q5WSjm2lPJgKWVJKWXGes6XUsrMdecXlVIO7fyoAAAAAGypTUagUsqgJJcm+VCSsUlOLqWM7bPsQ0kOXPcxPcllHZ4TAAAAgK3Qn51AhyVZUmtdWmt9McnsJMf3WXN8kqvqWncmGVZKGdHhWQEAAADYQv15JtA+SZb3er0iybv7sWafJI/1XlRKmZ61O4WS5DellAc3a1qATds7yVMDPQSvD+VvB3oCABrn9xb6ze8tbIa3b+hEfyJQWc+xvu812581qbVenuTyfnxPgC1SSplXa5040HMAAGyK31uA7a0/t4OtSLJvr9cjkzy6BWsAAAAAGCD9iUB3JzmwlLJ/KWVIko8luaHPmhuSnLbuXcImJ1lVa32s74UAAAAAGBibvB2s1rq6lHJekh8mGZTkilrr4lLK2evOz0pyU5KpSZYkeT7JGdtuZICNcsspAPB64fcWYLsqtb7m0T0AAAAA7GT6czsYAAAAAK9zIhAAAABAA0QgAAAAgAZs8sHQADuyUspBSY5Psk+SmuTRJDfUWu8f0MEAAAB2MHYCAa9bpZQLk8xOUpLcleTudZ9fW0qZMZCzAQD0VynFuysD24V3BwNet0opP08yrtb6Up/jQ5IsrrUeODCTAQD0Xynl4VrrfgM9B7DzczsY8Hr2cpK3Jflln+Mj1p0DANghlFIWbehUkrdsz1mAdolAwOvZnye5tZTyUJLl647tl+QdSc4bqKEAANbjLUk+mOTf+xwvSeZu/3GAFolAwOtWrfXmUso7kxyWtQ+GLklWJLm71rpmQIcDAHi1G5PsVmtd0PdEKeW27T4N0CTPBAIAAABogHcHAwAAAGiACAQAAADQABEIAGhKKWVNKWVBr49R2+B7LCul7N3p6wIAbA0PhgYAWvPbWmv3+k6UUkrWPjPx5e07EgDAtmcnEADQtFLKqFLK/aWUrya5J8m+pZTLSinzSimLSymf77W2Z4dPKWXiK+/oU0rZq5Tyf0opPy2lfC1r360QAGCHIgIBAK15Y69bwb6z7tjoJFfVWt9Va/1lks/UWicm6UoypZTStYlrfi7JnFrru5LckGS/bTY9AMAWcjsYANCaV90Otu6ZQL+std7Za80fl1KmZ+3vSiOSjE2yaCPXPCrJHyZJrfX7pZR/7/TQAABbSwQCAEiee+WTUsr+Sf4iyaRa67+XUq5MMnTd6dX5z53UQ/NqdVsPCQCwNdwOBgDwartnbRRaVUp5S5IP9Tq3LMmEdZ+f1Ov4vyY5JUlKKR9Ksue2HxMAYPOIQAAAvdRaFyb5aZLFSa5Icnuv059P8g+llB8nWdPn+FGllHuSHJPk4e00LgBAv5Va7VwGAAAA2NnZCQQAAADQABEIAAAAoAEiEAAAAEADRCAAAACABohAAAAAAA0QgQAAAAAaIAIBAAAANEAEAgAAAGjA/wc3HtwA552HtwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dummy_columns = ['PolicyholderOccupation', 'ClaimCause', 'DamageImportance', 'FirstPartyVehicleType','ConnectionBetweenParties', 'PolicyWasSubscribedOnInternet']\n",
    "\n",
    "fig = plt.figure(figsize=(20,20))\n",
    "\n",
    "names = locals()\n",
    "for i, col in enumerate(dummy_columns):\n",
    "    names[f\"ax_{i}\"] = df.groupby(['Fraud'])[col].value_counts(normalize=True).unstack().plot(kind='bar', stacked=True, figsize=(20,10),title=f\"Fig {i+1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7 Clean features\n",
    "1. deal with outliers \n",
    "    The presence of outliers in the data is a major problem for machine learning algorithms (Chakravarty, et al., 2020). \n",
    "    TODO: deal with outliers, or at the end to illustrate the lackness of the research\n",
    "   \n",
    "     \n",
    "2. dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LossDate</th>\n",
       "      <th>FirstPolicySubscriptionDate</th>\n",
       "      <th>ClaimInvolvedCovers</th>\n",
       "      <th>NumberOfPoliciesOfPolicyholder</th>\n",
       "      <th>FpVehicleAgeMonths</th>\n",
       "      <th>EasinessToStage</th>\n",
       "      <th>ClaimWihoutIdentifiedThirdParty</th>\n",
       "      <th>ClaimAmount</th>\n",
       "      <th>LossHour</th>\n",
       "      <th>PolicyHolderAge</th>\n",
       "      <th>...</th>\n",
       "      <th>DamageImportance_TotalLoss</th>\n",
       "      <th>FirstPartyVehicleType_Caravan</th>\n",
       "      <th>FirstPartyVehicleType_Motorcycle</th>\n",
       "      <th>FirstPartyVehicleType_PrivateCar</th>\n",
       "      <th>ConnectionBetweenParties_SameAddress</th>\n",
       "      <th>ConnectionBetweenParties_SameBankAccount</th>\n",
       "      <th>ConnectionBetweenParties_SameEmail</th>\n",
       "      <th>ConnectionBetweenParties_SamePhone</th>\n",
       "      <th>ConnectionBetweenParties_SamePolice</th>\n",
       "      <th>PolicyWasSubscribedOnInternet_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.546387e+09</td>\n",
       "      <td>1.516234e+09</td>\n",
       "      <td>MaterialDamages ActLiability</td>\n",
       "      <td>1</td>\n",
       "      <td>104.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>4624.73</td>\n",
       "      <td>8.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.546387e+09</td>\n",
       "      <td>1.485648e+09</td>\n",
       "      <td>MaterialDamages ActLiability</td>\n",
       "      <td>3</td>\n",
       "      <td>230.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1</td>\n",
       "      <td>1606.81</td>\n",
       "      <td>11.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.546387e+09</td>\n",
       "      <td>1.483575e+09</td>\n",
       "      <td>MaterialDamages ActLiability</td>\n",
       "      <td>9</td>\n",
       "      <td>93.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0</td>\n",
       "      <td>998.20</td>\n",
       "      <td>18.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.546387e+09</td>\n",
       "      <td>1.484957e+09</td>\n",
       "      <td>MaterialDamages ActLiability ReplacementVehicle</td>\n",
       "      <td>2</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0</td>\n",
       "      <td>2506.92</td>\n",
       "      <td>11.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.546387e+09</td>\n",
       "      <td>1.515802e+09</td>\n",
       "      <td>ActLiability</td>\n",
       "      <td>4</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0</td>\n",
       "      <td>12.00</td>\n",
       "      <td>12.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11525</th>\n",
       "      <td>1.610842e+09</td>\n",
       "      <td>1.547511e+09</td>\n",
       "      <td>Windscreen</td>\n",
       "      <td>1</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1</td>\n",
       "      <td>1010.23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11526</th>\n",
       "      <td>1.609978e+09</td>\n",
       "      <td>1.484871e+09</td>\n",
       "      <td>Windscreen</td>\n",
       "      <td>3</td>\n",
       "      <td>119.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1</td>\n",
       "      <td>154.35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11527</th>\n",
       "      <td>1.610669e+09</td>\n",
       "      <td>1.580343e+09</td>\n",
       "      <td>Windscreen</td>\n",
       "      <td>4</td>\n",
       "      <td>139.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1</td>\n",
       "      <td>420.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11528</th>\n",
       "      <td>1.609891e+09</td>\n",
       "      <td>1.517098e+09</td>\n",
       "      <td>Windscreen</td>\n",
       "      <td>6</td>\n",
       "      <td>105.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1</td>\n",
       "      <td>96.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11529</th>\n",
       "      <td>1.610496e+09</td>\n",
       "      <td>1.483229e+09</td>\n",
       "      <td>Windscreen</td>\n",
       "      <td>2</td>\n",
       "      <td>124.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1</td>\n",
       "      <td>223.60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11371 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           LossDate  FirstPolicySubscriptionDate  \\\n",
       "0      1.546387e+09                 1.516234e+09   \n",
       "1      1.546387e+09                 1.485648e+09   \n",
       "2      1.546387e+09                 1.483575e+09   \n",
       "3      1.546387e+09                 1.484957e+09   \n",
       "4      1.546387e+09                 1.515802e+09   \n",
       "...             ...                          ...   \n",
       "11525  1.610842e+09                 1.547511e+09   \n",
       "11526  1.609978e+09                 1.484871e+09   \n",
       "11527  1.610669e+09                 1.580343e+09   \n",
       "11528  1.609891e+09                 1.517098e+09   \n",
       "11529  1.610496e+09                 1.483229e+09   \n",
       "\n",
       "                                   ClaimInvolvedCovers  \\\n",
       "0                         MaterialDamages ActLiability   \n",
       "1                         MaterialDamages ActLiability   \n",
       "2                         MaterialDamages ActLiability   \n",
       "3      MaterialDamages ActLiability ReplacementVehicle   \n",
       "4                                         ActLiability   \n",
       "...                                                ...   \n",
       "11525                                       Windscreen   \n",
       "11526                                       Windscreen   \n",
       "11527                                       Windscreen   \n",
       "11528                                       Windscreen   \n",
       "11529                                       Windscreen   \n",
       "\n",
       "       NumberOfPoliciesOfPolicyholder  FpVehicleAgeMonths  EasinessToStage  \\\n",
       "0                                   1               104.0             0.25   \n",
       "1                                   3               230.0             0.50   \n",
       "2                                   9                93.0             0.25   \n",
       "3                                   2                56.0             0.25   \n",
       "4                                   4               110.0             0.25   \n",
       "...                               ...                 ...              ...   \n",
       "11525                               1                85.0             0.50   \n",
       "11526                               3               119.0             0.50   \n",
       "11527                               4               139.0             0.50   \n",
       "11528                               6               105.0             0.50   \n",
       "11529                               2               124.0             0.50   \n",
       "\n",
       "       ClaimWihoutIdentifiedThirdParty  ClaimAmount  LossHour  \\\n",
       "0                                    1      4624.73       8.0   \n",
       "1                                    1      1606.81      11.0   \n",
       "2                                    0       998.20      18.0   \n",
       "3                                    0      2506.92      11.0   \n",
       "4                                    0        12.00      12.0   \n",
       "...                                ...          ...       ...   \n",
       "11525                                1      1010.23       0.0   \n",
       "11526                                1       154.35       0.0   \n",
       "11527                                1       420.25       0.0   \n",
       "11528                                1        96.40       0.0   \n",
       "11529                                1       223.60       0.0   \n",
       "\n",
       "       PolicyHolderAge  ...  DamageImportance_TotalLoss  \\\n",
       "0                 45.0  ...                           0   \n",
       "1                 20.0  ...                           0   \n",
       "2                 32.0  ...                           0   \n",
       "3                 46.0  ...                           0   \n",
       "4                 28.0  ...                           0   \n",
       "...                ...  ...                         ...   \n",
       "11525             56.0  ...                           0   \n",
       "11526             54.0  ...                           0   \n",
       "11527             34.0  ...                           0   \n",
       "11528             58.0  ...                           0   \n",
       "11529             55.0  ...                           0   \n",
       "\n",
       "       FirstPartyVehicleType_Caravan  FirstPartyVehicleType_Motorcycle  \\\n",
       "0                                  0                                 0   \n",
       "1                                  0                                 0   \n",
       "2                                  0                                 0   \n",
       "3                                  0                                 0   \n",
       "4                                  0                                 0   \n",
       "...                              ...                               ...   \n",
       "11525                              0                                 0   \n",
       "11526                              0                                 0   \n",
       "11527                              0                                 0   \n",
       "11528                              0                                 0   \n",
       "11529                              0                                 0   \n",
       "\n",
       "       FirstPartyVehicleType_PrivateCar  ConnectionBetweenParties_SameAddress  \\\n",
       "0                                     0                                     0   \n",
       "1                                     0                                     0   \n",
       "2                                     0                                     0   \n",
       "3                                     0                                     0   \n",
       "4                                     0                                     0   \n",
       "...                                 ...                                   ...   \n",
       "11525                                 0                                     0   \n",
       "11526                                 0                                     0   \n",
       "11527                                 0                                     0   \n",
       "11528                                 0                                     0   \n",
       "11529                                 0                                     0   \n",
       "\n",
       "       ConnectionBetweenParties_SameBankAccount  \\\n",
       "0                                             0   \n",
       "1                                             0   \n",
       "2                                             0   \n",
       "3                                             0   \n",
       "4                                             0   \n",
       "...                                         ...   \n",
       "11525                                         0   \n",
       "11526                                         0   \n",
       "11527                                         0   \n",
       "11528                                         0   \n",
       "11529                                         0   \n",
       "\n",
       "       ConnectionBetweenParties_SameEmail  ConnectionBetweenParties_SamePhone  \\\n",
       "0                                       0                                   0   \n",
       "1                                       0                                   0   \n",
       "2                                       0                                   0   \n",
       "3                                       0                                   0   \n",
       "4                                       0                                   0   \n",
       "...                                   ...                                 ...   \n",
       "11525                                   0                                   0   \n",
       "11526                                   0                                   0   \n",
       "11527                                   0                                   0   \n",
       "11528                                   0                                   0   \n",
       "11529                                   0                                   0   \n",
       "\n",
       "       ConnectionBetweenParties_SamePolice  PolicyWasSubscribedOnInternet_1  \n",
       "0                                        0                                1  \n",
       "1                                        0                                0  \n",
       "2                                        0                                0  \n",
       "3                                        0                                0  \n",
       "4                                        0                                0  \n",
       "...                                    ...                              ...  \n",
       "11525                                    0                                0  \n",
       "11526                                    0                                0  \n",
       "11527                                    0                                0  \n",
       "11528                                    0                                0  \n",
       "11529                                    0                                0  \n",
       "\n",
       "[11371 rows x 54 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get dummy variables for categorical data\n",
    "dummy_columns = ['PolicyholderOccupation', 'ClaimCause', 'DamageImportance', 'FirstPartyVehicleType','ConnectionBetweenParties', 'PolicyWasSubscribedOnInternet']\n",
    "# Dummy variables for categorical data\n",
    "df = pd.get_dummies(df,columns=dummy_columns,drop_first=True)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ReplacementVehicle', 'ActLiability', 'MaterialDamages', 'Theft', 'Burglary', 'Accessories', 'MedicalCare', 'NaN', 'Fire', 'NaturalCatastrophes', 'ThirdPartyMaterialDamages', 'Windscreen', 'ThirdParty'}\n"
     ]
    }
   ],
   "source": [
    "# Extract ClaimInvolvedCovers data\n",
    "# Get all covers\n",
    "all_unique =  df[\"ClaimInvolvedCovers\"].unique().tolist()\n",
    "all_covers = str.join(' ', all_unique) # join the string to list\n",
    "all_covers_set = set(all_covers.split()) # use set to drop duplicate covers\n",
    "print(all_covers_set)\n",
    "\n",
    "for cover in all_covers_set:\n",
    "    df[f\"ClaimInvolvedCovers_{cover}\"] = df[\"ClaimInvolvedCovers\"].apply(lambda x: 1 if cover in x else 0)\n",
    "df = df.drop(columns=['ClaimInvolvedCovers'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.8 Split the data and scale\n",
    "We are going to use MinMaxScaler in this case, since we can find the dataset not follow a Gaussian distribution. In addition, we will fit the MinMaxScaler model with trainning and validation dataset and apply the model to the test dataset to ensure we are blind to the data information before we test the data.\n",
    "Here is the process of split and scale data:\n",
    "1. Turn the dataframe into X and y array\n",
    "1. Split the train and test\n",
    "2. Fit the MinMaxScaler to train data and then apply the model to test data\n",
    "3. Split the train data into train and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of X:\n",
      "(11371, 65)\n",
      "-----------------------------------------------------\n",
      "The shape of y:\n",
      "(11371,)\n",
      "-----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Turn the dataframe into X and y array\n",
    "X = df.drop(['Fraud'],axis=1,inplace=False).to_numpy()\n",
    "y = df[['Fraud']].to_numpy().flatten()\n",
    "print('The shape of X:')\n",
    "print(X.shape)\n",
    "print('-----------------------------------------------------')\n",
    "print('The shape of y:')\n",
    "print(y.shape)\n",
    "print('-----------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the train and test datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=192,test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the train datasets into train and validation datasets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train,y_train,random_state=192,test_size=0.25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------\n",
      "Shape of X_train:\n",
      "(6822, 65)\n",
      "-----------------------------------------------------\n",
      "Shape of y_train:\n",
      "(6822,)\n",
      "-----------------------------------------------------\n",
      "Shape of X_val:\n",
      "(2274, 65)\n",
      "-----------------------------------------------------\n",
      "Shape of y_val:\n",
      "(2274,)\n",
      "-----------------------------------------------------\n",
      "Shape of X_test:\n",
      "(2275, 65)\n",
      "-----------------------------------------------------\n",
      "Shape of y_test:\n",
      "(2275,)\n",
      "-----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "## 2.9 Show the data structure of the data\n",
    "print('-----------------------------------------------------')\n",
    "print('Shape of X_train:')\n",
    "print(X_train.shape)\n",
    "print('-----------------------------------------------------')\n",
    "print('Shape of y_train:')\n",
    "print(y_train.shape)\n",
    "print('-----------------------------------------------------')\n",
    "print('Shape of X_val:')\n",
    "print(X_val.shape)\n",
    "print('-----------------------------------------------------')\n",
    "print('Shape of y_val:')\n",
    "print(y_val.shape)\n",
    "print('-----------------------------------------------------')\n",
    "print('Shape of X_test:')\n",
    "print(X_test.shape)\n",
    "print('-----------------------------------------------------')\n",
    "print('Shape of y_test:')\n",
    "print(y_test.shape)\n",
    "print('-----------------------------------------------------')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3\n",
    "#### TODO:\n",
    "1. record number of layer\n",
    "2. set the threshold\n",
    "\n",
    "\n",
    "### Question\n",
    "Start by creating a (deep) neural network in TensorFlow and train it on the data. Using training and validation sets, find a model with high accuracy, then evaluate it on the test set. In particular, record both the accuracy and AUC. Briefly discuss what issues you observe based on the metrics.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rm -rf ./logs100/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the range of hyperparameters\n",
    "We are going to explore the performance of dinstinct neural network when training with different hyperparameters. And we are going to use the following hyperparameters:\n",
    "1. Learning rate:\n",
    "    Usually, a lower learning rate will result in a better model and higher learning rate will accelerate the training process but result in a underfitting model. In this case, we set the range of learning rate from 10**(0.001) to 10**(0.1)\n",
    "2. Optimizer:\n",
    "    We are going to try both AdamOptimizer and sgd optimizer. In most case, SGD sacrifices the efficiency for better convergence quality.\n",
    "3. Dropout:\n",
    "    We are going to use HP_WHETHER_DROPOUT to decide whether to drop, and HP_DROPOUT to set the dropout rate. We set the range of dropout rate from 0.1 to 0.3 to see how the performance of the model changes.\n",
    "4. Number of neurons in the hidden layer:\n",
    "    In each hidden layer, we are going to use same number of neurons. In terms of the number of neurons, we are going to use a rule of thumb, in which we can calculate the number of neurons as:\n",
    "    \n",
    "    $N_h = \\frac{N_i}{\\alpha * (N_i+N_o))})$\n",
    "    \n",
    "    Ni = number of input neurons.\n",
    "    \n",
    "    No = number of output neurons.\n",
    "    \n",
    "    Ns = number of samples in training data set.\n",
    "    \n",
    "    α = an arbitrary scaling factor usually 2-10.\n",
    "\n",
    "    In our case, we are going to set $\\alpha$ ramdonly to 2,3,4\n",
    "5. Number of hidden layers:\n",
    "    Normally, if the model is very simple, one hidden layer is enough according to Reed's argument (Reed, 1999).\n",
    "    ```\n",
    "    Since a single sufficiently large hidden layer is adequate for approximation of most functions, why would anyone ever use more? One reason hangs on the words “sufficiently large”. Although a single hidden layer is optimal for some functions, there are others for which a single-hidden-layer-solution is very inefficient compared to solutions with more layers.\n",
    "    ``` \n",
    "\n",
    "    However, in terms of a complex model, Bengio (2016) argued that \n",
    "    ```\n",
    "    Specifically, the universal approximation theorem states that a feedforward network with a linear output layer and at least one hidden layer with any “squashing” activation function (such as the logistic sigmoid activation function) can approximate any Borel measurable function from one finite-dimensional space to another with any desired non-zero amount of error, provided that the network is given enough hidden units.\n",
    "    ——Deep learning, 2016\n",
    "    ```\n",
    "    Since our model might not be able to be explained by a linear function, we are going to set the range of hidden layers from 1 to 3.\n",
    "6. Activation\n",
    "    We are going to compare the performance of the following activation functions:\n",
    "    1. sigmoid\n",
    "    2. relu\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "HP_LEARNING_RATE = hp.HParam('learning_rate', hp.RealInterval(0.001,0.1))\n",
    "HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam', 'sgd']))\n",
    "HP_WHETHER_DROPOUT = hp.HParam('whether_dropout', hp.Discrete([True, False]))\n",
    "HP_DROPOUT = hp.HParam('dropout', hp.RealInterval(0.1, 0.3))\n",
    "# the number of units in the hidden layer, 1 time, 2 times or 3 times of the unit number of input layer\n",
    "BASE_NUM_UNITS = X_train.shape[0]/(X_train.shape[1] + 1)\n",
    "HP_NUM_UNITS = hp.HParam('num_units', hp.Discrete([int(BASE_NUM_UNITS/2), int(BASE_NUM_UNITS/3), int(BASE_NUM_UNITS/4),int(BASE_NUM_UNITS/5)])) \n",
    "HP_ACTIVATION = hp.HParam('activation', hp.Discrete(['relu', 'sigmoid']))\n",
    "HP_HIDDEN_LAYER_NUMBER = hp.HParam('hidden_layer_number', hp.Discrete(range(1,4)))\n",
    "METRIC_CROSSENTROPY = 'binary_crossentropy'\n",
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have set up our parameters and metrics, we write those into our folder with the logs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.summary.create_file_writer('logs100/hparam_tuning').as_default():\n",
    "    hp.hparams_config(hparams=[HP_LEARNING_RATE, HP_OPTIMIZER, HP_DROPOUT, HP_NUM_UNITS,HP_ACTIVATION,HP_HIDDEN_LAYER_NUMBER],\n",
    "                      metrics = [hp.Metric(METRIC_CROSSENTROPY, display_name='CROSSENTROPY')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(hparams,X_train=X_train,y_train=y_train,X_test=X_test,y_test=y_test):\n",
    "    early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True) # set patience to 10 to accelerate the training\n",
    "    if hparams[HP_WHETHER_DROPOUT] == True:\n",
    "        model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Dropout(hparams[HP_DROPOUT]),\n",
    "            tf.keras.layers.Dense(hparams[HP_NUM_UNITS], activation=hparams[HP_ACTIVATION])]*hparams[HP_HIDDEN_LAYER_NUMBER]+[\n",
    "            tf.keras.layers.Dense(1,activation='sigmoid')])\n",
    "    else:\n",
    "        model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Dense(hparams[HP_NUM_UNITS], activation=hparams[HP_ACTIVATION])]*hparams[HP_HIDDEN_LAYER_NUMBER]+[\n",
    "            tf.keras.layers.Dense(1,activation='sigmoid')])\n",
    "    if hparams[HP_OPTIMIZER] == 'sgd':\n",
    "        # Note that exploding gradients can be a big problem when running regressions, especially under SGD\n",
    "        # Hence, we use \"gradient clipping\" with parameter alpha, which means that the gradients are manually kept between -1 and 1\n",
    "        # This is of course another hyperparameter that we might tune!\n",
    "        optimizer = tf.keras.optimizers.SGD(\n",
    "            learning_rate=hparams[HP_LEARNING_RATE], clipvalue=1)\n",
    "    elif hparams[HP_OPTIMIZER] == 'adam':\n",
    "        optimizer = tf.keras.optimizers.Adam(\n",
    "            learning_rate=hparams[HP_LEARNING_RATE])\n",
    "\n",
    "    # random_seed = 192\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='binary_crossentropy')\n",
    "\n",
    "    model.fit(X_train, y_train, epochs=EPOCHS, validation_data=(X_val,y_val) ,callbacks=[early_stopping_cb],)\n",
    "    loss = model.evaluate(X_test, y_test)\n",
    "    x_test_predict = model.predict(X_test)\n",
    "    # calculate the roc\n",
    "    roc_score = roc_auc_score(y_test, x_test_predict)\n",
    "    # calculate the accuracy suppose the threshold is 0.5\n",
    "    x_test_predict_binary = np.where(x_test_predict>0.5,1,0)\n",
    "    accuracy = accuracy_score(y_test, x_test_predict_binary)\n",
    "    # calculate the sensitivity\n",
    "    sensitivity = recall_score(y_test, x_test_predict_binary)\n",
    "    return loss, accuracy,roc_score,sensitivity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(run_dir, hparams):\n",
    "    with tf.summary.create_file_writer(run_dir).as_default():\n",
    "        hp.hparams(hparams)\n",
    "        \n",
    "        loss, accuracy,roc_score,sensitivity = train_model(hparams) #TODO whether I did it right\n",
    "        tf.summary.scalar('ACCUARY', accuracy, step=1)\n",
    "        tf.summary.scalar('LOSS', loss, step=1)\n",
    "        tf.summary.scalar('ROC', roc_score, step=1)\n",
    "        tf.summary.scalar('SENSITIVITY', sensitivity, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting trial: run-0\n",
      "{'learning_rate': 0.046246040114833964, 'optimizer': 'sgd', 'whether_dropout': False, 'dropout': 0.19513086599790694, 'num_units': 27, 'activation': 'sigmoid', 'hidden_layer_number': 1}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 906us/step - loss: 0.0259 - val_loss: 0.2518\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 964us/step - loss: 0.0054 - val_loss: 0.2828\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 929us/step - loss: 0.0031 - val_loss: 0.3023\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0022 - val_loss: 0.3165\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 1000us/step - loss: 0.0017 - val_loss: 0.3276\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 610us/step - loss: 0.0013 - val_loss: 0.3368\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 669us/step - loss: 0.0011 - val_loss: 0.3446\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 638us/step - loss: 9.7137e-04 - val_loss: 0.3514\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 647us/step - loss: 8.5147e-04 - val_loss: 0.3574\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 646us/step - loss: 7.5742e-04 - val_loss: 0.3628\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 660us/step - loss: 6.8170e-04 - val_loss: 0.3677\n",
      "36/36 [==============================] - 0s 514us/step - loss: 0.2516\n",
      "--- Starting trial: run-1\n",
      "{'learning_rate': 0.009338762119833664, 'optimizer': 'adam', 'whether_dropout': True, 'dropout': 0.17779183940431265, 'num_units': 68, 'activation': 'relu', 'hidden_layer_number': 1}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0073 - val_loss: 0.8565\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 4.3095e-06 - val_loss: 1.0182\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 943us/step - loss: 1.8436e-06 - val_loss: 1.1315\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 786us/step - loss: 7.0032e-07 - val_loss: 1.2082\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 762us/step - loss: 2.7492e-07 - val_loss: 1.2618\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 754us/step - loss: 3.3486e-07 - val_loss: 1.3214\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 763us/step - loss: 1.7667e-07 - val_loss: 1.3638\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 770us/step - loss: 2.3943e-07 - val_loss: 1.4185\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 791us/step - loss: 1.3581e-07 - val_loss: 1.4592\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 763us/step - loss: 7.5769e-08 - val_loss: 1.4861\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 812us/step - loss: 3.4333e-08 - val_loss: 1.5122\n",
      "36/36 [==============================] - 0s 457us/step - loss: 0.8838\n",
      "--- Starting trial: run-2\n",
      "{'learning_rate': 0.0016688817084995259, 'optimizer': 'adam', 'whether_dropout': False, 'dropout': 0.17817417002387081, 'num_units': 68, 'activation': 'relu', 'hidden_layer_number': 2}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0240 - val_loss: 0.4865\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 975us/step - loss: 7.1883e-05 - val_loss: 0.5766\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 2.2060e-05 - val_loss: 0.6275\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 811us/step - loss: 1.0703e-05 - val_loss: 0.6638\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 2ms/step - loss: 6.2569e-06 - val_loss: 0.6925\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 4.0653e-06 - val_loss: 0.7165\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 760us/step - loss: 2.8177e-06 - val_loss: 0.7373\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 817us/step - loss: 2.0430e-06 - val_loss: 0.7557\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 821us/step - loss: 1.5294e-06 - val_loss: 0.7727\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 834us/step - loss: 1.1735e-06 - val_loss: 0.7884\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 771us/step - loss: 9.1781e-07 - val_loss: 0.8030\n",
      "36/36 [==============================] - 0s 521us/step - loss: 0.4955\n",
      "--- Starting trial: run-3\n",
      "{'learning_rate': 0.0032061571873792443, 'optimizer': 'sgd', 'whether_dropout': False, 'dropout': 0.2080091798066182, 'num_units': 27, 'activation': 'sigmoid', 'hidden_layer_number': 3}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 1s 1ms/step - loss: 0.3419 - val_loss: 0.2438\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 983us/step - loss: 0.1044 - val_loss: 0.2046\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0595 - val_loss: 0.2007\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0411 - val_loss: 0.2037\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 672us/step - loss: 0.0313 - val_loss: 0.2083\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 653us/step - loss: 0.0251 - val_loss: 0.2133\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 694us/step - loss: 0.0210 - val_loss: 0.2181\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 679us/step - loss: 0.0180 - val_loss: 0.2227\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 839us/step - loss: 0.0157 - val_loss: 0.2271\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 714us/step - loss: 0.0139 - val_loss: 0.2312\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 696us/step - loss: 0.0125 - val_loss: 0.2350\n",
      "Epoch 12/100\n",
      "285/285 [==============================] - 0s 677us/step - loss: 0.0113 - val_loss: 0.2386\n",
      "Epoch 13/100\n",
      "285/285 [==============================] - 0s 665us/step - loss: 0.0104 - val_loss: 0.2420\n",
      "36/36 [==============================] - 0s 463us/step - loss: 0.2011\n",
      "--- Starting trial: run-4\n",
      "{'learning_rate': 0.0016040138170844327, 'optimizer': 'adam', 'whether_dropout': False, 'dropout': 0.18704802951071484, 'num_units': 68, 'activation': 'sigmoid', 'hidden_layer_number': 2}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0569 - val_loss: 0.2832\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0025 - val_loss: 0.3357\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.3687\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 861us/step - loss: 5.9319e-04 - val_loss: 0.3932\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 782us/step - loss: 3.8048e-04 - val_loss: 0.4129\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 756us/step - loss: 2.6407e-04 - val_loss: 0.4296\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 764us/step - loss: 1.9287e-04 - val_loss: 0.4442\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 753us/step - loss: 1.4598e-04 - val_loss: 0.4573\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 776us/step - loss: 1.1337e-04 - val_loss: 0.4694\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 785us/step - loss: 8.9802e-05 - val_loss: 0.4805\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 740us/step - loss: 7.2242e-05 - val_loss: 0.4910\n",
      "36/36 [==============================] - 0s 547us/step - loss: 0.2850\n",
      "--- Starting trial: run-5\n",
      "{'learning_rate': 0.0012768695953084344, 'optimizer': 'adam', 'whether_dropout': False, 'dropout': 0.25738174783047685, 'num_units': 45, 'activation': 'relu', 'hidden_layer_number': 3}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 957us/step - loss: 0.0449 - val_loss: 0.3806\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 5.0945e-04 - val_loss: 0.4554\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 1.7622e-04 - val_loss: 0.5004\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 842us/step - loss: 8.8933e-05 - val_loss: 0.5332\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 779us/step - loss: 5.2974e-05 - val_loss: 0.5596\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 809us/step - loss: 3.4783e-05 - val_loss: 0.5817\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 744us/step - loss: 2.4272e-05 - val_loss: 0.6010\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 746us/step - loss: 1.7676e-05 - val_loss: 0.6183\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 796us/step - loss: 1.3269e-05 - val_loss: 0.6342\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 788us/step - loss: 1.0199e-05 - val_loss: 0.6489\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 7.9863e-06 - val_loss: 0.6627\n",
      "36/36 [==============================] - 0s 647us/step - loss: 0.3885\n",
      "--- Starting trial: run-6\n",
      "{'learning_rate': 0.04680174222490786, 'optimizer': 'sgd', 'whether_dropout': True, 'dropout': 0.10510422181179008, 'num_units': 27, 'activation': 'sigmoid', 'hidden_layer_number': 3}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 980us/step - loss: 0.0572 - val_loss: 0.2387\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.2705\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0034 - val_loss: 0.2903\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 947us/step - loss: 0.0023 - val_loss: 0.3047\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 667us/step - loss: 0.0018 - val_loss: 0.3159\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 751us/step - loss: 0.0014 - val_loss: 0.3252\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 673us/step - loss: 0.0012 - val_loss: 0.3331\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 712us/step - loss: 0.0010 - val_loss: 0.3399\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 761us/step - loss: 9.1003e-04 - val_loss: 0.3460\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 696us/step - loss: 8.0945e-04 - val_loss: 0.3515\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 754us/step - loss: 7.2671e-04 - val_loss: 0.3564\n",
      "36/36 [==============================] - 0s 529us/step - loss: 0.2393\n",
      "--- Starting trial: run-7\n",
      "{'learning_rate': 0.039957942340065784, 'optimizer': 'adam', 'whether_dropout': False, 'dropout': 0.23416094602976573, 'num_units': 27, 'activation': 'sigmoid', 'hidden_layer_number': 1}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0024 - val_loss: 0.5351\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 941us/step - loss: 1.6211e-05 - val_loss: 0.5599\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 1.0263e-05 - val_loss: 0.5804\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 795us/step - loss: 6.9956e-06 - val_loss: 0.5978\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 759us/step - loss: 5.0365e-06 - val_loss: 0.6129\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 780us/step - loss: 3.7692e-06 - val_loss: 0.6265\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 731us/step - loss: 2.9016e-06 - val_loss: 0.6388\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 748us/step - loss: 2.2825e-06 - val_loss: 0.6503\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 748us/step - loss: 1.8256e-06 - val_loss: 0.6609\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 759us/step - loss: 1.4798e-06 - val_loss: 0.6710\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 776us/step - loss: 1.2124e-06 - val_loss: 0.6806\n",
      "36/36 [==============================] - 0s 498us/step - loss: 0.5363\n",
      "--- Starting trial: run-8\n",
      "{'learning_rate': 0.011657206921105837, 'optimizer': 'sgd', 'whether_dropout': True, 'dropout': 0.13977440768730592, 'num_units': 45, 'activation': 'sigmoid', 'hidden_layer_number': 2}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 877us/step - loss: 0.1066 - val_loss: 0.2083\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 754us/step - loss: 0.0162 - val_loss: 0.2324\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 964us/step - loss: 0.0092 - val_loss: 0.2495\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0065 - val_loss: 0.2624\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 732us/step - loss: 0.0050 - val_loss: 0.2727\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 676us/step - loss: 0.0040 - val_loss: 0.2814\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 673us/step - loss: 0.0034 - val_loss: 0.2887\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 678us/step - loss: 0.0029 - val_loss: 0.2952\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 669us/step - loss: 0.0026 - val_loss: 0.3009\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 697us/step - loss: 0.0023 - val_loss: 0.3061\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 684us/step - loss: 0.0021 - val_loss: 0.3107\n",
      "36/36 [==============================] - 0s 538us/step - loss: 0.2085\n",
      "--- Starting trial: run-9\n",
      "{'learning_rate': 0.007215049104922526, 'optimizer': 'adam', 'whether_dropout': False, 'dropout': 0.21478267338801094, 'num_units': 34, 'activation': 'sigmoid', 'hidden_layer_number': 1}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 986us/step - loss: 0.0049 - val_loss: 0.4186\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 896us/step - loss: 1.4678e-04 - val_loss: 0.4676\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 6.5864e-05 - val_loss: 0.4986\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 997us/step - loss: 3.8176e-05 - val_loss: 0.5217\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 906us/step - loss: 2.5020e-05 - val_loss: 0.5405\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 856us/step - loss: 1.7635e-05 - val_loss: 0.5564\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 2s 8ms/step - loss: 1.3033e-05 - val_loss: 0.5703\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 9.9593e-06 - val_loss: 0.5829\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 775us/step - loss: 7.7968e-06 - val_loss: 0.5944\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 832us/step - loss: 6.2186e-06 - val_loss: 0.6052\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 788us/step - loss: 5.0324e-06 - val_loss: 0.6153\n",
      "36/36 [==============================] - 0s 518us/step - loss: 0.4211\n",
      "--- Starting trial: run-10\n",
      "{'learning_rate': 0.0076861184004607805, 'optimizer': 'adam', 'whether_dropout': False, 'dropout': 0.15250871724241155, 'num_units': 27, 'activation': 'relu', 'hidden_layer_number': 1}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 1s 1ms/step - loss: 0.0105 - val_loss: 0.5416\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 3.4734e-05 - val_loss: 0.6092\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 1s 3ms/step - loss: 1.3049e-05 - val_loss: 0.6525\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 2ms/step - loss: 6.7376e-06 - val_loss: 0.6846\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 933us/step - loss: 4.0498e-06 - val_loss: 0.7106\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 920us/step - loss: 2.6752e-06 - val_loss: 0.7325\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 1.8734e-06 - val_loss: 0.7516\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 1.3678e-06 - val_loss: 0.7687\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 925us/step - loss: 1.0289e-06 - val_loss: 0.7844\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 2ms/step - loss: 7.9198e-07 - val_loss: 0.7990\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 6.2091e-07 - val_loss: 0.8126\n",
      "36/36 [==============================] - 0s 522us/step - loss: 0.5602\n",
      "--- Starting trial: run-11\n",
      "{'learning_rate': 0.015778626373926546, 'optimizer': 'adam', 'whether_dropout': True, 'dropout': 0.13251832085378143, 'num_units': 45, 'activation': 'relu', 'hidden_layer_number': 1}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 1s 1ms/step - loss: 0.0060 - val_loss: 0.8767\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 2.4400e-06 - val_loss: 0.8898\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 967us/step - loss: 4.3358e-06 - val_loss: 0.9128\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 852us/step - loss: 2.0146e-06 - val_loss: 0.9317\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 2ms/step - loss: 1.4961e-06 - val_loss: 0.9522\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 9.9588e-07 - val_loss: 0.9689\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 963us/step - loss: 8.7426e-07 - val_loss: 0.9851\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 818us/step - loss: 6.0235e-07 - val_loss: 0.9994\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 952us/step - loss: 9.2597e-07 - val_loss: 1.0213\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 816us/step - loss: 6.8432e-07 - val_loss: 1.0389\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 850us/step - loss: 1.0411e-06 - val_loss: 1.0694\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.9075\n",
      "--- Starting trial: run-12\n",
      "{'learning_rate': 0.13404047187717852, 'optimizer': 'adam', 'whether_dropout': True, 'dropout': 0.2125005999838529, 'num_units': 27, 'activation': 'relu', 'hidden_layer_number': 3}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 1s 1ms/step - loss: 0.0026 - val_loss: 6.3842\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 2.8998e-21 - val_loss: 6.3842\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 964us/step - loss: 1.7216e-17 - val_loss: 6.3842\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 830us/step - loss: 1.3814e-17 - val_loss: 6.3842\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 840us/step - loss: 8.1529e-22 - val_loss: 6.3842\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 943us/step - loss: 3.6382e-11 - val_loss: 6.3842\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 2.2675e-15 - val_loss: 6.3842\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 1.4859e-17 - val_loss: 6.3842\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 981us/step - loss: 1.9481e-17 - val_loss: 6.3842\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 852us/step - loss: 1.3944e-15 - val_loss: 6.3842\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 884us/step - loss: 8.1990e-20 - val_loss: 6.3842\n",
      "36/36 [==============================] - 0s 558us/step - loss: 6.6021\n",
      "--- Starting trial: run-13\n",
      "{'learning_rate': 0.012729872255485535, 'optimizer': 'sgd', 'whether_dropout': False, 'dropout': 0.21767336944333632, 'num_units': 27, 'activation': 'relu', 'hidden_layer_number': 1}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 906us/step - loss: 0.0927 - val_loss: 0.2135\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.2483\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 0.0070 - val_loss: 0.2723\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 2s 6ms/step - loss: 0.0046 - val_loss: 0.2902\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 1s 3ms/step - loss: 0.0034 - val_loss: 0.3042\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 2ms/step - loss: 0.0027 - val_loss: 0.3158\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 0.0022 - val_loss: 0.3257\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0018 - val_loss: 0.3343\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0016 - val_loss: 0.3419\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 0.3487\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 872us/step - loss: 0.0012 - val_loss: 0.3549\n",
      "36/36 [==============================] - 0s 603us/step - loss: 0.2143\n",
      "--- Starting trial: run-14\n",
      "{'learning_rate': 0.005087886370691307, 'optimizer': 'adam', 'whether_dropout': True, 'dropout': 0.2662144286773921, 'num_units': 27, 'activation': 'sigmoid', 'hidden_layer_number': 1}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 1s 3ms/step - loss: 0.0474 - val_loss: 0.3007\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0017 - val_loss: 0.3525\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 985us/step - loss: 7.1408e-04 - val_loss: 0.3851\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 921us/step - loss: 4.0225e-04 - val_loss: 0.4094\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 2.5653e-04 - val_loss: 0.4289\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 1.7925e-04 - val_loss: 0.4456\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 1.3047e-04 - val_loss: 0.4602\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 834us/step - loss: 9.7996e-05 - val_loss: 0.4731\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 921us/step - loss: 7.6998e-05 - val_loss: 0.4852\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 885us/step - loss: 6.1153e-05 - val_loss: 0.4964\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 978us/step - loss: 4.8421e-05 - val_loss: 0.5068\n",
      "36/36 [==============================] - 0s 835us/step - loss: 0.3018\n",
      "--- Starting trial: run-15\n",
      "{'learning_rate': 0.04412413278912642, 'optimizer': 'adam', 'whether_dropout': True, 'dropout': 0.25732133280969405, 'num_units': 45, 'activation': 'relu', 'hidden_layer_number': 3}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 1s 1ms/step - loss: 0.0035 - val_loss: 2.5866\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 2.6331e-10 - val_loss: 2.5866\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 2.7450e-08 - val_loss: 2.6732\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 2ms/step - loss: 1.1768e-08 - val_loss: 2.6926\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 1.4907e-10 - val_loss: 2.6934\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 850us/step - loss: 8.3730e-08 - val_loss: 2.8035\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 1.5517e-10 - val_loss: 2.8340\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 1.4355e-10 - val_loss: 2.8354\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 2.0199e-10 - val_loss: 2.8375\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 9.3551e-11 - val_loss: 2.8390\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 2ms/step - loss: 2.6093e-11 - val_loss: 2.8398\n",
      "36/36 [==============================] - 0s 565us/step - loss: 2.6857\n",
      "--- Starting trial: run-16\n",
      "{'learning_rate': 0.006401393446344375, 'optimizer': 'sgd', 'whether_dropout': True, 'dropout': 0.2653618134842588, 'num_units': 34, 'activation': 'relu', 'hidden_layer_number': 3}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 0.2906 - val_loss: 0.2001\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 0.0529 - val_loss: 0.2064\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 2ms/step - loss: 0.0259 - val_loss: 0.2263\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0167 - val_loss: 0.2440\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0121 - val_loss: 0.2590\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 847us/step - loss: 0.0096 - val_loss: 0.2717\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0077 - val_loss: 0.2829\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 0.2924\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 942us/step - loss: 0.0056 - val_loss: 0.3011\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 826us/step - loss: 0.0050 - val_loss: 0.3091\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 791us/step - loss: 0.0044 - val_loss: 0.3164\n",
      "36/36 [==============================] - 0s 659us/step - loss: 0.2029\n",
      "--- Starting trial: run-17\n",
      "{'learning_rate': 0.43079155277762265, 'optimizer': 'adam', 'whether_dropout': True, 'dropout': 0.29205922974293674, 'num_units': 34, 'activation': 'relu', 'hidden_layer_number': 1}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 1s 1ms/step - loss: 0.0024 - val_loss: 46.9959\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 973us/step - loss: 0.0000e+00 - val_loss: 46.9959\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - val_loss: 46.9959\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - val_loss: 46.9959\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 897us/step - loss: 0.0000e+00 - val_loss: 46.9959\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - val_loss: 46.9959\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - val_loss: 46.9959\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 988us/step - loss: 0.0000e+00 - val_loss: 46.9959\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 837us/step - loss: 0.0000e+00 - val_loss: 46.9959\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 818us/step - loss: 0.0000e+00 - val_loss: 46.9959\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 923us/step - loss: 0.0000e+00 - val_loss: 46.9959\n",
      "36/36 [==============================] - 0s 637us/step - loss: 48.2728\n",
      "--- Starting trial: run-18\n",
      "{'learning_rate': 0.7727825461704738, 'optimizer': 'adam', 'whether_dropout': True, 'dropout': 0.26474349287822896, 'num_units': 45, 'activation': 'relu', 'hidden_layer_number': 1}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 1s 1ms/step - loss: 0.0021 - val_loss: 218.4705\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - val_loss: 218.4705\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - val_loss: 218.4705\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - val_loss: 218.4705\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 953us/step - loss: 0.0000e+00 - val_loss: 218.4705\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - val_loss: 218.4705\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - val_loss: 218.4705\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - val_loss: 218.4705\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - val_loss: 218.4705\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - val_loss: 218.4705\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 950us/step - loss: 0.0000e+00 - val_loss: 218.4705\n",
      "36/36 [==============================] - 0s 552us/step - loss: 224.2949\n",
      "--- Starting trial: run-19\n",
      "{'learning_rate': 0.0013204465754007057, 'optimizer': 'sgd', 'whether_dropout': True, 'dropout': 0.18518643854447675, 'num_units': 45, 'activation': 'sigmoid', 'hidden_layer_number': 1}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 1s 1ms/step - loss: 0.5182 - val_loss: 0.3095\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.1695 - val_loss: 0.2222\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 0.0955 - val_loss: 0.2024\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 894us/step - loss: 0.0657 - val_loss: 0.1977\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 876us/step - loss: 0.0498 - val_loss: 0.1978\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 798us/step - loss: 0.0400 - val_loss: 0.1999\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 835us/step - loss: 0.0333 - val_loss: 0.2027\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 768us/step - loss: 0.0285 - val_loss: 0.2058\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 748us/step - loss: 0.0250 - val_loss: 0.2090\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 764us/step - loss: 0.0222 - val_loss: 0.2122\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 738us/step - loss: 0.0199 - val_loss: 0.2152\n",
      "Epoch 12/100\n",
      "285/285 [==============================] - 0s 719us/step - loss: 0.0181 - val_loss: 0.2182\n",
      "Epoch 13/100\n",
      "285/285 [==============================] - 0s 724us/step - loss: 0.0165 - val_loss: 0.2210\n",
      "Epoch 14/100\n",
      "285/285 [==============================] - 0s 747us/step - loss: 0.0153 - val_loss: 0.2237\n",
      "36/36 [==============================] - 0s 533us/step - loss: 0.1977\n",
      "--- Starting trial: run-20\n",
      "{'learning_rate': 0.012370826717418631, 'optimizer': 'sgd', 'whether_dropout': False, 'dropout': 0.1723547470640915, 'num_units': 34, 'activation': 'relu', 'hidden_layer_number': 2}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 961us/step - loss: 0.1289 - val_loss: 0.2106\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0169 - val_loss: 0.2442\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 934us/step - loss: 0.0083 - val_loss: 0.2685\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 737us/step - loss: 0.0053 - val_loss: 0.2867\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 792us/step - loss: 0.0039 - val_loss: 0.3011\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 775us/step - loss: 0.0030 - val_loss: 0.3130\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 718us/step - loss: 0.0024 - val_loss: 0.3231\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 747us/step - loss: 0.0021 - val_loss: 0.3319\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 793us/step - loss: 0.0018 - val_loss: 0.3396\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 836us/step - loss: 0.0015 - val_loss: 0.3466\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 784us/step - loss: 0.0014 - val_loss: 0.3529\n",
      "36/36 [==============================] - 0s 736us/step - loss: 0.2155\n",
      "--- Starting trial: run-21\n",
      "{'learning_rate': 0.0326532734967011, 'optimizer': 'adam', 'whether_dropout': True, 'dropout': 0.12034544785231074, 'num_units': 45, 'activation': 'relu', 'hidden_layer_number': 3}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 1s 1ms/step - loss: 0.0033 - val_loss: 1.7885\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 8.3384e-10 - val_loss: 1.7885\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 7.0454e-08 - val_loss: 1.7898\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 4.6248e-09 - val_loss: 1.7900\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 4.0959e-09 - val_loss: 1.7909\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 990us/step - loss: 5.1281e-10 - val_loss: 1.7910\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 954us/step - loss: 6.1767e-10 - val_loss: 1.7911\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 8.7624e-10 - val_loss: 1.7912\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 1.9700e-09 - val_loss: 1.7914\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 8.6095e-10 - val_loss: 1.7916\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 951us/step - loss: 1.7546e-09 - val_loss: 1.7919\n",
      "36/36 [==============================] - 0s 966us/step - loss: 1.8550\n",
      "--- Starting trial: run-22\n",
      "{'learning_rate': 0.9130204827588444, 'optimizer': 'sgd', 'whether_dropout': True, 'dropout': 0.2516074757333651, 'num_units': 27, 'activation': 'relu', 'hidden_layer_number': 1}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 1s 1ms/step - loss: 0.0036 - val_loss: 0.5060\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 1.4901e-04 - val_loss: 0.5603\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 8.3743e-05 - val_loss: 0.5931\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 843us/step - loss: 6.1004e-05 - val_loss: 0.6168\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 761us/step - loss: 4.2611e-05 - val_loss: 0.6344\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 752us/step - loss: 4.5759e-05 - val_loss: 0.6513\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 699us/step - loss: 2.9049e-05 - val_loss: 0.6634\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 906us/step - loss: 2.8418e-05 - val_loss: 0.6743\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 2.3908e-05 - val_loss: 0.6843\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 2.1152e-05 - val_loss: 0.6931\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 738us/step - loss: 1.7597e-05 - val_loss: 0.7007\n",
      "36/36 [==============================] - 0s 697us/step - loss: 0.5110\n",
      "--- Starting trial: run-23\n",
      "{'learning_rate': 0.04013482433208903, 'optimizer': 'sgd', 'whether_dropout': True, 'dropout': 0.2677326635392208, 'num_units': 68, 'activation': 'relu', 'hidden_layer_number': 1}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 1s 1ms/step - loss: 0.0472 - val_loss: 0.2799\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0046 - val_loss: 0.3298\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0025 - val_loss: 0.3603\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 813us/step - loss: 0.0017 - val_loss: 0.3826\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 790us/step - loss: 0.0013 - val_loss: 0.3997\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 703us/step - loss: 0.0011 - val_loss: 0.4139\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 857us/step - loss: 8.6041e-04 - val_loss: 0.4258\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 853us/step - loss: 7.3360e-04 - val_loss: 0.4360\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 711us/step - loss: 6.6057e-04 - val_loss: 0.4454\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 693us/step - loss: 6.0051e-04 - val_loss: 0.4539\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 746us/step - loss: 4.9991e-04 - val_loss: 0.4613\n",
      "36/36 [==============================] - 0s 606us/step - loss: 0.2870\n",
      "--- Starting trial: run-24\n",
      "{'learning_rate': 0.5464866921144468, 'optimizer': 'sgd', 'whether_dropout': True, 'dropout': 0.215889988005536, 'num_units': 27, 'activation': 'sigmoid', 'hidden_layer_number': 2}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.3653\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 4.2720e-04 - val_loss: 0.4011\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 2ms/step - loss: 2.4382e-04 - val_loss: 0.4223\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 980us/step - loss: 1.6992e-04 - val_loss: 0.4374\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 947us/step - loss: 1.3016e-04 - val_loss: 0.4491\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 850us/step - loss: 1.0547e-04 - val_loss: 0.4587\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 734us/step - loss: 8.8656e-05 - val_loss: 0.4669\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 959us/step - loss: 7.5244e-05 - val_loss: 0.4738\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 768us/step - loss: 6.6730e-05 - val_loss: 0.4801\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 887us/step - loss: 5.9434e-05 - val_loss: 0.4856\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 740us/step - loss: 5.3257e-05 - val_loss: 0.4907\n",
      "36/36 [==============================] - 0s 634us/step - loss: 0.3654\n",
      "--- Starting trial: run-25\n",
      "{'learning_rate': 0.0021171765371396606, 'optimizer': 'adam', 'whether_dropout': False, 'dropout': 0.2784706332588353, 'num_units': 27, 'activation': 'relu', 'hidden_layer_number': 3}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 1s 1ms/step - loss: 0.0364 - val_loss: 0.3851\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 2ms/step - loss: 5.8355e-04 - val_loss: 0.4520\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 2ms/step - loss: 2.2324e-04 - val_loss: 0.4935\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 1.1846e-04 - val_loss: 0.5241\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 963us/step - loss: 7.2893e-05 - val_loss: 0.5490\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 850us/step - loss: 4.9016e-05 - val_loss: 0.5700\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 867us/step - loss: 3.4840e-05 - val_loss: 0.5884\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 879us/step - loss: 2.5760e-05 - val_loss: 0.6049\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 922us/step - loss: 1.9586e-05 - val_loss: 0.6200\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 821us/step - loss: 1.5218e-05 - val_loss: 0.6342\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 830us/step - loss: 1.2028e-05 - val_loss: 0.6474\n",
      "36/36 [==============================] - 0s 596us/step - loss: 0.3985\n",
      "--- Starting trial: run-26\n",
      "{'learning_rate': 0.01833584556602331, 'optimizer': 'sgd', 'whether_dropout': False, 'dropout': 0.22874141721301827, 'num_units': 34, 'activation': 'relu', 'hidden_layer_number': 1}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 969us/step - loss: 0.0989 - val_loss: 0.2349\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0099 - val_loss: 0.2759\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 0.3020\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 878us/step - loss: 0.0032 - val_loss: 0.3210\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 863us/step - loss: 0.0023 - val_loss: 0.3358\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 752us/step - loss: 0.0018 - val_loss: 0.3479\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 761us/step - loss: 0.0015 - val_loss: 0.3581\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 802us/step - loss: 0.0013 - val_loss: 0.3670\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 748us/step - loss: 0.0011 - val_loss: 0.3748\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 711us/step - loss: 9.5175e-04 - val_loss: 0.3818\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 767us/step - loss: 8.4583e-04 - val_loss: 0.3882\n",
      "36/36 [==============================] - 0s 523us/step - loss: 0.2324\n",
      "--- Starting trial: run-27\n",
      "{'learning_rate': 0.0018125914726106263, 'optimizer': 'adam', 'whether_dropout': False, 'dropout': 0.2734795698016351, 'num_units': 27, 'activation': 'sigmoid', 'hidden_layer_number': 1}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 1s 1ms/step - loss: 0.0288 - val_loss: 0.2856\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0022 - val_loss: 0.3360\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 9.2742e-04 - val_loss: 0.3678\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 5.2751e-04 - val_loss: 0.3913\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 907us/step - loss: 3.4179e-04 - val_loss: 0.4104\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 920us/step - loss: 2.3893e-04 - val_loss: 0.4266\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 1.7547e-04 - val_loss: 0.4408\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 1.3341e-04 - val_loss: 0.4536\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 981us/step - loss: 1.0401e-04 - val_loss: 0.4653\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 8.2677e-05 - val_loss: 0.4761\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 919us/step - loss: 6.6715e-05 - val_loss: 0.4864\n",
      "36/36 [==============================] - 0s 647us/step - loss: 0.2880\n",
      "--- Starting trial: run-28\n",
      "{'learning_rate': 0.0010259636178788646, 'optimizer': 'sgd', 'whether_dropout': False, 'dropout': 0.17836389572313482, 'num_units': 45, 'activation': 'sigmoid', 'hidden_layer_number': 1}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 0.3637 - val_loss: 0.2977\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 2ms/step - loss: 0.1756 - val_loss: 0.2301\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.1116 - val_loss: 0.2078\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 813us/step - loss: 0.0808 - val_loss: 0.1995\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0630 - val_loss: 0.1968\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 958us/step - loss: 0.0515 - val_loss: 0.1966\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 797us/step - loss: 0.0434 - val_loss: 0.1977\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 826us/step - loss: 0.0375 - val_loss: 0.1995\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 833us/step - loss: 0.0330 - val_loss: 0.2015\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 786us/step - loss: 0.0294 - val_loss: 0.2038\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0265 - val_loss: 0.2061\n",
      "Epoch 12/100\n",
      "285/285 [==============================] - 0s 860us/step - loss: 0.0241 - val_loss: 0.2084\n",
      "Epoch 13/100\n",
      "285/285 [==============================] - 0s 774us/step - loss: 0.0221 - val_loss: 0.2107\n",
      "Epoch 14/100\n",
      "285/285 [==============================] - 0s 691us/step - loss: 0.0204 - val_loss: 0.2130\n",
      "Epoch 15/100\n",
      "285/285 [==============================] - 0s 2ms/step - loss: 0.0190 - val_loss: 0.2152\n",
      "Epoch 16/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0177 - val_loss: 0.2173\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.1969\n",
      "--- Starting trial: run-29\n",
      "{'learning_rate': 0.17330762001542252, 'optimizer': 'adam', 'whether_dropout': False, 'dropout': 0.23207567283139838, 'num_units': 45, 'activation': 'relu', 'hidden_layer_number': 3}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 3s 7ms/step - loss: 0.0022 - val_loss: 16.5869\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - val_loss: 16.5869\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - val_loss: 16.5869\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 964us/step - loss: 0.0000e+00 - val_loss: 16.5869\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 892us/step - loss: 0.0000e+00 - val_loss: 16.5869\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 865us/step - loss: 0.0000e+00 - val_loss: 16.5869\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 882us/step - loss: 0.0000e+00 - val_loss: 16.5869\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 839us/step - loss: 0.0000e+00 - val_loss: 16.5869\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 818us/step - loss: 0.0000e+00 - val_loss: 16.5869\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 928us/step - loss: 0.0000e+00 - val_loss: 16.5869\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - val_loss: 16.5869\n",
      "36/36 [==============================] - 0s 557us/step - loss: 17.0123\n",
      "--- Starting trial: run-30\n",
      "{'learning_rate': 0.0020967095038594437, 'optimizer': 'adam', 'whether_dropout': True, 'dropout': 0.2937650041460256, 'num_units': 34, 'activation': 'sigmoid', 'hidden_layer_number': 3}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 1s 1ms/step - loss: 0.1294 - val_loss: 0.2306\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.2770\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0034 - val_loss: 0.3081\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 791us/step - loss: 0.0019 - val_loss: 0.3318\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 833us/step - loss: 0.0012 - val_loss: 0.3509\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 2ms/step - loss: 8.3872e-04 - val_loss: 0.3674\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 6.0994e-04 - val_loss: 0.3819\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 904us/step - loss: 4.5804e-04 - val_loss: 0.3949\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 955us/step - loss: 3.5801e-04 - val_loss: 0.4071\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 991us/step - loss: 2.8377e-04 - val_loss: 0.4185\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 2.2403e-04 - val_loss: 0.4291\n",
      "36/36 [==============================] - 0s 607us/step - loss: 0.2326\n",
      "--- Starting trial: run-31\n",
      "{'learning_rate': 0.0020054497020999635, 'optimizer': 'adam', 'whether_dropout': True, 'dropout': 0.2621898040756854, 'num_units': 34, 'activation': 'sigmoid', 'hidden_layer_number': 2}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 1s 1ms/step - loss: 0.0475 - val_loss: 0.2780\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 0.0027 - val_loss: 0.3305\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 943us/step - loss: 0.0011 - val_loss: 0.3637\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 877us/step - loss: 6.4233e-04 - val_loss: 0.3884\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 906us/step - loss: 4.0905e-04 - val_loss: 0.4082\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 863us/step - loss: 2.8569e-04 - val_loss: 0.4250\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 2.0885e-04 - val_loss: 0.4397\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 907us/step - loss: 1.5639e-04 - val_loss: 0.4527\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 919us/step - loss: 1.2350e-04 - val_loss: 0.4649\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 829us/step - loss: 9.8366e-05 - val_loss: 0.4762\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 837us/step - loss: 7.7618e-05 - val_loss: 0.4867\n",
      "36/36 [==============================] - 0s 540us/step - loss: 0.2799\n",
      "--- Starting trial: run-32\n",
      "{'learning_rate': 0.014778342455800238, 'optimizer': 'adam', 'whether_dropout': False, 'dropout': 0.19632287170878127, 'num_units': 34, 'activation': 'sigmoid', 'hidden_layer_number': 3}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 1s 1ms/step - loss: 0.0090 - val_loss: 0.4131\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 1.7641e-04 - val_loss: 0.4551\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 8.5895e-05 - val_loss: 0.4839\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 914us/step - loss: 5.1226e-05 - val_loss: 0.5060\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 866us/step - loss: 3.4042e-05 - val_loss: 0.5241\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 829us/step - loss: 2.4183e-05 - val_loss: 0.5396\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 1.7960e-05 - val_loss: 0.5533\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 987us/step - loss: 1.3768e-05 - val_loss: 0.5657\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 938us/step - loss: 1.0803e-05 - val_loss: 0.5771\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 823us/step - loss: 8.6305e-06 - val_loss: 0.5878\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 866us/step - loss: 6.9924e-06 - val_loss: 0.5978\n",
      "36/36 [==============================] - 0s 484us/step - loss: 0.4154\n",
      "--- Starting trial: run-33\n",
      "{'learning_rate': 0.0026559844016543726, 'optimizer': 'sgd', 'whether_dropout': False, 'dropout': 0.23731544655933437, 'num_units': 27, 'activation': 'relu', 'hidden_layer_number': 1}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 984us/step - loss: 0.3745 - val_loss: 0.2841\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 2ms/step - loss: 0.1340 - val_loss: 0.2198\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0675 - val_loss: 0.2126\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 776us/step - loss: 0.0419 - val_loss: 0.2179\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 715us/step - loss: 0.0293 - val_loss: 0.2259\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 695us/step - loss: 0.0220 - val_loss: 0.2343\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 694us/step - loss: 0.0175 - val_loss: 0.2423\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 666us/step - loss: 0.0143 - val_loss: 0.2497\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0121 - val_loss: 0.2566\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 846us/step - loss: 0.0104 - val_loss: 0.2629\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 794us/step - loss: 0.0091 - val_loss: 0.2687\n",
      "Epoch 12/100\n",
      "285/285 [==============================] - 0s 649us/step - loss: 0.0080 - val_loss: 0.2742\n",
      "Epoch 13/100\n",
      "285/285 [==============================] - 0s 684us/step - loss: 0.0072 - val_loss: 0.2792\n",
      "36/36 [==============================] - 0s 545us/step - loss: 0.2176\n",
      "--- Starting trial: run-34\n",
      "{'learning_rate': 0.40129916519149766, 'optimizer': 'adam', 'whether_dropout': False, 'dropout': 0.2454304034000479, 'num_units': 68, 'activation': 'sigmoid', 'hidden_layer_number': 1}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 1s 1ms/step - loss: 0.0011 - val_loss: 5.5134\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - val_loss: 5.5134\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - val_loss: 5.5134\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 861us/step - loss: 0.0000e+00 - val_loss: 5.5134\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 844us/step - loss: 0.0000e+00 - val_loss: 5.5134\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - val_loss: 5.5134\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - val_loss: 5.5134\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - val_loss: 5.5134\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 917us/step - loss: 0.0000e+00 - val_loss: 5.5134\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 900us/step - loss: 0.0000e+00 - val_loss: 5.5134\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 892us/step - loss: 0.0000e+00 - val_loss: 5.5134\n",
      "36/36 [==============================] - 0s 646us/step - loss: 5.5134\n",
      "--- Starting trial: run-35\n",
      "{'learning_rate': 0.0074077570838147234, 'optimizer': 'sgd', 'whether_dropout': True, 'dropout': 0.21330922623585152, 'num_units': 27, 'activation': 'relu', 'hidden_layer_number': 2}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 1s 1ms/step - loss: 0.2514 - val_loss: 0.2016\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.2084\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 745us/step - loss: 0.0231 - val_loss: 0.2295\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 795us/step - loss: 0.0145 - val_loss: 0.2481\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 669us/step - loss: 0.0103 - val_loss: 0.2635\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 671us/step - loss: 0.0081 - val_loss: 0.2766\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.2879\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 917us/step - loss: 0.0052 - val_loss: 0.2975\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 778us/step - loss: 0.0046 - val_loss: 0.3063\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 700us/step - loss: 0.0042 - val_loss: 0.3144\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 758us/step - loss: 0.0035 - val_loss: 0.3215\n",
      "36/36 [==============================] - 0s 518us/step - loss: 0.2021\n",
      "--- Starting trial: run-36\n",
      "{'learning_rate': 0.02943839581826807, 'optimizer': 'sgd', 'whether_dropout': True, 'dropout': 0.16631886422802453, 'num_units': 27, 'activation': 'relu', 'hidden_layer_number': 3}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 855us/step - loss: 0.0519 - val_loss: 0.2723\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.3183\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0032 - val_loss: 0.3473\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 854us/step - loss: 0.0022 - val_loss: 0.3682\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 678us/step - loss: 0.0017 - val_loss: 0.3846\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 671us/step - loss: 0.0013 - val_loss: 0.3981\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 706us/step - loss: 0.0010 - val_loss: 0.4092\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 649us/step - loss: 9.1190e-04 - val_loss: 0.4188\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 8.2383e-04 - val_loss: 0.4278\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 868us/step - loss: 7.1900e-04 - val_loss: 0.4357\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 654us/step - loss: 6.6738e-04 - val_loss: 0.4430\n",
      "36/36 [==============================] - 0s 737us/step - loss: 0.2734\n",
      "--- Starting trial: run-37\n",
      "{'learning_rate': 0.0010322553883650217, 'optimizer': 'sgd', 'whether_dropout': False, 'dropout': 0.14397411241183553, 'num_units': 68, 'activation': 'relu', 'hidden_layer_number': 1}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 850us/step - loss: 0.5879 - val_loss: 0.4658\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 985us/step - loss: 0.3441 - val_loss: 0.3249\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 921us/step - loss: 0.2190 - val_loss: 0.2568\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.1499 - val_loss: 0.2235\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 875us/step - loss: 0.1091 - val_loss: 0.2072\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 742us/step - loss: 0.0835 - val_loss: 0.1997\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 673us/step - loss: 0.0664 - val_loss: 0.1969\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 663us/step - loss: 0.0545 - val_loss: 0.1967\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 683us/step - loss: 0.0457 - val_loss: 0.1979\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 948us/step - loss: 0.0392 - val_loss: 0.2000\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 924us/step - loss: 0.0340 - val_loss: 0.2025\n",
      "Epoch 12/100\n",
      "285/285 [==============================] - 0s 754us/step - loss: 0.0300 - val_loss: 0.2054\n",
      "Epoch 13/100\n",
      "285/285 [==============================] - 0s 905us/step - loss: 0.0267 - val_loss: 0.2083\n",
      "Epoch 14/100\n",
      "285/285 [==============================] - 0s 668us/step - loss: 0.0240 - val_loss: 0.2114\n",
      "Epoch 15/100\n",
      "285/285 [==============================] - 0s 708us/step - loss: 0.0218 - val_loss: 0.2144\n",
      "Epoch 16/100\n",
      "285/285 [==============================] - 0s 992us/step - loss: 0.0199 - val_loss: 0.2174\n",
      "Epoch 17/100\n",
      "285/285 [==============================] - 0s 980us/step - loss: 0.0182 - val_loss: 0.2203\n",
      "Epoch 18/100\n",
      "285/285 [==============================] - 0s 662us/step - loss: 0.0168 - val_loss: 0.2232\n",
      "36/36 [==============================] - 0s 556us/step - loss: 0.1972\n",
      "--- Starting trial: run-38\n",
      "{'learning_rate': 0.004887314761730563, 'optimizer': 'sgd', 'whether_dropout': False, 'dropout': 0.29742885262797153, 'num_units': 27, 'activation': 'sigmoid', 'hidden_layer_number': 1}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0891 - val_loss: 0.1969\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 976us/step - loss: 0.0434 - val_loss: 0.2004\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0284 - val_loss: 0.2080\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0210 - val_loss: 0.2157\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 961us/step - loss: 0.0166 - val_loss: 0.2228\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 762us/step - loss: 0.0137 - val_loss: 0.2292\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 721us/step - loss: 0.0117 - val_loss: 0.2350\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 679us/step - loss: 0.0101 - val_loss: 0.2402\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 671us/step - loss: 0.0089 - val_loss: 0.2451\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 683us/step - loss: 0.0080 - val_loss: 0.2495\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 731us/step - loss: 0.0072 - val_loss: 0.2536\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1979\n",
      "--- Starting trial: run-39\n",
      "{'learning_rate': 0.04521645884500582, 'optimizer': 'sgd', 'whether_dropout': False, 'dropout': 0.2548327208781046, 'num_units': 27, 'activation': 'sigmoid', 'hidden_layer_number': 2}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 1s 1ms/step - loss: 0.0518 - val_loss: 0.2416\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.2739\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 949us/step - loss: 0.0034 - val_loss: 0.2940\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 720us/step - loss: 0.0024 - val_loss: 0.3086\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 686us/step - loss: 0.0018 - val_loss: 0.3200\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0015 - val_loss: 0.3294\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 870us/step - loss: 0.0012 - val_loss: 0.3373\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 803us/step - loss: 0.0011 - val_loss: 0.3443\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 693us/step - loss: 9.2007e-04 - val_loss: 0.3504\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 770us/step - loss: 8.1762e-04 - val_loss: 0.3559\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 666us/step - loss: 7.3525e-04 - val_loss: 0.3609\n",
      "36/36 [==============================] - 0s 472us/step - loss: 0.2413\n",
      "--- Starting trial: run-40\n",
      "{'learning_rate': 0.004753482673245415, 'optimizer': 'sgd', 'whether_dropout': False, 'dropout': 0.28583333724547044, 'num_units': 34, 'activation': 'sigmoid', 'hidden_layer_number': 2}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 1s 1ms/step - loss: 0.1295 - val_loss: 0.1993\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0460 - val_loss: 0.2012\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 844us/step - loss: 0.0279 - val_loss: 0.2097\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 762us/step - loss: 0.0199 - val_loss: 0.2182\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 702us/step - loss: 0.0154 - val_loss: 0.2259\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 688us/step - loss: 0.0126 - val_loss: 0.2327\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 995us/step - loss: 0.0106 - val_loss: 0.2388\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 953us/step - loss: 0.0092 - val_loss: 0.2443\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 899us/step - loss: 0.0081 - val_loss: 0.2493\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 790us/step - loss: 0.0072 - val_loss: 0.2539\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 751us/step - loss: 0.0065 - val_loss: 0.2581\n",
      "36/36 [==============================] - 0s 559us/step - loss: 0.1987\n",
      "--- Starting trial: run-41\n",
      "{'learning_rate': 0.001227413574151663, 'optimizer': 'adam', 'whether_dropout': False, 'dropout': 0.1785114322075035, 'num_units': 34, 'activation': 'sigmoid', 'hidden_layer_number': 3}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 0.1189 - val_loss: 0.2272\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 0.0098 - val_loss: 0.2695\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 958us/step - loss: 0.0042 - val_loss: 0.2989\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0024 - val_loss: 0.3214\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 973us/step - loss: 0.0015 - val_loss: 0.3398\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.3555\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 7.9478e-04 - val_loss: 0.3693\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 6.0525e-04 - val_loss: 0.3818\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 925us/step - loss: 4.7253e-04 - val_loss: 0.3933\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 868us/step - loss: 3.7600e-04 - val_loss: 0.4040\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 849us/step - loss: 3.0367e-04 - val_loss: 0.4140\n",
      "36/36 [==============================] - 0s 555us/step - loss: 0.2296\n",
      "--- Starting trial: run-42\n",
      "{'learning_rate': 0.006879123083100537, 'optimizer': 'sgd', 'whether_dropout': False, 'dropout': 0.1901689474881616, 'num_units': 34, 'activation': 'sigmoid', 'hidden_layer_number': 2}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 1s 1ms/step - loss: 0.0843 - val_loss: 0.1965\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0292 - val_loss: 0.2090\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 859us/step - loss: 0.0177 - val_loss: 0.2213\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 752us/step - loss: 0.0127 - val_loss: 0.2318\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 727us/step - loss: 0.0099 - val_loss: 0.2406\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 708us/step - loss: 0.0081 - val_loss: 0.2483\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 701us/step - loss: 0.0068 - val_loss: 0.2549\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.2609\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 993us/step - loss: 0.0052 - val_loss: 0.2662\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 900us/step - loss: 0.0046 - val_loss: 0.2710\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 926us/step - loss: 0.0042 - val_loss: 0.2754\n",
      "36/36 [==============================] - 0s 544us/step - loss: 0.1960\n",
      "--- Starting trial: run-43\n",
      "{'learning_rate': 0.053583301488607474, 'optimizer': 'sgd', 'whether_dropout': True, 'dropout': 0.15998963845996567, 'num_units': 45, 'activation': 'sigmoid', 'hidden_layer_number': 3}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 925us/step - loss: 0.0267 - val_loss: 0.2725\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 964us/step - loss: 0.0032 - val_loss: 0.3054\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 0.0019 - val_loss: 0.3252\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.3395\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 741us/step - loss: 0.0010 - val_loss: 0.3506\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 722us/step - loss: 8.2180e-04 - val_loss: 0.3597\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 732us/step - loss: 6.8981e-04 - val_loss: 0.3674\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 699us/step - loss: 5.9426e-04 - val_loss: 0.3742\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 5.2387e-04 - val_loss: 0.3801\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 955us/step - loss: 4.6819e-04 - val_loss: 0.3854\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 892us/step - loss: 4.2098e-04 - val_loss: 0.3903\n",
      "36/36 [==============================] - 0s 524us/step - loss: 0.2713\n",
      "--- Starting trial: run-44\n",
      "{'learning_rate': 0.0059562472212459, 'optimizer': 'adam', 'whether_dropout': False, 'dropout': 0.27931088490293604, 'num_units': 45, 'activation': 'relu', 'hidden_layer_number': 3}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.5570\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 3.3154e-05 - val_loss: 0.6303\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 2ms/step - loss: 1.1395e-05 - val_loss: 0.6790\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 5.5178e-06 - val_loss: 0.7152\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 895us/step - loss: 3.1749e-06 - val_loss: 0.7444\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 909us/step - loss: 2.0325e-06 - val_loss: 0.7689\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 825us/step - loss: 1.3892e-06 - val_loss: 0.7902\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 9.9511e-07 - val_loss: 0.8092\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 887us/step - loss: 7.3676e-07 - val_loss: 0.8266\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 826us/step - loss: 5.5984e-07 - val_loss: 0.8428\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 734us/step - loss: 4.3380e-07 - val_loss: 0.8578\n",
      "36/36 [==============================] - 0s 474us/step - loss: 0.5685\n",
      "--- Starting trial: run-45\n",
      "{'learning_rate': 0.0034827201210574244, 'optimizer': 'sgd', 'whether_dropout': True, 'dropout': 0.14581041250231272, 'num_units': 68, 'activation': 'sigmoid', 'hidden_layer_number': 2}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 956us/step - loss: 0.2735 - val_loss: 0.1987\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 757us/step - loss: 0.0430 - val_loss: 0.2032\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0238 - val_loss: 0.2145\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0165 - val_loss: 0.2248\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 709us/step - loss: 0.0126 - val_loss: 0.2335\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 766us/step - loss: 0.0102 - val_loss: 0.2411\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 664us/step - loss: 0.0085 - val_loss: 0.2478\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 661us/step - loss: 0.0073 - val_loss: 0.2537\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 683us/step - loss: 0.0064 - val_loss: 0.2590\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0057 - val_loss: 0.2638\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 777us/step - loss: 0.0052 - val_loss: 0.2681\n",
      "36/36 [==============================] - 0s 453us/step - loss: 0.1984\n",
      "--- Starting trial: run-46\n",
      "{'learning_rate': 0.32718316057324676, 'optimizer': 'sgd', 'whether_dropout': True, 'dropout': 0.27571126043482896, 'num_units': 27, 'activation': 'sigmoid', 'hidden_layer_number': 3}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 911us/step - loss: 0.0106 - val_loss: 0.3470\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 774us/step - loss: 7.1917e-04 - val_loss: 0.3829\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 4.1426e-04 - val_loss: 0.4042\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 838us/step - loss: 2.9022e-04 - val_loss: 0.4193\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 669us/step - loss: 2.2321e-04 - val_loss: 0.4311\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 1.8096e-04 - val_loss: 0.4408\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 749us/step - loss: 1.5239e-04 - val_loss: 0.4489\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 725us/step - loss: 1.2986e-04 - val_loss: 0.4560\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 657us/step - loss: 1.1553e-04 - val_loss: 0.4622\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 706us/step - loss: 1.0251e-04 - val_loss: 0.4678\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 674us/step - loss: 9.2138e-05 - val_loss: 0.4729\n",
      "36/36 [==============================] - 0s 525us/step - loss: 0.3463\n",
      "--- Starting trial: run-47\n",
      "{'learning_rate': 0.3738515995308471, 'optimizer': 'adam', 'whether_dropout': False, 'dropout': 0.12925919706247435, 'num_units': 34, 'activation': 'relu', 'hidden_layer_number': 1}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 1s 1ms/step - loss: 0.0025 - val_loss: 43.5501\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - val_loss: 43.5501\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 963us/step - loss: 0.0000e+00 - val_loss: 43.5501\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 821us/step - loss: 0.0000e+00 - val_loss: 43.5501\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - val_loss: 43.5501\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 936us/step - loss: 0.0000e+00 - val_loss: 43.5501\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 941us/step - loss: 0.0000e+00 - val_loss: 43.5501\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 729us/step - loss: 0.0000e+00 - val_loss: 43.5501\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 777us/step - loss: 0.0000e+00 - val_loss: 43.5501\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 718us/step - loss: 0.0000e+00 - val_loss: 43.5501\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 739us/step - loss: 0.0000e+00 - val_loss: 43.5501\n",
      "36/36 [==============================] - 0s 498us/step - loss: 44.7113\n",
      "--- Starting trial: run-48\n",
      "{'learning_rate': 0.041476567352464674, 'optimizer': 'adam', 'whether_dropout': False, 'dropout': 0.13566984684872613, 'num_units': 27, 'activation': 'sigmoid', 'hidden_layer_number': 3}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 1s 1ms/step - loss: 0.0032 - val_loss: 0.5287\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 1.9783e-05 - val_loss: 0.5482\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 817us/step - loss: 1.3530e-05 - val_loss: 0.5669\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 776us/step - loss: 9.5004e-06 - val_loss: 0.5837\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 737us/step - loss: 6.9011e-06 - val_loss: 0.5988\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 726us/step - loss: 5.1675e-06 - val_loss: 0.6126\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 3.9666e-06 - val_loss: 0.6251\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 946us/step - loss: 3.1061e-06 - val_loss: 0.6368\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 825us/step - loss: 2.4709e-06 - val_loss: 0.6478\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 836us/step - loss: 1.9910e-06 - val_loss: 0.6582\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 754us/step - loss: 1.6212e-06 - val_loss: 0.6682\n",
      "36/36 [==============================] - 0s 455us/step - loss: 0.5297\n",
      "--- Starting trial: run-49\n",
      "{'learning_rate': 0.0023690253620430547, 'optimizer': 'adam', 'whether_dropout': True, 'dropout': 0.2556890655621875, 'num_units': 45, 'activation': 'relu', 'hidden_layer_number': 1}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 1s 1ms/step - loss: 0.0271 - val_loss: 0.4959\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 3.0237e-04 - val_loss: 0.5941\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 913us/step - loss: 1.1174e-04 - val_loss: 0.6550\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 853us/step - loss: 6.7683e-05 - val_loss: 0.7043\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 759us/step - loss: 3.0882e-05 - val_loss: 0.7384\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 817us/step - loss: 4.2680e-05 - val_loss: 0.7781\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 2.0470e-05 - val_loss: 0.8073\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 845us/step - loss: 1.7955e-05 - val_loss: 0.8345\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 794us/step - loss: 1.2851e-05 - val_loss: 0.8611\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 750us/step - loss: 9.9244e-06 - val_loss: 0.8859\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 743us/step - loss: 5.8610e-06 - val_loss: 0.9059\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5060\n",
      "--- Starting trial: run-50\n",
      "{'learning_rate': 0.0011460408317515913, 'optimizer': 'sgd', 'whether_dropout': False, 'dropout': 0.10610581134582647, 'num_units': 68, 'activation': 'sigmoid', 'hidden_layer_number': 2}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 0.2574 - val_loss: 0.2325\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.1075 - val_loss: 0.1976\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 859us/step - loss: 0.0665 - val_loss: 0.1910\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 762us/step - loss: 0.0478 - val_loss: 0.1915\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 666us/step - loss: 0.0372 - val_loss: 0.1942\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0304 - val_loss: 0.1976\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 795us/step - loss: 0.0257 - val_loss: 0.2013\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 701us/step - loss: 0.0222 - val_loss: 0.2049\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 725us/step - loss: 0.0196 - val_loss: 0.2085\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 658us/step - loss: 0.0175 - val_loss: 0.2119\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 655us/step - loss: 0.0158 - val_loss: 0.2151\n",
      "Epoch 12/100\n",
      "285/285 [==============================] - 0s 658us/step - loss: 0.0144 - val_loss: 0.2182\n",
      "Epoch 13/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0132 - val_loss: 0.2211\n",
      "36/36 [==============================] - 0s 799us/step - loss: 0.1903\n",
      "--- Starting trial: run-51\n",
      "{'learning_rate': 0.005640470366715252, 'optimizer': 'adam', 'whether_dropout': False, 'dropout': 0.20704163855792007, 'num_units': 68, 'activation': 'relu', 'hidden_layer_number': 2}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 981us/step - loss: 0.0114 - val_loss: 0.5949\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 957us/step - loss: 2.0134e-05 - val_loss: 0.6516\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 8.5910e-06 - val_loss: 0.6918\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 877us/step - loss: 4.6549e-06 - val_loss: 0.7227\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 2.8668e-06 - val_loss: 0.7483\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 1.9176e-06 - val_loss: 0.7702\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 853us/step - loss: 1.3530e-06 - val_loss: 0.7895\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 759us/step - loss: 9.9227e-07 - val_loss: 0.8068\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 749us/step - loss: 7.4842e-07 - val_loss: 0.8228\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 751us/step - loss: 5.7711e-07 - val_loss: 0.8377\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 4.5290e-07 - val_loss: 0.8516\n",
      "36/36 [==============================] - 0s 580us/step - loss: 0.6156\n",
      "--- Starting trial: run-52\n",
      "{'learning_rate': 0.0014084280682562303, 'optimizer': 'sgd', 'whether_dropout': True, 'dropout': 0.26346107084138815, 'num_units': 68, 'activation': 'sigmoid', 'hidden_layer_number': 2}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 921us/step - loss: 0.3644 - val_loss: 0.2421\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 725us/step - loss: 0.1052 - val_loss: 0.2009\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 759us/step - loss: 0.0599 - val_loss: 0.1965\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 861us/step - loss: 0.0416 - val_loss: 0.1990\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 706us/step - loss: 0.0317 - val_loss: 0.2033\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 737us/step - loss: 0.0256 - val_loss: 0.2079\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0215 - val_loss: 0.2124\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 862us/step - loss: 0.0185 - val_loss: 0.2168\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 700us/step - loss: 0.0162 - val_loss: 0.2209\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 682us/step - loss: 0.0144 - val_loss: 0.2247\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 699us/step - loss: 0.0130 - val_loss: 0.2283\n",
      "Epoch 12/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0118 - val_loss: 0.2317\n",
      "Epoch 13/100\n",
      "285/285 [==============================] - 0s 841us/step - loss: 0.0108 - val_loss: 0.2349\n",
      "36/36 [==============================] - 0s 477us/step - loss: 0.1968\n",
      "--- Starting trial: run-53\n",
      "{'learning_rate': 0.03591056932499208, 'optimizer': 'sgd', 'whether_dropout': False, 'dropout': 0.20720456350210534, 'num_units': 27, 'activation': 'sigmoid', 'hidden_layer_number': 3}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 860us/step - loss: 0.0487 - val_loss: 0.2360\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 710us/step - loss: 0.0077 - val_loss: 0.2659\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 967us/step - loss: 0.0044 - val_loss: 0.2849\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 839us/step - loss: 0.0030 - val_loss: 0.2989\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 810us/step - loss: 0.0023 - val_loss: 0.3099\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0019 - val_loss: 0.3190\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 687us/step - loss: 0.0016 - val_loss: 0.3267\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 705us/step - loss: 0.0013 - val_loss: 0.3334\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 643us/step - loss: 0.0012 - val_loss: 0.3394\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 647us/step - loss: 0.0010 - val_loss: 0.3447\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 9.4413e-04 - val_loss: 0.3495\n",
      "36/36 [==============================] - 0s 654us/step - loss: 0.2362\n",
      "--- Starting trial: run-54\n",
      "{'learning_rate': 0.8885970049897385, 'optimizer': 'adam', 'whether_dropout': False, 'dropout': 0.1470967990083472, 'num_units': 45, 'activation': 'relu', 'hidden_layer_number': 1}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 974us/step - loss: 0.0024 - val_loss: 267.3339\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 868us/step - loss: 0.0000e+00 - val_loss: 267.3339\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - val_loss: 267.3339\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 782us/step - loss: 0.0000e+00 - val_loss: 267.3339\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 772us/step - loss: 0.0000e+00 - val_loss: 267.3339\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 805us/step - loss: 0.0000e+00 - val_loss: 267.3339\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - val_loss: 267.3339\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 916us/step - loss: 0.0000e+00 - val_loss: 267.3339\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 869us/step - loss: 0.0000e+00 - val_loss: 267.3339\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 776us/step - loss: 0.0000e+00 - val_loss: 267.3339\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 740us/step - loss: 0.0000e+00 - val_loss: 267.3339\n",
      "36/36 [==============================] - 0s 436us/step - loss: 274.0829\n",
      "--- Starting trial: run-55\n",
      "{'learning_rate': 0.01307594364717629, 'optimizer': 'adam', 'whether_dropout': False, 'dropout': 0.14569640261958822, 'num_units': 27, 'activation': 'relu', 'hidden_layer_number': 1}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 1s 1ms/step - loss: 0.0066 - val_loss: 1.0251\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 9.9839e-09 - val_loss: 1.1197\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 882us/step - loss: 3.0910e-09 - val_loss: 1.1666\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 793us/step - loss: 1.6046e-09 - val_loss: 1.1989\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 831us/step - loss: 1.0046e-09 - val_loss: 1.2235\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 6.9816e-10 - val_loss: 1.2434\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 815us/step - loss: 5.1645e-10 - val_loss: 1.2602\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 824us/step - loss: 3.9947e-10 - val_loss: 1.2744\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 736us/step - loss: 3.1946e-10 - val_loss: 1.2875\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 724us/step - loss: 2.6213e-10 - val_loss: 1.2990\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 721us/step - loss: 2.1944e-10 - val_loss: 1.3092\n",
      "36/36 [==============================] - 0s 505us/step - loss: 1.0527\n",
      "--- Starting trial: run-56\n",
      "{'learning_rate': 0.003881418829014591, 'optimizer': 'adam', 'whether_dropout': True, 'dropout': 0.21757880370042743, 'num_units': 68, 'activation': 'sigmoid', 'hidden_layer_number': 1}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 1s 1ms/step - loss: 0.0409 - val_loss: 0.3313\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 971us/step - loss: 0.0010 - val_loss: 0.3838\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 916us/step - loss: 4.3767e-04 - val_loss: 0.4170\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 867us/step - loss: 2.4881e-04 - val_loss: 0.4416\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 916us/step - loss: 1.5867e-04 - val_loss: 0.4613\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 1.1195e-04 - val_loss: 0.4781\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 8.1568e-05 - val_loss: 0.4928\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 967us/step - loss: 6.0910e-05 - val_loss: 0.5057\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 794us/step - loss: 4.8311e-05 - val_loss: 0.5178\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 796us/step - loss: 3.8825e-05 - val_loss: 0.5292\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 769us/step - loss: 3.0488e-05 - val_loss: 0.5396\n",
      "36/36 [==============================] - 0s 492us/step - loss: 0.3339\n",
      "--- Starting trial: run-57\n",
      "{'learning_rate': 0.18787297907329922, 'optimizer': 'sgd', 'whether_dropout': True, 'dropout': 0.16930227581068585, 'num_units': 27, 'activation': 'sigmoid', 'hidden_layer_number': 2}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 0.0127 - val_loss: 0.3108\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.3455\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 849us/step - loss: 7.2596e-04 - val_loss: 0.3662\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 679us/step - loss: 5.0649e-04 - val_loss: 0.3809\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 690us/step - loss: 3.8791e-04 - val_loss: 0.3924\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 3.1412e-04 - val_loss: 0.4018\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 818us/step - loss: 2.6315e-04 - val_loss: 0.4098\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 677us/step - loss: 2.2486e-04 - val_loss: 0.4166\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 737us/step - loss: 1.9854e-04 - val_loss: 0.4227\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 665us/step - loss: 1.7722e-04 - val_loss: 0.4282\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 678us/step - loss: 1.5957e-04 - val_loss: 0.4331\n",
      "36/36 [==============================] - 0s 493us/step - loss: 0.3113\n",
      "--- Starting trial: run-58\n",
      "{'learning_rate': 0.016025876160704416, 'optimizer': 'adam', 'whether_dropout': False, 'dropout': 0.15331821583726363, 'num_units': 68, 'activation': 'sigmoid', 'hidden_layer_number': 1}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0055 - val_loss: 0.5178\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 3.0858e-05 - val_loss: 0.5397\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 887us/step - loss: 2.0459e-05 - val_loss: 0.5598\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 754us/step - loss: 1.4115e-05 - val_loss: 0.5774\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 744us/step - loss: 1.0148e-05 - val_loss: 0.5931\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 733us/step - loss: 7.5521e-06 - val_loss: 0.6072\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 748us/step - loss: 5.7748e-06 - val_loss: 0.6200\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 720us/step - loss: 4.5124e-06 - val_loss: 0.6319\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 741us/step - loss: 3.5862e-06 - val_loss: 0.6429\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 728us/step - loss: 2.8903e-06 - val_loss: 0.6534\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 995us/step - loss: 2.3563e-06 - val_loss: 0.6632\n",
      "36/36 [==============================] - 0s 795us/step - loss: 0.5212\n",
      "--- Starting trial: run-59\n",
      "{'learning_rate': 0.5361004430734125, 'optimizer': 'sgd', 'whether_dropout': False, 'dropout': 0.18311034933477405, 'num_units': 68, 'activation': 'sigmoid', 'hidden_layer_number': 1}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 878us/step - loss: 0.0030 - val_loss: 0.3987\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 731us/step - loss: 2.1746e-04 - val_loss: 0.4328\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 906us/step - loss: 1.2703e-04 - val_loss: 0.4529\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 8.9831e-05 - val_loss: 0.4673\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 6.9451e-05 - val_loss: 0.4785\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 890us/step - loss: 5.6578e-05 - val_loss: 0.4876\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 664us/step - loss: 4.7711e-05 - val_loss: 0.4954\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 741us/step - loss: 4.1229e-05 - val_loss: 0.5021\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 648us/step - loss: 3.6286e-05 - val_loss: 0.5080\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 781us/step - loss: 3.2393e-05 - val_loss: 0.5134\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 689us/step - loss: 2.9249e-05 - val_loss: 0.5182\n",
      "36/36 [==============================] - 0s 477us/step - loss: 0.3995\n",
      "--- Starting trial: run-60\n",
      "{'learning_rate': 0.01179306286162873, 'optimizer': 'sgd', 'whether_dropout': True, 'dropout': 0.24670036805150974, 'num_units': 68, 'activation': 'sigmoid', 'hidden_layer_number': 3}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0842 - val_loss: 0.2175\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 862us/step - loss: 0.0115 - val_loss: 0.2444\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 896us/step - loss: 0.0066 - val_loss: 0.2622\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 713us/step - loss: 0.0046 - val_loss: 0.2754\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 663us/step - loss: 0.0036 - val_loss: 0.2858\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 668us/step - loss: 0.0029 - val_loss: 0.2945\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0024 - val_loss: 0.3019\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 812us/step - loss: 0.0021 - val_loss: 0.3083\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 707us/step - loss: 0.0019 - val_loss: 0.3140\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 675us/step - loss: 0.0017 - val_loss: 0.3191\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 738us/step - loss: 0.0015 - val_loss: 0.3238\n",
      "36/36 [==============================] - 0s 604us/step - loss: 0.2183\n",
      "--- Starting trial: run-61\n",
      "{'learning_rate': 0.46234633568697847, 'optimizer': 'sgd', 'whether_dropout': True, 'dropout': 0.24836375626988502, 'num_units': 45, 'activation': 'sigmoid', 'hidden_layer_number': 3}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0044 - val_loss: 0.3760\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 3.5562e-04 - val_loss: 0.4110\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 2.0603e-04 - val_loss: 0.4316\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 737us/step - loss: 1.4519e-04 - val_loss: 0.4464\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 661us/step - loss: 1.1149e-04 - val_loss: 0.4578\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 707us/step - loss: 9.0958e-05 - val_loss: 0.4672\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 7.6492e-05 - val_loss: 0.4751\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 687us/step - loss: 6.5636e-05 - val_loss: 0.4820\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 857us/step - loss: 5.8117e-05 - val_loss: 0.4881\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 651us/step - loss: 5.1866e-05 - val_loss: 0.4935\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 662us/step - loss: 4.6596e-05 - val_loss: 0.4984\n",
      "36/36 [==============================] - 0s 461us/step - loss: 0.3756\n",
      "--- Starting trial: run-62\n",
      "{'learning_rate': 0.2983776581050556, 'optimizer': 'sgd', 'whether_dropout': False, 'dropout': 0.1686253423878689, 'num_units': 45, 'activation': 'sigmoid', 'hidden_layer_number': 2}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 990us/step - loss: 0.0074 - val_loss: 0.3444\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 779us/step - loss: 5.7463e-04 - val_loss: 0.3789\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 859us/step - loss: 3.3068e-04 - val_loss: 0.3993\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 725us/step - loss: 2.3205e-04 - val_loss: 0.4138\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 633us/step - loss: 1.7848e-04 - val_loss: 0.4251\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 651us/step - loss: 1.4484e-04 - val_loss: 0.4343\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 642us/step - loss: 1.2176e-04 - val_loss: 0.4421\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 662us/step - loss: 1.0495e-04 - val_loss: 0.4489\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 897us/step - loss: 9.2177e-05 - val_loss: 0.4549\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 908us/step - loss: 8.2137e-05 - val_loss: 0.4603\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 680us/step - loss: 7.4042e-05 - val_loss: 0.4651\n",
      "36/36 [==============================] - 0s 581us/step - loss: 0.3453\n",
      "--- Starting trial: run-63\n",
      "{'learning_rate': 0.014683861394107538, 'optimizer': 'adam', 'whether_dropout': False, 'dropout': 0.27220540984475594, 'num_units': 34, 'activation': 'sigmoid', 'hidden_layer_number': 3}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 943us/step - loss: 0.0097 - val_loss: 0.4147\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 768us/step - loss: 1.6499e-04 - val_loss: 0.4603\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 996us/step - loss: 7.6983e-05 - val_loss: 0.4901\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 4.5383e-05 - val_loss: 0.5124\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 992us/step - loss: 3.0062e-05 - val_loss: 0.5305\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 747us/step - loss: 2.1343e-05 - val_loss: 0.5460\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 759us/step - loss: 1.5859e-05 - val_loss: 0.5596\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 749us/step - loss: 1.2168e-05 - val_loss: 0.5719\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 734us/step - loss: 9.5566e-06 - val_loss: 0.5833\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 7.6422e-06 - val_loss: 0.5938\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 880us/step - loss: 6.1977e-06 - val_loss: 0.6038\n",
      "36/36 [==============================] - 0s 555us/step - loss: 0.4163\n",
      "--- Starting trial: run-64\n",
      "{'learning_rate': 0.0033633045220215745, 'optimizer': 'adam', 'whether_dropout': False, 'dropout': 0.10025593610066585, 'num_units': 27, 'activation': 'relu', 'hidden_layer_number': 3}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 908us/step - loss: 0.0348 - val_loss: 0.4521\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 872us/step - loss: 1.5253e-04 - val_loss: 0.5315\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 5.1493e-05 - val_loss: 0.5792\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 2.5622e-05 - val_loss: 0.6137\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 848us/step - loss: 1.5135e-05 - val_loss: 0.6414\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 868us/step - loss: 9.8775e-06 - val_loss: 0.6646\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 732us/step - loss: 6.8603e-06 - val_loss: 0.6848\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 768us/step - loss: 4.9781e-06 - val_loss: 0.7028\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 782us/step - loss: 3.7265e-06 - val_loss: 0.7193\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 2.8572e-06 - val_loss: 0.7346\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 885us/step - loss: 2.2329e-06 - val_loss: 0.7488\n",
      "36/36 [==============================] - 0s 454us/step - loss: 0.4682\n",
      "--- Starting trial: run-65\n",
      "{'learning_rate': 0.7670500523028955, 'optimizer': 'sgd', 'whether_dropout': True, 'dropout': 0.16894879153667164, 'num_units': 68, 'activation': 'relu', 'hidden_layer_number': 2}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 856us/step - loss: 0.0044 - val_loss: 0.4878\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 680us/step - loss: 1.6107e-04 - val_loss: 0.5385\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 788us/step - loss: 9.8821e-05 - val_loss: 0.5705\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 2ms/step - loss: 6.3474e-05 - val_loss: 0.5925\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 764us/step - loss: 5.2367e-05 - val_loss: 0.6106\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 727us/step - loss: 4.4622e-05 - val_loss: 0.6255\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 666us/step - loss: 3.1586e-05 - val_loss: 0.6368\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 663us/step - loss: 3.0119e-05 - val_loss: 0.6473\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 680us/step - loss: 2.6851e-05 - val_loss: 0.6569\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 2.3472e-05 - val_loss: 0.6655\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 817us/step - loss: 2.0863e-05 - val_loss: 0.6731\n",
      "36/36 [==============================] - 0s 486us/step - loss: 0.4910\n",
      "--- Starting trial: run-66\n",
      "{'learning_rate': 0.4364395732233059, 'optimizer': 'sgd', 'whether_dropout': True, 'dropout': 0.11682802873389726, 'num_units': 34, 'activation': 'sigmoid', 'hidden_layer_number': 3}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 837us/step - loss: 0.0075 - val_loss: 0.3607\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 684us/step - loss: 4.6379e-04 - val_loss: 0.3958\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 781us/step - loss: 2.6694e-04 - val_loss: 0.4165\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 2ms/step - loss: 1.8729e-04 - val_loss: 0.4314\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 786us/step - loss: 1.4371e-04 - val_loss: 0.4429\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 704us/step - loss: 1.1648e-04 - val_loss: 0.4523\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 666us/step - loss: 9.7503e-05 - val_loss: 0.4603\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 638us/step - loss: 8.3701e-05 - val_loss: 0.4671\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 682us/step - loss: 7.4108e-05 - val_loss: 0.4732\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 6.5883e-05 - val_loss: 0.4787\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 930us/step - loss: 5.9347e-05 - val_loss: 0.4837\n",
      "36/36 [==============================] - 0s 507us/step - loss: 0.3625\n",
      "--- Starting trial: run-67\n",
      "{'learning_rate': 0.6038924850817771, 'optimizer': 'adam', 'whether_dropout': False, 'dropout': 0.16358850148665416, 'num_units': 34, 'activation': 'relu', 'hidden_layer_number': 3}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 920us/step - loss: 0.0032 - val_loss: 97.0880\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 934us/step - loss: 0.0000e+00 - val_loss: 97.0880\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - val_loss: 97.0880\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - val_loss: 97.0880\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 843us/step - loss: 0.0000e+00 - val_loss: 97.0880\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 815us/step - loss: 0.0000e+00 - val_loss: 97.0880\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 749us/step - loss: 0.0000e+00 - val_loss: 97.0880\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 766us/step - loss: 0.0000e+00 - val_loss: 97.0880\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - val_loss: 97.0880\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 954us/step - loss: 0.0000e+00 - val_loss: 97.0880\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 842us/step - loss: 0.0000e+00 - val_loss: 97.0880\n",
      "36/36 [==============================] - 0s 474us/step - loss: 99.2733\n",
      "--- Starting trial: run-68\n",
      "{'learning_rate': 0.016534939586837074, 'optimizer': 'sgd', 'whether_dropout': False, 'dropout': 0.16527664803227288, 'num_units': 45, 'activation': 'relu', 'hidden_layer_number': 3}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 807us/step - loss: 0.1560 - val_loss: 0.2263\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 763us/step - loss: 0.0133 - val_loss: 0.2670\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.2938\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 832us/step - loss: 0.0040 - val_loss: 0.3132\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 706us/step - loss: 0.0028 - val_loss: 0.3284\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 641us/step - loss: 0.0022 - val_loss: 0.3407\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 646us/step - loss: 0.0018 - val_loss: 0.3511\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 654us/step - loss: 0.0015 - val_loss: 0.3601\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 664us/step - loss: 0.0013 - val_loss: 0.3681\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.3752\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 789us/step - loss: 9.9205e-04 - val_loss: 0.3816\n",
      "36/36 [==============================] - 0s 468us/step - loss: 0.2278\n",
      "--- Starting trial: run-69\n",
      "{'learning_rate': 0.005931613570349265, 'optimizer': 'adam', 'whether_dropout': False, 'dropout': 0.28256127399023256, 'num_units': 45, 'activation': 'relu', 'hidden_layer_number': 3}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 944us/step - loss: 0.0189 - val_loss: 0.5050\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 792us/step - loss: 7.3879e-05 - val_loss: 0.5677\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 923us/step - loss: 3.0140e-05 - val_loss: 0.6082\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 1.6341e-05 - val_loss: 0.6385\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 1.0157e-05 - val_loss: 0.6633\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 879us/step - loss: 6.8568e-06 - val_loss: 0.6846\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 856us/step - loss: 4.7718e-06 - val_loss: 0.7049\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 758us/step - loss: 3.1404e-06 - val_loss: 0.7310\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 752us/step - loss: 1.8201e-06 - val_loss: 0.7644\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 9.8618e-07 - val_loss: 0.8000\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 940us/step - loss: 5.5199e-07 - val_loss: 0.8321\n",
      "36/36 [==============================] - 0s 515us/step - loss: 0.5124\n",
      "--- Starting trial: run-70\n",
      "{'learning_rate': 0.507569289261735, 'optimizer': 'sgd', 'whether_dropout': True, 'dropout': 0.2809967063116481, 'num_units': 27, 'activation': 'relu', 'hidden_layer_number': 3}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 854us/step - loss: 0.0083 - val_loss: 0.4816\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 887us/step - loss: 3.1693e-04 - val_loss: 0.5375\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 931us/step - loss: 1.7356e-04 - val_loss: 0.5703\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 1.2907e-04 - val_loss: 0.5944\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 878us/step - loss: 9.0816e-05 - val_loss: 0.6127\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 812us/step - loss: 8.5603e-05 - val_loss: 0.6287\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 759us/step - loss: 5.9547e-05 - val_loss: 0.6411\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 662us/step - loss: 5.8731e-05 - val_loss: 0.6525\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 808us/step - loss: 5.0308e-05 - val_loss: 0.6627\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 5.2237e-05 - val_loss: 0.6725\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 701us/step - loss: 3.6767e-05 - val_loss: 0.6804\n",
      "36/36 [==============================] - 0s 561us/step - loss: 0.4848\n",
      "--- Starting trial: run-71\n",
      "{'learning_rate': 0.09260898183928852, 'optimizer': 'sgd', 'whether_dropout': True, 'dropout': 0.2695212482955841, 'num_units': 68, 'activation': 'sigmoid', 'hidden_layer_number': 3}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 839us/step - loss: 0.0136 - val_loss: 0.3081\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 720us/step - loss: 0.0013 - val_loss: 0.3418\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 7.7684e-04 - val_loss: 0.3618\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 944us/step - loss: 5.4888e-04 - val_loss: 0.3761\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 753us/step - loss: 4.2406e-04 - val_loss: 0.3872\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 672us/step - loss: 3.4509e-04 - val_loss: 0.3963\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 667us/step - loss: 2.9130e-04 - val_loss: 0.4040\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 658us/step - loss: 2.5056e-04 - val_loss: 0.4107\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 682us/step - loss: 2.2154e-04 - val_loss: 0.4166\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 1.9784e-04 - val_loss: 0.4219\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 717us/step - loss: 1.7820e-04 - val_loss: 0.4267\n",
      "36/36 [==============================] - 0s 601us/step - loss: 0.3085\n",
      "--- Starting trial: run-72\n",
      "{'learning_rate': 0.14909127785426582, 'optimizer': 'sgd', 'whether_dropout': False, 'dropout': 0.268262299338181, 'num_units': 68, 'activation': 'relu', 'hidden_layer_number': 2}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 889us/step - loss: 0.0148 - val_loss: 0.3644\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 722us/step - loss: 7.2043e-04 - val_loss: 0.4092\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 2ms/step - loss: 3.8684e-04 - val_loss: 0.4355\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 938us/step - loss: 2.6146e-04 - val_loss: 0.4541\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 747us/step - loss: 1.9599e-04 - val_loss: 0.4685\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 658us/step - loss: 1.5615e-04 - val_loss: 0.4803\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 685us/step - loss: 1.2938e-04 - val_loss: 0.4903\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 665us/step - loss: 1.1024e-04 - val_loss: 0.4989\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 9.5853e-05 - val_loss: 0.5065\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 786us/step - loss: 8.4684e-05 - val_loss: 0.5134\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 655us/step - loss: 7.5773e-05 - val_loss: 0.5195\n",
      "36/36 [==============================] - 0s 643us/step - loss: 0.3690\n",
      "--- Starting trial: run-73\n",
      "{'learning_rate': 0.008390739361948205, 'optimizer': 'adam', 'whether_dropout': True, 'dropout': 0.2776470335140818, 'num_units': 45, 'activation': 'relu', 'hidden_layer_number': 2}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 966us/step - loss: 0.0112 - val_loss: 0.7272\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 864us/step - loss: 3.4339e-05 - val_loss: 0.8566\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 1.1949e-05 - val_loss: 0.9499\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 8.0320e-06 - val_loss: 1.0360\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 1.9692e-06 - val_loss: 1.0755\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 768us/step - loss: 7.5340e-06 - val_loss: 1.1718\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 1.7252e-06 - val_loss: 1.2146\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 943us/step - loss: 1.8588e-06 - val_loss: 1.2609\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 744us/step - loss: 9.6804e-07 - val_loss: 1.2937\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 757us/step - loss: 1.2874e-06 - val_loss: 1.3421\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 732us/step - loss: 2.5721e-07 - val_loss: 1.3605\n",
      "36/36 [==============================] - 0s 484us/step - loss: 0.7445\n",
      "--- Starting trial: run-74\n",
      "{'learning_rate': 0.002912834185550962, 'optimizer': 'adam', 'whether_dropout': False, 'dropout': 0.21629851931865118, 'num_units': 68, 'activation': 'relu', 'hidden_layer_number': 1}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0181 - val_loss: 0.6033\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 1.7053e-05 - val_loss: 0.6925\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 5.4319e-06 - val_loss: 0.7433\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 2.6808e-06 - val_loss: 0.7794\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 857us/step - loss: 1.5812e-06 - val_loss: 0.8082\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 810us/step - loss: 1.0355e-06 - val_loss: 0.8323\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 733us/step - loss: 7.2193e-07 - val_loss: 0.8531\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 744us/step - loss: 5.2573e-07 - val_loss: 0.8716\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 3.9511e-07 - val_loss: 0.8886\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 915us/step - loss: 3.0412e-07 - val_loss: 0.9044\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 825us/step - loss: 2.3854e-07 - val_loss: 0.9190\n",
      "36/36 [==============================] - 0s 530us/step - loss: 0.6226\n",
      "--- Starting trial: run-75\n",
      "{'learning_rate': 0.04760626394521947, 'optimizer': 'sgd', 'whether_dropout': False, 'dropout': 0.26570884567762854, 'num_units': 27, 'activation': 'relu', 'hidden_layer_number': 1}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 845us/step - loss: 0.0603 - val_loss: 0.2892\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 693us/step - loss: 0.0033 - val_loss: 0.3356\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 0.0017 - val_loss: 0.3628\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 838us/step - loss: 0.0011 - val_loss: 0.3822\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 675us/step - loss: 8.0008e-04 - val_loss: 0.3971\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 617us/step - loss: 6.2991e-04 - val_loss: 0.4092\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 645us/step - loss: 5.1733e-04 - val_loss: 0.4195\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 611us/step - loss: 4.3765e-04 - val_loss: 0.4284\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 624us/step - loss: 3.7827e-04 - val_loss: 0.4362\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 3.3256e-04 - val_loss: 0.4432\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 708us/step - loss: 2.9633e-04 - val_loss: 0.4495\n",
      "36/36 [==============================] - 0s 483us/step - loss: 0.2942\n",
      "--- Starting trial: run-76\n",
      "{'learning_rate': 0.14407034066144414, 'optimizer': 'sgd', 'whether_dropout': False, 'dropout': 0.20828082202840958, 'num_units': 45, 'activation': 'sigmoid', 'hidden_layer_number': 1}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 847us/step - loss: 0.0103 - val_loss: 0.3184\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 867us/step - loss: 0.0012 - val_loss: 0.3530\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 773us/step - loss: 6.9137e-04 - val_loss: 0.3736\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 4.8514e-04 - val_loss: 0.3882\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 820us/step - loss: 3.7317e-04 - val_loss: 0.3996\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 656us/step - loss: 3.0283e-04 - val_loss: 0.4090\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 742us/step - loss: 2.5458e-04 - val_loss: 0.4169\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 641us/step - loss: 2.1944e-04 - val_loss: 0.4237\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 972us/step - loss: 1.9272e-04 - val_loss: 0.4298\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 920us/step - loss: 1.7172e-04 - val_loss: 0.4352\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 688us/step - loss: 1.5479e-04 - val_loss: 0.4401\n",
      "36/36 [==============================] - 0s 520us/step - loss: 0.3168\n",
      "--- Starting trial: run-77\n",
      "{'learning_rate': 0.3030651593027368, 'optimizer': 'adam', 'whether_dropout': False, 'dropout': 0.22270329070470074, 'num_units': 68, 'activation': 'relu', 'hidden_layer_number': 2}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0024 - val_loss: 51.8273\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - val_loss: 51.8273\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - val_loss: 51.8273\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - val_loss: 51.8273\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 819us/step - loss: 0.0000e+00 - val_loss: 51.8273\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 743us/step - loss: 0.0000e+00 - val_loss: 51.8273\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 749us/step - loss: 0.0000e+00 - val_loss: 51.8273\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - val_loss: 51.8273\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 962us/step - loss: 0.0000e+00 - val_loss: 51.8273\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 760us/step - loss: 0.0000e+00 - val_loss: 51.8273\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 748us/step - loss: 0.0000e+00 - val_loss: 51.8273\n",
      "36/36 [==============================] - 0s 490us/step - loss: 53.2739\n",
      "--- Starting trial: run-78\n",
      "{'learning_rate': 0.007685102570948405, 'optimizer': 'adam', 'whether_dropout': True, 'dropout': 0.1246143690333619, 'num_units': 68, 'activation': 'relu', 'hidden_layer_number': 2}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 942us/step - loss: 0.0099 - val_loss: 0.6959\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 8.4648e-06 - val_loss: 0.8106\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 4.4688e-06 - val_loss: 0.9136\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 990us/step - loss: 1.2868e-06 - val_loss: 0.9714\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 826us/step - loss: 6.3527e-07 - val_loss: 1.0171\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 790us/step - loss: 3.6102e-07 - val_loss: 1.0505\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 762us/step - loss: 2.9937e-07 - val_loss: 1.0828\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 1.4950e-07 - val_loss: 1.1056\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 893us/step - loss: 1.9836e-07 - val_loss: 1.1392\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 845us/step - loss: 1.2317e-07 - val_loss: 1.1632\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 759us/step - loss: 1.2333e-07 - val_loss: 1.1977\n",
      "36/36 [==============================] - 0s 510us/step - loss: 0.7199\n",
      "--- Starting trial: run-79\n",
      "{'learning_rate': 0.2944689809180534, 'optimizer': 'sgd', 'whether_dropout': False, 'dropout': 0.18075936851421584, 'num_units': 68, 'activation': 'relu', 'hidden_layer_number': 3}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 881us/step - loss: 0.0079 - val_loss: 0.3968\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 2ms/step - loss: 3.3673e-04 - val_loss: 0.4415\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 1.8317e-04 - val_loss: 0.4676\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 761us/step - loss: 1.2463e-04 - val_loss: 0.4862\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 654us/step - loss: 9.3798e-05 - val_loss: 0.5005\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 659us/step - loss: 7.4961e-05 - val_loss: 0.5123\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 6.2259e-05 - val_loss: 0.5222\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 821us/step - loss: 5.3143e-05 - val_loss: 0.5308\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 729us/step - loss: 4.6282e-05 - val_loss: 0.5384\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 654us/step - loss: 4.0945e-05 - val_loss: 0.5452\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 690us/step - loss: 3.6679e-05 - val_loss: 0.5514\n",
      "36/36 [==============================] - 0s 481us/step - loss: 0.4065\n",
      "--- Starting trial: run-80\n",
      "{'learning_rate': 0.0011910412533411047, 'optimizer': 'sgd', 'whether_dropout': True, 'dropout': 0.27555823774040034, 'num_units': 68, 'activation': 'relu', 'hidden_layer_number': 1}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 958us/step - loss: 0.4964 - val_loss: 0.3954\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.2568 - val_loss: 0.2784\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.1602 - val_loss: 0.2319\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 871us/step - loss: 0.1118 - val_loss: 0.2122\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 678us/step - loss: 0.0832 - val_loss: 0.2043\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 684us/step - loss: 0.0658 - val_loss: 0.2020\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0540 - val_loss: 0.2025\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 809us/step - loss: 0.0445 - val_loss: 0.2045\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 667us/step - loss: 0.0392 - val_loss: 0.2074\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 748us/step - loss: 0.0341 - val_loss: 0.2107\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 657us/step - loss: 0.0300 - val_loss: 0.2143\n",
      "Epoch 12/100\n",
      "285/285 [==============================] - 0s 720us/step - loss: 0.0269 - val_loss: 0.2179\n",
      "Epoch 13/100\n",
      "285/285 [==============================] - 0s 641us/step - loss: 0.0241 - val_loss: 0.2216\n",
      "Epoch 14/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0225 - val_loss: 0.2252\n",
      "Epoch 15/100\n",
      "285/285 [==============================] - 0s 730us/step - loss: 0.0201 - val_loss: 0.2287\n",
      "Epoch 16/100\n",
      "285/285 [==============================] - 0s 811us/step - loss: 0.0185 - val_loss: 0.2322\n",
      "36/36 [==============================] - 0s 451us/step - loss: 0.2057\n",
      "--- Starting trial: run-81\n",
      "{'learning_rate': 0.028051922267271594, 'optimizer': 'adam', 'whether_dropout': False, 'dropout': 0.28809070711492957, 'num_units': 68, 'activation': 'relu', 'hidden_layer_number': 1}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 933us/step - loss: 0.0033 - val_loss: 1.9869\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 946us/step - loss: 4.8533e-13 - val_loss: 1.9869\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 4.8530e-13 - val_loss: 1.9869\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 870us/step - loss: 4.8527e-13 - val_loss: 1.9869\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 865us/step - loss: 4.8523e-13 - val_loss: 1.9869\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 4.8519e-13 - val_loss: 1.9869\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 943us/step - loss: 4.8514e-13 - val_loss: 1.9869\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 759us/step - loss: 4.8510e-13 - val_loss: 1.9869\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 727us/step - loss: 4.8505e-13 - val_loss: 1.9869\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 748us/step - loss: 4.8500e-13 - val_loss: 1.9869\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 730us/step - loss: 4.8496e-13 - val_loss: 1.9869\n",
      "36/36 [==============================] - 0s 486us/step - loss: 2.0486\n",
      "--- Starting trial: run-82\n",
      "{'learning_rate': 0.18100553966044045, 'optimizer': 'adam', 'whether_dropout': False, 'dropout': 0.17530785174793756, 'num_units': 45, 'activation': 'sigmoid', 'hidden_layer_number': 2}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 1s 1ms/step - loss: 0.0043 - val_loss: 1.3645\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 9.2997e-13 - val_loss: 1.3645\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 9.2997e-13 - val_loss: 1.3645\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 784us/step - loss: 9.2997e-13 - val_loss: 1.3645\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 808us/step - loss: 9.2997e-13 - val_loss: 1.3645\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 9.2997e-13 - val_loss: 1.3645\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 9.2997e-13 - val_loss: 1.3645\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 856us/step - loss: 9.2997e-13 - val_loss: 1.3645\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 794us/step - loss: 9.2997e-13 - val_loss: 1.3645\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 806us/step - loss: 9.2997e-13 - val_loss: 1.3645\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 786us/step - loss: 9.2997e-13 - val_loss: 1.3645\n",
      "36/36 [==============================] - 0s 472us/step - loss: 1.3645\n",
      "--- Starting trial: run-83\n",
      "{'learning_rate': 0.347153006760165, 'optimizer': 'sgd', 'whether_dropout': False, 'dropout': 0.1042067590813378, 'num_units': 68, 'activation': 'relu', 'hidden_layer_number': 3}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 1s 1ms/step - loss: 0.0071 - val_loss: 0.4112\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 794us/step - loss: 2.8127e-04 - val_loss: 0.4561\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 898us/step - loss: 1.5331e-04 - val_loss: 0.4824\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 691us/step - loss: 1.0440e-04 - val_loss: 0.5011\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 806us/step - loss: 7.8616e-05 - val_loss: 0.5155\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 960us/step - loss: 6.2855e-05 - val_loss: 0.5274\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 744us/step - loss: 5.2209e-05 - val_loss: 0.5373\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 728us/step - loss: 4.4578e-05 - val_loss: 0.5460\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 646us/step - loss: 3.8832e-05 - val_loss: 0.5536\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 641us/step - loss: 3.4359e-05 - val_loss: 0.5604\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 651us/step - loss: 3.0784e-05 - val_loss: 0.5666\n",
      "36/36 [==============================] - 0s 475us/step - loss: 0.4098\n",
      "--- Starting trial: run-84\n",
      "{'learning_rate': 0.4534920035992712, 'optimizer': 'adam', 'whether_dropout': True, 'dropout': 0.18872263132529427, 'num_units': 27, 'activation': 'relu', 'hidden_layer_number': 1}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 1s 1ms/step - loss: 0.0028 - val_loss: 44.3442\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - val_loss: 44.3442\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 894us/step - loss: 0.0000e+00 - val_loss: 44.3442\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - val_loss: 44.3442\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 944us/step - loss: 0.0000e+00 - val_loss: 44.3442\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 856us/step - loss: 0.0000e+00 - val_loss: 44.3442\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 737us/step - loss: 0.0000e+00 - val_loss: 44.3442\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 743us/step - loss: 0.0000e+00 - val_loss: 44.3442\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 742us/step - loss: 0.0000e+00 - val_loss: 44.3442\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - val_loss: 44.3442\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 841us/step - loss: 0.0000e+00 - val_loss: 44.3442\n",
      "36/36 [==============================] - 0s 586us/step - loss: 45.5327\n",
      "--- Starting trial: run-85\n",
      "{'learning_rate': 0.1338505435786426, 'optimizer': 'adam', 'whether_dropout': True, 'dropout': 0.12309876213553664, 'num_units': 34, 'activation': 'sigmoid', 'hidden_layer_number': 1}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 0.0056 - val_loss: 0.7093\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 5.4550e-07 - val_loss: 0.7102\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 918us/step - loss: 5.3399e-07 - val_loss: 0.7115\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 852us/step - loss: 5.1863e-07 - val_loss: 0.7132\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 5.0078e-07 - val_loss: 0.7153\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 951us/step - loss: 4.7968e-07 - val_loss: 0.7179\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 787us/step - loss: 4.5608e-07 - val_loss: 0.7211\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 776us/step - loss: 4.3005e-07 - val_loss: 0.7247\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 900us/step - loss: 4.0103e-07 - val_loss: 0.7289\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 851us/step - loss: 3.7062e-07 - val_loss: 0.7338\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 786us/step - loss: 3.3757e-07 - val_loss: 0.7393\n",
      "36/36 [==============================] - 0s 485us/step - loss: 0.7098\n",
      "--- Starting trial: run-86\n",
      "{'learning_rate': 0.9001435035411669, 'optimizer': 'adam', 'whether_dropout': True, 'dropout': 0.12353793604418123, 'num_units': 45, 'activation': 'sigmoid', 'hidden_layer_number': 3}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 1s 3ms/step - loss: 0.0036 - val_loss: 6.0553\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 894us/step - loss: 0.0000e+00 - val_loss: 6.0553\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 784us/step - loss: 0.0000e+00 - val_loss: 6.0553\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 764us/step - loss: 0.0000e+00 - val_loss: 6.0553\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - val_loss: 6.0553\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 887us/step - loss: 0.0000e+00 - val_loss: 6.0553\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 850us/step - loss: 0.0000e+00 - val_loss: 6.0553\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 745us/step - loss: 0.0000e+00 - val_loss: 6.0553\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 747us/step - loss: 0.0000e+00 - val_loss: 6.0553\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 779us/step - loss: 0.0000e+00 - val_loss: 6.0553\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - val_loss: 6.0553\n",
      "36/36 [==============================] - 0s 733us/step - loss: 6.0553\n",
      "--- Starting trial: run-87\n",
      "{'learning_rate': 0.05024844635966394, 'optimizer': 'sgd', 'whether_dropout': False, 'dropout': 0.268254191353848, 'num_units': 27, 'activation': 'relu', 'hidden_layer_number': 3}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 846us/step - loss: 0.0375 - val_loss: 0.2926\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 770us/step - loss: 0.0028 - val_loss: 0.3376\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 748us/step - loss: 0.0014 - val_loss: 0.3643\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 886us/step - loss: 9.4836e-04 - val_loss: 0.3832\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 7.0220e-04 - val_loss: 0.3978\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 996us/step - loss: 5.5450e-04 - val_loss: 0.4098\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 799us/step - loss: 4.5619e-04 - val_loss: 0.4199\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 652us/step - loss: 3.8650e-04 - val_loss: 0.4286\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 648us/step - loss: 3.3450e-04 - val_loss: 0.4363\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 2.9435e-04 - val_loss: 0.4432\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 841us/step - loss: 2.6249e-04 - val_loss: 0.4495\n",
      "36/36 [==============================] - 0s 482us/step - loss: 0.2996\n",
      "--- Starting trial: run-88\n",
      "{'learning_rate': 0.2839303405592472, 'optimizer': 'adam', 'whether_dropout': True, 'dropout': 0.10962731204061316, 'num_units': 27, 'activation': 'relu', 'hidden_layer_number': 3}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 932us/step - loss: 0.0028 - val_loss: 16.5755\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 955us/step - loss: 0.0000e+00 - val_loss: 16.5755\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 979us/step - loss: 0.0000e+00 - val_loss: 16.5755\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 839us/step - loss: 0.0000e+00 - val_loss: 16.5755\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 733us/step - loss: 0.0000e+00 - val_loss: 16.5755\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - val_loss: 16.5755\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 810us/step - loss: 0.0000e+00 - val_loss: 16.5755\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 871us/step - loss: 0.0000e+00 - val_loss: 16.5755\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 768us/step - loss: 0.0000e+00 - val_loss: 16.5755\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - val_loss: 16.5755\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 978us/step - loss: 0.0000e+00 - val_loss: 16.5755\n",
      "36/36 [==============================] - 0s 641us/step - loss: 16.9888\n",
      "--- Starting trial: run-89\n",
      "{'learning_rate': 0.965709800584807, 'optimizer': 'sgd', 'whether_dropout': False, 'dropout': 0.15007645964368518, 'num_units': 27, 'activation': 'relu', 'hidden_layer_number': 2}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 874us/step - loss: 0.0047 - val_loss: 0.4702\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 772us/step - loss: 9.5671e-05 - val_loss: 0.5153\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 973us/step - loss: 5.2741e-05 - val_loss: 0.5417\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 875us/step - loss: 3.6126e-05 - val_loss: 0.5606\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 2.7292e-05 - val_loss: 0.57523e-0\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 798us/step - loss: 2.1877e-05 - val_loss: 0.5871\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 705us/step - loss: 1.8208e-05 - val_loss: 0.5972\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 664us/step - loss: 1.5569e-05 - val_loss: 0.6059\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 691us/step - loss: 1.3577e-05 - val_loss: 0.6136\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 947us/step - loss: 1.2024e-05 - val_loss: 0.6205\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 832us/step - loss: 1.0781e-05 - val_loss: 0.6267\n",
      "36/36 [==============================] - 0s 537us/step - loss: 0.4696\n",
      "--- Starting trial: run-90\n",
      "{'learning_rate': 0.1687448670673701, 'optimizer': 'sgd', 'whether_dropout': False, 'dropout': 0.21640169104283274, 'num_units': 34, 'activation': 'sigmoid', 'hidden_layer_number': 3}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 807us/step - loss: 0.0153 - val_loss: 0.3178\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 733us/step - loss: 0.0013 - val_loss: 0.3531\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 780us/step - loss: 7.4533e-04 - val_loss: 0.3740\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 5.2009e-04 - val_loss: 0.3889\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 3.9846e-04 - val_loss: 0.4005\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 763us/step - loss: 3.2239e-04 - val_loss: 0.4100\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 698us/step - loss: 2.7037e-04 - val_loss: 0.4180\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 667us/step - loss: 2.3260e-04 - val_loss: 0.4250\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 2.0391e-04 - val_loss: 0.4311\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 781us/step - loss: 1.8142e-04 - val_loss: 0.4366\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 641us/step - loss: 1.6332e-04 - val_loss: 0.4416\n",
      "36/36 [==============================] - 0s 550us/step - loss: 0.3172\n",
      "--- Starting trial: run-91\n",
      "{'learning_rate': 0.0011298571621346635, 'optimizer': 'adam', 'whether_dropout': False, 'dropout': 0.20712703304455432, 'num_units': 68, 'activation': 'sigmoid', 'hidden_layer_number': 1}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 945us/step - loss: 0.0421 - val_loss: 0.2780\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 951us/step - loss: 0.0027 - val_loss: 0.3298\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.3627\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 6.2744e-04 - val_loss: 0.3871\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 802us/step - loss: 4.0315e-04 - val_loss: 0.4068\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 755us/step - loss: 2.8004e-04 - val_loss: 0.4236\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 741us/step - loss: 2.0460e-04 - val_loss: 0.4383\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 1.5486e-04 - val_loss: 0.4515\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 942us/step - loss: 1.2024e-04 - val_loss: 0.4636\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 759us/step - loss: 9.5223e-05 - val_loss: 0.4748\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 748us/step - loss: 7.6575e-05 - val_loss: 0.4853\n",
      "36/36 [==============================] - 0s 500us/step - loss: 0.2801\n",
      "--- Starting trial: run-92\n",
      "{'learning_rate': 0.001231660891942008, 'optimizer': 'sgd', 'whether_dropout': False, 'dropout': 0.2975306537237523, 'num_units': 34, 'activation': 'relu', 'hidden_layer_number': 3}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 950us/step - loss: 0.6837 - val_loss: 0.5266\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 987us/step - loss: 0.3970 - val_loss: 0.3606\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.2506 - val_loss: 0.2769\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 895us/step - loss: 0.1678 - val_loss: 0.2347\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 686us/step - loss: 0.1188 - val_loss: 0.2138\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 721us/step - loss: 0.0884 - val_loss: 0.2042\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0686 - val_loss: 0.2005\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 748us/step - loss: 0.0550 - val_loss: 0.2000\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 769us/step - loss: 0.0454 - val_loss: 0.2014\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 652us/step - loss: 0.0382 - val_loss: 0.2038\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 650us/step - loss: 0.0328 - val_loss: 0.2068\n",
      "Epoch 12/100\n",
      "285/285 [==============================] - 0s 644us/step - loss: 0.0286 - val_loss: 0.2100\n",
      "Epoch 13/100\n",
      "285/285 [==============================] - 0s 626us/step - loss: 0.0252 - val_loss: 0.2134\n",
      "Epoch 14/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0224 - val_loss: 0.2168\n",
      "Epoch 15/100\n",
      "285/285 [==============================] - 0s 859us/step - loss: 0.0202 - val_loss: 0.2202\n",
      "Epoch 16/100\n",
      "285/285 [==============================] - 0s 635us/step - loss: 0.0183 - val_loss: 0.2236\n",
      "Epoch 17/100\n",
      "285/285 [==============================] - 0s 696us/step - loss: 0.0167 - val_loss: 0.2269\n",
      "Epoch 18/100\n",
      "285/285 [==============================] - 0s 651us/step - loss: 0.0153 - val_loss: 0.2300\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1991\n",
      "--- Starting trial: run-93\n",
      "{'learning_rate': 0.2517277803940719, 'optimizer': 'sgd', 'whether_dropout': False, 'dropout': 0.12919621682946045, 'num_units': 45, 'activation': 'sigmoid', 'hidden_layer_number': 3}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 908us/step - loss: 0.0078 - val_loss: 0.3420\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 656us/step - loss: 6.8834e-04 - val_loss: 0.3766\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 693us/step - loss: 3.9584e-04 - val_loss: 0.3970\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 742us/step - loss: 2.7767e-04 - val_loss: 0.4115\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 840us/step - loss: 2.1350e-04 - val_loss: 0.4228\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 1.7322e-04 - val_loss: 0.4321\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 786us/step - loss: 1.4560e-04 - val_loss: 0.4399\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 647us/step - loss: 1.2549e-04 - val_loss: 0.4467\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 750us/step - loss: 1.1020e-04 - val_loss: 0.4527\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 661us/step - loss: 9.8184e-05 - val_loss: 0.4580\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 664us/step - loss: 8.8498e-05 - val_loss: 0.4629\n",
      "36/36 [==============================] - 0s 486us/step - loss: 0.3425\n",
      "--- Starting trial: run-94\n",
      "{'learning_rate': 0.058281200572107235, 'optimizer': 'sgd', 'whether_dropout': False, 'dropout': 0.2893370230969769, 'num_units': 68, 'activation': 'relu', 'hidden_layer_number': 3}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 964us/step - loss: 0.0327 - val_loss: 0.3104\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 814us/step - loss: 0.0021 - val_loss: 0.3541\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 917us/step - loss: 0.0011 - val_loss: 0.3799\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 788us/step - loss: 7.6174e-04 - val_loss: 0.3984\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 678us/step - loss: 5.6855e-04 - val_loss: 0.4127\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 4.5167e-04 - val_loss: 0.4244\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 793us/step - loss: 3.7338e-04 - val_loss: 0.4342\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 700us/step - loss: 3.1758e-04 - val_loss: 0.4428\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 702us/step - loss: 2.7573e-04 - val_loss: 0.4504\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 2.4332e-04 - val_loss: 0.4572\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 829us/step - loss: 2.1749e-04 - val_loss: 0.4633\n",
      "36/36 [==============================] - 0s 488us/step - loss: 0.3112\n",
      "--- Starting trial: run-95\n",
      "{'learning_rate': 0.10721576302211444, 'optimizer': 'sgd', 'whether_dropout': True, 'dropout': 0.18444018033469578, 'num_units': 68, 'activation': 'sigmoid', 'hidden_layer_number': 2}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0167 - val_loss: 0.3103\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.3443\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 861us/step - loss: 7.2281e-04 - val_loss: 0.3646\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 5.0830e-04 - val_loss: 0.3790\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 885us/step - loss: 3.9205e-04 - val_loss: 0.3902\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 768us/step - loss: 3.1905e-04 - val_loss: 0.3994\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 654us/step - loss: 2.6880e-04 - val_loss: 0.4071\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 2.3165e-04 - val_loss: 0.4139\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 2.0408e-04 - val_loss: 0.4198\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 690us/step - loss: 1.8212e-04 - val_loss: 0.4251\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 652us/step - loss: 1.6446e-04 - val_loss: 0.4299\n",
      "36/36 [==============================] - 0s 456us/step - loss: 0.3098\n",
      "--- Starting trial: run-96\n",
      "{'learning_rate': 0.022685877806136494, 'optimizer': 'adam', 'whether_dropout': True, 'dropout': 0.2947696485576423, 'num_units': 27, 'activation': 'relu', 'hidden_layer_number': 2}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 933us/step - loss: 0.0045 - val_loss: 1.0032\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 6.6502e-06 - val_loss: 1.0390\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 3.8533e-06 - val_loss: 1.0699\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 874us/step - loss: 7.5895e-06 - val_loss: 1.1264\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 770us/step - loss: 1.5320e-06 - val_loss: 1.1506\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 7.5363e-06 - val_loss: 1.2126\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 942us/step - loss: 4.0066e-06 - val_loss: 1.2572\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 788us/step - loss: 1.9318e-06 - val_loss: 1.2863\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 856us/step - loss: 1.2274e-06 - val_loss: 1.3096\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 740us/step - loss: 1.9102e-06 - val_loss: 1.3505\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 754us/step - loss: 3.7779e-07 - val_loss: 1.3666\n",
      "36/36 [==============================] - 0s 537us/step - loss: 1.0382\n",
      "--- Starting trial: run-97\n",
      "{'learning_rate': 0.14168758082543087, 'optimizer': 'adam', 'whether_dropout': True, 'dropout': 0.21734101631602087, 'num_units': 68, 'activation': 'sigmoid', 'hidden_layer_number': 2}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 1s 1ms/step - loss: 0.0026 - val_loss: 1.6216\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 969us/step - loss: 5.0296e-15 - val_loss: 1.6216\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 920us/step - loss: 5.0338e-15 - val_loss: 1.6216\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 788us/step - loss: 5.0350e-15 - val_loss: 1.6216\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 762us/step - loss: 5.0309e-15 - val_loss: 1.6216\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 788us/step - loss: 5.0372e-15 - val_loss: 1.6216\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 752us/step - loss: 5.0322e-15 - val_loss: 1.6216\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 795us/step - loss: 5.0326e-15 - val_loss: 1.6216\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 5.0318e-15 - val_loss: 1.6216\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 5.0368e-15 - val_loss: 1.6216\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 890us/step - loss: 5.0303e-15 - val_loss: 1.6216\n",
      "36/36 [==============================] - 0s 475us/step - loss: 1.6216\n",
      "--- Starting trial: run-98\n",
      "{'learning_rate': 0.005986533422459209, 'optimizer': 'sgd', 'whether_dropout': False, 'dropout': 0.2668652330670327, 'num_units': 27, 'activation': 'sigmoid', 'hidden_layer_number': 1}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 1s 1ms/step - loss: 0.4001 - val_loss: 0.2069\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 960us/step - loss: 0.0558 - val_loss: 0.2007\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 828us/step - loss: 0.0299 - val_loss: 0.2099\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 709us/step - loss: 0.0203 - val_loss: 0.2194\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 641us/step - loss: 0.0153 - val_loss: 0.2279\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 855us/step - loss: 0.0123 - val_loss: 0.2353\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0102 - val_loss: 0.2419\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 806us/step - loss: 0.0088 - val_loss: 0.2478\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 741us/step - loss: 0.0077 - val_loss: 0.2532\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 966us/step - loss: 0.0068 - val_loss: 0.2580\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 885us/step - loss: 0.0061 - val_loss: 0.2625\n",
      "Epoch 12/100\n",
      "285/285 [==============================] - 0s 744us/step - loss: 0.0055 - val_loss: 0.2666\n",
      "36/36 [==============================] - 0s 470us/step - loss: 0.2004\n",
      "--- Starting trial: run-99\n",
      "{'learning_rate': 0.0012158497974410272, 'optimizer': 'adam', 'whether_dropout': False, 'dropout': 0.17830298939672734, 'num_units': 68, 'activation': 'relu', 'hidden_layer_number': 1}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 944us/step - loss: 0.0454 - val_loss: 0.4131\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 933us/step - loss: 1.8040e-04 - val_loss: 0.5645\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 1.9914e-05 - val_loss: 0.6389\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 7.2141e-06 - val_loss: 0.6849\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 3.7084e-06 - val_loss: 0.7190\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 888us/step - loss: 2.2461e-06 - val_loss: 0.7465\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 828us/step - loss: 1.4865e-06 - val_loss: 0.7697\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 751us/step - loss: 1.0432e-06 - val_loss: 0.7900\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 7.6252e-07 - val_loss: 0.8085\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 975us/step - loss: 5.7463e-07 - val_loss: 0.8255\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 762us/step - loss: 4.4295e-07 - val_loss: 0.8411\n",
      "36/36 [==============================] - 0s 491us/step - loss: 0.4262\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(192)\n",
    "\n",
    "# 100 total sessions\n",
    "total_sessions = 100 #FIXME: change this to the number of sessions you want to run, and fix the issue in the metrics\n",
    "\n",
    "for session in range(total_sessions):\n",
    "    \n",
    "    # Create hyperparameters randomly\n",
    "    whether_dropout = HP_WHETHER_DROPOUT.domain.sample_uniform()\n",
    "    dropout_rate = HP_DROPOUT.domain.sample_uniform()\n",
    "    num_units = HP_NUM_UNITS.domain.sample_uniform()\n",
    "    optimizer = HP_OPTIMIZER.domain.sample_uniform()\n",
    "    activation = HP_ACTIVATION.domain.sample_uniform()\n",
    "    hidden_layer_number = HP_HIDDEN_LAYER_NUMBER.domain.sample_uniform()\n",
    "    \n",
    "    \n",
    "    r = -3*np.random.rand()\n",
    "    learning_rate = 10.0**r\n",
    "    \n",
    "    # Create a dictionary of hyperparameters\n",
    "    hparams = { HP_LEARNING_RATE: learning_rate,\n",
    "                HP_OPTIMIZER: optimizer,\n",
    "                HP_WHETHER_DROPOUT: whether_dropout,\n",
    "                HP_DROPOUT: dropout_rate,\n",
    "                HP_NUM_UNITS: num_units,\n",
    "                HP_ACTIVATION: activation,\n",
    "                HP_HIDDEN_LAYER_NUMBER: hidden_layer_number}\n",
    "    \n",
    "    # train the model with the chosen parameters\n",
    "    run_name = \"run-%d\" % session\n",
    "    print('--- Starting trial: %s' % run_name)\n",
    "    print({h.name: hparams[h] for h in hparams})\n",
    "    run('logs100/hparam_tuning/' + run_name, hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6007 (pid 27350), started 0:16:22 ago. (Use '!kill 27350' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-da2aea82fb2a7e0d\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-da2aea82fb2a7e0d\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4\n",
    "### Question\n",
    "The file \"SMOTE.ipynb\" explains the process in detail and shows how to change the dataset with an example. You can copy and adjust the code to make it work within your analysis. You can adjust the \"sampling_strategy\" parameters as you see fit, particularly if\n",
    "you want to fine-tune your model in part 5.\n",
    "\n",
    "### Principle\n",
    "In this part, we are going to try both oversampling and undersampling.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the procedure to process the data\n",
    "1. Split the raw data into train and test\n",
    "2. Fit the MinMaxScaler to train data and then apply the model to test data\n",
    "3. Oversample and undersample the train data\n",
    "4. Split the train data into train and validation data\n",
    "5. Show the data distribution before and after oversampling and undersampling\n",
    "\n",
    "The reason to do so is that we want to make sure that we want to make sure the training data and validation data is similar. And when we test our model, we tend to use real test data instead of the simulated test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Split the raw data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=192,test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Fit the MinMaxScaler to train data and then apply the model to test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Oversample and undersample the train data\n",
    "We will successively try to oversample the minority class to 10%, 30%,50% of the size of all datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oversampling\n",
    "# k_neighbors set to 20 to make sure that the result is more general \n",
    "over = imblearn.over_sampling.SMOTE(sampling_strategy=0.1, random_state = 483, k_neighbors=20)  \n",
    "X_over_synth_10, y_over_synth_10 = over.fit_resample(X_train, y_train)\n",
    "over = imblearn.over_sampling.SMOTE(sampling_strategy=0.5, random_state = 483, k_neighbors=20)\n",
    "X_over_synth_30, y_over_synth_30 = over.fit_resample(X_train, y_train)\n",
    "over = imblearn.over_sampling.SMOTE(sampling_strategy=1, random_state = 483, k_neighbors=20)\n",
    "X_over_synth_50, y_over_synth_50 = over.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of 1 in y_over_synth10: 0.09090909090909091\n",
      "Percentage of 1 in y_over_synth30: 0.3333333333333333\n",
      "Percentage of 1 in y_over_synth50: 0.5\n"
     ]
    }
   ],
   "source": [
    "print(\"Percentage of 1 in y_over_synth10:\", Counter(y_over_synth_10)[1]/len(y_over_synth_10))\n",
    "print(\"Percentage of 1 in y_over_synth30:\", Counter(y_over_synth_30)[1]/len(y_over_synth_30))\n",
    "print(\"Percentage of 1 in y_over_synth50:\", Counter(y_over_synth_50)[1]/len(y_over_synth_50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Undersampling\n",
    "We will successively try to undersample the minority class to 10%, 30%,50% of the size of majority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "under = imblearn.under_sampling.RandomUnderSampler(sampling_strategy=0.1, random_state = 483)  \n",
    "X_under_synth_10, y_under_synth_10 = under.fit_resample(X_train, y_train)\n",
    "under = imblearn.under_sampling.RandomUnderSampler(sampling_strategy=0.5, random_state = 483)\n",
    "X_under_synth_30, y_under_synth_30 = under.fit_resample(X_train, y_train)\n",
    "under = imblearn.under_sampling.RandomUnderSampler(sampling_strategy=1, random_state = 483)\n",
    "X_under_synth_50, y_under_synth_50 = under.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of 1 in y_under_synth_10: 0.09090909090909091\n",
      "Percentage of 1 in y_under_synth_30: 0.3333333333333333\n",
      "Percentage of 1 in y_under_synth_50: 0.5\n"
     ]
    }
   ],
   "source": [
    "print(\"Percentage of 1 in y_under_synth_10:\", Counter(y_under_synth_10)[1]/len(y_under_synth_10))\n",
    "print(\"Percentage of 1 in y_under_synth_30:\", Counter(y_under_synth_30)[1]/len(y_under_synth_30))\n",
    "print(\"Percentage of 1 in y_under_synth_50:\", Counter(y_under_synth_50)[1]/len(y_under_synth_50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fbf9b5b8fd0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# set plot xticks\n",
    "x = np.arange(0, len(y_over_synth_10), 1)\n",
    "plt.xticks(x, x)\n",
    "plt.subplot(1,2,1)\n",
    "plt.scatter(X_train[:, 2], X_train[:, 3], c=y_train, s=10, cmap=\"Accent_r\")\n",
    "plt.subplot(1,2,2)\n",
    "plt.scatter(X_under_synth_10[:, 2], X_under_synth_10[:, 3], c=y_under_synth_10, s=10, cmap=\"Accent_r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Split the train data into train and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_over_synth_10_train, X_over_synth_10_val, y_over_synth_10_train, y_over_synth_10_val = train_test_split(\n",
    "    X_over_synth_10, y_over_synth_10, random_state=192, test_size=0.25)\n",
    "X_over_synth_30_train, X_over_synth_30_val, y_over_synth_30_train, y_over_synth_30_val = train_test_split(\n",
    "    X_over_synth_30, y_over_synth_30, random_state=192, test_size=0.25)\n",
    "X_over_synth_50_train, X_over_synth_50_val, y_over_synth_50_train, y_over_synth_50_val = train_test_split(\n",
    "    X_over_synth_50, y_over_synth_50, random_state=192, test_size=0.25)\n",
    "X_under_synth_10_train, X_under_synth_10_val, y_under_synth_10_train, y_under_synth_10_val = train_test_split(\n",
    "    X_under_synth_10, y_under_synth_10, random_state=192, test_size=0.25)\n",
    "X_under_synth_30_train, X_under_synth_30_val, y_under_synth_30_train, y_under_synth_30_val = train_test_split(\n",
    "    X_under_synth_30, y_under_synth_30, random_state=192, test_size=0.25)\n",
    "X_under_synth_50_train, X_under_synth_50_val, y_under_synth_50_train, y_under_synth_50_val = train_test_split(\n",
    "    X_under_synth_50, y_under_synth_50, random_state=192, test_size=0.25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of X_over_synth_10_train is: 7433\n",
      "The length of X_over_synth_10_val is: 2478\n",
      "The length of X_over_synth_30_train is: 10136\n",
      "The length of X_over_synth_30_val is: 3379\n",
      "The length of X_over_synth_50_train is: 13515\n",
      "The length of X_over_synth_50_val is: 4505\n",
      "The length of X_under_synth_10_train is: 709\n",
      "The length of X_under_synth_10_val is: 237\n",
      "The length of X_under_synth_30_train is: 193\n",
      "The length of X_under_synth_30_val is: 65\n",
      "The length of X_under_synth_50_train is: 129\n",
      "The length of X_under_synth_50_val is: 43\n"
     ]
    }
   ],
   "source": [
    "print(\"The length of X_over_synth_10_train is:\", len(X_over_synth_10_train))\n",
    "print(\"The length of X_over_synth_10_val is:\", len(X_over_synth_10_val))\n",
    "print(\"The length of X_over_synth_30_train is:\", len(X_over_synth_30_train))\n",
    "print(\"The length of X_over_synth_30_val is:\", len(X_over_synth_30_val))\n",
    "print(\"The length of X_over_synth_50_train is:\", len(X_over_synth_50_train))\n",
    "print(\"The length of X_over_synth_50_val is:\", len(X_over_synth_50_val))\n",
    "print(\"The length of X_under_synth_10_train is:\", len(X_under_synth_10_train))\n",
    "print(\"The length of X_under_synth_10_val is:\", len(X_under_synth_10_val))\n",
    "print(\"The length of X_under_synth_30_train is:\", len(X_under_synth_30_train))\n",
    "print(\"The length of X_under_synth_30_val is:\", len(X_under_synth_30_val))\n",
    "print(\"The length of X_under_synth_50_train is:\", len(X_under_synth_50_train))\n",
    "print(\"The length of X_under_synth_50_val is:\", len(X_under_synth_50_val))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5\n",
    "### Question\n",
    " Create a new (deep) neural network and train it on your enhanced dataset. Use training and validation sets derived from the enhanced dataset to find a model with high accuracy. Evaluate your final model on a test set consisting only of original data. Again, record the accuracy and AUC. Briefly discuss the changes you would expect in the metrics and the actual changes you observe. Would you say that you are now doing better at identifying fraudulent claims?\n",
    "\n",
    "### Principle\n",
    "To simplify the problem, and save computational time, we will train the synthetic data to a very simple neural network, and then compare the performance of these dinstinct synthetic data.\n",
    "After doing this, we are going to select the best performance dataset and then we can use tunner to train the model for it.\n",
    "\n",
    "The neural network structure is as follows:\n",
    "1. Input layer\n",
    "2. 2 Hiiden layers, in which the number of neurons in each layer is equal to 60 and 'relu' function is used\n",
    "3. No dropout layer\n",
    "4. Output layer, with 'sigmoid' activation function.\n",
    "5. Optimizer: AdamOptimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a controlled model to compare the performance of the different sampling strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainModel:\n",
    "    def __init__(self, X_train, y_train, X_val=None, y_val=None,X_test=None,y_test=None, epochs=100,early_stopping:bool=False,patience:int=10):\n",
    "        tf.keras.backend.clear_session()\n",
    "        tf.random.set_seed(192)\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_val = X_val\n",
    "        self.y_val = y_val\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        self.epochs = epochs\n",
    "        self.early_stopping= early_stopping\n",
    "        self.patience = patience\n",
    "        self.simple_model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Dense(60, activation='relu'),\n",
    "            tf.keras.layers.Dense(60, activation='relu'),\n",
    "            tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "        ])\n",
    "\n",
    "    def compile(self):\n",
    "        self.simple_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    def fit(self): # We fit the model with train and validation data becasue validation data can tell us when to stop training\n",
    "        if self.early_stopping:\n",
    "            early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=self.patience, restore_best_weights=True) # set patience to 10 to accelerate the training\n",
    "            self.log = self.simple_model.fit(self.X_train, self.y_train,validation_data= (self.X_val, self.y_val),callbacks=[early_stopping_cb], epochs=self.epochs)\n",
    "        else:\n",
    "            self.log = self.simple_model.fit(self.X_train, self.y_train,validation_data= (self.X_val, self.y_val),epochs=self.epochs)\n",
    "\n",
    "    def evaluate(self): # evalute it on the test dataset, since we are going to predict the raw data like test one\n",
    "        loss = self.simple_model.evaluate(self.X_test, self.y_test)\n",
    "        x_test_predict = self.simple_model.predict(self.X_test)\n",
    "        # calculate the roc\n",
    "        roc_score = roc_auc_score(self.y_test, x_test_predict)\n",
    "        # calculate the accuracy suppose the threshold is 0.5\n",
    "        x_test_predict_binary = np.where(x_test_predict>0.5,1,0)\n",
    "        accuracy = accuracy_score(self.y_test, x_test_predict_binary)\n",
    "        # calculate the sensitivity\n",
    "        sensitivity = recall_score(self.y_test, x_test_predict_binary)\n",
    "        return {'loss': loss, 'accuracy': accuracy, 'sensitivity': sensitivity, 'roc': roc_score,'modle':self.simple_model}\n",
    "    \n",
    "    def draw_the_loss_curve(self):\n",
    "        # plt.plot(log.history['accuracy'],label = \"training accuracy\",color='green')\n",
    "        plt.plot(self.log.history['loss'],label = \"training loss\",color='darkgreen')\n",
    "        # plt.plot(log.history['val_accuracy'], label = \"validation accuracy\",color='grey')\n",
    "        plt.plot(self.log.history['val_loss'], label = \"validation loss\",color='darkblue')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    def run(self):\n",
    "        self.compile()\n",
    "        self.fit()\n",
    "        # self.draw_the_loss_curve()\n",
    "        return self.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, if we apply the model to the test data (real data), and select ROC as the metrics to select the sampling strategy, we can find that in the oversampling strategy, the ROC rate is higher than undersampling strategy. Since there is a slight difference between about 10%, 30% and 50% oversampling, we will use the 10% oversampling strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-09 10:17:32.369998: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "233/233 [==============================] - 1s 1ms/step - loss: 0.2513 - accuracy: 0.9080 - val_loss: 0.1673 - val_accuracy: 0.9124\n",
      "Epoch 2/100\n",
      "233/233 [==============================] - 0s 1ms/step - loss: 0.1440 - accuracy: 0.9346 - val_loss: 0.1103 - val_accuracy: 0.9572\n",
      "Epoch 3/100\n",
      "233/233 [==============================] - 0s 991us/step - loss: 0.1059 - accuracy: 0.9555 - val_loss: 0.0908 - val_accuracy: 0.9669\n",
      "Epoch 4/100\n",
      "233/233 [==============================] - 0s 973us/step - loss: 0.0817 - accuracy: 0.9684 - val_loss: 0.0703 - val_accuracy: 0.9734\n",
      "Epoch 5/100\n",
      "233/233 [==============================] - 0s 2ms/step - loss: 0.0668 - accuracy: 0.9742 - val_loss: 0.0644 - val_accuracy: 0.9754\n",
      "Epoch 6/100\n",
      "233/233 [==============================] - 0s 1ms/step - loss: 0.0566 - accuracy: 0.9794 - val_loss: 0.0533 - val_accuracy: 0.9806\n",
      "Epoch 7/100\n",
      "233/233 [==============================] - 0s 1ms/step - loss: 0.0501 - accuracy: 0.9817 - val_loss: 0.0455 - val_accuracy: 0.9839\n",
      "Epoch 8/100\n",
      "233/233 [==============================] - 0s 1ms/step - loss: 0.0437 - accuracy: 0.9835 - val_loss: 0.0560 - val_accuracy: 0.9790\n",
      "Epoch 9/100\n",
      "233/233 [==============================] - 0s 1ms/step - loss: 0.0407 - accuracy: 0.9840 - val_loss: 0.0477 - val_accuracy: 0.9831\n",
      "Epoch 10/100\n",
      "233/233 [==============================] - 0s 1ms/step - loss: 0.0347 - accuracy: 0.9863 - val_loss: 0.0537 - val_accuracy: 0.9806\n",
      "Epoch 11/100\n",
      "233/233 [==============================] - 0s 1ms/step - loss: 0.0325 - accuracy: 0.9874 - val_loss: 0.0370 - val_accuracy: 0.9867\n",
      "Epoch 12/100\n",
      "233/233 [==============================] - 0s 1ms/step - loss: 0.0282 - accuracy: 0.9890 - val_loss: 0.0352 - val_accuracy: 0.9855\n",
      "Epoch 13/100\n",
      "233/233 [==============================] - 0s 1ms/step - loss: 0.0268 - accuracy: 0.9907 - val_loss: 0.0432 - val_accuracy: 0.9831\n",
      "Epoch 14/100\n",
      "233/233 [==============================] - 0s 1ms/step - loss: 0.0239 - accuracy: 0.9913 - val_loss: 0.0312 - val_accuracy: 0.9883\n",
      "Epoch 15/100\n",
      "233/233 [==============================] - 0s 1ms/step - loss: 0.0246 - accuracy: 0.9906 - val_loss: 0.0380 - val_accuracy: 0.9851\n",
      "Epoch 16/100\n",
      "233/233 [==============================] - 0s 1ms/step - loss: 0.0251 - accuracy: 0.9895 - val_loss: 0.0358 - val_accuracy: 0.9847\n",
      "Epoch 17/100\n",
      " 60/233 [======>.......................] - ETA: 0s - loss: 0.0207 - accuracy: 0.9911"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [37]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m X_train,y_train,X_val,y_val,name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m([X_over_synth_10_train,X_over_synth_30_train,X_over_synth_50_train,X_under_synth_10_train,X_under_synth_30_train,X_under_synth_50_train], \n\u001b[1;32m      5\u001b[0m                            [y_over_synth_10_train,y_over_synth_30_train,y_over_synth_50_train,y_under_synth_10_train,y_under_synth_30_train,y_under_synth_50_train],\n\u001b[1;32m      6\u001b[0m                            [X_over_synth_10_val,X_over_synth_30_val,X_over_synth_50_val,X_under_synth_10_val,X_under_synth_30_val,X_under_synth_50_val],\n\u001b[1;32m      7\u001b[0m                            [y_over_synth_10_val,y_over_synth_30_val,y_over_synth_50_val,y_under_synth_10_val,y_under_synth_30_val,y_under_synth_50_val],\n\u001b[1;32m      8\u001b[0m                            [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mover_synth_10\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mover_synth_30\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mover_synth_50\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munder_synth_10\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munder_synth_30\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munder_synth_50\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n\u001b[1;32m      9\u001b[0m     tm \u001b[38;5;241m=\u001b[39m TrainModel(X_train,y_train,X_val, y_val, X_test \u001b[38;5;241m=\u001b[39m X_test, y_test \u001b[38;5;241m=\u001b[39my_test,early_stopping\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 10\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mtm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     res_dict[name] \u001b[38;5;241m=\u001b[39m (res)\n",
      "Input \u001b[0;32mIn [36]\u001b[0m, in \u001b[0;36mTrainModel.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompile()\n\u001b[0;32m---> 52\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;66;03m# self.draw_the_loss_curve()\u001b[39;00m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluate()\n",
      "Input \u001b[0;32mIn [36]\u001b[0m, in \u001b[0;36mTrainModel.fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mearly_stopping:\n\u001b[1;32m     25\u001b[0m     early_stopping_cb \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatience, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;66;03m# set patience to 10 to accelerate the training\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimple_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping_cb\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msimple_model\u001b[38;5;241m.\u001b[39mfit(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_train, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_train,validation_data\u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_val, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_val),epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepochs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/adl-mtp/lib/python3.8/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/adl-mtp/lib/python3.8/site-packages/keras/engine/training.py:1216\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1209\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1210\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1211\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1212\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1213\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1214\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1215\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1216\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1217\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1218\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/adl-mtp/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/adl-mtp/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:910\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    907\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    909\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 910\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    912\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    913\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/adl-mtp/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:942\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    939\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    940\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    941\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 942\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    943\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/adl-mtp/lib/python3.8/site-packages/tensorflow/python/eager/function.py:3130\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3127\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   3128\u001b[0m   (graph_function,\n\u001b[1;32m   3129\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3131\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/adl-mtp/lib/python3.8/site-packages/tensorflow/python/eager/function.py:1959\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1955\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1956\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1957\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1958\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1959\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1960\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1961\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1962\u001b[0m     args,\n\u001b[1;32m   1963\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1964\u001b[0m     executing_eagerly)\n\u001b[1;32m   1965\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/adl-mtp/lib/python3.8/site-packages/tensorflow/python/eager/function.py:598\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    597\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 598\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    599\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    600\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    602\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    604\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    605\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    606\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    607\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    610\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    611\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/adl-mtp/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:58\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     57\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 58\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     61\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(192)\n",
    "res_dict = {} # FIXME\n",
    "for X_train,y_train,X_val,y_val,name in zip([X_over_synth_10_train,X_over_synth_30_train,X_over_synth_50_train,X_under_synth_10_train,X_under_synth_30_train,X_under_synth_50_train], \n",
    "                           [y_over_synth_10_train,y_over_synth_30_train,y_over_synth_50_train,y_under_synth_10_train,y_under_synth_30_train,y_under_synth_50_train],\n",
    "                           [X_over_synth_10_val,X_over_synth_30_val,X_over_synth_50_val,X_under_synth_10_val,X_under_synth_30_val,X_under_synth_50_val],\n",
    "                           [y_over_synth_10_val,y_over_synth_30_val,y_over_synth_50_val,y_under_synth_10_val,y_under_synth_30_val,y_under_synth_50_val],\n",
    "                           [\"over_synth_10\",\"over_synth_30\",\"over_synth_50\",\"under_synth_10\",\"under_synth_30\",\"under_synth_50\"]):\n",
    "    tm = TrainModel(X_train,y_train,X_val, y_val, X_test = X_test, y_test =y_test,early_stopping=True)\n",
    "    res = tm.run()\n",
    "    res_dict[name] = (res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key,value in res_dict.items():\n",
    "    print(f\"{key}:{value['roc']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(hp):\n",
    "    number_units = hp.Int('number_units', min_value=20, max_value=80, step=20)\n",
    "    dropout_rate = hp.Float('dropout_rate', min_value = 0.1, max_value=0.3) \n",
    "    # optim_algo = hp.Choice('optimizer', values=['sgd','adam']) \n",
    "    optim_algo = 'adam'\n",
    "    learning_rate = hp.Float('learning_rate', min_value = 0.001, max_value=1, sampling='log') \n",
    "    number_layers = hp.Int('number_layers', min_value=1, max_value=3) # hidden layers\n",
    "    activation = hp.Choice('activation', values=['relu','sigmoid'])\n",
    "    whether_dropout = hp.Choice('whether_dropout', values=[True,False])\n",
    "\n",
    "    if whether_dropout == True:\n",
    "        model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Dropout(dropout_rate),\n",
    "            tf.keras.layers.Dense(number_units, activation=activation)]*number_layers+[ # number_layers is the number of hidden layers\n",
    "            tf.keras.layers.Dense(1,activation='sigmoid')])\n",
    "    else:\n",
    "        model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Dense(number_units, activation=activation)]*number_layers+[ # number_layers is the number of hidden layers\n",
    "            tf.keras.layers.Dense(1,activation='sigmoid')])\n",
    "\n",
    "    if optim_algo== 'sgd':\n",
    "        # Note that exploding gradients can be a big problem when running regressions, especially under SGD\n",
    "        # Hence, we use \"gradient clipping\" with parameter alpha, which means that the gradients are manually kept between -1 and 1\n",
    "        # This is of course another hyperparameter that we might tune!\n",
    "        optimizer = tf.keras.optimizers.SGD(\n",
    "            learning_rate=learning_rate, clipvalue=1)\n",
    "    elif optim_algo == 'adam':\n",
    "        optimizer = tf.keras.optimizers.Adam(\n",
    "            learning_rate=learning_rate)\n",
    "\n",
    "    # random_seed = 192\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rm log file\n",
    "# ! rm -rf ./logs_over_synth_10/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project logs_over_synth_10/kt_tutorial_over_synth_10/oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from logs_over_synth_10/kt_tutorial_over_synth_10/tuner0.json\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "# Run the best model for X_over_synth_10_train\n",
    "tuner = kt.Hyperband(train_model,\n",
    "                     objective='val_loss',\n",
    "                     max_epochs=10,\n",
    "                     factor=3,\n",
    "                     directory='logs_over_synth_10',\n",
    "                     project_name='kt_tutorial_over_synth_10')\n",
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(48)\n",
    "tuner.search(X_over_synth_10_train, y_over_synth_10_train, epochs=10, validation_data =(X_over_synth_10_val,y_over_synth_10_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hps = tuner.get_best_hyperparameters()[0]\n",
    "best_model = tuner.hypermodel.build(best_hps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "233/233 [==============================] - 0s 1ms/step - loss: 0.2074 - val_loss: 0.1455\n",
      "Epoch 2/100\n",
      "233/233 [==============================] - 0s 853us/step - loss: 0.1354 - val_loss: 0.1195\n",
      "Epoch 3/100\n",
      "233/233 [==============================] - 0s 1ms/step - loss: 0.1110 - val_loss: 0.0909\n",
      "Epoch 4/100\n",
      "233/233 [==============================] - 0s 822us/step - loss: 0.0895 - val_loss: 0.0774\n",
      "Epoch 5/100\n",
      "233/233 [==============================] - 0s 870us/step - loss: 0.0754 - val_loss: 0.0675\n",
      "Epoch 6/100\n",
      "233/233 [==============================] - 0s 838us/step - loss: 0.0679 - val_loss: 0.0604\n",
      "Epoch 7/100\n",
      "233/233 [==============================] - 0s 810us/step - loss: 0.0600 - val_loss: 0.0593\n",
      "Epoch 8/100\n",
      "233/233 [==============================] - 0s 859us/step - loss: 0.0579 - val_loss: 0.0603\n",
      "Epoch 9/100\n",
      "233/233 [==============================] - 0s 900us/step - loss: 0.0505 - val_loss: 0.0496\n",
      "Epoch 10/100\n",
      "233/233 [==============================] - 0s 851us/step - loss: 0.0446 - val_loss: 0.0521\n",
      "Epoch 11/100\n",
      "233/233 [==============================] - 0s 863us/step - loss: 0.0402 - val_loss: 0.0520\n",
      "Epoch 12/100\n",
      "233/233 [==============================] - 0s 903us/step - loss: 0.0413 - val_loss: 0.0480\n",
      "Epoch 13/100\n",
      "233/233 [==============================] - 0s 895us/step - loss: 0.0360 - val_loss: 0.0452\n",
      "Epoch 14/100\n",
      "233/233 [==============================] - 0s 892us/step - loss: 0.0356 - val_loss: 0.0473\n",
      "Epoch 15/100\n",
      "233/233 [==============================] - 0s 873us/step - loss: 0.0313 - val_loss: 0.0444\n",
      "Epoch 16/100\n",
      "233/233 [==============================] - 0s 874us/step - loss: 0.0329 - val_loss: 0.0432\n",
      "Epoch 17/100\n",
      "233/233 [==============================] - 0s 849us/step - loss: 0.0289 - val_loss: 0.0499\n",
      "Epoch 18/100\n",
      "233/233 [==============================] - 0s 870us/step - loss: 0.0303 - val_loss: 0.0446\n",
      "Epoch 19/100\n",
      "233/233 [==============================] - 0s 814us/step - loss: 0.0291 - val_loss: 0.0448\n",
      "Epoch 20/100\n",
      "233/233 [==============================] - 0s 791us/step - loss: 0.0305 - val_loss: 0.0404\n",
      "Epoch 21/100\n",
      "233/233 [==============================] - 0s 787us/step - loss: 0.0227 - val_loss: 0.0476\n",
      "Epoch 22/100\n",
      "233/233 [==============================] - 0s 779us/step - loss: 0.0253 - val_loss: 0.0457\n",
      "Epoch 23/100\n",
      "233/233 [==============================] - 0s 842us/step - loss: 0.0222 - val_loss: 0.0431\n",
      "Epoch 24/100\n",
      "233/233 [==============================] - 0s 819us/step - loss: 0.0217 - val_loss: 0.0459\n",
      "Epoch 25/100\n",
      "233/233 [==============================] - 0s 812us/step - loss: 0.0220 - val_loss: 0.0399\n",
      "Epoch 26/100\n",
      "233/233 [==============================] - 0s 1ms/step - loss: 0.0206 - val_loss: 0.0386\n",
      "Epoch 27/100\n",
      "233/233 [==============================] - 0s 1ms/step - loss: 0.0232 - val_loss: 0.0365\n",
      "Epoch 28/100\n",
      "233/233 [==============================] - 0s 1ms/step - loss: 0.0184 - val_loss: 0.0693\n",
      "Epoch 29/100\n",
      "233/233 [==============================] - 0s 840us/step - loss: 0.0200 - val_loss: 0.0345\n",
      "Epoch 30/100\n",
      "233/233 [==============================] - 0s 799us/step - loss: 0.0215 - val_loss: 0.0401\n",
      "Epoch 31/100\n",
      "233/233 [==============================] - 0s 788us/step - loss: 0.0197 - val_loss: 0.0347\n",
      "Epoch 32/100\n",
      "233/233 [==============================] - 0s 787us/step - loss: 0.0174 - val_loss: 0.0369\n",
      "Epoch 33/100\n",
      "233/233 [==============================] - 0s 809us/step - loss: 0.0196 - val_loss: 0.0343\n",
      "Epoch 34/100\n",
      "233/233 [==============================] - 0s 794us/step - loss: 0.0171 - val_loss: 0.0488\n",
      "Epoch 35/100\n",
      "233/233 [==============================] - 0s 853us/step - loss: 0.0179 - val_loss: 0.0386\n",
      "Epoch 36/100\n",
      "233/233 [==============================] - 0s 797us/step - loss: 0.0160 - val_loss: 0.0385\n",
      "Epoch 37/100\n",
      "233/233 [==============================] - 0s 794us/step - loss: 0.0181 - val_loss: 0.0387\n",
      "Epoch 38/100\n",
      "233/233 [==============================] - 0s 805us/step - loss: 0.0200 - val_loss: 0.0417\n",
      "Epoch 39/100\n",
      "233/233 [==============================] - 0s 805us/step - loss: 0.0157 - val_loss: 0.0396\n",
      "Epoch 40/100\n",
      "233/233 [==============================] - 0s 880us/step - loss: 0.0174 - val_loss: 0.0420\n",
      "Epoch 41/100\n",
      "233/233 [==============================] - 0s 880us/step - loss: 0.0169 - val_loss: 0.0387\n",
      "Epoch 42/100\n",
      "233/233 [==============================] - 0s 868us/step - loss: 0.0154 - val_loss: 0.0372\n",
      "Epoch 43/100\n",
      "233/233 [==============================] - 0s 937us/step - loss: 0.0162 - val_loss: 0.0402\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(48)\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True) # set patience to 10 to accelerate the training\n",
    "log = best_model.fit(X_over_synth_10_train, y_over_synth_10_train, epochs=100, validation_data =(X_over_synth_10_val,y_over_synth_10_val),callbacks=[early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABBlklEQVR4nO3dd3hUZfbA8e9JJ5Qk9FBD7z1SBAkgKE0QRRc7ui6iYl1d0J+LZVfXFVSssKgoFkREQaRIkyKCQEIJvUoJJQk1IZS08/tjhpCElAkEJmHO53nmycx733vnzEXnzH3bFVXFGGOM5/FydwDGGGPcwxKAMcZ4KEsAxhjjoSwBGGOMh7IEYIwxHsrH3QEURPny5TUsLMzdYRhjTLESFRV1RFUrZC8vVgkgLCyMyMhId4dhjDHFiojszancmoCMMcZDWQIwxhgPZQnAGGM8VLHqAzDGXH0pKSnExMRw9uxZd4di8hEQEEC1atXw9fV1qb4lAGNMnmJiYihdujRhYWGIiLvDMblQVY4ePUpMTAy1atVyaR9rAjLG5Ons2bOUK1fOvvyLOBGhXLlyBbpSswRgjMmXffkXDwX9d/KIBDBz/UzenPOmu8MwxpgixSMSwPwt83lj9hvuDsMYcwlOnDjBxx9/fEn79u7dmxMnTuRZZ+TIkSxYsOCSjp9dWFgYR44cKZRjXQ0ekQBCg0JJPJtI0rkkd4dijCmgvBJAWlpanvvOnj2b4ODgPOu89tprdO/e/VLDK9Y8JgEAHDp5yM2RGGMKasSIEezatYuWLVvy/PPPs3jxYrp27crdd99Ns2bNALj11ltp06YNTZo0Yfz48Rn7nv9FvmfPHho1asTf/vY3mjRpwk033cSZM2cAGDx4MFOnTs2o//LLL9O6dWuaNWvG1q1bAYiPj6dHjx60bt2aRx55hJo1a+b7S/+dd96hadOmNG3alDFjxgCQlJREnz59aNGiBU2bNuW7777L+IyNGzemefPmPPfcc4V6/vLiEcNAMxLAiUPUrVjXzdEYU3w9Pflp1u1fV6jHbFm9JWMGjcl1+5tvvsnGjRtZt87xvosXL2bVqlVs3LgxY7jjhAkTKFu2LGfOnOG6667j9ttvp1y5clmOs2PHDr799ls++eQT7rzzTn744Qfuvffei96vfPnyrFmzho8//pjRo0fz6aef8uqrr9KtWzdeeOEFfvnllyxJJidRUVF8/vnnrFy5ElWlXbt2REREsHv3bqpUqcKsWbMAOHnyJMeOHWPatGls3boVEcm3yaow2RWAMabYadu2bZax7u+//z4tWrSgffv27N+/nx07dly0T61atWjZsiUAbdq0Yc+ePTke+7bbbruozrJlyxg0aBAAPXv2JCQkJM/4li1bxoABAyhZsiSlSpXitttu47fffqNZs2YsWLCA4cOH89tvvxEUFESZMmUICAjg4Ycf5scffyQwMLCAZ+PSuXQFICI9gfcAb+BTVX0z2/Z7gOHOl6eAR1V1fV77ikhZ4DsgDNgD3Kmqxy/z8+SoSnAVwBKAMZcrr1/qV1PJkiUzni9evJgFCxawYsUKAgMD6dKlS45j4f39/TOee3t7ZzQB5VbP29ub1NRUwDHJqiByq1+/fn2ioqKYPXs2L7zwAjfddBMjR45k1apVLFy4kMmTJ/Phhx/y66+/Fuj9LlW+VwAi4g18BPQCGgN3iUjjbNX+BCJUtTnwL2C8C/uOABaqaj1gofP1FVG2ZFn8fPwsARhTDJUuXZrExMRct588eZKQkBACAwPZunUrf/zxR6HH0KlTJ6ZMmQLAvHnzOH4879+qnTt3Zvr06Zw+fZqkpCSmTZvGDTfcwMGDBwkMDOTee+/lueeeY82aNZw6dYqTJ0/Su3dvxowZk9HUdTW4cgXQFtipqrsBRGQy0B/YfL6Cqi7PVP8PoJoL+/YHujjrTQQWc+EqolCJCJXLVLYEYEwxVK5cOTp27EjTpk3p1asXffr0ybK9Z8+ejBs3jubNm9OgQQPat29f6DG8/PLL3HXXXXz33XdEREQQGhpK6dKlc63funVrBg8eTNu2bQF4+OGHadWqFXPnzuX555/Hy8sLX19fxo4dS2JiIv379+fs2bOoKu+++26hx58bye/SRkQGAj1V9WHn6/uAdqo6LJf6zwENVfXhvPYVkROqGpxpv+OqelHDmogMAYYA1KhRo83evTne1yBf7d9oT5kSZZj3zLxL2t8YT7VlyxYaNWrk7jDc6ty5c3h7e+Pj48OKFSt49NFHr+ov9YLI6d9LRKJUNTx7XVeuAHKaW5xj1hCRrsBfgU4F3Tc3qjoeZ5NSeHh4wRriMgkNCmVn/M5L3d0Y48H27dvHnXfeSXp6On5+fnzyySfuDqlQuJIAYoDqmV5XAw5mryQizYFPgV6qetSFfWNFJFRVD4lIKBBX0OALIjQ4lN92/nYl38IYc42qV68ea9eudXcYhc6VYaCrgXoiUktE/IBBwIzMFUSkBvAjcJ+qbndx3xnAA87nDwA/XfrHyF9oUChHTx3lXMq5K/k2xhhTbOR7BaCqqSIyDJiLYyjnBFXdJCJDndvHASOBcsDHztXoUlU1PLd9nYd+E5giIn8F9gF3FPJny+L8XIDDCYepWa7mlXwrY4wpFlyaB6Cqs4HZ2crGZXr+MPCwq/s6y48CNxYk2MuReTawJQBjjPGQmcBgs4GNMSY7SwDGmGtOqVKlADh48CADBw7MsU6XLl2IjIzM8zhjxozh9OnTGa9dWV7aFa+88gqjR4++7ONcLo9JABXLVMRLvCwBGONBqlSpkrHS56XIngBcWV66OPGYBODt5U3FMhUtARhTzAwfPjzL/QBeeeUV3n77bU6dOsWNN96YsXTzTz9dPJBwz549NG3aFIAzZ84waNAgmjdvzl/+8pcsawE9+uijhIeH06RJE15++WXAscDcwYMH6dq1K127dgWy3vAlp+We81p2Ojfr1q2jffv2NG/enAEDBmQsM/H+++9nLBF9fiG6JUuW0LJlS1q2bEmrVq3yXCLDFR6xHPR5oUGhlgCMuQxPP/0r69YV7pSdli0rMmZMt1y3Dxo0iKeffprHHnsMgClTpvDLL78QEBDAtGnTKFOmDEeOHKF9+/b069cv1/vijh07lsDAQKKjo4mOjqZ169YZ215//XXKli1LWloaN954I9HR0Tz55JO88847LFq0iPLly2c5Vm7LPYeEhLi87PR5999/Px988AERERGMHDmSV199lTFjxvDmm2/y559/4u/vn9HsNHr0aD766CM6duzIqVOnCAgIcPU058hjrgDAEoAxxVGrVq2Ii4vj4MGDrF+/npCQEGrUqIGq8uKLL9K8eXO6d+/OgQMHiI2NzfU4S5cuzfgibt68Oc2bN8/YNmXKFFq3bk2rVq3YtGkTmzdvzu0wQO7LPYPry06DYyG7EydOEBERAcADDzzA0qVLM2K85557+Prrr/HxcfxW79ixI88++yzvv/8+J06cyCi/VB53BbBm3xp3h2FMsZXXL/UraeDAgUydOpXDhw9nNId88803xMfHExUVha+vL2FhYTkuA51ZTlcHf/75J6NHj2b16tWEhIQwePDgfI+T1xpqri47nZ9Zs2axdOlSZsyYwb/+9S82bdrEiBEj6NOnD7Nnz6Z9+/YsWLCAhg0bXtLxwQOvAOIS4khLz/s+osaYomXQoEFMnjyZqVOnZozqOXnyJBUrVsTX15dFixaR30KRnTt35ptvvgFg48aNREdHA5CQkEDJkiUJCgoiNjaWOXPmZOyT21LUuS33XFBBQUGEhIRkXD189dVXREREkJ6ezv79++natStvvfUWJ06c4NSpU+zatYtmzZoxfPhwwsPDM25Zeak87gogXdOJS4gjNDjU3eEYY1zUpEkTEhMTqVq1KqGhjv9377nnHm655RbCw8Np2bJlvr+EH330UR588EGaN29Oy5YtM5ZqbtGiBa1ataJJkybUrl2bjh07ZuwzZMgQevXqRWhoKIsWLcooz22557yae3IzceJEhg4dyunTp6lduzaff/45aWlp3HvvvZw8eRJV5ZlnniE4OJh//vOfLFq0CG9vbxo3bkyvXr0K/H6Z5bscdFESHh6u+Y3bzcu0NdO4bextRL0UReuarfPfwRhjy0EXMwVZDtrjmoDAJoMZYwx4WgIItgRgjDHneVQCqFymMmAJwJiCKk5NxZ6soP9OHpUA/H39KVuyrCUAYwogICCAo0ePWhIo4lSVo0ePFmhymEeNAgKoElyFQycsARjjqmrVqhETE0N8fLy7QzH5CAgIoFq1ai7X97gEYLOBjSkYX19fatWq5e4wzBXgUhOQiPQUkW0islNERuSwvaGIrBCRcyLyXKbyBiKyLtMjQUSedm57RUQOZNrWu9A+VR5Cg0I5ePKiWxobY4zHyfcKQES8gY+AHjhu8r5aRGaoaubFMo4BTwK3Zt5XVbcBLTMd5wAwLVOVd1X1qi6KHRoUyuGTh1HVXBeNMsYYT+DKFUBbYKeq7lbVZGAy0D9zBVWNU9XVQEoex7kR2KWqec/XvsJCg0JJSUvh6Kmj7gzDGGPczpUEUBXYn+l1jLOsoAYB32YrGyYi0SIyQURCLuGYBWaTwYwxxsGVBJBTO0mBxoOJiB/QD/g+U/FYoA6OJqJDwNu57DtERCJFJLIwRiFYAjDGGAdXEkAMUD3T62pAQXtRewFrVDVjsW5VjVXVNFVNBz7B0dR0EVUdr6rhqhpeoUKFAr7txWw2sDHGOLiSAFYD9USklvOX/CBgRgHf5y6yNf+ISOblOAcAGwt4zEtiVwDGGOOQ7yggVU0VkWHAXMAbmKCqm0RkqHP7OBGpDEQCZYB051DPxqqaICKBOEYQPZLt0G+JSEsczUl7cth+RZT0L0npgNKWAIwxHs+liWCqOhuYna1sXKbnh3E0DeW072mgXA7l9xUo0kIUGhRqs4GNMR7Po9YCOs9mAxtjjCUAY4zxWB6dAGx1Q2OMJ/PMBBAcyunk0ySevfhmz8YY4yk8MwHYUFBjjLEEYIwxnsqzE4ANBTXGeDDPTgB2BWCM8WAemQCCA4Px9/G3BGCM8WgemQBExOYCGGM8nkcmAHAMBT14wm4NaYzxXB6bAKoEVbErAGOMR/PYBGBNQMYYT+fRCeDkmZOcST7j7lCMMcYtPDcB2J3BjDEeznMTgM0FMMZ4OEsAlgCMMR7KpQQgIj1FZJuI7BSRETlsbygiK0TknIg8l23bHhHZICLrRCQyU3lZEZkvIjucf0Mu/+O4zpaDMMZ4unwTgIh4Ax8BvYDGwF0i0jhbtWPAk8DoXA7TVVVbqmp4prIRwEJVrQcsdL6+asqXKo+Pt49dARhjPJYrVwBtgZ2qultVk4HJQP/MFVQ1TlVXAykFeO/+wETn84nArQXY97J5eXlRqXQlSwDGGI/lSgKoCuzP9DrGWeYqBeaJSJSIDMlUXklVDwE4/1bMaWcRGSIikSISGR8fX4C3zZ/NBTDGeDJXEoDkUFaQeyl2VNXWOJqQHheRzgXYF1Udr6rhqhpeoUKFguyar9BgSwDGGM/lSgKIAapnel0NcHkRHVU96PwbB0zD0aQEECsioQDOv3GuHrOw2BWAMcaTuZIAVgP1RKSWiPgBg4AZrhxcREqKSOnzz4GbgI3OzTOAB5zPHwB+KkjgBZXTDeBDg0KJT4wnJbUgXRfGGHNtyDcBqGoqMAyYC2wBpqjqJhEZKiJDAUSksojEAM8CL4lIjIiUASoBy0RkPbAKmKWqvzgP/SbQQ0R2AD2cr6+IV19dTocOky4qPz8UNDYh9kq9tTHGFFk+rlRS1dnA7Gxl4zI9P4yjaSi7BKBFLsc8CtzocqSXoVQpX1auPERMTCLVqpXOKM88Gaxa2ZzCN8aYa5dHzATu0SMMgAUL9mYpt9nAxhhP5hEJoFmz8lSqFMj8+ZYAjDHmPI9IACJC9+41WbBgL+npFzqDK5WphIjYncGMMR7JIxIAQI8eNYmLO82GDRcmk/n6+FK+VHm7AjDGeCSPSQDdu9cEyLEZyBKAMcYTeUwCqFq1NI0bl7MEYIwxTh6TAMDRDLR0aQxnz6ZmlFkCMMZ4Ko9LAGfPprJs2YGMstCgUGITYklLT3NjZMYYc/V5VAKIiKiOr68X8+fvySirElyFtPQ0jpw64r7AjDHGDTwqAZQq5cf111fJ0g8QVi4MgM0HN7spKmOMcQ+PSgDgmBW8dm0c8fGnAehcvzO+3r78svGXfPY0xphriwcmAMdw0IUL9wFQpkQZOtXtxOyNs/PazRhjrjkelwDatKlESEhAln6A3s16s/HARvYf25/7jsYYc43xuATg7e1Ft27VmT9/b8Y9Ano36w3AnI1z3BmaMcZcVR6XAMDRD7B/fyLbtx8HoFFoI2qWq8nsDdYMZIzxHB6aAM4vC7EHcCwW17tZbxZsWcC5lHNujMwYY64ej0wAtWsHU7t2EPPmXRgO2rtpb5LOJfHbjt/cGJkxxlw9LiUAEekpIttEZKeIjMhhe0MRWSEi50TkuUzl1UVkkYhsEZFNIvJUpm2viMgBEVnnfPQunI/kmh49wli8eD8pKY4ZwF0bdsXPx8/6AYwxHiPfBCAi3sBHQC+gMXCXiDTOVu0Y8CQwOlt5KvB3VW0EtAcez7bvu6ra0vm4qg3wPXrUJDExmZUrHesAlfQvSZf6XawfwBjjMVy5AmgL7FTV3aqaDEwG+meuoKpxqroaSMlWfkhV1zifJ+K4qXzVQon8MnXrVgMvL8kyK7h3s95sPbyV3fG73RiZMcZcHa4kgKpA5gHyMVzCl7iIhAGtgJWZioeJSLSITBCRkFz2GyIikSISGR8fn1OVSxISEkB4eKWLEgDYcFBjjGdwJQFIDmWaQ1nuBxApBfwAPK2qCc7isUAdoCVwCHg7p31VdbyqhqtqeIUKFQrytvm66aYwVq06xMmTjpE/9SrVo27FutYMZIzxCK4kgBigeqbX1QCXb6IrIr44vvy/UdUfz5eraqyqpqlqOvAJjqamq6pHj5qkpSmLFu3LKOvVtBeLti3iTPKZqx2OMcZcVa4kgNVAPRGpJSJ+wCBghisHFxEBPgO2qOo72baFZno5ANjoWsiFp337KpQs6XtRM9CZ5DMs2b7kaodjjDFXVb4JQFVTgWHAXByduFNUdZOIDBWRoQAiUllEYoBngZdEJEZEygAdgfuAbjkM93xLRDaISDTQFXim8D9e3vz8vOnSpTrz5u3JKIuoH0EJvxLWDGSMueb5uFLJOURzdraycZmeH8bRNJTdMnLuQ0BV73M9zCunR4+azJq1mz17ThIWFkQJvxJ0a9CNWRtm8d6g93BcxBhjzLXHI2cCZ9atWw0Aliy5MNCpd7Pe7I7fzY7YHe4KyxhjrjiPTwBNmpSnbNkAliyJySjr1bQXYMNBjTHXNo9PAF5eQufO1bJcAdSqUIuGlRtaP4Ax5prm8QkAHDeL3737JPv3J2SU9W7Wm8XbF5N0LsmNkRljzJVjCQCIiHD0X2duBurdrDfJqcn8uvVXd4VljDFXlCUAoHnzCgQF+WdpBupUtxOl/EtZM5Ax5pplCQDHbSId/QAXrgD8ff3p3qg7czbOybh1pDHGXEssAThFRFRjx47jHDp0KqOsV7Ne7D26ly2HtrgxMmOMuTIsAThFRDiWO8ppOOjP6392S0zGGHMlWQJwatmyIqVL+7F48YV+gOplq3Nd2HX8sOYHN0ZmjDFXhiUAJx8fLzp1qpqlIxhgYJuBrN6zmr1H9+aypzHGFE+WADLp0qU6W7ceIzb2wtj/21vfDsAPUXYVYIy5tlgCyOR8P8DSpRf6AepUrEOrGq2Yumaqu8IyxpgrwhJAJq1bV6RkSd+Lm4FaD2TFrhXEHIvJZU9jjCl+LAFk4uvrTceOVbOMBAJHPwDAj2t/zGk3Y4wpliwBZBMRUY2NG49w5MjpjLL6levTrGozpkZZM5Ax5tphCSCbnPoBwHEVsGznMg6dOOSOsIwxptC5lABEpKeIbBORnSIyIoftDUVkhYicE5HnXNlXRMqKyHwR2eH8G3L5H+fyXXddZUqU8MmxGUhVmbZ2mpsiM8aYwpVvAhARb+AjoBfQGLhLRBpnq3YMeBIYXYB9RwALVbUesND52u38/Ly5/voqF3UEN67SmEahjawZyBhzzXDlCqAtsFNVd6tqMjAZ6J+5gqrGqepqIKUA+/YHJjqfTwRuvbSPUPgiIqoTHR3P8eNns5Tf3vp2lmxfQlxCnJsiM8aYwuNKAqgKZP45HOMsc0Ve+1ZS1UMAzr8VczqAiAwRkUgRiYyPj3fxbS9PREQ1VOG33y5uBkrXdKavm35V4jDGmCvJlQQgOZS5uj7y5ezrqKw6XlXDVTW8QoUKBdn1krVtG4q/v/dFzUDNqzWnbsW61gxkjLkmuJIAYoDqmV5XAw66ePy89o0VkVAA598i064SEOBD+/ahLF6c9QpARBjYZiC/bv2Vo6eOuik6Y4wpHK4kgNVAPRGpJSJ+wCBghovHz2vfGcADzucPAD+5HvaV16VLddati+PkyXNZyge2GUhaeho/rStS4RpjTIHlmwBUNRUYBswFtgBTVHWTiAwVkaEAIlJZRGKAZ4GXRCRGRMrktq/z0G8CPURkB9DD+brIiIioTnq6smxZ1quA1jVaE1YuzJqBjDHFno8rlVR1NjA7W9m4TM8P42jecWlfZ/lR4MaCBHs1tW8fip+fN0uWxNCnT52M8vPNQO8tfI8Tp08QHBjsviCNMeYy2EzgXJQo4UvbtpUv6ggGRzNQSlqK3SnMGFOsWQLIQ0REdaKiYklMTM5S3rZWW6qXrW7NQMaYYs0SQB4iIqqRlqb8/vuBLOUiwu2tb2fuprkknElwU3TGGHN5LAHkoWPHqoSEBPDhh2sv2jawzUDOpZ5jVvQsN0RmjDGXzxJAHgIDffnHP65j1qzdLF+e9SqgQ+0OVAmuwhfLv3BPcMYYc5ksAeTjiSdaUalSIP/3f8tQvTCJ2cvLiye7Pcm8zfNYuXulGyM0xphLYwkgHyVL+vHii+1ZvHg/Cxfuy7Lt8a6PU65UOV79+VU3RWeMMZfOEoALHnmkOdWrl+b//u+3LFcBpQJK8fcef2fOxjms+nOVGyM0xpiCswTgAn9/H15++XpWrTrMjBm7smwb1m0YZUuW5bWfX3NTdMYYc2ksAbjogQeaUK9eCC+9tIz09AtXAaUDSvP3Hn9n1oZZRO6JdGOExhhTMJYAXOTj48Vrr3Vk48YjTJ68Ncu2Yd2GERIYYn0BxphixRJAAdx5ZwOaN6/Ayy//TkpKWkZ5mRJleLbHs8yMnknU3ig3RmiMMa6zBFAAXl7Cv//diZ07TzBx4qYs257o9gQhgSHWF2CMKTYsARRQ3761adculFdfXcHZs6kZ5UGBQTzT4xlmrJ/B2n0Xzxw2xpiixhJAAYkIr7/eiZiYRP73v/VZtj3Z7UmCA4OtL8AYUyxYArgEN95Yk27davD6639w6tSFlUKDAoN4pvsz/LTuJ9btW+e+AI0xxgUuJQAR6Ski20Rkp4iMyGG7iMj7zu3RItLaWd5ARNZleiSIyNPOba+IyIFM23oX6ie7wl5/vRPx8Wd4552sQz+fvPFJgkoE8dpM6wswxhRt+SYAEfEGPgJ6AY2Bu0SkcbZqvYB6zscQYCyAqm5T1Zaq2hJoA5wGpmXa793z2513Dis22revwh131Off//6Ddesu3M8+ODCYp7s/zbS101i/f30eRzDGGPdy5QqgLbBTVXerajIwGeifrU5/4Et1+AMIFpHQbHVuBHap6t7LjrqIGDu2BxUqBHL33TM5fTolo/ypG5+iTIky/POnf2ZZOsIYY4oSVxJAVSDzfRFjnGUFrTMI+DZb2TBnk9EEEQlxIZYipVy5Ekyc2IstW47x/PNLMspDSobwYq8X+Xn9z7w0/SU3RmiMMblzJQFIDmXZf9bmWUdE/IB+wPeZto8F6gAtgUPA2zm+ucgQEYkUkcj4+HgXwr26unevybPPtuHjj9cxc+aFdYL+0fMfDOk8hDdmv8GouaPcGKExxuTMlQQQA1TP9LoacLCAdXoBa1Q19nyBqsaqapqqpgOf4GhquoiqjlfVcFUNr1ChggvhXn1vvHEDzZtX4KGHfiE2NglwDBf9+J6P+ct1f+EfU//BJ0s/cXOUxhiTlSsJYDVQT0RqOX/JDwJmZKszA7jfORqoPXBSVQ9l2n4X2Zp/svURDAA2Fjj6IsLf34dJk/qQmJjCgw/+ktHu7+3lzZcPfUmvpr145OtHmLJ6ipsjNcaYC/JNAKqaCgwD5gJbgCmquklEhorIUGe12cBuYCeOX/OPnd9fRAKBHsCP2Q79lohsEJFooCvwzOV+GHdq0qQ8o0dHMGfOn3z00YWZwH4+fkwdOpVOdTtx72f3MmfDHDdGaYwxF0hxGqUSHh6ukZFFd8llVaVv3x9ZuHAfUVH30aRJ+YxtJ0+fpOvbXdl6eCtzn5rLDfVvcGOkxpNFR8cTGlqSChUC3R2KuUpEJEpVw7OX20zgQiQiTJjQk6Agf+6+e9ZFawX98tQv1Chbg74f9mXN3jVujNR4qrS0dDp3nsyLL/7m7lBMEWAJoJBVqlSSzz/vSXR0PMOHL82yrWKZisx/Zj7BJYLp+V5Pth/e7qYojafatOkoJ0+eY+XKQ/lXNtc8SwBXQO/etXnqqda8//4a/vOflVm2VS9bnfnPzEdV6fleT2ITYnM5ijGF7/wX/6ZNR7NMXjSeyRLAFfL22124555GvPjib4wevTrLtvqV6zPryVnEJsTS+73eJJ5NdFOUxtOsWuVIAOnpyvr1RW9ejbm6LAFcId7eXnzxRS8GDWrI888vYcyYrHcKa1urLVMemcL6mPUMHDuQlFT7NWauvJUrD9GsmWNwQmTkYTdHY9zNEsAV5OPjxVdf9eb22+vxzDOL+PDDrB2/fZr3Yfx945m3eR4Pf/mwrRtkrqhTp5LZtOkot91Wj0qVAi0BGHzcHcC1zsfHi2+/7csdd/zME0/8iq+vN4880iJj+0OdHuLAiQOM/GkkVYKr8J/b/uPGaM21LDLyMOnpSrt2oURGxhIVZf1Pns6uAK4CX19vpky5hb59azN06Hw++2xDlu0v9XmJIZ2H8OacN/nw1w/dFKW51p3vAL7uusqEh1diy5ZjWW5oZDyPJYCrxM/Pm6lT+9GzZxh/+9tcPvtsA2lp6YBj/sBHd39Evxb9eHLyk/wQ9UOuxzlzJoX0dGsqMgW3atVh6tQJpnz5QMLDK5OerlnuZWE8jzUBXUX+/j78+GN/+vWbzsMPz+WxxxZQt24w9euH0KBBWXrVHskurzTufv8R7m2xhtp+7fA+VZFdu06yY8dxduw4wcGDpxg4sD5TptyCSE6LsBqTs5UrDxER4VizsU2bSgBERcXSqVM1d4Zl3MgSwFVWooQvM2bcypQp29i8+Sjbth1n69ZjzJq1m5SUdKAL0IUJAGwHtuNfOoWaYSW5oUsNSPPmu++2MWXKNv7yl4Zu/CSmODlwIJEDB07Rrp1jDcbQ0FJUqVKKyEjrB/BklgDcoEQJXx54oGmWstTUdPbsOcm2bcfYvfskpYIgTjaz7uRCFuyayfZTR9jl5U2HsI7U33QHw4YtpFu3Graei3HJ+fb/8wkAIDy8ko0E8nCWAIoIHx8v6tYNoW7dzDdGaw3cS1p6Gqv/XM3M6Jl8F/kdfzb6D7L1GZ54YiGTJ9/irpBNMbJy5SF8fb1o2fLCPTXatKnEzz/vIjExmdKl/dwYnXEX6wQuBry9vGlfpz3/HvBvIv8vklbNq6CtFvDdd9uYNm2Hu8MzxcDKlYdo2bIi/v4XfvOFh1dGFdautWYgT2UJoJgJCgxi7jNzaXTzIaT8IR4eMptjx864OyxThKWlpRMZGZul+QcudARbP4DnsgRQDJUtWZYFz8+jxq0rOHbsLPf/baq7QzJF2ObNR0lKSrkoAVSqVJLq1UtbP4AHswRQTFUqU4ll/51CcPs1zPoxlo8m/urukEwRlVMH8Hlt2lSyGcEezKVOYBHpCbwHeAOfquqb2baLc3tv4DQwWFXXOLftARKBNCD1/F1pRKQs8B0QBuwB7lTV45f9iTxItbLVWPHd6zRr+SlPDltCuw4VCa/f9KJ6SUnJ/PzzbpYu3Q84Opy9vb3w8RF8fLzw8fEiIMCHO+9sQL16IRftb4q3lSsPUbZsAHXrBl+0LTy8MtOn7+TkyXMEBflf/eCMW+WbAETEG/gIx319Y4DVIjJDVTdnqtYLqOd8tAPGOv+e11VVj2Q79Ahgoaq+KSIjnK+HX/In8VANq9Xl268HcEfvJUQMHMXGha9Qq0ItUlLSmDdvD5MmbeWnn3aSlJRCUJA//v7epKamZ3ooqanppKcrr7yynMcea8nIkR0oV66Euz+aKSQrVx6ibdvKOU4cDA939AOsWRNL1641rnZoxs1cuQJoC+xU1d0AIjIZ6A9kTgD9gS/VsZzlHyISLCKhqprXbYf645j1BDARWIwlgEsysGc7Bg/dzxdjvWhz15N0D72HhbOPcOzYWUJCArjnnkbcdVdDbrihGt7eObf6HT6cxCuvLOfDD9cyceImXnqpPcOGtSIgoOiNFN6z5ySHDyfRvn0Vd4dS5J1fAXTAgHo5br/QEXzYEoAHcqUPoCqwP9PrGGeZq3UUmCciUSIyJFOdSucThPNvxZzeXESGiEikiETGx9sNLHLz8dv9CasTyPGFEXw/eTfN2vnx888DOHz4Uf73v5vo0qVGrl/+AJUrl2TcuB5ERz9Ax45VeP75JTRqNIHJk7cWqWWqo6IOEx7+NR06TGLEiKWkpqa7O6QiLSoqNmMF0JyULx9IzZplimw/gKpy/PhZd4dxzXIlAeS04Ez2b4S86nRU1dY4mokeF5HOBYgPVR2vquGqGl6hQoX8d/BQJUr4snDe3fzvi060GDGd36o9yq6Amfj6Fqyfv0mT8syadTvz599BmTL+3HXXTDp0mMTcuX+6fRG6Zcti6NZtCqVK+TJ4cBP++99VdOs2hYMHT12V9y9KidBV5zuA27atnGsdx4zgopkA3nxzFaGhY22k0hXiyrdDDFA90+tqwEFX66jq+b9xwDQcTUoAsSISCuD8a8sSXqbatYMZ8kB7fn9pEf1b9ufp757msW8eu6S7jXXvXpM1a+5jwoSb2b8/kZ49f6BBg88YPXo1R4/mP+9g587jvPtuJEOHzmf+/D2XnTzmz9/DzTdPJTS0FMuW3cXnn/fi6697s2ZNLC1bTmTBgr2Xdfy8nD2byoAB0wkJ+ZBbb53Oxx+vZefO48UiIaxceShjBdDctGlTmV27ThS5X9oJCed4661VnDuXxn33zebMGbtrXqFT1TwfOPoJdgO1AD9gPdAkW50+wBwcVwLtgVXO8pJA6UzPlwM9na9HASOcz0cAb+UXS5s2bdS4Ji0tTUf8MEJ5GO3+dnc9nnT8ko919myKfvPNZu3UaZLCKPX3f0fvu2+WLl9+QNPT01VVNSUlTZcs2afPPbdIGzb8TGGUwigtUeJdhVFar96nOnr0Kj1y5HSB33/69B3q5/eOtmjxhcbGnsqybfPmI9q48QQVGaWvvvq7pqamXfLnzMm5c6nap88PCqP0jjt+0lq1xmd8tlq1xusjj8zTH37YpsePn7mk4x8+fErPnUst1Jgzq1p1rN5998w868yb96fCKF2wYM8Vi+NSvPHGHwqj9D//cfx96qmF7g6p2AIiNafv95wKL6rkGN65HdgF/J+zbCgw1PlccIwU2gVsAMKd5bWdCWM9sOn8vs5t5YCFwA7n37L5xWEJoOA+X/a5+j7iqw1faqg7Yndc9vGio+P0scfma+nS7ymM0hYtvtC77vpZy5b9QGGU+vq+rd27T9H33ovSXbuO65kzKfr115u0Y8cLyeP++2fpihUXkkdevvlms3p7j9Z27b7WY8dy/pI9deqc3nffLIVRetNN32tcXFLGttTUNE1IOKeHD5/S3buP644dx1x6X1XV5ORUvfXWaQqjdNy4daqqmp6erjt2HNOPPlqj/ftPyzgPPj5va//+03Tq1G169mxKnsdNSkrWL7/cqJ07f6swShs3nqC7dx93KaaCiIlJUBil770XlWe9o0dPK4zSN9/8o9BjuFSnTp3T8uU/1F69pqqq6rBhC4pkkioucksAosXgMva88PBwjYyMdHcYxc7S7UsZ8PEAVJUxfxnDfR3uu+x7CSQmJjNp0hbGjVvPwYOn6NkzjFtuqcNNN4VRpkzO48k3bIhn3Lj1fPXVZhITk2nRogJdulSnceNyNG5cjkaNymUZfjp+/HqGDp1PRER1ZswYkOeCZarKZ59tYNiwhXh7C35+3pw+nUpyctpFdbt2rc64cT2oX79srsdLTU3n7rtn8v3323n//W488UTrHOulpKSxcuUhpk/fyaRJWzh0KImQkADuvLMB99/fmA4dqiAiqCpRUbF89tkGJk3aQkJCMnXqBDNwYH3Gj4/Gx0f46acBdOhQeCObpk3bwW23/cSKFXfnO2KqTp1PaN26Et9/36/Q3v9yvP32ap57bgnLl99Nhw5VOH06hVatvuT06VQ2bHiA4OAAd4dYrIhIlDrnYGUptwTgGXbG7eT+CfezYtcKujXsxrh7x1GvUs5DA6+088lj4sRNREfHk5R0oW23YsVAGjcuR8WKgUyZso3evWsxdWo/SpTwdenY69fHOb9QvQgM9CEw0JcSJXwynsfHn+b111dy5kwq//d/7Rg+vG2WBdLAsXbOfffN5ttvt/L221149tmL/r/JUVpaOgsX7uPLLzcxbdoOTp9OpU6dYG65pQ6//rqP6Oh4SpTwYeDA+vz1r83o3LkaIsK2bcfo0+dHYmIS+eKLXgwaVDj3eRgxYinvvBNJQsKT+Q7nvfPOGURGxrJ7998K5b0vx5kzKdSq9QlNm5ZnwYI7M8pXrTrE9ddP4u67G/Hll73dGGHxk1sCcKkJqKg8rAno8qSlpenYRWM16Ikg9R/qr6/9/JqeTT7r5pjSde/ekzpnzm59++3V+te//qIdOnyjZct+oPffP+uKtI8fOnRKBw36WWGUNmz4mS5Zsi9LPPffP+uym0QSEs7pF19s0Btv/E5FRml4+Jc6duxaPXEi5/MdH5+kN9zgaBJ67bXlLjdT5aVLl8l63XVfuVT3v/9dqTDqkvpoCtv770cpjNLFi/ddtG3kyGUKo3Tq1G1uiCxv6enpumlTfK7/xu7E5fQBFJWHJYDCcfD4Qb1z3J3Kw2ijfzbSpduWXlTnTPIZjd4frd+t+k7/9fO/dNHWRVc/0CtszpzdGZ26Dz00R+Pjk/Thh3/J+BIuLPn1CWSudz753HvvLJf3y0lqapqWKjVGhw1b4FL9hQv3KozSuXP/vOT3LAxnz6ZotWrjtFOnSTkmweTkVG3T5kstV+5DPXToVA5HuHTp6em6ZMk+HTjwJw0L+58OHjxbp07dpidP5v6Fnp6eruvWxeoLLyzV2rUd/y2VLv2ejhixRA8fLtz4LoclAHORWdGztObwmsrD6AOfPaDPf/+89n2/r9Z5oY56/c1LeZiMh/xNdOT0kZqaduVGrLhDUlKyDh++RL29R6u//zsKo/Sll35zWzzp6en673+vUBilnTpN0vj4pPx3ykF0dJzCKP3qq00u1T9+/IzCKH399RW51jlzJkXXr4+7pHhc9b//rcs3EW3efEQDAt7VPn1+KJQrpdOnk/Wzz6K1RYsvFEZp2bIfaL9+P2pIyIWBDT16XBjYcD6Gl19eljHizdt7tN500/f68cdr9c47Z6jIKA0IeFefeGKB7t178rLiO3bsjL77bqQmJp675GNYAjA5OnX2lP7j+3+o9xBv9Rvqp01fbqp3jL1DR04fqd+u/FbX7VunRxKP6OAJgzOGlMaejHV32IVu/fo4vemm7/WVV34vlC+Vy/Xdd1vU3/8d9fV9W1u0+ELvu2+Wjhq1Sn/5ZbcePJiYb4yffLJeYZRu337M5fesW/cTve226Tlu27PnhLZqNVFhlD722PzLujrJTXJyqoaF/U/btv0q3883Zkykwij95JP1l/x++/ad1BEjlmi5ch8qjNJmzT7XTz5Zr0lJyap6YWjz888v1kaNLgxtrlTpI4VRKjJKu3SZrGPHrs0y8kxVdevWo/rgg3PUx+dt9fF5Wx98cI5u23a0QPGtXx+nQ4bM1cDAdxVG6fffb73kz5pbArBOYANA4tlESviWwMc7987CCcsm8PikxylbsixTHplCx7odr2KEnmfduji++24r0dHxREcfISYmMWNb+fIlaNWqIr1716Z//zrUqhWcZd8hQ+Yxdep2jh593OURX3fdNZPlyw+wd+8jWcoXLdrHnXf+THJyGv361eXrrzcTHu4YMRQWFnTZn/O8L77YyIMP/sLPPw+gb986edZNT1d69PielSsP0b17Tby8BBHw8pIsz1NS0klOTuPcuQuP5OQ0zp5NZevWY6hC//51efLJVkREVM/zXO3adYJZs3azYsVBrr++CgMH1ic0tFSece7bl8Do0av55JMNnDuXSrduNWjXLpTw8MqEh1eiWrXSWd4zJSWN6dN38uGHa1m6NIaAAB/uuacRjz/eklatKhXshGZio4BMoVi3bx0Dxw1kz9E9/Pf2//Jsj2cve0ipcc2xY2fYsOGIMyHE8/vvB9iy5RgAzZqVp1+/uvTvX4c2bSrTqtWXhIaW5JdfBrp8/PNDL+PiHqNChUBUlfffX8Pf/76YevVCmD79Vho0KMv06TsYPPgXvLyEL7/sle+XtSvS0tJp1OhzSpXyJSrKtWHK+/cn8NBDc4mLO016uuMXreMvGX99fAR/fx/8/Lzw9/fB398bf39v/Py8adAghEceaVGoSSw3sbFJvP/+GubM+ZMNG45krGFVsWIg4eGVCA+vjAh8+ukGDhw4RVhYGR5/vBUPPti0UFbmtVFAptCcSDqhAz4aoDyMDvhowGXNMjaXZ8eOY/rOO6s1IuJb9fIarTBKq1QZq15eo3XkyGUFOtaiRY6O4Dlzduvp08kZk+v69592UUfozp3HM5qEhg9foikpF8/ATkpK1unTd+hDD83RKlXGatu2X+mHH67JsV/jm282K4zSH34oeqN7CtuZMym6cuVB/eijNfrgg3O0WbPPM/7tbrrpe/35552FPqMdawIyhUlVeXf+uwz/cThp6WmU9CtJqYBSlPLP9AgoRWhQKC/0esFtcw48ydGjZ5g9ezczZuxixYqDTJ9+K+HhuS8Cl11CwjmCgj5gyJDmREXFEhUVy6uvXs9LL3XAy+viX+Rnz6by1FO/Mn58NJ07V2Py5L54eQkzZ+7mp592Mn/+Xs6eTSUoyJ+bbqrJtm3HiY6Ox9fXi969a3P//Y3p06c2vr7eNGv2BSIQHT04x/e61iUlJZOQkJxvk9KlsiYgc0Ws/nM1M9bPIOlcEqfOneLUuVNZnm85tIXk1GRe6PUCw3sNJ8DXZnAWZQ0bTmDbtmOUKePH11/34ZZb8m/e+frrzTzyyDy8vISkpBRUoUaN0vTvX5f+/etyww3V8PPzBhwT9b76ajPffLOFw4cds6avv74Ks2btZtKkPtx1V6Mr/RE9kiUA4xaHThzi2SnPMnn1ZOpVrMfH93xM98bd3R2WycULLyxl3ry9TJrUhwYNcl8qI7tNm47wxhsradAghP7969K8eYU82/FTU9NZuHAvX321mR9/3EGtWkFERz+Q5z0rzKWzBGDcat6meTz2zWPsit/F3W3v5u0736ZyUNbmiUMnDrFi9wpW7FrBqj2raFa1GS/f8jIVStt9IK5lSUnJqEKpUrmv9WQujyUA43ZnU87y5pw3+c+c/1DCtwSv9HsFX29flu9czvJdy9lzdA8Afj5+NKvajHX711HSvyQv9XmJJ7s9ib+v3bTcmEthCcAUGdsPb+exSY+xcMtCAKoEV+H6OtfToXYHrq9zPa1qtMLf158th7bw3PfPMXvDbGpXqM1bt7/Fba1vy7NpIeFMAvuP7adOxTou9zeoKn8e+ZPomGja1WpHaHDOt080priyBGCKFFVl1Z+rqBxUmRpla+T5pT5v0zyenfIsmw5uonP9zrxz5zu0qdmGpHNJrNu/jsg9kazes5rIvZFsO7wNAC/xokHlBjSr2ozm1ZpnPGqUrcGB4weI3OvcZ08kkXsjOZbkGE9fLaQay0csp3rZ6rnGY0xxYwnAFGupaal8+tun/POnf3I06Sj1K9VnR+wO0tUxoaZqcFXCw8K5Luw6wsqFsT12O+tj1hMdE82fR/7MOI6/jz/nUs8B4O3lTdMqTbmu1nWE1wynclBl7p9wP1WDq7Js+DLKlnS9E9SYoswSgLkmnDh9gv/+8l82xGygdc3WXBfm+PLOq9km4UwCGw9sJDommu2x26lVvhbhYeG0rN6SEn5ZZ1ku2baEm8fcTOuarVnwzAIC/XO/l64xxcVlJQAR6Qm8B3gDn6rqm9m2i3N7b+A0MFhV14hIdeBLoDKQDoxX1fec+7wC/A2Idx7mRVWdnVcclgDM1fDjmh+5Y9wd9Grai2mPTcPXx7Wb0RhTVOWWAPIddCsi3jju99sLaAzcJSKNs1XrBdRzPoYAY53lqcDfVbURjpvFP55t33dVtaXzkeeXvzFXy22tb+Pjez5m1oZZ/O3Lv+HKj6TidCVtzHmuzLpoC+xU1d2qmgxMBvpnq9Mf+NK57MQfQLCIhKrqIVVdA6CqicAWoGohxm/MFfFIxCO82u9VJq6YyIgfRuRYJy4hjvcWvEf4v8MJeCyAwRMGs3bf2qscqTGXzpUEUBXYn+l1DBd/iedbR0TCgFbAykzFw0QkWkQmiEhITm8uIkNEJFJEIuPj43OqYswV8c++/+TRLo/y1ty3eGfeO4BjLsOU1VPo+35fqjxfhae/expV5e62dzN1zVRa/6s1EaMimLZmGmnpF9+Q3piiJO87RTvkND4v+/VunnVEpBTwA/C0qiY4i8cC/3LW+xfwNvDQRQdRHQ+MB0cfgAvxGlMoRIQP7vqA+MR4/v7931m2cxm/bv2Vk2dOUjW4Ks/d9Bz3tb+PJlWbAPDuX97ls2Wf8cGvH3Db2NsIKxfGE92e4K+d/kpQ4JVfclhVWbtvLV8s/4KFWxbyYMcHeabHM3h7eV/x9zbFU76dwCLSAXhFVW92vn4BQFX/k6nO/4DFqvqt8/U2oIuqHhIRX2AmMFdV38nlPcKAmaraNK9YrBPYuMO5lHP0+aAPf+z+g9tb3879He6nS4MuuX6xpqal8tO6n3hv4Xv8tuM3Av0CCSsXRvnS5SlXshzlS5WnXCnn35LlEBFOJ5/OeCSdS8p4Xsq/FK1rtKZ1zdY0rNwwxxv2xCbE8s0f3/DF8i/YcGADfj5+NKnShLX71tK5fme+GPwFtSrUuuzzkJqWSsLZBBseWwxd8iggEfEBtgM3AgeA1cDdqropU50+wDAco4DaAe+ralvn6KCJwDFVfTrbcUNV9ZDz+TNAO1UdlFcslgCMu6Slp5GWnoafT8HWq1mzdw0TV0wk5ngMR08d5cipIxxNcvxNTUvNcR8/Hz8C/QIJ9AvkxOkTnE4+DUCAbwAtqrWgTc02tK7RmpL+JZm0ahKzN8wmLT2NdrXaMfj6wfzlur8QHBjMlyu+5MnJT5Kens6Yv4zhoU4PuXzzHlVld/xuVu9Zzeo9q1n15yrW7FvD6eTT1KtYj64Nu9KlfhciGkRQJbhKgc6Jufoudxhob2AMjmGgE1T1dREZCqCq45xf9B8CPXEMA31QVSNFpBPwG7ABxzBQcA73FJGvgJY4moD2AI+cTwi5sQRgrhWqSsKZBI4mHUUQAv0dX/jZb8uZlp7G9tjtrNm7hqi9UazZt4a1+9eScMbRkhoaFMr9He7ngesfoFHoxUsp7z26lwc/f5BF2xbRt3lfPrn/k4sW4QPHLUH/2P0Hv+/8nT92/8HqPaszZkcH+AbQqkYrrgu7jtCgUJbvWs7S7Us5eeYkAPUr1adLgy50bdCVnk17EhwYXKBzcTblLOnp6UVizsWeI3uYu2kucYlxPNblMcqVKufukAqFTQQz5hqRnp7O7iO7iUuIo22ttnnex/l8/Q9+/YARP46gpH9J/nfv/2hbqy2/7/zd8dj1O+v3rydd0/ESL5pUaULbWm1pW6st14VdR9MqTS+aC5GWnsa6/etYvG0xi7ctZumOpSScScDX25fujbozsM1A+rfsn+sXaGxCLLOiZzFj/Qzmb55PWnoat7S4hbvb3k2vZr2u2n0jks4lsXjbYuZumsvcTXPZHrs9Y1v5UuV5a+BbDL5+cLG/7aklAGM83JZDW7jvs/uI2huVUVbSvyTta7enY52OdKzbkfa121OmRJkCHzstPY3Vf67mx7U/8n3k9+w5ugdvL2+6NezGwDYDubXlrcQnxjNj/QxmrJ/Byj9XoqpUL1udfi36IQhTIqcQlxhHUIkgbm99O/e0u4eIBhFZ+lpUlWNJx9h3bB/7ju0jPjGeNjXb0KJaC7y88h/UqKpsO7yNmdEzmbNxDst2LiM5NZkSfiXoUr8LNze5mZ5Ne3Iu9RyPfv0oy3ctp1PdToy9dyxNq+bZRVmkWQIwxpCSmsKnyz4lJS2FjnU70qJai3yvIApKVVmzbw1To6YyNWoqO+N2ZtkeXjOcfi370a9FP5pXa57x6zo1LZWFWxYyadUkflzzI6fOnSI0KJRuDbsRnxif8aV/vk8kswqlK9CjUQ9ubnIzPRr3yLI0SHJqMku3L2Vm9ExmRs9kV/wuAJpWbUrPJj25ucnNdKrX6aKrjvT0dD7//XP+8cM/SDibwLPdn2XkLSMp6V8yy2fdEbuDJduXsGT7En7f+TtpmkaFUhUoX6q841G6fMbzWuVrcV3YdVe9ackSgDHmqlNVomOi+Xn9z1QoXYFbWtziUqfxmeQzzIyeyaSVk1i9ZzVVgqtQo2wNx6NcjYznwYHBrNi1gnmb5zFv0zziEuMAaFa1Gd0bdWffsX3M2zyPxLOJBPgG0K1hN/o270ufZn2oUa6GS5/hSOIRhv8wnAm/T6B62eq8MeANEs8mZnzpHz55GICKpSvSuX5nAv0COXLqSJbH+T6b8+pUqJPRzNY2rC2tarSihF8J0tPTiUuMY9+xfew/tp/9x/c7/h7bz8hbRl7yVYglAGPMNS09PZ3omGhHMtg8j992/EaFUhXo27wvfZv3pVvDbpfV0fz7zt8Z+vVQNh7YCDhWoI2oH0Hn+p2JqB9Bg8oNcu0rSE5N5sipI2yP3c6qP1c5HntWsf+YY/6st5c3VYKrcPjkYVLSUrLsG+AbQPWQ6oy/fzxdGnS5pNgtARhjPEpKago+3j6F2oGbkprCom2LqFOhDrUr1L7sYx86cShjmO2+Y/uoElyF6mWrUz2kesbfcqXKXfb7WAIwxhgPdcmrgRpjjLk2WQIwxhgPZQnAGGM8lCUAY4zxUJYAjDHGQ1kCMMYYD2UJwBhjPJQlAGOM8VDFaiKYiMQDey9x9/LAkUIM51pk5yhvdn7yZ+cob+46PzVVtUL2wmKVAC6HiETmNBPOXGDnKG92fvJn5yhvRe38WBOQMcZ4KEsAxhjjoTwpAYx3dwDFgJ2jvNn5yZ+do7wVqfPjMX0AxhhjsvKkKwBjjDGZWAIwxhgP5REJQER6isg2EdkpIiPcHY+7icgEEYkTkY2ZysqKyHwR2eH8G+LOGN1JRKqLyCIR2SIim0TkKWe5nSMnEQkQkVUist55jl51lts5ykREvEVkrYjMdL4uUufnmk8AIuINfAT0AhoDd4lIY/dG5XZfAD2zlY0AFqpqPWCh87WnSgX+rqqNgPbA487/ZuwcXXAO6KaqLYCWQE8RaY+do+yeArZkel2kzs81nwCAtsBOVd2tqsnAZKC/m2NyK1VdChzLVtwfmOh8PhG49WrGVJSo6iFVXeN8nojjf+Cq2DnKoA6nnC99nQ/FzlEGEakG9AE+zVRcpM6PJySAqsD+TK9jnGUmq0qqeggcX4BARTfHUySISBjQCliJnaMsnM0b64A4YL6q2jnKagzwDyA9U1mROj+ekAAkhzIb+2ryJSKlgB+Ap1U1wd3xFDWqmqaqLYFqQFsRaermkIoMEekLxKlqlLtjyYsnJIAYoHqm19WAg26KpSiLFZFQAOffODfH41Yi4ovjy/8bVf3RWWznKAeqegJYjKNfyc6RQ0egn4jswdHs3E1EvqaInR9PSACrgXoiUktE/IBBwAw3x1QUzQAecD5/APjJjbG4lYgI8BmwRVXfybTJzpGTiFQQkWDn8xJAd2Ardo4AUNUXVLWaqobh+M75VVXvpYidH4+YCSwivXG0x3kDE1T1dfdG5F4i8i3QBcfStLHAy8B0YApQA9gH3KGq2TuKPYKIdAJ+AzZwof32RRz9AHaOABFpjqMT0xvHD8kpqvqaiJTDzlEWItIFeE5V+xa18+MRCcAYY8zFPKEJyBhjTA4sARhjjIeyBGCMMR7KEoAxxngoSwDGGOOhLAEYY4yHsgRgjDEe6v8BgyC37X3djFkAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_plot(log):\n",
    "    # plt.plot(log.history['accuracy'],label = \"training accuracy\",color='green')\n",
    "    plt.plot(log.history['loss'],label = \"training loss\",color='darkgreen')\n",
    "    # plt.plot(log.history['val_accuracy'], label = \"validation accuracy\",color='grey')\n",
    "    plt.plot(log.history['val_loss'], label = \"validation loss\",color='darkblue')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "create_plot(log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the best model in question 5\n",
    "# best_model.save('./best_model_question_5.h5')\n",
    "\n",
    "# load the best model in question 5\n",
    "best_model=None\n",
    "best_model = tf.keras.models.load_model('./models/best_model_question_5.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model on the test dataset, and we can find that our ROC score is about 0.82 which is good. In the next part, we are going to select the threshold to predcit the fraud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 0s 500us/step - loss: 0.5465\n",
      "loss:0.5464516282081604\n",
      "roc:0.7800475424975203\n"
     ]
    }
   ],
   "source": [
    "loss = best_model.evaluate(X_test, y_test)\n",
    "y_test_predict = best_model.predict(X_test).flatten()\n",
    "# calculate the roc\n",
    "roc_score = roc_auc_score(y_test, y_test_predict)\n",
    "print(f\"loss:{loss}\")\n",
    "print(f\"roc:{roc_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since it is more costly to miss the fraud cases, and less costly to make a false alarm, we are going to suppose that the cost missed fraud is 10 times more than the cost of false alarm (This ratio can be adjusted to the real case).\n",
    "Thus, our cost function is:\n",
    "\n",
    "```Cost = 10*FN + FP```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cost(fn,fp):\n",
    "    return 20*fn+fp\n",
    "\n",
    "cost_lost = {}\n",
    "for i in np.linspace(0,0.1,501):\n",
    "    pred_y = np.where(y_test_predict.flatten()> i, 1, 0)\n",
    "    cm = confusion_matrix(y_test,pred_y)\n",
    "    fn,fp = cm[1][0],cm[0][1]\n",
    "    # cost_lost[\"Threshold: \"+str(i)] = calculate_cost(fn,fp)\n",
    "    cost_lost[i] = calculate_cost(fn,fp)\n",
    "\n",
    "optimal_threshold = min(cost_lost, key=cost_lost.get)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix is :\n",
      "[[2053  196]\n",
      " [  20    6]]\n",
      "Accuracy rate is 0.9050549450549451\n",
      "Sensitivity is 0.23076923076923078\n"
     ]
    }
   ],
   "source": [
    "pred_y = np.where(y_test_predict > optimal_threshold, 1, 0)\n",
    "cm = confusion_matrix(y_test, pred_y)\n",
    "print(f\"Confusion matrix is :\" )\n",
    "print(cm)\n",
    "accuracy_rate = (cm[0,0] + cm[1,1])/np.sum(cm)\n",
    "print(f\"Accuracy rate is {accuracy_rate}\")\n",
    "# calculate the sensitivity \n",
    "sensitivity = cm[1,1]/(cm[1,1] + cm[1,0])\n",
    "print(f\"Sensitivity is {sensitivity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6\n",
    "### Question\n",
    "Our second approach will be to use an autoencoder to learn what \"normal\" (non-fraudulent) data \"looks like.\"\n",
    "\n",
    "1. Prepare dataset for autoencoder\n",
    "\n",
    "   - Using the original data, create a training set that contains only non fraudulent claims\n",
    "   - As well as validation and test sets that contain non fraudulent and fraudulent claims. \n",
    "   - Make sure to spread fraudulent claims evenly across validation and test sets.\n",
    "\n",
    "2. Create an autoencoder using TensorFlow\n",
    "\n",
    "   - Ensure that the middle hidden layer has fewer neurons than your input features. \n",
    "   - Use training and validation sets to find a model that represents its input data well. In particular, you will want to predict your validation set observations. \n",
    "   - For each observation, you can measure the difference between the original observations and the predicted one, using, for example, the mean squared error of all features of the observation. \n",
    "   - Plot the errors for all your validation set observations in a histogram - in a good model, this error should be much higher for fraudulent claims than non-fraudulent ones.\n",
    "\n",
    "3. Assess predictions of autoencoder created\n",
    "\n",
    "   - Use your trained autoencoder to predict the test set and define the corresponding losses(?). \n",
    "   - Create a histogram of your test set claims, clearly marking fraudulent and non- fraudulent claims. \n",
    "   - Discuss how you could use this to decide whether a transaction is fraudulent or not. \n",
    "   - Can you also derive an AUC in this approach - if yes, how does it perform compared to the previous approaches?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of normal_df: 11259\n",
      "The length of fraud_df: 112\n",
      "normal_train_size: 9097\n",
      "fraud_val_test_size: 56\n",
      "normal_val_test_size: 1081\n",
      "\n",
      "len(train_df): 9097\n",
      "len(normal_df) excluding data in train_df: 2162\n",
      "\n",
      "len(val_df): 1081\n",
      "len(test_df): 1081\n",
      "\n",
      "len(test[test.LossDate == False]) = 0\n",
      "\n",
      "len(val_df): 1137\n",
      "len(test_df): 1137\n",
      "\n",
      "Check if len(train_df) + len(val_df) + len(test_df) == len(df_autoencoder): True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_63917/4067720204.py:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  val_df = val_df.append(fraud_df.sample(fraud_val_test_size, random_state=0))\n",
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_63917/4067720204.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  test_df = test_df.append(fraud_df[~fraud_df.isin(val_df)].dropna())\n"
     ]
    }
   ],
   "source": [
    "# get a copy of raw df\n",
    "\n",
    "df_autoencoder = df.copy()\n",
    "# split dataset into non-fraud (normal) and fraud\n",
    "normal_df = df_autoencoder[df_autoencoder.Fraud == 0]\n",
    "fraud_df = df_autoencoder[df_autoencoder.Fraud == 1]\n",
    "print(f'The length of normal_df: {len(normal_df)}')\n",
    "print(f'The length of fraud_df: {len(fraud_df)}')\n",
    "\n",
    "# variables for splitting data into train, val and test sets \n",
    "train_split = 0.8\n",
    "test_split = 1 - train_split\n",
    "normal_train_size = round(len(df_autoencoder) * train_split)\n",
    "fraud_val_test_size = int(len(fraud_df) / 2)\n",
    "normal_val_test_size = int(round(len(df_autoencoder) * test_split / 2) - fraud_val_test_size)\n",
    "print(f'normal_train_size: {normal_train_size}')\n",
    "print(f'fraud_val_test_size: {fraud_val_test_size}')\n",
    "print(f'normal_val_test_size: {normal_val_test_size}\\n')\n",
    "\n",
    "# sample non-fraud data for train set\n",
    "train_df = normal_df.sample(normal_train_size, random_state=0)\n",
    "normal_df = normal_df[~normal_df.isin(train_df)].dropna()\n",
    "print(f'len(train_df): {len(train_df)}')\n",
    "print(f'len(normal_df) excluding data in train_df: {len(normal_df)}\\n')\n",
    "\n",
    "# sample non-fraud data for val and test sets\n",
    "val_df = normal_df.sample(normal_val_test_size, random_state=0)\n",
    "test_df = normal_df[~normal_df.isin(val_df)].dropna()\n",
    "print(f'len(val_df): {len(val_df)}')\n",
    "print(f'len(test_df): {len(test_df)}\\n')\n",
    "\n",
    "# check if all normal data is in the train, val and test sets\n",
    "normal_df = df_autoencoder[df_autoencoder.Fraud == 0]\n",
    "test = pd.concat([train_df, val_df, test_df]).isin(normal_df)\n",
    "print(f'len(test[test.LossDate == False]) = {len(test[test.LossDate == False])}\\n')\n",
    "\n",
    "# sample fraud data for val and test sets\n",
    "val_df = val_df.append(fraud_df.sample(fraud_val_test_size, random_state=0))\n",
    "test_df = test_df.append(fraud_df[~fraud_df.isin(val_df)].dropna())\n",
    "print(f'len(val_df): {len(val_df)}')\n",
    "print(f'len(test_df): {len(test_df)}\\n')\n",
    "\n",
    "print(f'Check if len(train_df) + len(val_df) + len(test_df) == len(df_autoencoder): {len(train_df) + len(val_df) + len(test_df) == len(df_autoencoder)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn the dataframe into numpy arrays\n",
    "y_train = train_df[['Fraud']].to_numpy()\n",
    "y_val = val_df[['Fraud']].to_numpy()\n",
    "y_test = test_df[['Fraud']].to_numpy()\n",
    "\n",
    "X_train = train_df.drop(['Fraud'], axis=1)\n",
    "X_val = val_df.drop(['Fraud'], axis=1)\n",
    "X_test = test_df.drop(['Fraud'], axis=1)\n",
    "\n",
    "train_col_names = list(X_train.columns)+['df_key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check if len(X_train) + len(X_val) + len(X_test) == len(df_autoencoder): True\n",
      "X_train.shape: (9097, 65)\n",
      "X_val.shape: (1137, 65)\n",
      "X_test.shape: (1137, 65)\n"
     ]
    }
   ],
   "source": [
    "# Fit the MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train.loc[:,'df_key'] = 1\n",
    "X_val.loc[:,'df_key'] = 0\n",
    "X_test.loc[:,'df_key'] = 0\n",
    "X_train_val = pd.concat([X_train, X_val])\n",
    "# X_df_key = X_train_val[['df_key']]\n",
    "# X_train_val = X_train_val.drop(['df_key'], axis=1)\n",
    "\n",
    "X_train_val = pd.DataFrame(scaler.fit_transform(X_train_val), columns=train_col_names)\n",
    "X_test = pd.DataFrame(scaler.transform(X_test), columns=train_col_names)\n",
    "X_test = X_test.drop(['df_key'], axis=1)\n",
    "X_train = X_train_val[X_train_val.df_key == 1].drop(['df_key'], axis=1)\n",
    "X_val = X_train_val[X_train_val.df_key == 0].drop(['df_key'], axis=1)\n",
    "\n",
    "print(f'check if len(X_train) + len(X_val) + len(X_test) == len(df_autoencoder): {len(X_train) + len(X_val) + len(X_test) == len(df_autoencoder)}')\n",
    "print(f\"X_train.shape: {X_train.shape}\")\n",
    "print(f\"X_val.shape: {X_val.shape}\")\n",
    "print(f\"X_test.shape: {X_test.shape}\")\n",
    "X_train = X_train.to_numpy()\n",
    "X_val = X_val.to_numpy()\n",
    "X_test = X_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Question 6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_train,X_train_val, y_train_train, y_train_val = train_test_split(X_train, y_train, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncodingModel:\n",
    "    def __init__(self, reg_param, number_units_layers, number_units_bottleneck, dropout_rate, number_layers, whether_dropout, whether_regularizer, X_train_train=X_train_train, X_train_val=X_train_val, X_val=X_val,epochs=100) -> None:\n",
    "        tf.keras.backend.clear_session()\n",
    "        tf.random.set_seed(48)\n",
    "        self.X_train_train = X_train_train\n",
    "        self.X_train_val = X_train_val\n",
    "        self.X_val = X_val\n",
    "        self.reg_param = reg_param\n",
    "        self.number_units_layers = number_units_layers\n",
    "        self.number_units_bottleneck = number_units_bottleneck\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.number_layers = number_layers\n",
    "        self.whether_dropout =  whether_dropout\n",
    "        self.whether_regularizer = whether_regularizer\n",
    "        self.input_dim = self.X_train_train.shape[1]\n",
    "        self.epochs  = epochs\n",
    "        self.build_model()\n",
    "        self.compile_model()\n",
    "\n",
    "    def build_model(self):\n",
    "        \"\"\"\n",
    "        Build the model according to the hyperparameters input\n",
    "        \"\"\"\n",
    "        regularizer = tf.keras.regularizers.l2(\n",
    "            self.reg_param*self.whether_regularizer)\n",
    "        if self.whether_dropout == True:\n",
    "            encoder = tf.keras.models.Sequential([\n",
    "                tf.keras.layers.Dense(self.number_units_layers, activation=\"relu\")]*self.number_layers+[\n",
    "                tf.keras.layers.Dropout(self.dropout_rate), # dropout before the bottleneck layer\n",
    "                tf.keras.layers.Dense(self.number_units_bottleneck,activation='sigmoid', kernel_regularizer=regularizer)])\n",
    "        else:\n",
    "            encoder = tf.keras.models.Sequential([\n",
    "                tf.keras.layers.Dense(self.number_units_layers, activation=\"relu\")]*self.number_layers+[\n",
    "                tf.keras.layers.Dense(self.input_dim,activation='sigmoid')])\n",
    "        decoder = tf.keras.models.Sequential([\n",
    "                tf.keras.layers.Dense(self.number_units_layers, activation=\"relu\")]*self.number_layers+[\n",
    "                tf.keras.layers.Dense(self.input_dim, activation=\"sigmoid\")])\n",
    "        self.autoencoder = tf.keras.models.Sequential([encoder, decoder])\n",
    "\n",
    "        # random_seed = 192\n",
    "    def get_hp(self):\n",
    "        # get all hyperparameters\n",
    "        return {\n",
    "            'reg_param': self.reg_param,\n",
    "            'number_units_layers': self.number_units_layers,\n",
    "            'number_units_bottleneck': self.number_units_bottleneck,\n",
    "            'dropout_rate': self.dropout_rate,\n",
    "            'number_layers': self.number_layers,\n",
    "            'whether_dropout': self.whether_dropout,\n",
    "            'whether_regularizer': self.whether_regularizer\n",
    "        }\n",
    "\n",
    "    def get_model(self):\n",
    "        \"\"\"\n",
    "        get the model from the class\n",
    "        \"\"\"\n",
    "        return self.autoencoder\n",
    "\n",
    "    def compile_model(self):\n",
    "        \"\"\"\n",
    "        compile the model\n",
    "        \"\"\"\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "        self.autoencoder.compile(\n",
    "            optimizer=optimizer, loss='mean_squared_error')\n",
    "\n",
    "    def __train_model(self):\n",
    "        \"\"\"\n",
    "        Train the data only contains non-fraud claims\n",
    "        \"\"\"\n",
    "        early_stopping_cb = tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "        self.log_train_non_fraud = self.autoencoder.fit(x=self.X_train_train, y=self.X_train_train,\n",
    "                                                        epochs=self.epochs,\n",
    "                                                        validation_data=(X_train_val, X_train_val), callbacks=[early_stopping_cb])\n",
    "\n",
    "    def get_train_non_fraud_loss_diff(self):\n",
    "        \"\"\"\n",
    "        calculate the overfit_metric\n",
    "        \"\"\"\n",
    "        self.__train_model()\n",
    "        return self.log_train_non_fraud.history['val_loss'][-1]-self.log_train_non_fraud.history['loss'][-1] \n",
    "        \n",
    "    def get_train_val_loss(self):\n",
    "        \"\"\"\n",
    "        get the val1_loss\n",
    "        \"\"\"\n",
    "        return self.log_train_non_fraud.history['val_loss'][-1]\n",
    "\n",
    "    def __apply_model_fraud(self):\n",
    "        \"\"\"\n",
    "        apply the model on the val2, and get the overall average mse loss\n",
    "        \"\"\"\n",
    "        reconstructions = self.autoencoder.predict(self.X_val)\n",
    "        self.val_loss = np.mean(tf.keras.losses.mse(reconstructions, self.X_val))\n",
    "\n",
    "    def get_val_loss(self):\n",
    "        self.__apply_model_fraud()\n",
    "        return self.val_loss\n",
    "\n",
    "    def run(self):\n",
    "        # the difference of loss in the train_train and train_val, the metric to access the overfitting\n",
    "        overfit_metric = self.get_train_non_fraud_loss_diff()  #TODO change it to overfit_metric\n",
    "        val2_avg_recon_error = self.get_val_loss() #TODO change it to val2_avg_recon_error\n",
    "        val1_loss = self.get_train_val_loss()  #TODO change it to val1_loss\n",
    "        return {\"overfit_metric\": overfit_metric, \"val2_avg_recon_error\": val2_avg_recon_error, \"val1_loss\":val1_loss, \"model\": self.autoencoder, \"log\":self.log_train_non_fraud}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a list of hyperparameters and train the model. After trainnig the model, we will record the hyperparameters and the performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This round is 0\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-09 11:46:02.816044: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 1s 1ms/step - loss: 0.0932 - val_loss: 0.0480\n",
      "Epoch 2/100\n",
      "199/199 [==============================] - 0s 923us/step - loss: 0.0387 - val_loss: 0.0340\n",
      "Epoch 3/100\n",
      "199/199 [==============================] - 0s 884us/step - loss: 0.0290 - val_loss: 0.0252\n",
      "Epoch 4/100\n",
      "199/199 [==============================] - 0s 897us/step - loss: 0.0231 - val_loss: 0.0209\n",
      "Epoch 5/100\n",
      "199/199 [==============================] - 0s 888us/step - loss: 0.0193 - val_loss: 0.0177\n",
      "Epoch 6/100\n",
      "199/199 [==============================] - 0s 916us/step - loss: 0.0169 - val_loss: 0.0157\n",
      "Epoch 7/100\n",
      "199/199 [==============================] - 0s 882us/step - loss: 0.0148 - val_loss: 0.0137\n",
      "Epoch 8/100\n",
      "199/199 [==============================] - 0s 951us/step - loss: 0.0129 - val_loss: 0.0121\n",
      "Epoch 9/100\n",
      "199/199 [==============================] - 0s 899us/step - loss: 0.0114 - val_loss: 0.0110\n",
      "Epoch 10/100\n",
      "199/199 [==============================] - 0s 906us/step - loss: 0.0104 - val_loss: 0.0101\n",
      "Epoch 11/100\n",
      "199/199 [==============================] - 0s 912us/step - loss: 0.0096 - val_loss: 0.0094\n",
      "Epoch 12/100\n",
      "199/199 [==============================] - 0s 882us/step - loss: 0.0090 - val_loss: 0.0088\n",
      "Epoch 13/100\n",
      "199/199 [==============================] - 0s 900us/step - loss: 0.0083 - val_loss: 0.0082\n",
      "Epoch 14/100\n",
      "199/199 [==============================] - 0s 898us/step - loss: 0.0077 - val_loss: 0.0077\n",
      "Epoch 15/100\n",
      "199/199 [==============================] - 0s 893us/step - loss: 0.0073 - val_loss: 0.0073\n",
      "Epoch 16/100\n",
      "199/199 [==============================] - 0s 899us/step - loss: 0.0069 - val_loss: 0.0070\n",
      "Epoch 17/100\n",
      "199/199 [==============================] - 0s 892us/step - loss: 0.0066 - val_loss: 0.0067\n",
      "Epoch 18/100\n",
      "199/199 [==============================] - 0s 897us/step - loss: 0.0063 - val_loss: 0.0064\n",
      "Epoch 19/100\n",
      "199/199 [==============================] - 0s 904us/step - loss: 0.0060 - val_loss: 0.0061\n",
      "Epoch 20/100\n",
      "199/199 [==============================] - 0s 894us/step - loss: 0.0057 - val_loss: 0.0058\n",
      "Epoch 21/100\n",
      "199/199 [==============================] - 0s 891us/step - loss: 0.0055 - val_loss: 0.0057\n",
      "Epoch 22/100\n",
      "199/199 [==============================] - 0s 917us/step - loss: 0.0053 - val_loss: 0.0055\n",
      "Epoch 23/100\n",
      "199/199 [==============================] - 0s 904us/step - loss: 0.0051 - val_loss: 0.0053\n",
      "Epoch 24/100\n",
      "199/199 [==============================] - 0s 903us/step - loss: 0.0049 - val_loss: 0.0051\n",
      "Epoch 25/100\n",
      "199/199 [==============================] - 0s 907us/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 26/100\n",
      "199/199 [==============================] - 0s 907us/step - loss: 0.0044 - val_loss: 0.0047\n",
      "Epoch 27/100\n",
      "199/199 [==============================] - 0s 912us/step - loss: 0.0043 - val_loss: 0.0046\n",
      "Epoch 28/100\n",
      "199/199 [==============================] - 0s 912us/step - loss: 0.0041 - val_loss: 0.0044\n",
      "Epoch 29/100\n",
      "199/199 [==============================] - 0s 895us/step - loss: 0.0039 - val_loss: 0.0044\n",
      "Epoch 30/100\n",
      "199/199 [==============================] - 0s 916us/step - loss: 0.0038 - val_loss: 0.0043\n",
      "Epoch 31/100\n",
      "199/199 [==============================] - 0s 916us/step - loss: 0.0037 - val_loss: 0.0041\n",
      "Epoch 32/100\n",
      "199/199 [==============================] - 0s 972us/step - loss: 0.0036 - val_loss: 0.0040\n",
      "Epoch 33/100\n",
      "199/199 [==============================] - 0s 972us/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 34/100\n",
      "199/199 [==============================] - 0s 912us/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 35/100\n",
      "199/199 [==============================] - 0s 917us/step - loss: 0.0032 - val_loss: 0.0036\n",
      "Epoch 36/100\n",
      "199/199 [==============================] - 0s 920us/step - loss: 0.0031 - val_loss: 0.0035\n",
      "Epoch 37/100\n",
      "199/199 [==============================] - 0s 919us/step - loss: 0.0030 - val_loss: 0.0034\n",
      "Epoch 38/100\n",
      "199/199 [==============================] - 0s 912us/step - loss: 0.0029 - val_loss: 0.0033\n",
      "Epoch 39/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0028 - val_loss: 0.0033\n",
      "Epoch 40/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0028 - val_loss: 0.0032\n",
      "Epoch 41/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0027 - val_loss: 0.0032\n",
      "Epoch 42/100\n",
      "199/199 [==============================] - 0s 961us/step - loss: 0.0026 - val_loss: 0.0031\n",
      "Epoch 43/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0026 - val_loss: 0.0030\n",
      "Epoch 44/100\n",
      "199/199 [==============================] - 0s 956us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 45/100\n",
      "199/199 [==============================] - 0s 966us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 46/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 47/100\n",
      "199/199 [==============================] - 0s 943us/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 48/100\n",
      "199/199 [==============================] - 0s 935us/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 49/100\n",
      "199/199 [==============================] - 0s 937us/step - loss: 0.0021 - val_loss: 0.0026\n",
      "Epoch 50/100\n",
      "199/199 [==============================] - 0s 935us/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 51/100\n",
      "199/199 [==============================] - 0s 934us/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 52/100\n",
      "199/199 [==============================] - 0s 946us/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 53/100\n",
      "199/199 [==============================] - 0s 950us/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 54/100\n",
      "199/199 [==============================] - 0s 938us/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 55/100\n",
      "199/199 [==============================] - 0s 969us/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 56/100\n",
      "199/199 [==============================] - 0s 929us/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 57/100\n",
      "199/199 [==============================] - 0s 933us/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 58/100\n",
      "199/199 [==============================] - 0s 943us/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 59/100\n",
      "199/199 [==============================] - 0s 923us/step - loss: 0.0017 - val_loss: 0.0022\n",
      "Epoch 60/100\n",
      "199/199 [==============================] - 0s 928us/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 61/100\n",
      "199/199 [==============================] - 0s 923us/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 62/100\n",
      "199/199 [==============================] - 0s 918us/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 63/100\n",
      "199/199 [==============================] - 0s 913us/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 64/100\n",
      "199/199 [==============================] - 0s 912us/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 65/100\n",
      "199/199 [==============================] - 0s 922us/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 66/100\n",
      "199/199 [==============================] - 0s 922us/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 67/100\n",
      "199/199 [==============================] - 0s 930us/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 68/100\n",
      "199/199 [==============================] - 0s 926us/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 69/100\n",
      "199/199 [==============================] - 0s 924us/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 70/100\n",
      "199/199 [==============================] - 0s 926us/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 71/100\n",
      "199/199 [==============================] - 0s 917us/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 72/100\n",
      "199/199 [==============================] - 0s 931us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 73/100\n",
      "199/199 [==============================] - 0s 916us/step - loss: 0.0013 - val_loss: 0.0020\n",
      "Epoch 74/100\n",
      "199/199 [==============================] - 0s 902us/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 75/100\n",
      "199/199 [==============================] - 0s 914us/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 76/100\n",
      "199/199 [==============================] - 0s 907us/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 77/100\n",
      "199/199 [==============================] - 0s 914us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 78/100\n",
      "199/199 [==============================] - 0s 919us/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 79/100\n",
      "199/199 [==============================] - 0s 927us/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 80/100\n",
      "199/199 [==============================] - 0s 913us/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 81/100\n",
      "199/199 [==============================] - 0s 923us/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 82/100\n",
      "199/199 [==============================] - 0s 946us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 83/100\n",
      "199/199 [==============================] - 0s 926us/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 84/100\n",
      "199/199 [==============================] - 0s 931us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 85/100\n",
      "199/199 [==============================] - 0s 922us/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 86/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 87/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 88/100\n",
      "199/199 [==============================] - 0s 986us/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 89/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 90/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 91/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 92/100\n",
      "199/199 [==============================] - 0s 982us/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 93/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 94/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0010 - val_loss: 0.0016\n",
      "Epoch 95/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0010 - val_loss: 0.0016\n",
      "Epoch 96/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0010 - val_loss: 0.0016\n",
      "Epoch 97/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0010 - val_loss: 0.0016\n",
      "Epoch 98/100\n",
      "199/199 [==============================] - 0s 953us/step - loss: 0.0010 - val_loss: 0.0016\n",
      "Epoch 99/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0010 - val_loss: 0.0016\n",
      "Epoch 100/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 0.0016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_63917/2731616321.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  para_dfm = para_dfm.append({\"reg_param\": reg_param, \"number_units_layers\": numbers_units_layers, \"number_units_bottleneck\": numbers_units_bottleneck, \"dropout_rate\": dropout_rate, \"number_layers\": numbers_layers, \"whether_dropout\": whether_dropout, \"whether_regularizer\": whether_regularizer, \"overfit_metric\": overfit_metric, \"val2_avg_recon_error\": val2_avg_recon_error,'val1_loss':val1_loss}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This round is 1\n",
      "Epoch 1/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0869 - val_loss: 0.0551\n",
      "Epoch 2/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0483 - val_loss: 0.0396\n",
      "Epoch 3/100\n",
      "199/199 [==============================] - 0s 961us/step - loss: 0.0380 - val_loss: 0.0364\n",
      "Epoch 4/100\n",
      "199/199 [==============================] - 0s 923us/step - loss: 0.0346 - val_loss: 0.0313\n",
      "Epoch 5/100\n",
      "199/199 [==============================] - 0s 919us/step - loss: 0.0285 - val_loss: 0.0254\n",
      "Epoch 6/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0238 - val_loss: 0.0214\n",
      "Epoch 7/100\n",
      "199/199 [==============================] - 0s 964us/step - loss: 0.0206 - val_loss: 0.0186\n",
      "Epoch 8/100\n",
      "199/199 [==============================] - 0s 925us/step - loss: 0.0184 - val_loss: 0.0170\n",
      "Epoch 9/100\n",
      "199/199 [==============================] - 0s 986us/step - loss: 0.0169 - val_loss: 0.0156\n",
      "Epoch 10/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0154 - val_loss: 0.0142\n",
      "Epoch 11/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0142 - val_loss: 0.0133\n",
      "Epoch 12/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0134 - val_loss: 0.0127\n",
      "Epoch 13/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0129 - val_loss: 0.0122\n",
      "Epoch 14/100\n",
      "199/199 [==============================] - 0s 920us/step - loss: 0.0122 - val_loss: 0.0116\n",
      "Epoch 15/100\n",
      "199/199 [==============================] - 0s 922us/step - loss: 0.0115 - val_loss: 0.0109\n",
      "Epoch 16/100\n",
      "199/199 [==============================] - 0s 913us/step - loss: 0.0107 - val_loss: 0.0102\n",
      "Epoch 17/100\n",
      "199/199 [==============================] - 0s 918us/step - loss: 0.0101 - val_loss: 0.0096\n",
      "Epoch 18/100\n",
      "199/199 [==============================] - 0s 916us/step - loss: 0.0095 - val_loss: 0.0092\n",
      "Epoch 19/100\n",
      "199/199 [==============================] - 0s 923us/step - loss: 0.0091 - val_loss: 0.0088\n",
      "Epoch 20/100\n",
      "199/199 [==============================] - 0s 918us/step - loss: 0.0088 - val_loss: 0.0085\n",
      "Epoch 21/100\n",
      "199/199 [==============================] - 0s 928us/step - loss: 0.0084 - val_loss: 0.0083\n",
      "Epoch 22/100\n",
      "199/199 [==============================] - 0s 934us/step - loss: 0.0082 - val_loss: 0.0080\n",
      "Epoch 23/100\n",
      "199/199 [==============================] - 0s 926us/step - loss: 0.0079 - val_loss: 0.0078\n",
      "Epoch 24/100\n",
      "199/199 [==============================] - 0s 935us/step - loss: 0.0077 - val_loss: 0.0076\n",
      "Epoch 25/100\n",
      "199/199 [==============================] - 0s 926us/step - loss: 0.0075 - val_loss: 0.0074\n",
      "Epoch 26/100\n",
      "199/199 [==============================] - 0s 933us/step - loss: 0.0072 - val_loss: 0.0071\n",
      "Epoch 27/100\n",
      "199/199 [==============================] - 0s 933us/step - loss: 0.0070 - val_loss: 0.0069\n",
      "Epoch 28/100\n",
      "199/199 [==============================] - 0s 961us/step - loss: 0.0068 - val_loss: 0.0067\n",
      "Epoch 29/100\n",
      "199/199 [==============================] - 0s 939us/step - loss: 0.0066 - val_loss: 0.0065\n",
      "Epoch 30/100\n",
      "199/199 [==============================] - 0s 942us/step - loss: 0.0064 - val_loss: 0.0063\n",
      "Epoch 31/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0062 - val_loss: 0.0061\n",
      "Epoch 32/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0060\n",
      "Epoch 33/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0058\n",
      "Epoch 34/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0057 - val_loss: 0.0056\n",
      "Epoch 35/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0055 - val_loss: 0.0055\n",
      "Epoch 36/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0053 - val_loss: 0.0052\n",
      "Epoch 37/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0051 - val_loss: 0.0050\n",
      "Epoch 38/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0050 - val_loss: 0.0049\n",
      "Epoch 39/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 0.0048\n",
      "Epoch 40/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 41/100\n",
      "199/199 [==============================] - 0s 966us/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 42/100\n",
      "199/199 [==============================] - 0s 956us/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 43/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0045 - val_loss: 0.0044\n",
      "Epoch 44/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 45/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0043 - val_loss: 0.0042\n",
      "Epoch 46/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0041\n",
      "Epoch 47/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0041\n",
      "Epoch 48/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0040\n",
      "Epoch 49/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 50/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 51/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 52/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0039 - val_loss: 0.0038\n",
      "Epoch 53/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 54/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0038 - val_loss: 0.0037\n",
      "Epoch 55/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0037 - val_loss: 0.0036\n",
      "Epoch 56/100\n",
      "199/199 [==============================] - 0s 984us/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 57/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 58/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 59/100\n",
      "199/199 [==============================] - 0s 962us/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 60/100\n",
      "199/199 [==============================] - 0s 1000us/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 61/100\n",
      "199/199 [==============================] - 0s 999us/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 62/100\n",
      "199/199 [==============================] - 0s 983us/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 63/100\n",
      "199/199 [==============================] - 0s 957us/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 64/100\n",
      "199/199 [==============================] - 0s 962us/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 65/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 66/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 67/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 68/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 69/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 70/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 71/100\n",
      "199/199 [==============================] - 0s 988us/step - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 72/100\n",
      "199/199 [==============================] - 0s 952us/step - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 73/100\n",
      "199/199 [==============================] - 0s 979us/step - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 74/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 75/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 76/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0028 - val_loss: 0.0029\n",
      "Epoch 77/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0028 - val_loss: 0.0029\n",
      "Epoch 78/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0028 - val_loss: 0.0029\n",
      "Epoch 79/100\n",
      "199/199 [==============================] - 0s 998us/step - loss: 0.0028 - val_loss: 0.0029\n",
      "Epoch 80/100\n",
      "199/199 [==============================] - 0s 972us/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 81/100\n",
      "199/199 [==============================] - 0s 955us/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 82/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 83/100\n",
      "199/199 [==============================] - 0s 957us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 84/100\n",
      "199/199 [==============================] - 0s 969us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 85/100\n",
      "199/199 [==============================] - 0s 974us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 86/100\n",
      "199/199 [==============================] - 0s 989us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 87/100\n",
      "199/199 [==============================] - 0s 956us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 88/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 89/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 90/100\n",
      "199/199 [==============================] - 0s 972us/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 91/100\n",
      "199/199 [==============================] - 0s 983us/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 92/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 93/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 94/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 95/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 96/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 97/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 98/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 99/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 100/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0024 - val_loss: 0.0025\n",
      "This round is 2\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_63917/2731616321.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  para_dfm = para_dfm.append({\"reg_param\": reg_param, \"number_units_layers\": numbers_units_layers, \"number_units_bottleneck\": numbers_units_bottleneck, \"dropout_rate\": dropout_rate, \"number_layers\": numbers_layers, \"whether_dropout\": whether_dropout, \"whether_regularizer\": whether_regularizer, \"overfit_metric\": overfit_metric, \"val2_avg_recon_error\": val2_avg_recon_error,'val1_loss':val1_loss}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0869 - val_loss: 0.0551\n",
      "Epoch 2/100\n",
      "199/199 [==============================] - 0s 954us/step - loss: 0.0484 - val_loss: 0.0397\n",
      "Epoch 3/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0380 - val_loss: 0.0360\n",
      "Epoch 4/100\n",
      "199/199 [==============================] - 0s 999us/step - loss: 0.0343 - val_loss: 0.0323\n",
      "Epoch 5/100\n",
      "199/199 [==============================] - 0s 972us/step - loss: 0.0308 - val_loss: 0.0289\n",
      "Epoch 6/100\n",
      "199/199 [==============================] - 0s 942us/step - loss: 0.0267 - val_loss: 0.0235\n",
      "Epoch 7/100\n",
      "199/199 [==============================] - 0s 932us/step - loss: 0.0215 - val_loss: 0.0189\n",
      "Epoch 8/100\n",
      "199/199 [==============================] - 0s 936us/step - loss: 0.0183 - val_loss: 0.0167\n",
      "Epoch 9/100\n",
      "199/199 [==============================] - 0s 943us/step - loss: 0.0164 - val_loss: 0.0153\n",
      "Epoch 10/100\n",
      "199/199 [==============================] - 0s 944us/step - loss: 0.0152 - val_loss: 0.0143\n",
      "Epoch 11/100\n",
      "199/199 [==============================] - 0s 945us/step - loss: 0.0142 - val_loss: 0.0134\n",
      "Epoch 12/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0134 - val_loss: 0.0127\n",
      "Epoch 13/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0126 - val_loss: 0.0120\n",
      "Epoch 14/100\n",
      "199/199 [==============================] - 0s 965us/step - loss: 0.0119 - val_loss: 0.0113\n",
      "Epoch 15/100\n",
      "199/199 [==============================] - 0s 968us/step - loss: 0.0112 - val_loss: 0.0107\n",
      "Epoch 16/100\n",
      "199/199 [==============================] - 0s 986us/step - loss: 0.0106 - val_loss: 0.0101\n",
      "Epoch 17/100\n",
      "199/199 [==============================] - 0s 971us/step - loss: 0.0100 - val_loss: 0.0096\n",
      "Epoch 18/100\n",
      "199/199 [==============================] - 0s 979us/step - loss: 0.0095 - val_loss: 0.0092\n",
      "Epoch 19/100\n",
      "199/199 [==============================] - 0s 950us/step - loss: 0.0091 - val_loss: 0.0088\n",
      "Epoch 20/100\n",
      "199/199 [==============================] - 0s 952us/step - loss: 0.0087 - val_loss: 0.0085\n",
      "Epoch 21/100\n",
      "199/199 [==============================] - 0s 957us/step - loss: 0.0084 - val_loss: 0.0082\n",
      "Epoch 22/100\n",
      "199/199 [==============================] - 0s 947us/step - loss: 0.0081 - val_loss: 0.0079\n",
      "Epoch 23/100\n",
      "199/199 [==============================] - 0s 995us/step - loss: 0.0078 - val_loss: 0.0076\n",
      "Epoch 24/100\n",
      "199/199 [==============================] - 0s 956us/step - loss: 0.0075 - val_loss: 0.0074\n",
      "Epoch 25/100\n",
      "199/199 [==============================] - 0s 957us/step - loss: 0.0073 - val_loss: 0.0072\n",
      "Epoch 26/100\n",
      "199/199 [==============================] - 0s 959us/step - loss: 0.0070 - val_loss: 0.0070\n",
      "Epoch 27/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 0.0068\n",
      "Epoch 28/100\n",
      "199/199 [==============================] - 0s 934us/step - loss: 0.0066 - val_loss: 0.0066\n",
      "Epoch 29/100\n",
      "199/199 [==============================] - 0s 943us/step - loss: 0.0064 - val_loss: 0.0064\n",
      "Epoch 30/100\n",
      "199/199 [==============================] - 0s 950us/step - loss: 0.0062 - val_loss: 0.0061\n",
      "Epoch 31/100\n",
      "199/199 [==============================] - 0s 965us/step - loss: 0.0060 - val_loss: 0.0060\n",
      "Epoch 32/100\n",
      "199/199 [==============================] - 0s 971us/step - loss: 0.0058 - val_loss: 0.0058\n",
      "Epoch 33/100\n",
      "199/199 [==============================] - 0s 963us/step - loss: 0.0056 - val_loss: 0.0056\n",
      "Epoch 34/100\n",
      "199/199 [==============================] - 0s 968us/step - loss: 0.0054 - val_loss: 0.0054\n",
      "Epoch 35/100\n",
      "199/199 [==============================] - 0s 968us/step - loss: 0.0052 - val_loss: 0.0052\n",
      "Epoch 36/100\n",
      "199/199 [==============================] - 0s 959us/step - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 37/100\n",
      "199/199 [==============================] - 0s 974us/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 38/100\n",
      "199/199 [==============================] - 0s 977us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 39/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 40/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 41/100\n",
      "199/199 [==============================] - 0s 975us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 42/100\n",
      "199/199 [==============================] - 0s 960us/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 43/100\n",
      "199/199 [==============================] - 0s 968us/step - loss: 0.0041 - val_loss: 0.0042\n",
      "Epoch 44/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0040 - val_loss: 0.0041\n",
      "Epoch 45/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 46/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 47/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 48/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 49/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 50/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 51/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 52/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 53/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 54/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 55/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 56/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 57/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 58/100\n",
      "199/199 [==============================] - 0s 954us/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 59/100\n",
      "199/199 [==============================] - 0s 957us/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 60/100\n",
      "199/199 [==============================] - 0s 975us/step - loss: 0.0030 - val_loss: 0.0032\n",
      "Epoch 61/100\n",
      "199/199 [==============================] - 0s 953us/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 62/100\n",
      "199/199 [==============================] - 0s 937us/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 63/100\n",
      "199/199 [==============================] - 0s 946us/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 64/100\n",
      "199/199 [==============================] - 0s 940us/step - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 65/100\n",
      "199/199 [==============================] - 0s 980us/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 66/100\n",
      "199/199 [==============================] - 0s 953us/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 67/100\n",
      "199/199 [==============================] - 0s 975us/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 68/100\n",
      "199/199 [==============================] - 0s 959us/step - loss: 0.0028 - val_loss: 0.0029\n",
      "Epoch 69/100\n",
      "199/199 [==============================] - 0s 973us/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 70/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 71/100\n",
      "199/199 [==============================] - 0s 975us/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 72/100\n",
      "199/199 [==============================] - 0s 955us/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 73/100\n",
      "199/199 [==============================] - 0s 978us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 74/100\n",
      "199/199 [==============================] - 0s 960us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 75/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 76/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 77/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 78/100\n",
      "199/199 [==============================] - 0s 964us/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 79/100\n",
      "199/199 [==============================] - 0s 990us/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 80/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0024 - val_loss: 0.0026\n",
      "Epoch 81/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 82/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 83/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 84/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 85/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 86/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 87/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 88/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 89/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 90/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 91/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 92/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 93/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 94/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 95/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 96/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 97/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 98/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 99/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 100/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0021 - val_loss: 0.0023\n",
      "This round is 3\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_63917/2731616321.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  para_dfm = para_dfm.append({\"reg_param\": reg_param, \"number_units_layers\": numbers_units_layers, \"number_units_bottleneck\": numbers_units_bottleneck, \"dropout_rate\": dropout_rate, \"number_layers\": numbers_layers, \"whether_dropout\": whether_dropout, \"whether_regularizer\": whether_regularizer, \"overfit_metric\": overfit_metric, \"val2_avg_recon_error\": val2_avg_recon_error,'val1_loss':val1_loss}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 0s 1ms/step - loss: 2.0476 - val_loss: 0.4914\n",
      "Epoch 2/100\n",
      "199/199 [==============================] - 0s 942us/step - loss: 0.1980 - val_loss: 0.0748\n",
      "Epoch 3/100\n",
      "199/199 [==============================] - 0s 994us/step - loss: 0.0603 - val_loss: 0.0554\n",
      "Epoch 4/100\n",
      "199/199 [==============================] - 0s 950us/step - loss: 0.0552 - val_loss: 0.0550\n",
      "Epoch 5/100\n",
      "199/199 [==============================] - 0s 936us/step - loss: 0.0551 - val_loss: 0.0551\n",
      "Epoch 6/100\n",
      "199/199 [==============================] - 0s 952us/step - loss: 0.0551 - val_loss: 0.0550\n",
      "Epoch 7/100\n",
      "199/199 [==============================] - 0s 972us/step - loss: 0.0551 - val_loss: 0.0550\n",
      "Epoch 8/100\n",
      "199/199 [==============================] - 0s 965us/step - loss: 0.0551 - val_loss: 0.0552\n",
      "Epoch 9/100\n",
      "199/199 [==============================] - 0s 936us/step - loss: 0.0551 - val_loss: 0.0551\n",
      "Epoch 10/100\n",
      "199/199 [==============================] - 0s 946us/step - loss: 0.0551 - val_loss: 0.0550\n",
      "Epoch 11/100\n",
      "199/199 [==============================] - 0s 945us/step - loss: 0.0551 - val_loss: 0.0550\n",
      "Epoch 12/100\n",
      "199/199 [==============================] - 0s 940us/step - loss: 0.0550 - val_loss: 0.0550\n",
      "Epoch 13/100\n",
      "199/199 [==============================] - 0s 948us/step - loss: 0.0550 - val_loss: 0.0549\n",
      "Epoch 14/100\n",
      "199/199 [==============================] - 0s 944us/step - loss: 0.0542 - val_loss: 0.0520\n",
      "Epoch 15/100\n",
      "199/199 [==============================] - 0s 947us/step - loss: 0.0462 - val_loss: 0.0418\n",
      "Epoch 16/100\n",
      "199/199 [==============================] - 0s 997us/step - loss: 0.0408 - val_loss: 0.0397\n",
      "Epoch 17/100\n",
      "199/199 [==============================] - 0s 958us/step - loss: 0.0394 - val_loss: 0.0387\n",
      "Epoch 18/100\n",
      "199/199 [==============================] - 0s 957us/step - loss: 0.0386 - val_loss: 0.0381\n",
      "Epoch 19/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0381 - val_loss: 0.0376\n",
      "Epoch 20/100\n",
      "199/199 [==============================] - 0s 948us/step - loss: 0.0377 - val_loss: 0.0373\n",
      "Epoch 21/100\n",
      "199/199 [==============================] - 0s 955us/step - loss: 0.0374 - val_loss: 0.0371\n",
      "Epoch 22/100\n",
      "199/199 [==============================] - 0s 991us/step - loss: 0.0372 - val_loss: 0.0369\n",
      "Epoch 23/100\n",
      "199/199 [==============================] - 0s 949us/step - loss: 0.0370 - val_loss: 0.0368\n",
      "Epoch 24/100\n",
      "199/199 [==============================] - 0s 967us/step - loss: 0.0369 - val_loss: 0.0367\n",
      "Epoch 25/100\n",
      "199/199 [==============================] - 0s 957us/step - loss: 0.0368 - val_loss: 0.0365\n",
      "Epoch 26/100\n",
      "199/199 [==============================] - 0s 961us/step - loss: 0.0367 - val_loss: 0.0364\n",
      "Epoch 27/100\n",
      "199/199 [==============================] - 0s 955us/step - loss: 0.0366 - val_loss: 0.0364\n",
      "Epoch 28/100\n",
      "199/199 [==============================] - 0s 957us/step - loss: 0.0366 - val_loss: 0.0363\n",
      "Epoch 29/100\n",
      "199/199 [==============================] - 0s 947us/step - loss: 0.0365 - val_loss: 0.0364\n",
      "Epoch 30/100\n",
      "199/199 [==============================] - 0s 950us/step - loss: 0.0365 - val_loss: 0.0362\n",
      "Epoch 31/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0364 - val_loss: 0.0362\n",
      "Epoch 32/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0363 - val_loss: 0.0363\n",
      "Epoch 33/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0363 - val_loss: 0.0361\n",
      "Epoch 34/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0363 - val_loss: 0.0363\n",
      "Epoch 35/100\n",
      "199/199 [==============================] - 0s 949us/step - loss: 0.0363 - val_loss: 0.0363\n",
      "Epoch 36/100\n",
      "199/199 [==============================] - 0s 971us/step - loss: 0.0362 - val_loss: 0.0361\n",
      "Epoch 37/100\n",
      "199/199 [==============================] - 0s 990us/step - loss: 0.0362 - val_loss: 0.0365\n",
      "Epoch 38/100\n",
      "199/199 [==============================] - 0s 992us/step - loss: 0.0363 - val_loss: 0.0367\n",
      "Epoch 39/100\n",
      "199/199 [==============================] - 0s 964us/step - loss: 0.0361 - val_loss: 0.0360\n",
      "Epoch 40/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0361 - val_loss: 0.0361\n",
      "Epoch 41/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0362 - val_loss: 0.0359\n",
      "Epoch 42/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0361 - val_loss: 0.0360\n",
      "Epoch 43/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0360 - val_loss: 0.0360\n",
      "Epoch 44/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0361 - val_loss: 0.0358\n",
      "Epoch 45/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0360 - val_loss: 0.0359\n",
      "Epoch 46/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0359 - val_loss: 0.0360\n",
      "Epoch 47/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0360 - val_loss: 0.0361\n",
      "Epoch 48/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0359 - val_loss: 0.0358\n",
      "Epoch 49/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0360 - val_loss: 0.0357\n",
      "Epoch 50/100\n",
      "199/199 [==============================] - 0s 980us/step - loss: 0.0359 - val_loss: 0.0360\n",
      "Epoch 51/100\n",
      "199/199 [==============================] - 0s 993us/step - loss: 0.0359 - val_loss: 0.0358\n",
      "Epoch 52/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0359 - val_loss: 0.0357\n",
      "Epoch 53/100\n",
      "199/199 [==============================] - 0s 954us/step - loss: 0.0358 - val_loss: 0.0357\n",
      "Epoch 54/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0358 - val_loss: 0.0357\n",
      "Epoch 55/100\n",
      "199/199 [==============================] - 0s 988us/step - loss: 0.0358 - val_loss: 0.0357\n",
      "Epoch 56/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0358 - val_loss: 0.0360\n",
      "Epoch 57/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0358 - val_loss: 0.0357\n",
      "Epoch 58/100\n",
      "199/199 [==============================] - 0s 971us/step - loss: 0.0358 - val_loss: 0.0357\n",
      "Epoch 59/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0358 - val_loss: 0.0356\n",
      "Epoch 60/100\n",
      "199/199 [==============================] - 0s 946us/step - loss: 0.0358 - val_loss: 0.0357\n",
      "Epoch 61/100\n",
      "199/199 [==============================] - 0s 945us/step - loss: 0.0358 - val_loss: 0.0355\n",
      "Epoch 62/100\n",
      "199/199 [==============================] - 0s 969us/step - loss: 0.0358 - val_loss: 0.0357\n",
      "Epoch 63/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0357 - val_loss: 0.0356\n",
      "Epoch 64/100\n",
      "199/199 [==============================] - 0s 990us/step - loss: 0.0357 - val_loss: 0.0354\n",
      "Epoch 65/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0356 - val_loss: 0.0357\n",
      "Epoch 66/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0356 - val_loss: 0.0355\n",
      "Epoch 67/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0357 - val_loss: 0.0364\n",
      "Epoch 68/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0355 - val_loss: 0.0354\n",
      "Epoch 69/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0353 - val_loss: 0.0351\n",
      "Epoch 70/100\n",
      "199/199 [==============================] - 0s 971us/step - loss: 0.0352 - val_loss: 0.0351\n",
      "Epoch 71/100\n",
      "199/199 [==============================] - 0s 937us/step - loss: 0.0353 - val_loss: 0.0352\n",
      "Epoch 72/100\n",
      "199/199 [==============================] - 0s 946us/step - loss: 0.0351 - val_loss: 0.0349\n",
      "Epoch 73/100\n",
      "199/199 [==============================] - 0s 997us/step - loss: 0.0350 - val_loss: 0.0348\n",
      "Epoch 74/100\n",
      "199/199 [==============================] - 0s 976us/step - loss: 0.0349 - val_loss: 0.0350\n",
      "Epoch 75/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0348 - val_loss: 0.0348\n",
      "Epoch 76/100\n",
      "199/199 [==============================] - 0s 996us/step - loss: 0.0351 - val_loss: 0.0345\n",
      "Epoch 77/100\n",
      "199/199 [==============================] - 0s 998us/step - loss: 0.0347 - val_loss: 0.0346\n",
      "Epoch 78/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0346 - val_loss: 0.0346\n",
      "Epoch 79/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0345 - val_loss: 0.0343\n",
      "Epoch 80/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0346 - val_loss: 0.0342\n",
      "Epoch 81/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0345 - val_loss: 0.0342\n",
      "Epoch 82/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0345 - val_loss: 0.0342\n",
      "Epoch 83/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0343 - val_loss: 0.0340\n",
      "Epoch 84/100\n",
      "199/199 [==============================] - 0s 992us/step - loss: 0.0342 - val_loss: 0.0339\n",
      "Epoch 85/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0341 - val_loss: 0.0339\n",
      "Epoch 86/100\n",
      "199/199 [==============================] - 0s 945us/step - loss: 0.0340 - val_loss: 0.0339\n",
      "Epoch 87/100\n",
      "199/199 [==============================] - 0s 965us/step - loss: 0.0340 - val_loss: 0.0341\n",
      "Epoch 88/100\n",
      "199/199 [==============================] - 0s 968us/step - loss: 0.0341 - val_loss: 0.0339\n",
      "Epoch 89/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0339 - val_loss: 0.0338\n",
      "Epoch 90/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0338 - val_loss: 0.0336\n",
      "Epoch 91/100\n",
      "199/199 [==============================] - 0s 970us/step - loss: 0.0338 - val_loss: 0.0336\n",
      "Epoch 92/100\n",
      "199/199 [==============================] - 0s 983us/step - loss: 0.0337 - val_loss: 0.0335\n",
      "Epoch 93/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0337 - val_loss: 0.0335\n",
      "Epoch 94/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0336 - val_loss: 0.0336\n",
      "Epoch 95/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0337 - val_loss: 0.0350\n",
      "Epoch 96/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0337 - val_loss: 0.0334\n",
      "Epoch 97/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0334 - val_loss: 0.0333\n",
      "Epoch 98/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0334 - val_loss: 0.0332\n",
      "Epoch 99/100\n",
      "199/199 [==============================] - 0s 974us/step - loss: 0.0334 - val_loss: 0.0332\n",
      "Epoch 100/100\n",
      "199/199 [==============================] - 0s 981us/step - loss: 0.0333 - val_loss: 0.0331\n",
      "This round is 4\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_63917/2731616321.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  para_dfm = para_dfm.append({\"reg_param\": reg_param, \"number_units_layers\": numbers_units_layers, \"number_units_bottleneck\": numbers_units_bottleneck, \"dropout_rate\": dropout_rate, \"number_layers\": numbers_layers, \"whether_dropout\": whether_dropout, \"whether_regularizer\": whether_regularizer, \"overfit_metric\": overfit_metric, \"val2_avg_recon_error\": val2_avg_recon_error,'val1_loss':val1_loss}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0929 - val_loss: 0.0540\n",
      "Epoch 2/100\n",
      "199/199 [==============================] - 0s 946us/step - loss: 0.0463 - val_loss: 0.0395\n",
      "Epoch 3/100\n",
      "199/199 [==============================] - 0s 931us/step - loss: 0.0380 - val_loss: 0.0366\n",
      "Epoch 4/100\n",
      "199/199 [==============================] - 0s 929us/step - loss: 0.0357 - val_loss: 0.0344\n",
      "Epoch 5/100\n",
      "199/199 [==============================] - 0s 941us/step - loss: 0.0324 - val_loss: 0.0302\n",
      "Epoch 6/100\n",
      "199/199 [==============================] - 0s 926us/step - loss: 0.0286 - val_loss: 0.0265\n",
      "Epoch 7/100\n",
      "199/199 [==============================] - 0s 982us/step - loss: 0.0254 - val_loss: 0.0241\n",
      "Epoch 8/100\n",
      "199/199 [==============================] - 0s 937us/step - loss: 0.0236 - val_loss: 0.0227\n",
      "Epoch 9/100\n",
      "199/199 [==============================] - 0s 928us/step - loss: 0.0225 - val_loss: 0.0217\n",
      "Epoch 10/100\n",
      "199/199 [==============================] - 0s 932us/step - loss: 0.0216 - val_loss: 0.0209\n",
      "Epoch 11/100\n",
      "199/199 [==============================] - 0s 934us/step - loss: 0.0209 - val_loss: 0.0203\n",
      "Epoch 12/100\n",
      "199/199 [==============================] - 0s 943us/step - loss: 0.0203 - val_loss: 0.0198\n",
      "Epoch 13/100\n",
      "199/199 [==============================] - 0s 942us/step - loss: 0.0197 - val_loss: 0.0192\n",
      "Epoch 14/100\n",
      "199/199 [==============================] - 0s 935us/step - loss: 0.0192 - val_loss: 0.0186\n",
      "Epoch 15/100\n",
      "199/199 [==============================] - 0s 994us/step - loss: 0.0184 - val_loss: 0.0177\n",
      "Epoch 16/100\n",
      "199/199 [==============================] - 0s 947us/step - loss: 0.0172 - val_loss: 0.0162\n",
      "Epoch 17/100\n",
      "199/199 [==============================] - 0s 953us/step - loss: 0.0157 - val_loss: 0.0150\n",
      "Epoch 18/100\n",
      "199/199 [==============================] - 0s 935us/step - loss: 0.0147 - val_loss: 0.0142\n",
      "Epoch 19/100\n",
      "199/199 [==============================] - 0s 937us/step - loss: 0.0140 - val_loss: 0.0136\n",
      "Epoch 20/100\n",
      "199/199 [==============================] - 0s 944us/step - loss: 0.0134 - val_loss: 0.0130\n",
      "Epoch 21/100\n",
      "199/199 [==============================] - 0s 960us/step - loss: 0.0128 - val_loss: 0.0125\n",
      "Epoch 22/100\n",
      "199/199 [==============================] - 0s 960us/step - loss: 0.0122 - val_loss: 0.0118\n",
      "Epoch 23/100\n",
      "199/199 [==============================] - 0s 946us/step - loss: 0.0115 - val_loss: 0.0112\n",
      "Epoch 24/100\n",
      "199/199 [==============================] - 0s 932us/step - loss: 0.0111 - val_loss: 0.0109\n",
      "Epoch 25/100\n",
      "199/199 [==============================] - 0s 942us/step - loss: 0.0107 - val_loss: 0.0105\n",
      "Epoch 26/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0103 - val_loss: 0.0102\n",
      "Epoch 27/100\n",
      "199/199 [==============================] - 0s 965us/step - loss: 0.0100 - val_loss: 0.0100\n",
      "Epoch 28/100\n",
      "199/199 [==============================] - 0s 948us/step - loss: 0.0096 - val_loss: 0.0096\n",
      "Epoch 29/100\n",
      "199/199 [==============================] - 0s 939us/step - loss: 0.0093 - val_loss: 0.0093\n",
      "Epoch 30/100\n",
      "199/199 [==============================] - 0s 966us/step - loss: 0.0091 - val_loss: 0.0091\n",
      "Epoch 31/100\n",
      "199/199 [==============================] - 0s 960us/step - loss: 0.0088 - val_loss: 0.0088\n",
      "Epoch 32/100\n",
      "199/199 [==============================] - 0s 957us/step - loss: 0.0086 - val_loss: 0.0087\n",
      "Epoch 33/100\n",
      "199/199 [==============================] - 0s 967us/step - loss: 0.0084 - val_loss: 0.0085\n",
      "Epoch 34/100\n",
      "199/199 [==============================] - 0s 971us/step - loss: 0.0082 - val_loss: 0.0083\n",
      "Epoch 35/100\n",
      "199/199 [==============================] - 0s 954us/step - loss: 0.0081 - val_loss: 0.0082\n",
      "Epoch 36/100\n",
      "199/199 [==============================] - 0s 960us/step - loss: 0.0080 - val_loss: 0.0081\n",
      "Epoch 37/100\n",
      "199/199 [==============================] - 0s 959us/step - loss: 0.0078 - val_loss: 0.0080\n",
      "Epoch 38/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0077 - val_loss: 0.0079\n",
      "Epoch 39/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0076 - val_loss: 0.0077\n",
      "Epoch 40/100\n",
      "199/199 [==============================] - 0s 967us/step - loss: 0.0075 - val_loss: 0.0077\n",
      "Epoch 41/100\n",
      "199/199 [==============================] - 0s 966us/step - loss: 0.0074 - val_loss: 0.0076\n",
      "Epoch 42/100\n",
      "199/199 [==============================] - 0s 971us/step - loss: 0.0073 - val_loss: 0.0075\n",
      "Epoch 43/100\n",
      "199/199 [==============================] - 0s 971us/step - loss: 0.0072 - val_loss: 0.0074\n",
      "Epoch 44/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0071 - val_loss: 0.0073\n",
      "Epoch 45/100\n",
      "199/199 [==============================] - 0s 986us/step - loss: 0.0070 - val_loss: 0.0072\n",
      "Epoch 46/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0069 - val_loss: 0.0071\n",
      "Epoch 47/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 0.0071\n",
      "Epoch 48/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 0.0070\n",
      "Epoch 49/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0067 - val_loss: 0.0069\n",
      "Epoch 50/100\n",
      "199/199 [==============================] - 0s 972us/step - loss: 0.0066 - val_loss: 0.0068\n",
      "Epoch 51/100\n",
      "199/199 [==============================] - 0s 974us/step - loss: 0.0065 - val_loss: 0.0067\n",
      "Epoch 52/100\n",
      "199/199 [==============================] - 0s 982us/step - loss: 0.0064 - val_loss: 0.0067\n",
      "Epoch 53/100\n",
      "199/199 [==============================] - 0s 996us/step - loss: 0.0063 - val_loss: 0.0066\n",
      "Epoch 54/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0062 - val_loss: 0.0065\n",
      "Epoch 55/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0065\n",
      "Epoch 56/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0064\n",
      "Epoch 57/100\n",
      "199/199 [==============================] - 0s 957us/step - loss: 0.0060 - val_loss: 0.0063\n",
      "Epoch 58/100\n",
      "199/199 [==============================] - 0s 970us/step - loss: 0.0059 - val_loss: 0.0062\n",
      "Epoch 59/100\n",
      "199/199 [==============================] - 0s 966us/step - loss: 0.0058 - val_loss: 0.0061\n",
      "Epoch 60/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0057 - val_loss: 0.0060\n",
      "Epoch 61/100\n",
      "199/199 [==============================] - 0s 988us/step - loss: 0.0056 - val_loss: 0.0060\n",
      "Epoch 62/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0058\n",
      "Epoch 63/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0054 - val_loss: 0.0057\n",
      "Epoch 64/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0053 - val_loss: 0.0056\n",
      "Epoch 65/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0052 - val_loss: 0.0056\n",
      "Epoch 66/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0051 - val_loss: 0.0055\n",
      "Epoch 67/100\n",
      "199/199 [==============================] - 0s 975us/step - loss: 0.0051 - val_loss: 0.0054\n",
      "Epoch 68/100\n",
      "199/199 [==============================] - 0s 981us/step - loss: 0.0050 - val_loss: 0.0054\n",
      "Epoch 69/100\n",
      "199/199 [==============================] - 0s 954us/step - loss: 0.0050 - val_loss: 0.0054\n",
      "Epoch 70/100\n",
      "199/199 [==============================] - 0s 953us/step - loss: 0.0049 - val_loss: 0.0053\n",
      "Epoch 71/100\n",
      "199/199 [==============================] - 0s 958us/step - loss: 0.0049 - val_loss: 0.0053\n",
      "Epoch 72/100\n",
      "199/199 [==============================] - 0s 955us/step - loss: 0.0048 - val_loss: 0.0053\n",
      "Epoch 73/100\n",
      "199/199 [==============================] - 0s 976us/step - loss: 0.0048 - val_loss: 0.0053\n",
      "Epoch 74/100\n",
      "199/199 [==============================] - 0s 951us/step - loss: 0.0048 - val_loss: 0.0053\n",
      "Epoch 75/100\n",
      "199/199 [==============================] - 0s 956us/step - loss: 0.0047 - val_loss: 0.0052\n",
      "Epoch 76/100\n",
      "199/199 [==============================] - 0s 955us/step - loss: 0.0047 - val_loss: 0.0052\n",
      "Epoch 77/100\n",
      "199/199 [==============================] - 0s 954us/step - loss: 0.0047 - val_loss: 0.0052\n",
      "Epoch 78/100\n",
      "199/199 [==============================] - 0s 952us/step - loss: 0.0046 - val_loss: 0.0051\n",
      "Epoch 79/100\n",
      "199/199 [==============================] - 0s 973us/step - loss: 0.0046 - val_loss: 0.0051\n",
      "Epoch 80/100\n",
      "199/199 [==============================] - 0s 945us/step - loss: 0.0046 - val_loss: 0.0051\n",
      "Epoch 81/100\n",
      "199/199 [==============================] - 0s 950us/step - loss: 0.0046 - val_loss: 0.0051\n",
      "Epoch 82/100\n",
      "199/199 [==============================] - 0s 960us/step - loss: 0.0045 - val_loss: 0.0050\n",
      "Epoch 83/100\n",
      "199/199 [==============================] - 0s 949us/step - loss: 0.0045 - val_loss: 0.0050\n",
      "Epoch 84/100\n",
      "199/199 [==============================] - 0s 960us/step - loss: 0.0045 - val_loss: 0.0050\n",
      "Epoch 85/100\n",
      "199/199 [==============================] - 0s 958us/step - loss: 0.0044 - val_loss: 0.0050\n",
      "Epoch 86/100\n",
      "199/199 [==============================] - 0s 954us/step - loss: 0.0044 - val_loss: 0.0050\n",
      "Epoch 87/100\n",
      "199/199 [==============================] - 0s 961us/step - loss: 0.0044 - val_loss: 0.0049\n",
      "Epoch 88/100\n",
      "199/199 [==============================] - 0s 965us/step - loss: 0.0044 - val_loss: 0.0049\n",
      "Epoch 89/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0043 - val_loss: 0.0049\n",
      "Epoch 90/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0043 - val_loss: 0.0049\n",
      "Epoch 91/100\n",
      "199/199 [==============================] - 0s 969us/step - loss: 0.0043 - val_loss: 0.0049\n",
      "Epoch 92/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0049\n",
      "Epoch 93/100\n",
      "199/199 [==============================] - 0s 998us/step - loss: 0.0042 - val_loss: 0.0048\n",
      "Epoch 94/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0048\n",
      "Epoch 95/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0047\n",
      "Epoch 96/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0047\n",
      "Epoch 97/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0047\n",
      "Epoch 98/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0047\n",
      "Epoch 99/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0040 - val_loss: 0.0047\n",
      "Epoch 100/100\n",
      "199/199 [==============================] - 0s 997us/step - loss: 0.0040 - val_loss: 0.0047\n",
      "This round is 5\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_63917/2731616321.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  para_dfm = para_dfm.append({\"reg_param\": reg_param, \"number_units_layers\": numbers_units_layers, \"number_units_bottleneck\": numbers_units_bottleneck, \"dropout_rate\": dropout_rate, \"number_layers\": numbers_layers, \"whether_dropout\": whether_dropout, \"whether_regularizer\": whether_regularizer, \"overfit_metric\": overfit_metric, \"val2_avg_recon_error\": val2_avg_recon_error,'val1_loss':val1_loss}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0932 - val_loss: 0.0480\n",
      "Epoch 2/100\n",
      "199/199 [==============================] - 0s 886us/step - loss: 0.0387 - val_loss: 0.0340\n",
      "Epoch 3/100\n",
      "199/199 [==============================] - 0s 876us/step - loss: 0.0290 - val_loss: 0.0252\n",
      "Epoch 4/100\n",
      "199/199 [==============================] - 0s 895us/step - loss: 0.0231 - val_loss: 0.0209\n",
      "Epoch 5/100\n",
      "199/199 [==============================] - 0s 902us/step - loss: 0.0193 - val_loss: 0.0177\n",
      "Epoch 6/100\n",
      "199/199 [==============================] - 0s 886us/step - loss: 0.0169 - val_loss: 0.0157\n",
      "Epoch 7/100\n",
      "199/199 [==============================] - 0s 900us/step - loss: 0.0148 - val_loss: 0.0137\n",
      "Epoch 8/100\n",
      "199/199 [==============================] - 0s 887us/step - loss: 0.0129 - val_loss: 0.0121\n",
      "Epoch 9/100\n",
      "199/199 [==============================] - 0s 892us/step - loss: 0.0114 - val_loss: 0.0110\n",
      "Epoch 10/100\n",
      "199/199 [==============================] - 0s 908us/step - loss: 0.0104 - val_loss: 0.0101\n",
      "Epoch 11/100\n",
      "199/199 [==============================] - 0s 903us/step - loss: 0.0096 - val_loss: 0.0094\n",
      "Epoch 12/100\n",
      "199/199 [==============================] - 0s 920us/step - loss: 0.0090 - val_loss: 0.0088\n",
      "Epoch 13/100\n",
      "199/199 [==============================] - 0s 908us/step - loss: 0.0083 - val_loss: 0.0082\n",
      "Epoch 14/100\n",
      "199/199 [==============================] - 0s 890us/step - loss: 0.0077 - val_loss: 0.0077\n",
      "Epoch 15/100\n",
      "199/199 [==============================] - 0s 906us/step - loss: 0.0073 - val_loss: 0.0073\n",
      "Epoch 16/100\n",
      "199/199 [==============================] - 0s 909us/step - loss: 0.0069 - val_loss: 0.0070\n",
      "Epoch 17/100\n",
      "199/199 [==============================] - 0s 902us/step - loss: 0.0066 - val_loss: 0.0067\n",
      "Epoch 18/100\n",
      "199/199 [==============================] - 0s 936us/step - loss: 0.0063 - val_loss: 0.0064\n",
      "Epoch 19/100\n",
      "199/199 [==============================] - 0s 916us/step - loss: 0.0060 - val_loss: 0.0061\n",
      "Epoch 20/100\n",
      "199/199 [==============================] - 0s 907us/step - loss: 0.0057 - val_loss: 0.0058\n",
      "Epoch 21/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0055 - val_loss: 0.0057\n",
      "Epoch 22/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0053 - val_loss: 0.0055\n",
      "Epoch 23/100\n",
      "199/199 [==============================] - 0s 948us/step - loss: 0.0051 - val_loss: 0.0053\n",
      "Epoch 24/100\n",
      "199/199 [==============================] - 0s 933us/step - loss: 0.0049 - val_loss: 0.0051\n",
      "Epoch 25/100\n",
      "199/199 [==============================] - 0s 981us/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 26/100\n",
      "199/199 [==============================] - 0s 977us/step - loss: 0.0044 - val_loss: 0.0047\n",
      "Epoch 27/100\n",
      "199/199 [==============================] - 0s 934us/step - loss: 0.0043 - val_loss: 0.0046\n",
      "Epoch 28/100\n",
      "199/199 [==============================] - 0s 926us/step - loss: 0.0041 - val_loss: 0.0044\n",
      "Epoch 29/100\n",
      "199/199 [==============================] - 0s 927us/step - loss: 0.0039 - val_loss: 0.0044\n",
      "Epoch 30/100\n",
      "199/199 [==============================] - 0s 914us/step - loss: 0.0038 - val_loss: 0.0043\n",
      "Epoch 31/100\n",
      "199/199 [==============================] - 0s 950us/step - loss: 0.0037 - val_loss: 0.0041\n",
      "Epoch 32/100\n",
      "199/199 [==============================] - 0s 939us/step - loss: 0.0036 - val_loss: 0.0040\n",
      "Epoch 33/100\n",
      "199/199 [==============================] - 0s 934us/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 34/100\n",
      "199/199 [==============================] - 0s 940us/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 35/100\n",
      "199/199 [==============================] - 0s 947us/step - loss: 0.0032 - val_loss: 0.0036\n",
      "Epoch 36/100\n",
      "199/199 [==============================] - 0s 943us/step - loss: 0.0031 - val_loss: 0.0035\n",
      "Epoch 37/100\n",
      "199/199 [==============================] - 0s 938us/step - loss: 0.0030 - val_loss: 0.0034\n",
      "Epoch 38/100\n",
      "199/199 [==============================] - 0s 963us/step - loss: 0.0029 - val_loss: 0.0033\n",
      "Epoch 39/100\n",
      "199/199 [==============================] - 0s 958us/step - loss: 0.0028 - val_loss: 0.0033\n",
      "Epoch 40/100\n",
      "199/199 [==============================] - 0s 937us/step - loss: 0.0028 - val_loss: 0.0032\n",
      "Epoch 41/100\n",
      "199/199 [==============================] - 0s 948us/step - loss: 0.0027 - val_loss: 0.0032\n",
      "Epoch 42/100\n",
      "199/199 [==============================] - 0s 940us/step - loss: 0.0026 - val_loss: 0.0031\n",
      "Epoch 43/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0026 - val_loss: 0.0030\n",
      "Epoch 44/100\n",
      "199/199 [==============================] - 0s 943us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 45/100\n",
      "199/199 [==============================] - 0s 929us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 46/100\n",
      "199/199 [==============================] - 0s 962us/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 47/100\n",
      "199/199 [==============================] - 0s 926us/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 48/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 49/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0021 - val_loss: 0.0026\n",
      "Epoch 50/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 51/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 52/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 53/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 54/100\n",
      "199/199 [==============================] - 0s 987us/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 55/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 56/100\n",
      "199/199 [==============================] - 0s 948us/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 57/100\n",
      "199/199 [==============================] - 0s 933us/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 58/100\n",
      "199/199 [==============================] - 0s 938us/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 59/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0017 - val_loss: 0.0022\n",
      "Epoch 60/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 61/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 62/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 63/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 64/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 65/100\n",
      "199/199 [==============================] - 0s 972us/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 66/100\n",
      "199/199 [==============================] - 0s 965us/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 67/100\n",
      "199/199 [==============================] - 0s 915us/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 68/100\n",
      "199/199 [==============================] - 0s 916us/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 69/100\n",
      "199/199 [==============================] - 0s 912us/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 70/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 71/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 72/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 73/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0020\n",
      "Epoch 74/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 75/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 76/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 77/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 78/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 79/100\n",
      "199/199 [==============================] - 0s 941us/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 80/100\n",
      "199/199 [==============================] - 0s 930us/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 81/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 82/100\n",
      "199/199 [==============================] - 0s 955us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 83/100\n",
      "199/199 [==============================] - 0s 943us/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 84/100\n",
      "199/199 [==============================] - 0s 946us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 85/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 86/100\n",
      "199/199 [==============================] - 0s 971us/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 87/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 88/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 89/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 90/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 91/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 92/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 93/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 94/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0010 - val_loss: 0.0016\n",
      "Epoch 95/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0010 - val_loss: 0.0016\n",
      "Epoch 96/100\n",
      "199/199 [==============================] - 0s 970us/step - loss: 0.0010 - val_loss: 0.0016\n",
      "Epoch 97/100\n",
      "199/199 [==============================] - 0s 994us/step - loss: 0.0010 - val_loss: 0.0016\n",
      "Epoch 98/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0010 - val_loss: 0.0016\n",
      "Epoch 99/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0010 - val_loss: 0.0016\n",
      "Epoch 100/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0010 - val_loss: 0.0016\n",
      "This round is 6\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_63917/2731616321.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  para_dfm = para_dfm.append({\"reg_param\": reg_param, \"number_units_layers\": numbers_units_layers, \"number_units_bottleneck\": numbers_units_bottleneck, \"dropout_rate\": dropout_rate, \"number_layers\": numbers_layers, \"whether_dropout\": whether_dropout, \"whether_regularizer\": whether_regularizer, \"overfit_metric\": overfit_metric, \"val2_avg_recon_error\": val2_avg_recon_error,'val1_loss':val1_loss}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0699 - val_loss: 0.0373\n",
      "Epoch 2/100\n",
      "199/199 [==============================] - 0s 947us/step - loss: 0.0300 - val_loss: 0.0243\n",
      "Epoch 3/100\n",
      "199/199 [==============================] - 0s 935us/step - loss: 0.0210 - val_loss: 0.0180\n",
      "Epoch 4/100\n",
      "199/199 [==============================] - 0s 949us/step - loss: 0.0160 - val_loss: 0.0140\n",
      "Epoch 5/100\n",
      "199/199 [==============================] - 0s 942us/step - loss: 0.0127 - val_loss: 0.0116\n",
      "Epoch 6/100\n",
      "199/199 [==============================] - 0s 960us/step - loss: 0.0109 - val_loss: 0.0101\n",
      "Epoch 7/100\n",
      "199/199 [==============================] - 0s 953us/step - loss: 0.0092 - val_loss: 0.0086\n",
      "Epoch 8/100\n",
      "199/199 [==============================] - 0s 934us/step - loss: 0.0078 - val_loss: 0.0075\n",
      "Epoch 9/100\n",
      "199/199 [==============================] - 0s 965us/step - loss: 0.0067 - val_loss: 0.0065\n",
      "Epoch 10/100\n",
      "199/199 [==============================] - 0s 930us/step - loss: 0.0058 - val_loss: 0.0057\n",
      "Epoch 11/100\n",
      "199/199 [==============================] - 0s 965us/step - loss: 0.0052 - val_loss: 0.0052\n",
      "Epoch 12/100\n",
      "199/199 [==============================] - 0s 930us/step - loss: 0.0048 - val_loss: 0.0048\n",
      "Epoch 13/100\n",
      "199/199 [==============================] - 0s 960us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 14/100\n",
      "199/199 [==============================] - 0s 944us/step - loss: 0.0041 - val_loss: 0.0042\n",
      "Epoch 15/100\n",
      "199/199 [==============================] - 0s 932us/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 16/100\n",
      "199/199 [==============================] - 0s 932us/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 17/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 18/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0030 - val_loss: 0.0032\n",
      "Epoch 19/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 20/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 21/100\n",
      "199/199 [==============================] - 0s 959us/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 22/100\n",
      "199/199 [==============================] - 0s 946us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 23/100\n",
      "199/199 [==============================] - 0s 944us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 24/100\n",
      "199/199 [==============================] - 0s 931us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 25/100\n",
      "199/199 [==============================] - 0s 937us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 26/100\n",
      "199/199 [==============================] - 0s 985us/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 27/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 28/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 29/100\n",
      "199/199 [==============================] - 0s 993us/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 30/100\n",
      "199/199 [==============================] - 0s 961us/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 31/100\n",
      "199/199 [==============================] - 0s 973us/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 32/100\n",
      "199/199 [==============================] - 0s 952us/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 33/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 34/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 9.9530e-04 - val_loss: 0.0014\n",
      "Epoch 35/100\n",
      "199/199 [==============================] - 0s 989us/step - loss: 9.5024e-04 - val_loss: 0.0013\n",
      "Epoch 36/100\n",
      "199/199 [==============================] - 0s 949us/step - loss: 9.2213e-04 - val_loss: 0.0013\n",
      "Epoch 37/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 8.9119e-04 - val_loss: 0.0013\n",
      "Epoch 38/100\n",
      "199/199 [==============================] - 0s 949us/step - loss: 8.6771e-04 - val_loss: 0.0012\n",
      "Epoch 39/100\n",
      "199/199 [==============================] - 0s 979us/step - loss: 8.4018e-04 - val_loss: 0.0012\n",
      "Epoch 40/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 8.1063e-04 - val_loss: 0.0012\n",
      "Epoch 41/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 7.8480e-04 - val_loss: 0.0012\n",
      "Epoch 42/100\n",
      "199/199 [==============================] - 0s 965us/step - loss: 7.6504e-04 - val_loss: 0.0012\n",
      "Epoch 43/100\n",
      "199/199 [==============================] - 0s 950us/step - loss: 7.4178e-04 - val_loss: 0.0011\n",
      "Epoch 44/100\n",
      "199/199 [==============================] - 0s 954us/step - loss: 7.1204e-04 - val_loss: 0.0011\n",
      "Epoch 45/100\n",
      "199/199 [==============================] - 0s 959us/step - loss: 6.7293e-04 - val_loss: 0.0011\n",
      "Epoch 46/100\n",
      "199/199 [==============================] - 0s 968us/step - loss: 6.2471e-04 - val_loss: 9.5763e-04\n",
      "Epoch 47/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 5.8229e-04 - val_loss: 9.3758e-04\n",
      "Epoch 48/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 5.5633e-04 - val_loss: 9.2038e-04\n",
      "Epoch 49/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 5.4654e-04 - val_loss: 9.0787e-04\n",
      "Epoch 50/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 5.2879e-04 - val_loss: 9.1672e-04\n",
      "Epoch 51/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 5.0119e-04 - val_loss: 9.0391e-04\n",
      "Epoch 52/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 4.8843e-04 - val_loss: 8.5025e-04\n",
      "Epoch 53/100\n",
      "199/199 [==============================] - 0s 960us/step - loss: 4.7490e-04 - val_loss: 8.2480e-04\n",
      "Epoch 54/100\n",
      "199/199 [==============================] - 0s 956us/step - loss: 4.6087e-04 - val_loss: 8.4040e-04\n",
      "Epoch 55/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 4.4193e-04 - val_loss: 8.4178e-04\n",
      "Epoch 56/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 4.3911e-04 - val_loss: 8.0614e-04\n",
      "Epoch 57/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 4.2882e-04 - val_loss: 7.9939e-04\n",
      "Epoch 58/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 4.1695e-04 - val_loss: 7.9969e-04\n",
      "Epoch 59/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 4.1676e-04 - val_loss: 7.6326e-04\n",
      "Epoch 60/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 4.0108e-04 - val_loss: 7.9102e-04\n",
      "Epoch 61/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 3.9839e-04 - val_loss: 7.4041e-04\n",
      "Epoch 62/100\n",
      "199/199 [==============================] - 0s 978us/step - loss: 3.9402e-04 - val_loss: 7.5520e-04\n",
      "Epoch 63/100\n",
      "199/199 [==============================] - 0s 951us/step - loss: 3.9158e-04 - val_loss: 7.7321e-04\n",
      "Epoch 64/100\n",
      "199/199 [==============================] - 0s 943us/step - loss: 3.8238e-04 - val_loss: 7.3286e-04\n",
      "Epoch 65/100\n",
      "199/199 [==============================] - 0s 944us/step - loss: 3.6796e-04 - val_loss: 7.5213e-04\n",
      "Epoch 66/100\n",
      "199/199 [==============================] - 0s 942us/step - loss: 3.5677e-04 - val_loss: 7.4517e-04\n",
      "Epoch 67/100\n",
      "199/199 [==============================] - 0s 947us/step - loss: 3.4930e-04 - val_loss: 7.3294e-04\n",
      "Epoch 68/100\n",
      "199/199 [==============================] - 0s 967us/step - loss: 3.3880e-04 - val_loss: 7.0683e-04\n",
      "Epoch 69/100\n",
      "199/199 [==============================] - 0s 968us/step - loss: 3.3460e-04 - val_loss: 7.0374e-04\n",
      "Epoch 70/100\n",
      "199/199 [==============================] - 0s 948us/step - loss: 3.2458e-04 - val_loss: 6.8036e-04\n",
      "Epoch 71/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 3.1666e-04 - val_loss: 6.8726e-04\n",
      "Epoch 72/100\n",
      "199/199 [==============================] - 0s 957us/step - loss: 3.1422e-04 - val_loss: 6.7975e-04\n",
      "Epoch 73/100\n",
      "199/199 [==============================] - 0s 943us/step - loss: 3.1384e-04 - val_loss: 7.0105e-04\n",
      "Epoch 74/100\n",
      "199/199 [==============================] - 0s 950us/step - loss: 3.0801e-04 - val_loss: 7.0062e-04\n",
      "Epoch 75/100\n",
      "199/199 [==============================] - 0s 961us/step - loss: 3.0664e-04 - val_loss: 6.7449e-04\n",
      "Epoch 76/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 2.9859e-04 - val_loss: 6.6884e-04\n",
      "Epoch 77/100\n",
      "199/199 [==============================] - 0s 964us/step - loss: 2.9297e-04 - val_loss: 6.6115e-04\n",
      "Epoch 78/100\n",
      "199/199 [==============================] - 0s 943us/step - loss: 2.8745e-04 - val_loss: 6.5642e-04\n",
      "Epoch 79/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 3.0058e-04 - val_loss: 6.5495e-04\n",
      "Epoch 80/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 3.0079e-04 - val_loss: 6.5450e-04\n",
      "Epoch 81/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 2.8054e-04 - val_loss: 6.9135e-04\n",
      "Epoch 82/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 2.7884e-04 - val_loss: 6.4445e-04\n",
      "Epoch 83/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 2.7465e-04 - val_loss: 6.2991e-04\n",
      "Epoch 84/100\n",
      "199/199 [==============================] - 0s 957us/step - loss: 2.7014e-04 - val_loss: 6.4011e-04\n",
      "Epoch 85/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 2.6960e-04 - val_loss: 6.5187e-04\n",
      "Epoch 86/100\n",
      "199/199 [==============================] - 0s 961us/step - loss: 2.6902e-04 - val_loss: 6.4111e-04\n",
      "Epoch 87/100\n",
      "199/199 [==============================] - 0s 940us/step - loss: 2.6500e-04 - val_loss: 6.4859e-04\n",
      "Epoch 88/100\n",
      "199/199 [==============================] - 0s 943us/step - loss: 2.7203e-04 - val_loss: 6.4057e-04\n",
      "Epoch 89/100\n",
      "199/199 [==============================] - 0s 955us/step - loss: 2.6745e-04 - val_loss: 6.3452e-04\n",
      "Epoch 90/100\n",
      "199/199 [==============================] - 0s 946us/step - loss: 2.5767e-04 - val_loss: 6.2085e-04\n",
      "Epoch 91/100\n",
      "199/199 [==============================] - 0s 940us/step - loss: 2.5498e-04 - val_loss: 6.4868e-04\n",
      "Epoch 92/100\n",
      "199/199 [==============================] - 0s 961us/step - loss: 2.5418e-04 - val_loss: 6.8624e-04\n",
      "Epoch 93/100\n",
      "199/199 [==============================] - 0s 951us/step - loss: 2.4864e-04 - val_loss: 6.1653e-04\n",
      "Epoch 94/100\n",
      "199/199 [==============================] - 0s 947us/step - loss: 2.4570e-04 - val_loss: 6.1198e-04\n",
      "Epoch 95/100\n",
      "199/199 [==============================] - 0s 960us/step - loss: 2.4445e-04 - val_loss: 6.2902e-04\n",
      "Epoch 96/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 2.4799e-04 - val_loss: 6.1011e-04\n",
      "Epoch 97/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 2.4190e-04 - val_loss: 6.8089e-04\n",
      "Epoch 98/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 2.4667e-04 - val_loss: 6.5833e-04\n",
      "Epoch 99/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 2.4726e-04 - val_loss: 6.5733e-04\n",
      "Epoch 100/100\n",
      "199/199 [==============================] - 0s 981us/step - loss: 2.9672e-04 - val_loss: 6.4177e-04\n",
      "This round is 7\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_63917/2731616321.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  para_dfm = para_dfm.append({\"reg_param\": reg_param, \"number_units_layers\": numbers_units_layers, \"number_units_bottleneck\": numbers_units_bottleneck, \"dropout_rate\": dropout_rate, \"number_layers\": numbers_layers, \"whether_dropout\": whether_dropout, \"whether_regularizer\": whether_regularizer, \"overfit_metric\": overfit_metric, \"val2_avg_recon_error\": val2_avg_recon_error,'val1_loss':val1_loss}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0870 - val_loss: 0.0551\n",
      "Epoch 2/100\n",
      "199/199 [==============================] - 0s 933us/step - loss: 0.0483 - val_loss: 0.0395\n",
      "Epoch 3/100\n",
      "199/199 [==============================] - 0s 938us/step - loss: 0.0378 - val_loss: 0.0363\n",
      "Epoch 4/100\n",
      "199/199 [==============================] - 0s 977us/step - loss: 0.0349 - val_loss: 0.0322\n",
      "Epoch 5/100\n",
      "199/199 [==============================] - 0s 956us/step - loss: 0.0291 - val_loss: 0.0260\n",
      "Epoch 6/100\n",
      "199/199 [==============================] - 0s 943us/step - loss: 0.0235 - val_loss: 0.0203\n",
      "Epoch 7/100\n",
      "199/199 [==============================] - 0s 920us/step - loss: 0.0196 - val_loss: 0.0177\n",
      "Epoch 8/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0174 - val_loss: 0.0160\n",
      "Epoch 9/100\n",
      "199/199 [==============================] - 0s 955us/step - loss: 0.0158 - val_loss: 0.0145\n",
      "Epoch 10/100\n",
      "199/199 [==============================] - 0s 965us/step - loss: 0.0145 - val_loss: 0.0135\n",
      "Epoch 11/100\n",
      "199/199 [==============================] - 0s 997us/step - loss: 0.0135 - val_loss: 0.0127\n",
      "Epoch 12/100\n",
      "199/199 [==============================] - 0s 978us/step - loss: 0.0128 - val_loss: 0.0121\n",
      "Epoch 13/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0121 - val_loss: 0.0114\n",
      "Epoch 14/100\n",
      "199/199 [==============================] - 0s 970us/step - loss: 0.0114 - val_loss: 0.0109\n",
      "Epoch 15/100\n",
      "199/199 [==============================] - 0s 975us/step - loss: 0.0108 - val_loss: 0.0104\n",
      "Epoch 16/100\n",
      "199/199 [==============================] - 0s 961us/step - loss: 0.0103 - val_loss: 0.0099\n",
      "Epoch 17/100\n",
      "199/199 [==============================] - 0s 963us/step - loss: 0.0098 - val_loss: 0.0094\n",
      "Epoch 18/100\n",
      "199/199 [==============================] - 0s 954us/step - loss: 0.0094 - val_loss: 0.0091\n",
      "Epoch 19/100\n",
      "199/199 [==============================] - 0s 948us/step - loss: 0.0090 - val_loss: 0.0087\n",
      "Epoch 20/100\n",
      "199/199 [==============================] - 0s 977us/step - loss: 0.0087 - val_loss: 0.0084\n",
      "Epoch 21/100\n",
      "199/199 [==============================] - 0s 953us/step - loss: 0.0084 - val_loss: 0.0082\n",
      "Epoch 22/100\n",
      "199/199 [==============================] - 0s 953us/step - loss: 0.0081 - val_loss: 0.0079\n",
      "Epoch 23/100\n",
      "199/199 [==============================] - 0s 932us/step - loss: 0.0079 - val_loss: 0.0077\n",
      "Epoch 24/100\n",
      "199/199 [==============================] - 0s 947us/step - loss: 0.0076 - val_loss: 0.0074\n",
      "Epoch 25/100\n",
      "199/199 [==============================] - 0s 996us/step - loss: 0.0073 - val_loss: 0.0071\n",
      "Epoch 26/100\n",
      "199/199 [==============================] - 0s 961us/step - loss: 0.0071 - val_loss: 0.0069\n",
      "Epoch 27/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 0.0066\n",
      "Epoch 28/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0065 - val_loss: 0.0064\n",
      "Epoch 29/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 0.0062\n",
      "Epoch 30/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0060\n",
      "Epoch 31/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0058\n",
      "Epoch 32/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0056\n",
      "Epoch 33/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0056 - val_loss: 0.0055\n",
      "Epoch 34/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0054 - val_loss: 0.0053\n",
      "Epoch 35/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0053 - val_loss: 0.0052\n",
      "Epoch 36/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0052 - val_loss: 0.0050\n",
      "Epoch 37/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0050 - val_loss: 0.0049\n",
      "Epoch 38/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 0.0047\n",
      "Epoch 39/100\n",
      "199/199 [==============================] - 0s 983us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 40/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0046 - val_loss: 0.0044\n",
      "Epoch 41/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 42/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0044 - val_loss: 0.0042\n",
      "Epoch 43/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0043 - val_loss: 0.0041\n",
      "Epoch 44/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0040\n",
      "Epoch 45/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0040\n",
      "Epoch 46/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0039\n",
      "Epoch 47/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0040 - val_loss: 0.0038\n",
      "Epoch 48/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0039 - val_loss: 0.0038\n",
      "Epoch 49/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0038 - val_loss: 0.0037\n",
      "Epoch 50/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0038 - val_loss: 0.0037\n",
      "Epoch 51/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0037 - val_loss: 0.0036\n",
      "Epoch 52/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0037 - val_loss: 0.0036\n",
      "Epoch 53/100\n",
      "199/199 [==============================] - 0s 955us/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 54/100\n",
      "199/199 [==============================] - 0s 951us/step - loss: 0.0036 - val_loss: 0.0035\n",
      "Epoch 55/100\n",
      "199/199 [==============================] - 0s 984us/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 56/100\n",
      "199/199 [==============================] - 0s 970us/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 57/100\n",
      "199/199 [==============================] - 0s 984us/step - loss: 0.0035 - val_loss: 0.0034\n",
      "Epoch 58/100\n",
      "199/199 [==============================] - 0s 953us/step - loss: 0.0035 - val_loss: 0.0034\n",
      "Epoch 59/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 60/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 61/100\n",
      "199/199 [==============================] - 0s 980us/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 62/100\n",
      "199/199 [==============================] - 0s 967us/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 63/100\n",
      "199/199 [==============================] - 0s 946us/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 64/100\n",
      "199/199 [==============================] - 0s 973us/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 65/100\n",
      "199/199 [==============================] - 0s 965us/step - loss: 0.0032 - val_loss: 0.0032\n",
      "Epoch 66/100\n",
      "199/199 [==============================] - 0s 969us/step - loss: 0.0032 - val_loss: 0.0032\n",
      "Epoch 67/100\n",
      "199/199 [==============================] - 0s 949us/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 68/100\n",
      "199/199 [==============================] - 0s 970us/step - loss: 0.0032 - val_loss: 0.0032\n",
      "Epoch 69/100\n",
      "199/199 [==============================] - 0s 958us/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 70/100\n",
      "199/199 [==============================] - 0s 974us/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 71/100\n",
      "199/199 [==============================] - 0s 986us/step - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 72/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 73/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 74/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 75/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 76/100\n",
      "199/199 [==============================] - 1s 3ms/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 77/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0028 - val_loss: 0.0029\n",
      "Epoch 78/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0028 - val_loss: 0.0029\n",
      "Epoch 79/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0028 - val_loss: 0.0029\n",
      "Epoch 80/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 81/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 82/100\n",
      "199/199 [==============================] - 0s 998us/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 83/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 84/100\n",
      "199/199 [==============================] - 0s 983us/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 85/100\n",
      "199/199 [==============================] - 0s 949us/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 86/100\n",
      "199/199 [==============================] - 0s 946us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 87/100\n",
      "199/199 [==============================] - 0s 969us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 88/100\n",
      "199/199 [==============================] - 0s 956us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 89/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 90/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 91/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 92/100\n",
      "199/199 [==============================] - 0s 984us/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 93/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 94/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0024 - val_loss: 0.0026\n",
      "Epoch 95/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0024 - val_loss: 0.0026\n",
      "Epoch 96/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 97/100\n",
      "199/199 [==============================] - 0s 972us/step - loss: 0.0024 - val_loss: 0.0026\n",
      "Epoch 98/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0024 - val_loss: 0.0026\n",
      "Epoch 99/100\n",
      "199/199 [==============================] - 0s 991us/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 100/100\n",
      "199/199 [==============================] - 0s 976us/step - loss: 0.0024 - val_loss: 0.0025\n",
      "This round is 8\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_63917/2731616321.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  para_dfm = para_dfm.append({\"reg_param\": reg_param, \"number_units_layers\": numbers_units_layers, \"number_units_bottleneck\": numbers_units_bottleneck, \"dropout_rate\": dropout_rate, \"number_layers\": numbers_layers, \"whether_dropout\": whether_dropout, \"whether_regularizer\": whether_regularizer, \"overfit_metric\": overfit_metric, \"val2_avg_recon_error\": val2_avg_recon_error,'val1_loss':val1_loss}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 0s 1ms/step - loss: 0.1153 - val_loss: 0.0558\n",
      "Epoch 2/100\n",
      "199/199 [==============================] - 0s 888us/step - loss: 0.0528 - val_loss: 0.0497\n",
      "Epoch 3/100\n",
      "199/199 [==============================] - 0s 890us/step - loss: 0.0465 - val_loss: 0.0436\n",
      "Epoch 4/100\n",
      "199/199 [==============================] - 0s 927us/step - loss: 0.0418 - val_loss: 0.0400\n",
      "Epoch 5/100\n",
      "199/199 [==============================] - 0s 900us/step - loss: 0.0394 - val_loss: 0.0386\n",
      "Epoch 6/100\n",
      "199/199 [==============================] - 0s 918us/step - loss: 0.0378 - val_loss: 0.0368\n",
      "Epoch 7/100\n",
      "199/199 [==============================] - 0s 880us/step - loss: 0.0364 - val_loss: 0.0358\n",
      "Epoch 8/100\n",
      "199/199 [==============================] - 0s 899us/step - loss: 0.0356 - val_loss: 0.0352\n",
      "Epoch 9/100\n",
      "199/199 [==============================] - 0s 883us/step - loss: 0.0349 - val_loss: 0.0343\n",
      "Epoch 10/100\n",
      "199/199 [==============================] - 0s 893us/step - loss: 0.0340 - val_loss: 0.0334\n",
      "Epoch 11/100\n",
      "199/199 [==============================] - 0s 889us/step - loss: 0.0327 - val_loss: 0.0315\n",
      "Epoch 12/100\n",
      "199/199 [==============================] - 0s 893us/step - loss: 0.0309 - val_loss: 0.0298\n",
      "Epoch 13/100\n",
      "199/199 [==============================] - 0s 895us/step - loss: 0.0294 - val_loss: 0.0284\n",
      "Epoch 14/100\n",
      "199/199 [==============================] - 0s 888us/step - loss: 0.0281 - val_loss: 0.0272\n",
      "Epoch 15/100\n",
      "199/199 [==============================] - 0s 888us/step - loss: 0.0269 - val_loss: 0.0259\n",
      "Epoch 16/100\n",
      "199/199 [==============================] - 0s 897us/step - loss: 0.0257 - val_loss: 0.0245\n",
      "Epoch 17/100\n",
      "199/199 [==============================] - 0s 901us/step - loss: 0.0239 - val_loss: 0.0223\n",
      "Epoch 18/100\n",
      "199/199 [==============================] - 0s 902us/step - loss: 0.0220 - val_loss: 0.0206\n",
      "Epoch 19/100\n",
      "199/199 [==============================] - 0s 904us/step - loss: 0.0207 - val_loss: 0.0196\n",
      "Epoch 20/100\n",
      "199/199 [==============================] - 0s 902us/step - loss: 0.0199 - val_loss: 0.0189\n",
      "Epoch 21/100\n",
      "199/199 [==============================] - 0s 918us/step - loss: 0.0193 - val_loss: 0.0183\n",
      "Epoch 22/100\n",
      "199/199 [==============================] - 0s 899us/step - loss: 0.0187 - val_loss: 0.0179\n",
      "Epoch 23/100\n",
      "199/199 [==============================] - 0s 911us/step - loss: 0.0183 - val_loss: 0.0174\n",
      "Epoch 24/100\n",
      "199/199 [==============================] - 0s 903us/step - loss: 0.0179 - val_loss: 0.0171\n",
      "Epoch 25/100\n",
      "199/199 [==============================] - 0s 917us/step - loss: 0.0175 - val_loss: 0.0167\n",
      "Epoch 26/100\n",
      "199/199 [==============================] - 0s 908us/step - loss: 0.0172 - val_loss: 0.0165\n",
      "Epoch 27/100\n",
      "199/199 [==============================] - 0s 926us/step - loss: 0.0170 - val_loss: 0.0162\n",
      "Epoch 28/100\n",
      "199/199 [==============================] - 0s 979us/step - loss: 0.0168 - val_loss: 0.0160\n",
      "Epoch 29/100\n",
      "199/199 [==============================] - 0s 923us/step - loss: 0.0165 - val_loss: 0.0159\n",
      "Epoch 30/100\n",
      "199/199 [==============================] - 0s 908us/step - loss: 0.0164 - val_loss: 0.0157\n",
      "Epoch 31/100\n",
      "199/199 [==============================] - 0s 921us/step - loss: 0.0162 - val_loss: 0.0155\n",
      "Epoch 32/100\n",
      "199/199 [==============================] - 0s 916us/step - loss: 0.0161 - val_loss: 0.0154\n",
      "Epoch 33/100\n",
      "199/199 [==============================] - 0s 954us/step - loss: 0.0159 - val_loss: 0.0153\n",
      "Epoch 34/100\n",
      "199/199 [==============================] - 0s 910us/step - loss: 0.0159 - val_loss: 0.0152\n",
      "Epoch 35/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0157 - val_loss: 0.0151\n",
      "Epoch 36/100\n",
      "199/199 [==============================] - 0s 945us/step - loss: 0.0156 - val_loss: 0.0149\n",
      "Epoch 37/100\n",
      "199/199 [==============================] - 0s 923us/step - loss: 0.0154 - val_loss: 0.0148\n",
      "Epoch 38/100\n",
      "199/199 [==============================] - 0s 928us/step - loss: 0.0153 - val_loss: 0.0147\n",
      "Epoch 39/100\n",
      "199/199 [==============================] - 0s 923us/step - loss: 0.0151 - val_loss: 0.0145\n",
      "Epoch 40/100\n",
      "199/199 [==============================] - 0s 959us/step - loss: 0.0150 - val_loss: 0.0144\n",
      "Epoch 41/100\n",
      "199/199 [==============================] - 0s 934us/step - loss: 0.0149 - val_loss: 0.0142\n",
      "Epoch 42/100\n",
      "199/199 [==============================] - 0s 926us/step - loss: 0.0147 - val_loss: 0.0141\n",
      "Epoch 43/100\n",
      "199/199 [==============================] - 0s 926us/step - loss: 0.0146 - val_loss: 0.0139\n",
      "Epoch 44/100\n",
      "199/199 [==============================] - 0s 982us/step - loss: 0.0144 - val_loss: 0.0138\n",
      "Epoch 45/100\n",
      "199/199 [==============================] - 0s 941us/step - loss: 0.0143 - val_loss: 0.0137\n",
      "Epoch 46/100\n",
      "199/199 [==============================] - 0s 945us/step - loss: 0.0142 - val_loss: 0.0136\n",
      "Epoch 47/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0141 - val_loss: 0.0135\n",
      "Epoch 48/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0139 - val_loss: 0.0134\n",
      "Epoch 49/100\n",
      "199/199 [==============================] - 0s 968us/step - loss: 0.0139 - val_loss: 0.0133\n",
      "Epoch 50/100\n",
      "199/199 [==============================] - 0s 946us/step - loss: 0.0138 - val_loss: 0.0133\n",
      "Epoch 51/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0137 - val_loss: 0.0131\n",
      "Epoch 52/100\n",
      "199/199 [==============================] - 0s 974us/step - loss: 0.0136 - val_loss: 0.0131\n",
      "Epoch 53/100\n",
      "199/199 [==============================] - 0s 966us/step - loss: 0.0135 - val_loss: 0.0130\n",
      "Epoch 54/100\n",
      "199/199 [==============================] - 0s 924us/step - loss: 0.0135 - val_loss: 0.0130\n",
      "Epoch 55/100\n",
      "199/199 [==============================] - 0s 961us/step - loss: 0.0134 - val_loss: 0.0129\n",
      "Epoch 56/100\n",
      "199/199 [==============================] - 0s 959us/step - loss: 0.0133 - val_loss: 0.0128\n",
      "Epoch 57/100\n",
      "199/199 [==============================] - 0s 919us/step - loss: 0.0132 - val_loss: 0.0128\n",
      "Epoch 58/100\n",
      "199/199 [==============================] - 0s 965us/step - loss: 0.0132 - val_loss: 0.0127\n",
      "Epoch 59/100\n",
      "199/199 [==============================] - 0s 932us/step - loss: 0.0132 - val_loss: 0.0127\n",
      "Epoch 60/100\n",
      "199/199 [==============================] - 0s 942us/step - loss: 0.0131 - val_loss: 0.0126\n",
      "Epoch 61/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0130 - val_loss: 0.0127\n",
      "Epoch 62/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0130 - val_loss: 0.0126\n",
      "Epoch 63/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0130 - val_loss: 0.0125\n",
      "Epoch 64/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0129 - val_loss: 0.0125\n",
      "Epoch 65/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0129 - val_loss: 0.0125\n",
      "Epoch 66/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0128 - val_loss: 0.0124\n",
      "Epoch 67/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0128 - val_loss: 0.0124\n",
      "Epoch 68/100\n",
      "199/199 [==============================] - 0s 976us/step - loss: 0.0128 - val_loss: 0.0124\n",
      "Epoch 69/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0127 - val_loss: 0.0123\n",
      "Epoch 70/100\n",
      "199/199 [==============================] - 0s 928us/step - loss: 0.0127 - val_loss: 0.0123\n",
      "Epoch 71/100\n",
      "199/199 [==============================] - 0s 927us/step - loss: 0.0127 - val_loss: 0.0123\n",
      "Epoch 72/100\n",
      "199/199 [==============================] - 0s 986us/step - loss: 0.0126 - val_loss: 0.0122\n",
      "Epoch 73/100\n",
      "199/199 [==============================] - 0s 931us/step - loss: 0.0126 - val_loss: 0.0122\n",
      "Epoch 74/100\n",
      "199/199 [==============================] - 0s 948us/step - loss: 0.0125 - val_loss: 0.0121\n",
      "Epoch 75/100\n",
      "199/199 [==============================] - 0s 963us/step - loss: 0.0125 - val_loss: 0.0121\n",
      "Epoch 76/100\n",
      "199/199 [==============================] - 0s 920us/step - loss: 0.0125 - val_loss: 0.0121\n",
      "Epoch 77/100\n",
      "199/199 [==============================] - 0s 953us/step - loss: 0.0124 - val_loss: 0.0121\n",
      "Epoch 78/100\n",
      "199/199 [==============================] - 0s 965us/step - loss: 0.0124 - val_loss: 0.0120\n",
      "Epoch 79/100\n",
      "199/199 [==============================] - 0s 952us/step - loss: 0.0123 - val_loss: 0.0120\n",
      "Epoch 80/100\n",
      "199/199 [==============================] - 0s 936us/step - loss: 0.0123 - val_loss: 0.0119\n",
      "Epoch 81/100\n",
      "199/199 [==============================] - 0s 999us/step - loss: 0.0122 - val_loss: 0.0119\n",
      "Epoch 82/100\n",
      "199/199 [==============================] - 0s 988us/step - loss: 0.0122 - val_loss: 0.0118\n",
      "Epoch 83/100\n",
      "199/199 [==============================] - 0s 924us/step - loss: 0.0121 - val_loss: 0.0118\n",
      "Epoch 84/100\n",
      "199/199 [==============================] - 0s 925us/step - loss: 0.0121 - val_loss: 0.0118\n",
      "Epoch 85/100\n",
      "199/199 [==============================] - 0s 924us/step - loss: 0.0120 - val_loss: 0.0117\n",
      "Epoch 86/100\n",
      "199/199 [==============================] - 0s 931us/step - loss: 0.0120 - val_loss: 0.0117\n",
      "Epoch 87/100\n",
      "199/199 [==============================] - 0s 930us/step - loss: 0.0119 - val_loss: 0.0117\n",
      "Epoch 88/100\n",
      "199/199 [==============================] - 0s 914us/step - loss: 0.0119 - val_loss: 0.0116\n",
      "Epoch 89/100\n",
      "199/199 [==============================] - 0s 929us/step - loss: 0.0118 - val_loss: 0.0116\n",
      "Epoch 90/100\n",
      "199/199 [==============================] - 0s 921us/step - loss: 0.0119 - val_loss: 0.0116\n",
      "Epoch 91/100\n",
      "199/199 [==============================] - 0s 931us/step - loss: 0.0119 - val_loss: 0.0115\n",
      "Epoch 92/100\n",
      "199/199 [==============================] - 0s 924us/step - loss: 0.0118 - val_loss: 0.0116\n",
      "Epoch 93/100\n",
      "199/199 [==============================] - 0s 934us/step - loss: 0.0118 - val_loss: 0.0115\n",
      "Epoch 94/100\n",
      "199/199 [==============================] - 0s 927us/step - loss: 0.0117 - val_loss: 0.0115\n",
      "Epoch 95/100\n",
      "199/199 [==============================] - 0s 919us/step - loss: 0.0117 - val_loss: 0.0114\n",
      "Epoch 96/100\n",
      "199/199 [==============================] - 0s 920us/step - loss: 0.0117 - val_loss: 0.0114\n",
      "Epoch 97/100\n",
      "199/199 [==============================] - 0s 931us/step - loss: 0.0117 - val_loss: 0.0114\n",
      "Epoch 98/100\n",
      "199/199 [==============================] - 0s 916us/step - loss: 0.0116 - val_loss: 0.0114\n",
      "Epoch 99/100\n",
      "199/199 [==============================] - 0s 959us/step - loss: 0.0116 - val_loss: 0.0114\n",
      "Epoch 100/100\n",
      "199/199 [==============================] - 0s 951us/step - loss: 0.0116 - val_loss: 0.0113\n",
      "This round is 9\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_63917/2731616321.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  para_dfm = para_dfm.append({\"reg_param\": reg_param, \"number_units_layers\": numbers_units_layers, \"number_units_bottleneck\": numbers_units_bottleneck, \"dropout_rate\": dropout_rate, \"number_layers\": numbers_layers, \"whether_dropout\": whether_dropout, \"whether_regularizer\": whether_regularizer, \"overfit_metric\": overfit_metric, \"val2_avg_recon_error\": val2_avg_recon_error,'val1_loss':val1_loss}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0932 - val_loss: 0.0480\n",
      "Epoch 2/100\n",
      "199/199 [==============================] - 0s 899us/step - loss: 0.0387 - val_loss: 0.0340\n",
      "Epoch 3/100\n",
      "199/199 [==============================] - 0s 899us/step - loss: 0.0290 - val_loss: 0.0252\n",
      "Epoch 4/100\n",
      "199/199 [==============================] - 0s 907us/step - loss: 0.0231 - val_loss: 0.0209\n",
      "Epoch 5/100\n",
      "199/199 [==============================] - 0s 905us/step - loss: 0.0193 - val_loss: 0.0177\n",
      "Epoch 6/100\n",
      "199/199 [==============================] - 0s 889us/step - loss: 0.0169 - val_loss: 0.0157\n",
      "Epoch 7/100\n",
      "199/199 [==============================] - 0s 890us/step - loss: 0.0148 - val_loss: 0.0137\n",
      "Epoch 8/100\n",
      "199/199 [==============================] - 0s 919us/step - loss: 0.0129 - val_loss: 0.0121\n",
      "Epoch 9/100\n",
      "199/199 [==============================] - 0s 897us/step - loss: 0.0114 - val_loss: 0.0110\n",
      "Epoch 10/100\n",
      "199/199 [==============================] - 0s 967us/step - loss: 0.0104 - val_loss: 0.0101\n",
      "Epoch 11/100\n",
      "199/199 [==============================] - 0s 905us/step - loss: 0.0096 - val_loss: 0.0094\n",
      "Epoch 12/100\n",
      "199/199 [==============================] - 0s 887us/step - loss: 0.0090 - val_loss: 0.0088\n",
      "Epoch 13/100\n",
      "199/199 [==============================] - 0s 953us/step - loss: 0.0083 - val_loss: 0.0082\n",
      "Epoch 14/100\n",
      "199/199 [==============================] - 0s 897us/step - loss: 0.0077 - val_loss: 0.0077\n",
      "Epoch 15/100\n",
      "199/199 [==============================] - 0s 882us/step - loss: 0.0073 - val_loss: 0.0073\n",
      "Epoch 16/100\n",
      "199/199 [==============================] - 0s 912us/step - loss: 0.0069 - val_loss: 0.0070\n",
      "Epoch 17/100\n",
      "199/199 [==============================] - 0s 909us/step - loss: 0.0066 - val_loss: 0.0067\n",
      "Epoch 18/100\n",
      "199/199 [==============================] - 0s 913us/step - loss: 0.0063 - val_loss: 0.0064\n",
      "Epoch 19/100\n",
      "199/199 [==============================] - 0s 905us/step - loss: 0.0060 - val_loss: 0.0061\n",
      "Epoch 20/100\n",
      "199/199 [==============================] - 0s 903us/step - loss: 0.0057 - val_loss: 0.0058\n",
      "Epoch 21/100\n",
      "199/199 [==============================] - 0s 908us/step - loss: 0.0055 - val_loss: 0.0057\n",
      "Epoch 22/100\n",
      "199/199 [==============================] - 0s 901us/step - loss: 0.0053 - val_loss: 0.0055\n",
      "Epoch 23/100\n",
      "199/199 [==============================] - 0s 914us/step - loss: 0.0051 - val_loss: 0.0053\n",
      "Epoch 24/100\n",
      "199/199 [==============================] - 0s 902us/step - loss: 0.0049 - val_loss: 0.0051\n",
      "Epoch 25/100\n",
      "199/199 [==============================] - 0s 906us/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 26/100\n",
      "199/199 [==============================] - 0s 933us/step - loss: 0.0044 - val_loss: 0.0047\n",
      "Epoch 27/100\n",
      "199/199 [==============================] - 0s 913us/step - loss: 0.0043 - val_loss: 0.0046\n",
      "Epoch 28/100\n",
      "199/199 [==============================] - 0s 918us/step - loss: 0.0041 - val_loss: 0.0044\n",
      "Epoch 29/100\n",
      "199/199 [==============================] - 0s 914us/step - loss: 0.0039 - val_loss: 0.0044\n",
      "Epoch 30/100\n",
      "199/199 [==============================] - 0s 947us/step - loss: 0.0038 - val_loss: 0.0043\n",
      "Epoch 31/100\n",
      "199/199 [==============================] - 0s 923us/step - loss: 0.0037 - val_loss: 0.0041\n",
      "Epoch 32/100\n",
      "199/199 [==============================] - 0s 928us/step - loss: 0.0036 - val_loss: 0.0040\n",
      "Epoch 33/100\n",
      "199/199 [==============================] - 0s 925us/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 34/100\n",
      "199/199 [==============================] - 0s 917us/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 35/100\n",
      "199/199 [==============================] - 0s 934us/step - loss: 0.0032 - val_loss: 0.0036\n",
      "Epoch 36/100\n",
      "199/199 [==============================] - 0s 915us/step - loss: 0.0031 - val_loss: 0.0035\n",
      "Epoch 37/100\n",
      "199/199 [==============================] - 0s 919us/step - loss: 0.0030 - val_loss: 0.0034\n",
      "Epoch 38/100\n",
      "199/199 [==============================] - 0s 936us/step - loss: 0.0029 - val_loss: 0.0033\n",
      "Epoch 39/100\n",
      "199/199 [==============================] - 0s 925us/step - loss: 0.0028 - val_loss: 0.0033\n",
      "Epoch 40/100\n",
      "199/199 [==============================] - 0s 927us/step - loss: 0.0028 - val_loss: 0.0032\n",
      "Epoch 41/100\n",
      "199/199 [==============================] - 0s 943us/step - loss: 0.0027 - val_loss: 0.0032\n",
      "Epoch 42/100\n",
      "199/199 [==============================] - 0s 937us/step - loss: 0.0026 - val_loss: 0.0031\n",
      "Epoch 43/100\n",
      "199/199 [==============================] - 0s 936us/step - loss: 0.0026 - val_loss: 0.0030\n",
      "Epoch 44/100\n",
      "199/199 [==============================] - 0s 929us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 45/100\n",
      "199/199 [==============================] - 0s 929us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 46/100\n",
      "199/199 [==============================] - 0s 954us/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 47/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 48/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 49/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0026\n",
      "Epoch 50/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 51/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 52/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 53/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 54/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 55/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 56/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 57/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 58/100\n",
      "199/199 [==============================] - 0s 967us/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 59/100\n",
      "199/199 [==============================] - 0s 965us/step - loss: 0.0017 - val_loss: 0.0022\n",
      "Epoch 60/100\n",
      "199/199 [==============================] - 0s 963us/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 61/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 62/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 63/100\n",
      "199/199 [==============================] - 0s 978us/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 64/100\n",
      "199/199 [==============================] - 0s 953us/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 65/100\n",
      "199/199 [==============================] - 0s 945us/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 66/100\n",
      "199/199 [==============================] - 0s 990us/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 67/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 68/100\n",
      "199/199 [==============================] - 0s 952us/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 69/100\n",
      "199/199 [==============================] - 0s 918us/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 70/100\n",
      "199/199 [==============================] - 0s 918us/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 71/100\n",
      "199/199 [==============================] - 0s 927us/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 72/100\n",
      "199/199 [==============================] - 0s 937us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 73/100\n",
      "199/199 [==============================] - 0s 927us/step - loss: 0.0013 - val_loss: 0.0020\n",
      "Epoch 74/100\n",
      "199/199 [==============================] - 0s 934us/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 75/100\n",
      "199/199 [==============================] - 0s 928us/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 76/100\n",
      "199/199 [==============================] - 0s 952us/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 77/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 78/100\n",
      "199/199 [==============================] - 0s 930us/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 79/100\n",
      "199/199 [==============================] - 0s 929us/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 80/100\n",
      "199/199 [==============================] - 0s 951us/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 81/100\n",
      "199/199 [==============================] - 0s 917us/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 82/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 83/100\n",
      "199/199 [==============================] - 0s 981us/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 84/100\n",
      "199/199 [==============================] - 0s 960us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 85/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 86/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 87/100\n",
      "199/199 [==============================] - 0s 964us/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 88/100\n",
      "199/199 [==============================] - 0s 936us/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 89/100\n",
      "199/199 [==============================] - 0s 970us/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 90/100\n",
      "199/199 [==============================] - 0s 968us/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 91/100\n",
      "199/199 [==============================] - 0s 936us/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 92/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 93/100\n",
      "199/199 [==============================] - 0s 970us/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 94/100\n",
      "199/199 [==============================] - 0s 922us/step - loss: 0.0010 - val_loss: 0.0016\n",
      "Epoch 95/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0010 - val_loss: 0.0016\n",
      "Epoch 96/100\n",
      "199/199 [==============================] - 0s 944us/step - loss: 0.0010 - val_loss: 0.0016\n",
      "Epoch 97/100\n",
      "199/199 [==============================] - 0s 945us/step - loss: 0.0010 - val_loss: 0.0016\n",
      "Epoch 98/100\n",
      "199/199 [==============================] - 0s 959us/step - loss: 0.0010 - val_loss: 0.0016\n",
      "Epoch 99/100\n",
      "199/199 [==============================] - 0s 929us/step - loss: 0.0010 - val_loss: 0.0016\n",
      "Epoch 100/100\n",
      "199/199 [==============================] - 0s 925us/step - loss: 0.0010 - val_loss: 0.0016\n",
      "This round is 10\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_63917/2731616321.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  para_dfm = para_dfm.append({\"reg_param\": reg_param, \"number_units_layers\": numbers_units_layers, \"number_units_bottleneck\": numbers_units_bottleneck, \"dropout_rate\": dropout_rate, \"number_layers\": numbers_layers, \"whether_dropout\": whether_dropout, \"whether_regularizer\": whether_regularizer, \"overfit_metric\": overfit_metric, \"val2_avg_recon_error\": val2_avg_recon_error,'val1_loss':val1_loss}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 1s 1ms/step - loss: 0.0932 - val_loss: 0.0480\n",
      "Epoch 2/100\n",
      "199/199 [==============================] - 0s 940us/step - loss: 0.0387 - val_loss: 0.0340\n",
      "Epoch 3/100\n",
      "199/199 [==============================] - 0s 900us/step - loss: 0.0290 - val_loss: 0.0252\n",
      "Epoch 4/100\n",
      "199/199 [==============================] - 0s 897us/step - loss: 0.0231 - val_loss: 0.0209\n",
      "Epoch 5/100\n",
      "199/199 [==============================] - 0s 912us/step - loss: 0.0193 - val_loss: 0.0177\n",
      "Epoch 6/100\n",
      "199/199 [==============================] - 0s 919us/step - loss: 0.0169 - val_loss: 0.0157\n",
      "Epoch 7/100\n",
      "199/199 [==============================] - 0s 916us/step - loss: 0.0148 - val_loss: 0.0137\n",
      "Epoch 8/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0129 - val_loss: 0.0121\n",
      "Epoch 9/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0114 - val_loss: 0.0110\n",
      "Epoch 10/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0104 - val_loss: 0.0101\n",
      "Epoch 11/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.0094\n",
      "Epoch 12/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0088\n",
      "Epoch 13/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0082\n",
      "Epoch 14/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 0.0077\n",
      "Epoch 15/100\n",
      "199/199 [==============================] - 1s 3ms/step - loss: 0.0073 - val_loss: 0.0073\n",
      "Epoch 16/100\n",
      "199/199 [==============================] - 1s 3ms/step - loss: 0.0069 - val_loss: 0.0070\n",
      "Epoch 17/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0067\n",
      "Epoch 18/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0064\n",
      "Epoch 19/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0061\n",
      "Epoch 20/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0057 - val_loss: 0.0058\n",
      "Epoch 21/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0055 - val_loss: 0.0057\n",
      "Epoch 22/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0053 - val_loss: 0.0055\n",
      "Epoch 23/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0051 - val_loss: 0.0053\n",
      "Epoch 24/100\n",
      "199/199 [==============================] - 0s 971us/step - loss: 0.0049 - val_loss: 0.0051\n",
      "Epoch 25/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 26/100\n",
      "199/199 [==============================] - 0s 999us/step - loss: 0.0044 - val_loss: 0.0047\n",
      "Epoch 27/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0043 - val_loss: 0.0046\n",
      "Epoch 28/100\n",
      "199/199 [==============================] - 0s 974us/step - loss: 0.0041 - val_loss: 0.0044\n",
      "Epoch 29/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0039 - val_loss: 0.0044\n",
      "Epoch 30/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0038 - val_loss: 0.0043\n",
      "Epoch 31/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0037 - val_loss: 0.0041\n",
      "Epoch 32/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0036 - val_loss: 0.0040\n",
      "Epoch 33/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 34/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 35/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0032 - val_loss: 0.0036\n",
      "Epoch 36/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0031 - val_loss: 0.0035\n",
      "Epoch 37/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0030 - val_loss: 0.0034\n",
      "Epoch 38/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0029 - val_loss: 0.0033\n",
      "Epoch 39/100\n",
      "199/199 [==============================] - 1s 4ms/step - loss: 0.0028 - val_loss: 0.0033\n",
      "Epoch 40/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0028 - val_loss: 0.0032\n",
      "Epoch 41/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0027 - val_loss: 0.0032\n",
      "Epoch 42/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0026 - val_loss: 0.0031\n",
      "Epoch 43/100\n",
      "199/199 [==============================] - 1s 3ms/step - loss: 0.0026 - val_loss: 0.0030\n",
      "Epoch 44/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 45/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 46/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 47/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 48/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 49/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0021 - val_loss: 0.0026\n",
      "Epoch 50/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 51/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 52/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 53/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 54/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 55/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 56/100\n",
      "199/199 [==============================] - 0s 991us/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 57/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 58/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 59/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0017 - val_loss: 0.0022\n",
      "Epoch 60/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 61/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 62/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 63/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 64/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 65/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 66/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 67/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 68/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 69/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 70/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 71/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 72/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 73/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0020\n",
      "Epoch 74/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 75/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 76/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 77/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 78/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 79/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 80/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 81/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 82/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 83/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 84/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 85/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 86/100\n",
      "199/199 [==============================] - 1s 4ms/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 87/100\n",
      "199/199 [==============================] - 1s 4ms/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 88/100\n",
      "199/199 [==============================] - 1s 3ms/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 89/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 90/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 91/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 92/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 93/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 94/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0010 - val_loss: 0.0016\n",
      "Epoch 95/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0010 - val_loss: 0.0016\n",
      "Epoch 96/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0010 - val_loss: 0.0016\n",
      "Epoch 97/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0010 - val_loss: 0.0016\n",
      "Epoch 98/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0010 - val_loss: 0.0016\n",
      "Epoch 99/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0010 - val_loss: 0.0016\n",
      "Epoch 100/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0010 - val_loss: 0.0016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_63917/2731616321.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  para_dfm = para_dfm.append({\"reg_param\": reg_param, \"number_units_layers\": numbers_units_layers, \"number_units_bottleneck\": numbers_units_bottleneck, \"dropout_rate\": dropout_rate, \"number_layers\": numbers_layers, \"whether_dropout\": whether_dropout, \"whether_regularizer\": whether_regularizer, \"overfit_metric\": overfit_metric, \"val2_avg_recon_error\": val2_avg_recon_error,'val1_loss':val1_loss}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This round is 11\n",
      "Epoch 1/100\n",
      "199/199 [==============================] - 1s 2ms/step - loss: 0.8599 - val_loss: 0.2357\n",
      "Epoch 2/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.1161 - val_loss: 0.0644\n",
      "Epoch 3/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0576 - val_loss: 0.0552\n",
      "Epoch 4/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0550 - val_loss: 0.0548\n",
      "Epoch 5/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0544 - val_loss: 0.0533\n",
      "Epoch 6/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0484 - val_loss: 0.0428\n",
      "Epoch 7/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0412 - val_loss: 0.0399\n",
      "Epoch 8/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0394 - val_loss: 0.0388\n",
      "Epoch 9/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0386 - val_loss: 0.0381\n",
      "Epoch 10/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0380 - val_loss: 0.0376\n",
      "Epoch 11/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0375 - val_loss: 0.0372\n",
      "Epoch 12/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0373 - val_loss: 0.0370\n",
      "Epoch 13/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0371 - val_loss: 0.0368\n",
      "Epoch 14/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0369 - val_loss: 0.0367\n",
      "Epoch 15/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0368 - val_loss: 0.0365\n",
      "Epoch 16/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0367 - val_loss: 0.0365\n",
      "Epoch 17/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0366 - val_loss: 0.0363\n",
      "Epoch 18/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0365 - val_loss: 0.0363\n",
      "Epoch 19/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0364 - val_loss: 0.0363\n",
      "Epoch 20/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0364 - val_loss: 0.0363\n",
      "Epoch 21/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0363 - val_loss: 0.0362\n",
      "Epoch 22/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0363 - val_loss: 0.0361\n",
      "Epoch 23/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0363 - val_loss: 0.0360\n",
      "Epoch 24/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0363 - val_loss: 0.0361\n",
      "Epoch 25/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0362 - val_loss: 0.0360\n",
      "Epoch 26/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0362 - val_loss: 0.0360\n",
      "Epoch 27/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0362 - val_loss: 0.0360\n",
      "Epoch 28/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0361 - val_loss: 0.0360\n",
      "Epoch 29/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0361 - val_loss: 0.0360\n",
      "Epoch 30/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0361 - val_loss: 0.0359\n",
      "Epoch 31/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0360 - val_loss: 0.0359\n",
      "Epoch 32/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0360 - val_loss: 0.0359\n",
      "Epoch 33/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0360 - val_loss: 0.0359\n",
      "Epoch 34/100\n",
      "199/199 [==============================] - 0s 951us/step - loss: 0.0360 - val_loss: 0.0365\n",
      "Epoch 35/100\n",
      "199/199 [==============================] - 0s 966us/step - loss: 0.0360 - val_loss: 0.0359\n",
      "Epoch 36/100\n",
      "199/199 [==============================] - 0s 953us/step - loss: 0.0360 - val_loss: 0.0358\n",
      "Epoch 37/100\n",
      "199/199 [==============================] - 0s 943us/step - loss: 0.0360 - val_loss: 0.0358\n",
      "Epoch 38/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0359 - val_loss: 0.0361\n",
      "Epoch 39/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0359 - val_loss: 0.0358\n",
      "Epoch 40/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0360 - val_loss: 0.0358\n",
      "Epoch 41/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0359 - val_loss: 0.0357\n",
      "Epoch 42/100\n",
      "199/199 [==============================] - 0s 961us/step - loss: 0.0359 - val_loss: 0.0358\n",
      "Epoch 43/100\n",
      "199/199 [==============================] - 0s 950us/step - loss: 0.0359 - val_loss: 0.0358\n",
      "Epoch 44/100\n",
      "199/199 [==============================] - 0s 967us/step - loss: 0.0359 - val_loss: 0.0361\n",
      "Epoch 45/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0359 - val_loss: 0.0357\n",
      "Epoch 46/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0359 - val_loss: 0.0358\n",
      "Epoch 47/100\n",
      "199/199 [==============================] - 0s 971us/step - loss: 0.0358 - val_loss: 0.0356\n",
      "Epoch 48/100\n",
      "199/199 [==============================] - 0s 978us/step - loss: 0.0358 - val_loss: 0.0357\n",
      "Epoch 49/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0358 - val_loss: 0.0356\n",
      "Epoch 50/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0358 - val_loss: 0.0358\n",
      "Epoch 51/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0358 - val_loss: 0.0357\n",
      "Epoch 52/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0357 - val_loss: 0.0356\n",
      "Epoch 53/100\n",
      "199/199 [==============================] - 0s 966us/step - loss: 0.0357 - val_loss: 0.0356\n",
      "Epoch 54/100\n",
      "199/199 [==============================] - 0s 945us/step - loss: 0.0358 - val_loss: 0.0362\n",
      "Epoch 55/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0357 - val_loss: 0.0355\n",
      "Epoch 56/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0356 - val_loss: 0.0354\n",
      "Epoch 57/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0356 - val_loss: 0.0354\n",
      "Epoch 58/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0356 - val_loss: 0.0356\n",
      "Epoch 59/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0356 - val_loss: 0.0354\n",
      "Epoch 60/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0354 - val_loss: 0.0352\n",
      "Epoch 61/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0353 - val_loss: 0.0352\n",
      "Epoch 62/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0352 - val_loss: 0.0350\n",
      "Epoch 63/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0351 - val_loss: 0.0349\n",
      "Epoch 64/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0349 - val_loss: 0.0347\n",
      "Epoch 65/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0348 - val_loss: 0.0346\n",
      "Epoch 66/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0347 - val_loss: 0.0346\n",
      "Epoch 67/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0347 - val_loss: 0.0345\n",
      "Epoch 68/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0345 - val_loss: 0.0344\n",
      "Epoch 69/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0344 - val_loss: 0.0342\n",
      "Epoch 70/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0342 - val_loss: 0.0341\n",
      "Epoch 71/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0342 - val_loss: 0.0340\n",
      "Epoch 72/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0338 - val_loss: 0.0335\n",
      "Epoch 73/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0334 - val_loss: 0.0329\n",
      "Epoch 74/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0328 - val_loss: 0.0324\n",
      "Epoch 75/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0323 - val_loss: 0.0318\n",
      "Epoch 76/100\n",
      "199/199 [==============================] - 0s 960us/step - loss: 0.0318 - val_loss: 0.0314\n",
      "Epoch 77/100\n",
      "199/199 [==============================] - 0s 980us/step - loss: 0.0314 - val_loss: 0.0312\n",
      "Epoch 78/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0310 - val_loss: 0.0307\n",
      "Epoch 79/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0307 - val_loss: 0.0305\n",
      "Epoch 80/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0303 - val_loss: 0.0300\n",
      "Epoch 81/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0300 - val_loss: 0.0300\n",
      "Epoch 82/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0298 - val_loss: 0.0297\n",
      "Epoch 83/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0295 - val_loss: 0.0292\n",
      "Epoch 84/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0292 - val_loss: 0.0290\n",
      "Epoch 85/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0291 - val_loss: 0.0288\n",
      "Epoch 86/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0289 - val_loss: 0.0287\n",
      "Epoch 87/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0287 - val_loss: 0.0285\n",
      "Epoch 88/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0286 - val_loss: 0.0284\n",
      "Epoch 89/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0284 - val_loss: 0.0281\n",
      "Epoch 90/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0283 - val_loss: 0.0280\n",
      "Epoch 91/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0282 - val_loss: 0.0279\n",
      "Epoch 92/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0281 - val_loss: 0.0278\n",
      "Epoch 93/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0280 - val_loss: 0.0279\n",
      "Epoch 94/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0279 - val_loss: 0.0283\n",
      "Epoch 95/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0278 - val_loss: 0.0276\n",
      "Epoch 96/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0276 - val_loss: 0.0274\n",
      "Epoch 97/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0275 - val_loss: 0.0275\n",
      "Epoch 98/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0275 - val_loss: 0.0275\n",
      "Epoch 99/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0274 - val_loss: 0.0273\n",
      "Epoch 100/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0274 - val_loss: 0.0271\n",
      "This round is 12\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_63917/2731616321.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  para_dfm = para_dfm.append({\"reg_param\": reg_param, \"number_units_layers\": numbers_units_layers, \"number_units_bottleneck\": numbers_units_bottleneck, \"dropout_rate\": dropout_rate, \"number_layers\": numbers_layers, \"whether_dropout\": whether_dropout, \"whether_regularizer\": whether_regularizer, \"overfit_metric\": overfit_metric, \"val2_avg_recon_error\": val2_avg_recon_error,'val1_loss':val1_loss}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 1s 1ms/step - loss: 0.1014 - val_loss: 0.0558\n",
      "Epoch 2/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0553 - val_loss: 0.0553\n",
      "Epoch 3/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0519 - val_loss: 0.0421\n",
      "Epoch 4/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0401 - val_loss: 0.0386\n",
      "Epoch 5/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0381 - val_loss: 0.0372\n",
      "Epoch 6/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0369 - val_loss: 0.0364\n",
      "Epoch 7/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0360 - val_loss: 0.0347\n",
      "Epoch 8/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0334 - val_loss: 0.0320\n",
      "Epoch 9/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0316 - val_loss: 0.0309\n",
      "Epoch 10/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0306 - val_loss: 0.0301\n",
      "Epoch 11/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0299 - val_loss: 0.0294\n",
      "Epoch 12/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0291 - val_loss: 0.0283\n",
      "Epoch 13/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0280 - val_loss: 0.0272\n",
      "Epoch 14/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0270 - val_loss: 0.0263\n",
      "Epoch 15/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0260 - val_loss: 0.0253\n",
      "Epoch 16/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0250 - val_loss: 0.0242\n",
      "Epoch 17/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0234 - val_loss: 0.0222\n",
      "Epoch 18/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0220 - val_loss: 0.0215\n",
      "Epoch 19/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0215 - val_loss: 0.0210\n",
      "Epoch 20/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0211 - val_loss: 0.0207\n",
      "Epoch 21/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0207 - val_loss: 0.0203\n",
      "Epoch 22/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0203 - val_loss: 0.0199\n",
      "Epoch 23/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0199 - val_loss: 0.0195\n",
      "Epoch 24/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0195 - val_loss: 0.0189\n",
      "Epoch 25/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0188 - val_loss: 0.0181\n",
      "Epoch 26/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0178 - val_loss: 0.0170\n",
      "Epoch 27/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0168 - val_loss: 0.0163\n",
      "Epoch 28/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0162 - val_loss: 0.0158\n",
      "Epoch 29/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0158 - val_loss: 0.0154\n",
      "Epoch 30/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0154 - val_loss: 0.0151\n",
      "Epoch 31/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0148\n",
      "Epoch 32/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0145\n",
      "Epoch 33/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0145 - val_loss: 0.0143\n",
      "Epoch 34/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0143 - val_loss: 0.0141\n",
      "Epoch 35/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0140 - val_loss: 0.0139\n",
      "Epoch 36/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0139 - val_loss: 0.0137\n",
      "Epoch 37/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0137 - val_loss: 0.0136\n",
      "Epoch 38/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0135 - val_loss: 0.0134\n",
      "Epoch 39/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0134 - val_loss: 0.0132\n",
      "Epoch 40/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0132 - val_loss: 0.0131\n",
      "Epoch 41/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0130 - val_loss: 0.0130\n",
      "Epoch 42/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0129 - val_loss: 0.0128\n",
      "Epoch 43/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0127 - val_loss: 0.0128\n",
      "Epoch 44/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0126 - val_loss: 0.0126\n",
      "Epoch 45/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0125 - val_loss: 0.0124\n",
      "Epoch 46/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.0123\n",
      "Epoch 47/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0122 - val_loss: 0.0122\n",
      "Epoch 48/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0121 - val_loss: 0.0121\n",
      "Epoch 49/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0120 - val_loss: 0.0120\n",
      "Epoch 50/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0119 - val_loss: 0.0119\n",
      "Epoch 51/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0118 - val_loss: 0.0118\n",
      "Epoch 52/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0117 - val_loss: 0.0118\n",
      "Epoch 53/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0117\n",
      "Epoch 54/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0116 - val_loss: 0.0116\n",
      "Epoch 55/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.0116\n",
      "Epoch 56/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0114 - val_loss: 0.0115\n",
      "Epoch 57/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0113 - val_loss: 0.0115\n",
      "Epoch 58/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0113 - val_loss: 0.0114\n",
      "Epoch 59/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0112 - val_loss: 0.0113\n",
      "Epoch 60/100\n",
      "199/199 [==============================] - 0s 986us/step - loss: 0.0111 - val_loss: 0.0113\n",
      "Epoch 61/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.0113\n",
      "Epoch 62/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0110 - val_loss: 0.0112\n",
      "Epoch 63/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0109 - val_loss: 0.0112\n",
      "Epoch 64/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0109 - val_loss: 0.0111\n",
      "Epoch 65/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0108 - val_loss: 0.0111\n",
      "Epoch 66/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0108 - val_loss: 0.0110\n",
      "Epoch 67/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0108 - val_loss: 0.0110\n",
      "Epoch 68/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.0109\n",
      "Epoch 69/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.0109\n",
      "Epoch 70/100\n",
      "199/199 [==============================] - 1s 3ms/step - loss: 0.0107 - val_loss: 0.0109\n",
      "Epoch 71/100\n",
      "199/199 [==============================] - 1s 3ms/step - loss: 0.0106 - val_loss: 0.0108\n",
      "Epoch 72/100\n",
      "199/199 [==============================] - 1s 4ms/step - loss: 0.0106 - val_loss: 0.0108\n",
      "Epoch 73/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.0108\n",
      "Epoch 74/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.0107\n",
      "Epoch 75/100\n",
      "199/199 [==============================] - 1s 4ms/step - loss: 0.0104 - val_loss: 0.0107\n",
      "Epoch 76/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0107\n",
      "Epoch 77/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0103 - val_loss: 0.0106\n",
      "Epoch 78/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0103 - val_loss: 0.0106\n",
      "Epoch 79/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0103 - val_loss: 0.0106\n",
      "Epoch 80/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0103 - val_loss: 0.0106\n",
      "Epoch 81/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0105\n",
      "Epoch 82/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0102 - val_loss: 0.0105\n",
      "Epoch 83/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0101 - val_loss: 0.0105\n",
      "Epoch 84/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0101 - val_loss: 0.0105\n",
      "Epoch 85/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0101 - val_loss: 0.0104\n",
      "Epoch 86/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0100 - val_loss: 0.0104\n",
      "Epoch 87/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0104\n",
      "Epoch 88/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0104\n",
      "Epoch 89/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0100 - val_loss: 0.0104\n",
      "Epoch 90/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0104\n",
      "Epoch 91/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0104\n",
      "Epoch 92/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0099 - val_loss: 0.0103\n",
      "Epoch 93/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0103\n",
      "Epoch 94/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0099 - val_loss: 0.0103\n",
      "Epoch 95/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0099 - val_loss: 0.0103\n",
      "Epoch 96/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0099 - val_loss: 0.0103\n",
      "Epoch 97/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0098 - val_loss: 0.0102\n",
      "Epoch 98/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0098 - val_loss: 0.0102\n",
      "Epoch 99/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0102\n",
      "Epoch 100/100\n",
      "199/199 [==============================] - 1s 3ms/step - loss: 0.0097 - val_loss: 0.0101\n",
      "This round is 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_63917/2731616321.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  para_dfm = para_dfm.append({\"reg_param\": reg_param, \"number_units_layers\": numbers_units_layers, \"number_units_bottleneck\": numbers_units_bottleneck, \"dropout_rate\": dropout_rate, \"number_layers\": numbers_layers, \"whether_dropout\": whether_dropout, \"whether_regularizer\": whether_regularizer, \"overfit_metric\": overfit_metric, \"val2_avg_recon_error\": val2_avg_recon_error,'val1_loss':val1_loss}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "199/199 [==============================] - 1s 2ms/step - loss: 0.0948 - val_loss: 0.0551\n",
      "Epoch 2/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0527 - val_loss: 0.0478\n",
      "Epoch 3/100\n",
      "199/199 [==============================] - 0s 964us/step - loss: 0.0400 - val_loss: 0.0353\n",
      "Epoch 4/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0328 - val_loss: 0.0305\n",
      "Epoch 5/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0292 - val_loss: 0.0266\n",
      "Epoch 6/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0243 - val_loss: 0.0218\n",
      "Epoch 7/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0206 - val_loss: 0.0186\n",
      "Epoch 8/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0182 - val_loss: 0.0170\n",
      "Epoch 9/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0169 - val_loss: 0.0160\n",
      "Epoch 10/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0160 - val_loss: 0.0152\n",
      "Epoch 11/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.0145\n",
      "Epoch 12/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0141\n",
      "Epoch 13/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0142 - val_loss: 0.0136\n",
      "Epoch 14/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0137 - val_loss: 0.0132\n",
      "Epoch 15/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0133 - val_loss: 0.0127\n",
      "Epoch 16/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0129 - val_loss: 0.0122\n",
      "Epoch 17/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0123 - val_loss: 0.0118\n",
      "Epoch 18/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0119 - val_loss: 0.0114\n",
      "Epoch 19/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.0110\n",
      "Epoch 20/100\n",
      "199/199 [==============================] - 0s 959us/step - loss: 0.0111 - val_loss: 0.0106\n",
      "Epoch 21/100\n",
      "199/199 [==============================] - 0s 992us/step - loss: 0.0107 - val_loss: 0.0102\n",
      "Epoch 22/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0100\n",
      "Epoch 23/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0101 - val_loss: 0.0097\n",
      "Epoch 24/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0098 - val_loss: 0.0094\n",
      "Epoch 25/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.0092\n",
      "Epoch 26/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0091\n",
      "Epoch 27/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0089\n",
      "Epoch 28/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0088\n",
      "Epoch 29/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0086\n",
      "Epoch 30/100\n",
      "199/199 [==============================] - 0s 960us/step - loss: 0.0088 - val_loss: 0.0085\n",
      "Epoch 31/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0084\n",
      "Epoch 32/100\n",
      "199/199 [==============================] - 0s 972us/step - loss: 0.0085 - val_loss: 0.0083\n",
      "Epoch 33/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0082\n",
      "Epoch 34/100\n",
      "199/199 [==============================] - 0s 971us/step - loss: 0.0083 - val_loss: 0.0081\n",
      "Epoch 35/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0080\n",
      "Epoch 36/100\n",
      "199/199 [==============================] - 0s 974us/step - loss: 0.0081 - val_loss: 0.0080\n",
      "Epoch 37/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0080 - val_loss: 0.0078\n",
      "Epoch 38/100\n",
      "199/199 [==============================] - 0s 970us/step - loss: 0.0079 - val_loss: 0.0077\n",
      "Epoch 39/100\n",
      "199/199 [==============================] - 0s 991us/step - loss: 0.0078 - val_loss: 0.0076\n",
      "Epoch 40/100\n",
      "199/199 [==============================] - 0s 938us/step - loss: 0.0077 - val_loss: 0.0075\n",
      "Epoch 41/100\n",
      "199/199 [==============================] - 0s 898us/step - loss: 0.0075 - val_loss: 0.0074\n",
      "Epoch 42/100\n",
      "199/199 [==============================] - 0s 959us/step - loss: 0.0074 - val_loss: 0.0072\n",
      "Epoch 43/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0073 - val_loss: 0.0071\n",
      "Epoch 44/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0073 - val_loss: 0.0070\n",
      "Epoch 45/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0071 - val_loss: 0.0070\n",
      "Epoch 46/100\n",
      "199/199 [==============================] - 0s 951us/step - loss: 0.0070 - val_loss: 0.0069\n",
      "Epoch 47/100\n",
      "199/199 [==============================] - 0s 965us/step - loss: 0.0070 - val_loss: 0.0068\n",
      "Epoch 48/100\n",
      "199/199 [==============================] - 0s 924us/step - loss: 0.0069 - val_loss: 0.0068\n",
      "Epoch 49/100\n",
      "199/199 [==============================] - 0s 934us/step - loss: 0.0068 - val_loss: 0.0067\n",
      "Epoch 50/100\n",
      "199/199 [==============================] - 0s 911us/step - loss: 0.0068 - val_loss: 0.0066\n",
      "Epoch 51/100\n",
      "199/199 [==============================] - 0s 935us/step - loss: 0.0068 - val_loss: 0.0066\n",
      "Epoch 52/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0067 - val_loss: 0.0066\n",
      "Epoch 53/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0067 - val_loss: 0.0065\n",
      "Epoch 54/100\n",
      "199/199 [==============================] - 0s 985us/step - loss: 0.0066 - val_loss: 0.0064\n",
      "Epoch 55/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0066 - val_loss: 0.0064\n",
      "Epoch 56/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0065 - val_loss: 0.0063\n",
      "Epoch 57/100\n",
      "199/199 [==============================] - 0s 939us/step - loss: 0.0065 - val_loss: 0.0063\n",
      "Epoch 58/100\n",
      "199/199 [==============================] - 0s 956us/step - loss: 0.0064 - val_loss: 0.0063\n",
      "Epoch 59/100\n",
      "199/199 [==============================] - 0s 932us/step - loss: 0.0063 - val_loss: 0.0062\n",
      "Epoch 60/100\n",
      "199/199 [==============================] - 0s 943us/step - loss: 0.0063 - val_loss: 0.0062\n",
      "Epoch 61/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 0.0062\n",
      "Epoch 62/100\n",
      "199/199 [==============================] - 0s 963us/step - loss: 0.0062 - val_loss: 0.0061\n",
      "Epoch 63/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 0.0061\n",
      "Epoch 64/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0060\n",
      "Epoch 65/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0060\n",
      "Epoch 66/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0059\n",
      "Epoch 67/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0059\n",
      "Epoch 68/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0059\n",
      "Epoch 69/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0059\n",
      "Epoch 70/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0058\n",
      "Epoch 71/100\n",
      "199/199 [==============================] - 0s 943us/step - loss: 0.0060 - val_loss: 0.0058\n",
      "Epoch 72/100\n",
      "199/199 [==============================] - 0s 943us/step - loss: 0.0058 - val_loss: 0.0058\n",
      "Epoch 73/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0057\n",
      "Epoch 74/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0057\n",
      "Epoch 75/100\n",
      "199/199 [==============================] - 0s 970us/step - loss: 0.0058 - val_loss: 0.0057\n",
      "Epoch 76/100\n",
      "199/199 [==============================] - 0s 956us/step - loss: 0.0058 - val_loss: 0.0056\n",
      "Epoch 77/100\n",
      "199/199 [==============================] - 0s 934us/step - loss: 0.0057 - val_loss: 0.0056\n",
      "Epoch 78/100\n",
      "199/199 [==============================] - 0s 965us/step - loss: 0.0057 - val_loss: 0.0056\n",
      "Epoch 79/100\n",
      "199/199 [==============================] - 0s 931us/step - loss: 0.0057 - val_loss: 0.0055\n",
      "Epoch 80/100\n",
      "199/199 [==============================] - 0s 928us/step - loss: 0.0056 - val_loss: 0.0055\n",
      "Epoch 81/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0056 - val_loss: 0.0055\n",
      "Epoch 82/100\n",
      "199/199 [==============================] - 0s 970us/step - loss: 0.0056 - val_loss: 0.0055\n",
      "Epoch 83/100\n",
      "199/199 [==============================] - 0s 975us/step - loss: 0.0055 - val_loss: 0.0055\n",
      "Epoch 84/100\n",
      "199/199 [==============================] - 0s 931us/step - loss: 0.0055 - val_loss: 0.0054\n",
      "Epoch 85/100\n",
      "199/199 [==============================] - 0s 980us/step - loss: 0.0055 - val_loss: 0.0054\n",
      "Epoch 86/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0055 - val_loss: 0.0053\n",
      "Epoch 87/100\n",
      "199/199 [==============================] - 0s 915us/step - loss: 0.0054 - val_loss: 0.0053\n",
      "Epoch 88/100\n",
      "199/199 [==============================] - 0s 904us/step - loss: 0.0054 - val_loss: 0.0053\n",
      "Epoch 89/100\n",
      "199/199 [==============================] - 0s 924us/step - loss: 0.0053 - val_loss: 0.0053\n",
      "Epoch 90/100\n",
      "199/199 [==============================] - 0s 929us/step - loss: 0.0053 - val_loss: 0.0052\n",
      "Epoch 91/100\n",
      "199/199 [==============================] - 0s 978us/step - loss: 0.0054 - val_loss: 0.0052\n",
      "Epoch 92/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0053 - val_loss: 0.0052\n",
      "Epoch 93/100\n",
      "199/199 [==============================] - 0s 989us/step - loss: 0.0053 - val_loss: 0.0052\n",
      "Epoch 94/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0053 - val_loss: 0.0052\n",
      "Epoch 95/100\n",
      "199/199 [==============================] - 0s 981us/step - loss: 0.0052 - val_loss: 0.0052\n",
      "Epoch 96/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0052 - val_loss: 0.0051\n",
      "Epoch 97/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0052 - val_loss: 0.0051\n",
      "Epoch 98/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0052 - val_loss: 0.0051\n",
      "Epoch 99/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 100/100\n",
      "199/199 [==============================] - 0s 976us/step - loss: 0.0051 - val_loss: 0.0050\n",
      "This round is 14\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_63917/2731616321.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  para_dfm = para_dfm.append({\"reg_param\": reg_param, \"number_units_layers\": numbers_units_layers, \"number_units_bottleneck\": numbers_units_bottleneck, \"dropout_rate\": dropout_rate, \"number_layers\": numbers_layers, \"whether_dropout\": whether_dropout, \"whether_regularizer\": whether_regularizer, \"overfit_metric\": overfit_metric, \"val2_avg_recon_error\": val2_avg_recon_error,'val1_loss':val1_loss}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 1s 2ms/step - loss: 0.1018 - val_loss: 0.0561\n",
      "Epoch 2/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0555 - val_loss: 0.0553\n",
      "Epoch 3/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0551 - val_loss: 0.0548\n",
      "Epoch 4/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0503 - val_loss: 0.0447\n",
      "Epoch 5/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0422 - val_loss: 0.0401\n",
      "Epoch 6/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0389 - val_loss: 0.0376\n",
      "Epoch 7/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0368 - val_loss: 0.0354\n",
      "Epoch 8/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0335 - val_loss: 0.0307\n",
      "Epoch 9/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0295 - val_loss: 0.0282\n",
      "Epoch 10/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0273 - val_loss: 0.0257\n",
      "Epoch 11/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0247 - val_loss: 0.0234\n",
      "Epoch 12/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0230 - val_loss: 0.0221\n",
      "Epoch 13/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0218 - val_loss: 0.0212\n",
      "Epoch 14/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0210 - val_loss: 0.0205\n",
      "Epoch 15/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0203 - val_loss: 0.0200\n",
      "Epoch 16/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0198 - val_loss: 0.0194\n",
      "Epoch 17/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0193 - val_loss: 0.0190\n",
      "Epoch 18/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0188 - val_loss: 0.0186\n",
      "Epoch 19/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0185 - val_loss: 0.0182\n",
      "Epoch 20/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0181 - val_loss: 0.0179\n",
      "Epoch 21/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0178 - val_loss: 0.0176\n",
      "Epoch 22/100\n",
      "199/199 [==============================] - 1s 3ms/step - loss: 0.0175 - val_loss: 0.0173\n",
      "Epoch 23/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0172 - val_loss: 0.0170\n",
      "Epoch 24/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0169 - val_loss: 0.0167\n",
      "Epoch 25/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0166 - val_loss: 0.0163\n",
      "Epoch 26/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0162 - val_loss: 0.0160\n",
      "Epoch 27/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0159 - val_loss: 0.0157\n",
      "Epoch 28/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0156 - val_loss: 0.0155\n",
      "Epoch 29/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0154 - val_loss: 0.0153\n",
      "Epoch 30/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.0150\n",
      "Epoch 31/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0149 - val_loss: 0.0147\n",
      "Epoch 32/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0147 - val_loss: 0.0144\n",
      "Epoch 33/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0144 - val_loss: 0.0142\n",
      "Epoch 34/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0141 - val_loss: 0.0139\n",
      "Epoch 35/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0139 - val_loss: 0.0137\n",
      "Epoch 36/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0137 - val_loss: 0.0135\n",
      "Epoch 37/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0135 - val_loss: 0.0133\n",
      "Epoch 38/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0133 - val_loss: 0.0131\n",
      "Epoch 39/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0131 - val_loss: 0.0129\n",
      "Epoch 40/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0129 - val_loss: 0.0128\n",
      "Epoch 41/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0128 - val_loss: 0.0126\n",
      "Epoch 42/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0126 - val_loss: 0.0125\n",
      "Epoch 43/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0125 - val_loss: 0.0124\n",
      "Epoch 44/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0123 - val_loss: 0.0122\n",
      "Epoch 45/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.0121\n",
      "Epoch 46/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0121 - val_loss: 0.0120\n",
      "Epoch 47/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.0118\n",
      "Epoch 48/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0118 - val_loss: 0.0117\n",
      "Epoch 49/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0117 - val_loss: 0.0116\n",
      "Epoch 50/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.0115\n",
      "Epoch 51/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0114\n",
      "Epoch 52/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0113 - val_loss: 0.0113\n",
      "Epoch 53/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0113\n",
      "Epoch 54/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0111 - val_loss: 0.0111\n",
      "Epoch 55/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0110 - val_loss: 0.0111\n",
      "Epoch 56/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0110 - val_loss: 0.0110\n",
      "Epoch 57/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 0.0109\n",
      "Epoch 58/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0107 - val_loss: 0.0108\n",
      "Epoch 59/100\n",
      "199/199 [==============================] - 0s 946us/step - loss: 0.0107 - val_loss: 0.0107\n",
      "Epoch 60/100\n",
      "199/199 [==============================] - 0s 993us/step - loss: 0.0106 - val_loss: 0.0107\n",
      "Epoch 61/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0105 - val_loss: 0.0107\n",
      "Epoch 62/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0104 - val_loss: 0.0105\n",
      "Epoch 63/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0103 - val_loss: 0.0105\n",
      "Epoch 64/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0103 - val_loss: 0.0104\n",
      "Epoch 65/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0102 - val_loss: 0.0104\n",
      "Epoch 66/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0101 - val_loss: 0.0103\n",
      "Epoch 67/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0101 - val_loss: 0.0102\n",
      "Epoch 68/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0099 - val_loss: 0.0102\n",
      "Epoch 69/100\n",
      "199/199 [==============================] - 0s 939us/step - loss: 0.0099 - val_loss: 0.0101\n",
      "Epoch 70/100\n",
      "199/199 [==============================] - 0s 953us/step - loss: 0.0099 - val_loss: 0.0101\n",
      "Epoch 71/100\n",
      "199/199 [==============================] - 0s 951us/step - loss: 0.0098 - val_loss: 0.0100\n",
      "Epoch 72/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.0100\n",
      "Epoch 73/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.0100\n",
      "Epoch 74/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.0099\n",
      "Epoch 75/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.0099\n",
      "Epoch 76/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.0099\n",
      "Epoch 77/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0098\n",
      "Epoch 78/100\n",
      "199/199 [==============================] - 0s 972us/step - loss: 0.0095 - val_loss: 0.0097\n",
      "Epoch 79/100\n",
      "199/199 [==============================] - 0s 969us/step - loss: 0.0095 - val_loss: 0.0097\n",
      "Epoch 80/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0097\n",
      "Epoch 81/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0097\n",
      "Epoch 82/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0097\n",
      "Epoch 83/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0096\n",
      "Epoch 84/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0096\n",
      "Epoch 85/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0096\n",
      "Epoch 86/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0096\n",
      "Epoch 87/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0095\n",
      "Epoch 88/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0095\n",
      "Epoch 89/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0095\n",
      "Epoch 90/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0095\n",
      "Epoch 91/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0095\n",
      "Epoch 92/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0095\n",
      "Epoch 93/100\n",
      "199/199 [==============================] - 0s 924us/step - loss: 0.0091 - val_loss: 0.0094\n",
      "Epoch 94/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0094\n",
      "Epoch 95/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0094\n",
      "Epoch 96/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0094\n",
      "Epoch 97/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0093\n",
      "Epoch 98/100\n",
      "199/199 [==============================] - 0s 989us/step - loss: 0.0090 - val_loss: 0.0094\n",
      "Epoch 99/100\n",
      "199/199 [==============================] - 0s 889us/step - loss: 0.0090 - val_loss: 0.0094\n",
      "Epoch 100/100\n",
      "199/199 [==============================] - 0s 889us/step - loss: 0.0089 - val_loss: 0.0093\n",
      "This round is 15\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_63917/2731616321.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  para_dfm = para_dfm.append({\"reg_param\": reg_param, \"number_units_layers\": numbers_units_layers, \"number_units_bottleneck\": numbers_units_bottleneck, \"dropout_rate\": dropout_rate, \"number_layers\": numbers_layers, \"whether_dropout\": whether_dropout, \"whether_regularizer\": whether_regularizer, \"overfit_metric\": overfit_metric, \"val2_avg_recon_error\": val2_avg_recon_error,'val1_loss':val1_loss}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0932 - val_loss: 0.0480\n",
      "Epoch 2/100\n",
      "199/199 [==============================] - 0s 855us/step - loss: 0.0387 - val_loss: 0.0340\n",
      "Epoch 3/100\n",
      "199/199 [==============================] - 0s 856us/step - loss: 0.0290 - val_loss: 0.0252\n",
      "Epoch 4/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0231 - val_loss: 0.0209\n",
      "Epoch 5/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0193 - val_loss: 0.0177\n",
      "Epoch 6/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0169 - val_loss: 0.0157\n",
      "Epoch 7/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.0137\n",
      "Epoch 8/100\n",
      "199/199 [==============================] - 0s 960us/step - loss: 0.0129 - val_loss: 0.0121\n",
      "Epoch 9/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0114 - val_loss: 0.0110\n",
      "Epoch 10/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0104 - val_loss: 0.0101\n",
      "Epoch 11/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.0094\n",
      "Epoch 12/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0088\n",
      "Epoch 13/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0082\n",
      "Epoch 14/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0077 - val_loss: 0.0077\n",
      "Epoch 15/100\n",
      "199/199 [==============================] - 0s 996us/step - loss: 0.0073 - val_loss: 0.0073\n",
      "Epoch 16/100\n",
      "199/199 [==============================] - 0s 952us/step - loss: 0.0069 - val_loss: 0.0070\n",
      "Epoch 17/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0066 - val_loss: 0.0067\n",
      "Epoch 18/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 0.0064\n",
      "Epoch 19/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0061\n",
      "Epoch 20/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0057 - val_loss: 0.0058\n",
      "Epoch 21/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0055 - val_loss: 0.0057\n",
      "Epoch 22/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0053 - val_loss: 0.0055\n",
      "Epoch 23/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0051 - val_loss: 0.0053\n",
      "Epoch 24/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 0.0051\n",
      "Epoch 25/100\n",
      "199/199 [==============================] - 0s 905us/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 26/100\n",
      "199/199 [==============================] - 0s 862us/step - loss: 0.0044 - val_loss: 0.0047\n",
      "Epoch 27/100\n",
      "199/199 [==============================] - 0s 901us/step - loss: 0.0043 - val_loss: 0.0046\n",
      "Epoch 28/100\n",
      "199/199 [==============================] - 0s 958us/step - loss: 0.0041 - val_loss: 0.0044\n",
      "Epoch 29/100\n",
      "199/199 [==============================] - 0s 957us/step - loss: 0.0039 - val_loss: 0.0044\n",
      "Epoch 30/100\n",
      "199/199 [==============================] - 0s 858us/step - loss: 0.0038 - val_loss: 0.0043\n",
      "Epoch 31/100\n",
      "199/199 [==============================] - 0s 845us/step - loss: 0.0037 - val_loss: 0.0041\n",
      "Epoch 32/100\n",
      "199/199 [==============================] - 0s 904us/step - loss: 0.0036 - val_loss: 0.0040\n",
      "Epoch 33/100\n",
      "199/199 [==============================] - 0s 879us/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 34/100\n",
      "199/199 [==============================] - 0s 855us/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 35/100\n",
      "199/199 [==============================] - 0s 852us/step - loss: 0.0032 - val_loss: 0.0036\n",
      "Epoch 36/100\n",
      "199/199 [==============================] - 0s 874us/step - loss: 0.0031 - val_loss: 0.0035\n",
      "Epoch 37/100\n",
      "199/199 [==============================] - 0s 932us/step - loss: 0.0030 - val_loss: 0.0034\n",
      "Epoch 38/100\n",
      "199/199 [==============================] - 0s 861us/step - loss: 0.0029 - val_loss: 0.0033\n",
      "Epoch 39/100\n",
      "199/199 [==============================] - 0s 924us/step - loss: 0.0028 - val_loss: 0.0033\n",
      "Epoch 40/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0028 - val_loss: 0.0032\n",
      "Epoch 41/100\n",
      "199/199 [==============================] - 0s 905us/step - loss: 0.0027 - val_loss: 0.0032\n",
      "Epoch 42/100\n",
      "199/199 [==============================] - 0s 936us/step - loss: 0.0026 - val_loss: 0.0031\n",
      "Epoch 43/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0026 - val_loss: 0.0030\n",
      "Epoch 44/100\n",
      "199/199 [==============================] - 0s 887us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 45/100\n",
      "199/199 [==============================] - 0s 883us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 46/100\n",
      "199/199 [==============================] - 0s 994us/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 47/100\n",
      "199/199 [==============================] - 0s 965us/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 48/100\n",
      "199/199 [==============================] - 0s 950us/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 49/100\n",
      "199/199 [==============================] - 0s 879us/step - loss: 0.0021 - val_loss: 0.0026\n",
      "Epoch 50/100\n",
      "199/199 [==============================] - 0s 901us/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 51/100\n",
      "199/199 [==============================] - 0s 918us/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 52/100\n",
      "199/199 [==============================] - 0s 907us/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 53/100\n",
      "199/199 [==============================] - 0s 914us/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 54/100\n",
      "199/199 [==============================] - 0s 850us/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 55/100\n",
      "199/199 [==============================] - 0s 916us/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 56/100\n",
      "199/199 [==============================] - 0s 904us/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 57/100\n",
      "199/199 [==============================] - 0s 961us/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 58/100\n",
      "199/199 [==============================] - 0s 942us/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 59/100\n",
      "199/199 [==============================] - 0s 879us/step - loss: 0.0017 - val_loss: 0.0022\n",
      "Epoch 60/100\n",
      "199/199 [==============================] - 0s 906us/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 61/100\n",
      "199/199 [==============================] - 0s 872us/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 62/100\n",
      "199/199 [==============================] - 0s 865us/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 63/100\n",
      "199/199 [==============================] - 0s 893us/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 64/100\n",
      "199/199 [==============================] - 0s 856us/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 65/100\n",
      "199/199 [==============================] - 0s 998us/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 66/100\n",
      "199/199 [==============================] - 0s 942us/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 67/100\n",
      "199/199 [==============================] - 0s 867us/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 68/100\n",
      "199/199 [==============================] - 0s 889us/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 69/100\n",
      "199/199 [==============================] - 0s 880us/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 70/100\n",
      "199/199 [==============================] - 0s 868us/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 71/100\n",
      "199/199 [==============================] - 0s 912us/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 72/100\n",
      "199/199 [==============================] - 0s 874us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 73/100\n",
      "199/199 [==============================] - 0s 947us/step - loss: 0.0013 - val_loss: 0.0020\n",
      "Epoch 74/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 75/100\n",
      "199/199 [==============================] - 0s 856us/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 76/100\n",
      "199/199 [==============================] - 0s 864us/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 77/100\n",
      "199/199 [==============================] - 0s 882us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 78/100\n",
      "199/199 [==============================] - 0s 904us/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 79/100\n",
      "199/199 [==============================] - 0s 854us/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 80/100\n",
      "199/199 [==============================] - 0s 873us/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 81/100\n",
      "199/199 [==============================] - 0s 882us/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 82/100\n",
      "199/199 [==============================] - 0s 960us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 83/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 84/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 85/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 86/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 87/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 88/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 89/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 90/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 91/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 92/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 93/100\n",
      "199/199 [==============================] - 0s 983us/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 94/100\n",
      "199/199 [==============================] - 0s 979us/step - loss: 0.0010 - val_loss: 0.0016\n",
      "Epoch 95/100\n",
      "199/199 [==============================] - 0s 982us/step - loss: 0.0010 - val_loss: 0.0016\n",
      "Epoch 96/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0010 - val_loss: 0.0016\n",
      "Epoch 97/100\n",
      "199/199 [==============================] - 0s 964us/step - loss: 0.0010 - val_loss: 0.0016\n",
      "Epoch 98/100\n",
      "199/199 [==============================] - 0s 914us/step - loss: 0.0010 - val_loss: 0.0016\n",
      "Epoch 99/100\n",
      "199/199 [==============================] - 0s 941us/step - loss: 0.0010 - val_loss: 0.0016\n",
      "Epoch 100/100\n",
      "199/199 [==============================] - 0s 934us/step - loss: 0.0010 - val_loss: 0.0016\n",
      "This round is 16\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_63917/2731616321.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  para_dfm = para_dfm.append({\"reg_param\": reg_param, \"number_units_layers\": numbers_units_layers, \"number_units_bottleneck\": numbers_units_bottleneck, \"dropout_rate\": dropout_rate, \"number_layers\": numbers_layers, \"whether_dropout\": whether_dropout, \"whether_regularizer\": whether_regularizer, \"overfit_metric\": overfit_metric, \"val2_avg_recon_error\": val2_avg_recon_error,'val1_loss':val1_loss}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0723 - val_loss: 0.0396\n",
      "Epoch 2/100\n",
      "199/199 [==============================] - 0s 913us/step - loss: 0.0341 - val_loss: 0.0292\n",
      "Epoch 3/100\n",
      "199/199 [==============================] - 0s 913us/step - loss: 0.0242 - val_loss: 0.0202\n",
      "Epoch 4/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0184 - val_loss: 0.0166\n",
      "Epoch 5/100\n",
      "199/199 [==============================] - 0s 912us/step - loss: 0.0153 - val_loss: 0.0138\n",
      "Epoch 6/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0125 - val_loss: 0.0117\n",
      "Epoch 7/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0111 - val_loss: 0.0107\n",
      "Epoch 8/100\n",
      "199/199 [==============================] - 0s 945us/step - loss: 0.0101 - val_loss: 0.0098\n",
      "Epoch 9/100\n",
      "199/199 [==============================] - 0s 977us/step - loss: 0.0093 - val_loss: 0.0092\n",
      "Epoch 10/100\n",
      "199/199 [==============================] - 0s 963us/step - loss: 0.0087 - val_loss: 0.0085\n",
      "Epoch 11/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0078 - val_loss: 0.0076\n",
      "Epoch 12/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0070 - val_loss: 0.0069\n",
      "Epoch 13/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0065 - val_loss: 0.0065\n",
      "Epoch 14/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0061\n",
      "Epoch 15/100\n",
      "199/199 [==============================] - 0s 957us/step - loss: 0.0056 - val_loss: 0.0057\n",
      "Epoch 16/100\n",
      "199/199 [==============================] - 0s 915us/step - loss: 0.0051 - val_loss: 0.0052\n",
      "Epoch 17/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 18/100\n",
      "199/199 [==============================] - 0s 953us/step - loss: 0.0043 - val_loss: 0.0045\n",
      "Epoch 19/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0040 - val_loss: 0.0042\n",
      "Epoch 20/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0038 - val_loss: 0.0040\n",
      "Epoch 21/100\n",
      "199/199 [==============================] - 0s 998us/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 22/100\n",
      "199/199 [==============================] - 0s 949us/step - loss: 0.0033 - val_loss: 0.0037\n",
      "Epoch 23/100\n",
      "199/199 [==============================] - 0s 993us/step - loss: 0.0032 - val_loss: 0.0034\n",
      "Epoch 24/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0030 - val_loss: 0.0033\n",
      "Epoch 25/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 26/100\n",
      "199/199 [==============================] - 0s 990us/step - loss: 0.0027 - val_loss: 0.0030\n",
      "Epoch 27/100\n",
      "199/199 [==============================] - 0s 979us/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 28/100\n",
      "199/199 [==============================] - 0s 978us/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 29/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 30/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 31/100\n",
      "199/199 [==============================] - 0s 977us/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 32/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 33/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 34/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 35/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 36/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 37/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 38/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0016 - val_loss: 0.0020\n",
      "Epoch 39/100\n",
      "199/199 [==============================] - 0s 988us/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 40/100\n",
      "199/199 [==============================] - 0s 988us/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 41/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 42/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 43/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 44/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 45/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 46/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 47/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 48/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 49/100\n",
      "199/199 [==============================] - 0s 990us/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 50/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 51/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 52/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 0.0015\n",
      "Epoch 53/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0010 - val_loss: 0.0015\n",
      "Epoch 54/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 9.9641e-04 - val_loss: 0.0015\n",
      "Epoch 55/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 9.8029e-04 - val_loss: 0.0014\n",
      "Epoch 56/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 9.5297e-04 - val_loss: 0.0014\n",
      "Epoch 57/100\n",
      "199/199 [==============================] - 0s 967us/step - loss: 9.3077e-04 - val_loss: 0.0014\n",
      "Epoch 58/100\n",
      "199/199 [==============================] - 0s 956us/step - loss: 9.0306e-04 - val_loss: 0.0014\n",
      "Epoch 59/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 8.8699e-04 - val_loss: 0.0013\n",
      "Epoch 60/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 8.6784e-04 - val_loss: 0.0013\n",
      "Epoch 61/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 8.4569e-04 - val_loss: 0.0013\n",
      "Epoch 62/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 8.3157e-04 - val_loss: 0.0013\n",
      "Epoch 63/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 8.0720e-04 - val_loss: 0.0013\n",
      "Epoch 64/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 7.8756e-04 - val_loss: 0.0013\n",
      "Epoch 65/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 7.7249e-04 - val_loss: 0.0012\n",
      "Epoch 66/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 7.4773e-04 - val_loss: 0.0012\n",
      "Epoch 67/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 7.3805e-04 - val_loss: 0.0012\n",
      "Epoch 68/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 7.3476e-04 - val_loss: 0.0012\n",
      "Epoch 69/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 7.3122e-04 - val_loss: 0.0012\n",
      "Epoch 70/100\n",
      "199/199 [==============================] - 0s 935us/step - loss: 7.1295e-04 - val_loss: 0.0012\n",
      "Epoch 71/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 7.1759e-04 - val_loss: 0.0012\n",
      "Epoch 72/100\n",
      "199/199 [==============================] - 0s 950us/step - loss: 6.9211e-04 - val_loss: 0.0011\n",
      "Epoch 73/100\n",
      "199/199 [==============================] - 0s 955us/step - loss: 6.8093e-04 - val_loss: 0.0011\n",
      "Epoch 74/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 6.7822e-04 - val_loss: 0.0011\n",
      "Epoch 75/100\n",
      "199/199 [==============================] - 0s 952us/step - loss: 6.6960e-04 - val_loss: 0.0011\n",
      "Epoch 76/100\n",
      "199/199 [==============================] - 0s 960us/step - loss: 6.6395e-04 - val_loss: 0.0011\n",
      "Epoch 77/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 6.4810e-04 - val_loss: 0.0011\n",
      "Epoch 78/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 6.4488e-04 - val_loss: 0.0011\n",
      "Epoch 79/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 6.5345e-04 - val_loss: 0.0011\n",
      "Epoch 80/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 6.3258e-04 - val_loss: 0.0010\n",
      "Epoch 81/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 6.2033e-04 - val_loss: 0.0011\n",
      "Epoch 82/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 6.1761e-04 - val_loss: 0.0010\n",
      "Epoch 83/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 6.0956e-04 - val_loss: 0.0011\n",
      "Epoch 84/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 5.9139e-04 - val_loss: 9.9530e-04\n",
      "Epoch 85/100\n",
      "199/199 [==============================] - 0s 963us/step - loss: 5.9697e-04 - val_loss: 0.0010\n",
      "Epoch 86/100\n",
      "199/199 [==============================] - 0s 936us/step - loss: 5.9040e-04 - val_loss: 0.0011\n",
      "Epoch 87/100\n",
      "199/199 [==============================] - 0s 964us/step - loss: 5.8650e-04 - val_loss: 0.0010\n",
      "Epoch 88/100\n",
      "199/199 [==============================] - 0s 931us/step - loss: 5.7137e-04 - val_loss: 9.9106e-04\n",
      "Epoch 89/100\n",
      "199/199 [==============================] - 0s 957us/step - loss: 5.7186e-04 - val_loss: 9.6608e-04\n",
      "Epoch 90/100\n",
      "199/199 [==============================] - 0s 946us/step - loss: 5.6515e-04 - val_loss: 9.5962e-04\n",
      "Epoch 91/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 5.6592e-04 - val_loss: 9.5572e-04\n",
      "Epoch 92/100\n",
      "199/199 [==============================] - 0s 955us/step - loss: 5.5454e-04 - val_loss: 9.7297e-04\n",
      "Epoch 93/100\n",
      "199/199 [==============================] - 0s 955us/step - loss: 5.5094e-04 - val_loss: 9.8676e-04\n",
      "Epoch 94/100\n",
      "199/199 [==============================] - 0s 947us/step - loss: 5.4292e-04 - val_loss: 9.2052e-04\n",
      "Epoch 95/100\n",
      "199/199 [==============================] - 0s 946us/step - loss: 5.4498e-04 - val_loss: 9.6061e-04\n",
      "Epoch 96/100\n",
      "199/199 [==============================] - 0s 965us/step - loss: 5.3209e-04 - val_loss: 9.5815e-04\n",
      "Epoch 97/100\n",
      "199/199 [==============================] - 0s 943us/step - loss: 5.4000e-04 - val_loss: 9.2419e-04\n",
      "Epoch 98/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 5.2965e-04 - val_loss: 9.2235e-04\n",
      "Epoch 99/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 5.3237e-04 - val_loss: 8.6845e-04\n",
      "Epoch 100/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 4.7133e-04 - val_loss: 7.6499e-04\n",
      "This round is 17\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_63917/2731616321.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  para_dfm = para_dfm.append({\"reg_param\": reg_param, \"number_units_layers\": numbers_units_layers, \"number_units_bottleneck\": numbers_units_bottleneck, \"dropout_rate\": dropout_rate, \"number_layers\": numbers_layers, \"whether_dropout\": whether_dropout, \"whether_regularizer\": whether_regularizer, \"overfit_metric\": overfit_metric, \"val2_avg_recon_error\": val2_avg_recon_error,'val1_loss':val1_loss}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 1s 1ms/step - loss: 0.0932 - val_loss: 0.0548\n",
      "Epoch 2/100\n",
      "199/199 [==============================] - 0s 981us/step - loss: 0.0471 - val_loss: 0.0396\n",
      "Epoch 3/100\n",
      "199/199 [==============================] - 0s 958us/step - loss: 0.0380 - val_loss: 0.0366\n",
      "Epoch 4/100\n",
      "199/199 [==============================] - 0s 941us/step - loss: 0.0357 - val_loss: 0.0345\n",
      "Epoch 5/100\n",
      "199/199 [==============================] - 0s 943us/step - loss: 0.0328 - val_loss: 0.0306\n",
      "Epoch 6/100\n",
      "199/199 [==============================] - 0s 919us/step - loss: 0.0286 - val_loss: 0.0255\n",
      "Epoch 7/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0237 - val_loss: 0.0213\n",
      "Epoch 8/100\n",
      "199/199 [==============================] - 0s 916us/step - loss: 0.0206 - val_loss: 0.0194\n",
      "Epoch 9/100\n",
      "199/199 [==============================] - 0s 935us/step - loss: 0.0193 - val_loss: 0.0185\n",
      "Epoch 10/100\n",
      "199/199 [==============================] - 0s 947us/step - loss: 0.0185 - val_loss: 0.0177\n",
      "Epoch 11/100\n",
      "199/199 [==============================] - 0s 945us/step - loss: 0.0174 - val_loss: 0.0165\n",
      "Epoch 12/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0160 - val_loss: 0.0151\n",
      "Epoch 13/100\n",
      "199/199 [==============================] - 0s 980us/step - loss: 0.0147 - val_loss: 0.0141\n",
      "Epoch 14/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0139 - val_loss: 0.0134\n",
      "Epoch 15/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0133 - val_loss: 0.0128\n",
      "Epoch 16/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0127 - val_loss: 0.0123\n",
      "Epoch 17/100\n",
      "199/199 [==============================] - 0s 981us/step - loss: 0.0122 - val_loss: 0.0119\n",
      "Epoch 18/100\n",
      "199/199 [==============================] - 0s 956us/step - loss: 0.0117 - val_loss: 0.0114\n",
      "Epoch 19/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0113 - val_loss: 0.0110\n",
      "Epoch 20/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0108 - val_loss: 0.0105\n",
      "Epoch 21/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0102\n",
      "Epoch 22/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0101 - val_loss: 0.0099\n",
      "Epoch 23/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.0096\n",
      "Epoch 24/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0093\n",
      "Epoch 25/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0090\n",
      "Epoch 26/100\n",
      "199/199 [==============================] - 0s 923us/step - loss: 0.0089 - val_loss: 0.0088\n",
      "Epoch 27/100\n",
      "199/199 [==============================] - 0s 934us/step - loss: 0.0086 - val_loss: 0.0086\n",
      "Epoch 28/100\n",
      "199/199 [==============================] - 0s 914us/step - loss: 0.0084 - val_loss: 0.0083\n",
      "Epoch 29/100\n",
      "199/199 [==============================] - 0s 946us/step - loss: 0.0081 - val_loss: 0.0081\n",
      "Epoch 30/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0079 - val_loss: 0.0079\n",
      "Epoch 31/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0077 - val_loss: 0.0077\n",
      "Epoch 32/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0074 - val_loss: 0.0075\n",
      "Epoch 33/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0072 - val_loss: 0.0073\n",
      "Epoch 34/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0070 - val_loss: 0.0071\n",
      "Epoch 35/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 0.0069\n",
      "Epoch 36/100\n",
      "199/199 [==============================] - 0s 947us/step - loss: 0.0067 - val_loss: 0.0068\n",
      "Epoch 37/100\n",
      "199/199 [==============================] - 0s 995us/step - loss: 0.0066 - val_loss: 0.0067\n",
      "Epoch 38/100\n",
      "199/199 [==============================] - 0s 961us/step - loss: 0.0065 - val_loss: 0.0067\n",
      "Epoch 39/100\n",
      "199/199 [==============================] - 0s 972us/step - loss: 0.0064 - val_loss: 0.0065\n",
      "Epoch 40/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 0.0065\n",
      "Epoch 41/100\n",
      "199/199 [==============================] - 0s 943us/step - loss: 0.0062 - val_loss: 0.0064\n",
      "Epoch 42/100\n",
      "199/199 [==============================] - 0s 910us/step - loss: 0.0062 - val_loss: 0.0063\n",
      "Epoch 43/100\n",
      "199/199 [==============================] - 0s 946us/step - loss: 0.0061 - val_loss: 0.0063\n",
      "Epoch 44/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0062\n",
      "Epoch 45/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0062\n",
      "Epoch 46/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0061\n",
      "Epoch 47/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0061\n",
      "Epoch 48/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0061\n",
      "Epoch 49/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0060\n",
      "Epoch 50/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0057 - val_loss: 0.0060\n",
      "Epoch 51/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0056 - val_loss: 0.0059\n",
      "Epoch 52/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0056 - val_loss: 0.0059\n",
      "Epoch 53/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0055 - val_loss: 0.0058\n",
      "Epoch 54/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0055 - val_loss: 0.0058\n",
      "Epoch 55/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0055 - val_loss: 0.0057\n",
      "Epoch 56/100\n",
      "199/199 [==============================] - 0s 945us/step - loss: 0.0054 - val_loss: 0.0057\n",
      "Epoch 57/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0054 - val_loss: 0.0057\n",
      "Epoch 58/100\n",
      "199/199 [==============================] - 0s 950us/step - loss: 0.0053 - val_loss: 0.0056\n",
      "Epoch 59/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0052 - val_loss: 0.0056\n",
      "Epoch 60/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0052 - val_loss: 0.0055\n",
      "Epoch 61/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0052 - val_loss: 0.0054\n",
      "Epoch 62/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0051 - val_loss: 0.0054\n",
      "Epoch 63/100\n",
      "199/199 [==============================] - 0s 950us/step - loss: 0.0050 - val_loss: 0.0054\n",
      "Epoch 64/100\n",
      "199/199 [==============================] - 0s 945us/step - loss: 0.0050 - val_loss: 0.0054\n",
      "Epoch 65/100\n",
      "199/199 [==============================] - 0s 960us/step - loss: 0.0050 - val_loss: 0.0053\n",
      "Epoch 66/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 0.0053\n",
      "Epoch 67/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 0.0052\n",
      "Epoch 68/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 0.0052\n",
      "Epoch 69/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 0.0051\n",
      "Epoch 70/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 0.0051\n",
      "Epoch 71/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0047 - val_loss: 0.0051\n",
      "Epoch 72/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0047 - val_loss: 0.0051\n",
      "Epoch 73/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0047 - val_loss: 0.0051\n",
      "Epoch 74/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0051\n",
      "Epoch 75/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0046 - val_loss: 0.0050\n",
      "Epoch 76/100\n",
      "199/199 [==============================] - 0s 943us/step - loss: 0.0046 - val_loss: 0.0050\n",
      "Epoch 77/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.0049\n",
      "Epoch 78/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0046 - val_loss: 0.0050\n",
      "Epoch 79/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0045 - val_loss: 0.0049\n",
      "Epoch 80/100\n",
      "199/199 [==============================] - 0s 954us/step - loss: 0.0045 - val_loss: 0.0049\n",
      "Epoch 81/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0045 - val_loss: 0.0049\n",
      "Epoch 82/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0045 - val_loss: 0.0049\n",
      "Epoch 83/100\n",
      "199/199 [==============================] - 0s 989us/step - loss: 0.0044 - val_loss: 0.0049\n",
      "Epoch 84/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 85/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 86/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 87/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0043 - val_loss: 0.0047\n",
      "Epoch 88/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0043 - val_loss: 0.0047\n",
      "Epoch 89/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 90/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0043 - val_loss: 0.0047\n",
      "Epoch 91/100\n",
      "199/199 [==============================] - 0s 943us/step - loss: 0.0043 - val_loss: 0.0047\n",
      "Epoch 92/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0046\n",
      "Epoch 93/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0046\n",
      "Epoch 94/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0046\n",
      "Epoch 95/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0046\n",
      "Epoch 96/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0046\n",
      "Epoch 97/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0046\n",
      "Epoch 98/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0045\n",
      "Epoch 99/100\n",
      "199/199 [==============================] - 0s 964us/step - loss: 0.0041 - val_loss: 0.0046\n",
      "Epoch 100/100\n",
      "199/199 [==============================] - 0s 935us/step - loss: 0.0041 - val_loss: 0.0045\n",
      "This round is 18\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_63917/2731616321.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  para_dfm = para_dfm.append({\"reg_param\": reg_param, \"number_units_layers\": numbers_units_layers, \"number_units_bottleneck\": numbers_units_bottleneck, \"dropout_rate\": dropout_rate, \"number_layers\": numbers_layers, \"whether_dropout\": whether_dropout, \"whether_regularizer\": whether_regularizer, \"overfit_metric\": overfit_metric, \"val2_avg_recon_error\": val2_avg_recon_error,'val1_loss':val1_loss}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 0s 1ms/step - loss: 1.9851 - val_loss: 0.7347\n",
      "Epoch 2/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.3535 - val_loss: 0.1427\n",
      "Epoch 3/100\n",
      "199/199 [==============================] - 0s 877us/step - loss: 0.0892 - val_loss: 0.0628\n",
      "Epoch 4/100\n",
      "199/199 [==============================] - 0s 901us/step - loss: 0.0578 - val_loss: 0.0555\n",
      "Epoch 5/100\n",
      "199/199 [==============================] - 0s 866us/step - loss: 0.0552 - val_loss: 0.0551\n",
      "Epoch 6/100\n",
      "199/199 [==============================] - 0s 863us/step - loss: 0.0551 - val_loss: 0.0550\n",
      "Epoch 7/100\n",
      "199/199 [==============================] - 0s 873us/step - loss: 0.0550 - val_loss: 0.0550\n",
      "Epoch 8/100\n",
      "199/199 [==============================] - 0s 936us/step - loss: 0.0551 - val_loss: 0.0551\n",
      "Epoch 9/100\n",
      "199/199 [==============================] - 0s 908us/step - loss: 0.0550 - val_loss: 0.0550\n",
      "Epoch 10/100\n",
      "199/199 [==============================] - 0s 886us/step - loss: 0.0550 - val_loss: 0.0549\n",
      "Epoch 11/100\n",
      "199/199 [==============================] - 0s 908us/step - loss: 0.0550 - val_loss: 0.0548\n",
      "Epoch 12/100\n",
      "199/199 [==============================] - 0s 864us/step - loss: 0.0548 - val_loss: 0.0545\n",
      "Epoch 13/100\n",
      "199/199 [==============================] - 0s 860us/step - loss: 0.0537 - val_loss: 0.0520\n",
      "Epoch 14/100\n",
      "199/199 [==============================] - 0s 895us/step - loss: 0.0490 - val_loss: 0.0459\n",
      "Epoch 15/100\n",
      "199/199 [==============================] - 0s 906us/step - loss: 0.0443 - val_loss: 0.0427\n",
      "Epoch 16/100\n",
      "199/199 [==============================] - 0s 860us/step - loss: 0.0421 - val_loss: 0.0412\n",
      "Epoch 17/100\n",
      "199/199 [==============================] - 0s 928us/step - loss: 0.0409 - val_loss: 0.0403\n",
      "Epoch 18/100\n",
      "199/199 [==============================] - 0s 967us/step - loss: 0.0401 - val_loss: 0.0396\n",
      "Epoch 19/100\n",
      "199/199 [==============================] - 0s 887us/step - loss: 0.0395 - val_loss: 0.0392\n",
      "Epoch 20/100\n",
      "199/199 [==============================] - 0s 977us/step - loss: 0.0391 - val_loss: 0.0387\n",
      "Epoch 21/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0387 - val_loss: 0.0384\n",
      "Epoch 22/100\n",
      "199/199 [==============================] - 0s 890us/step - loss: 0.0384 - val_loss: 0.0381\n",
      "Epoch 23/100\n",
      "199/199 [==============================] - 0s 993us/step - loss: 0.0382 - val_loss: 0.0379\n",
      "Epoch 24/100\n",
      "199/199 [==============================] - 0s 933us/step - loss: 0.0379 - val_loss: 0.0377\n",
      "Epoch 25/100\n",
      "199/199 [==============================] - 0s 898us/step - loss: 0.0377 - val_loss: 0.0374\n",
      "Epoch 26/100\n",
      "199/199 [==============================] - 0s 886us/step - loss: 0.0375 - val_loss: 0.0373\n",
      "Epoch 27/100\n",
      "199/199 [==============================] - 0s 948us/step - loss: 0.0374 - val_loss: 0.0371\n",
      "Epoch 28/100\n",
      "199/199 [==============================] - 0s 901us/step - loss: 0.0372 - val_loss: 0.0370\n",
      "Epoch 29/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0371 - val_loss: 0.0369\n",
      "Epoch 30/100\n",
      "199/199 [==============================] - 0s 895us/step - loss: 0.0370 - val_loss: 0.0368\n",
      "Epoch 31/100\n",
      "199/199 [==============================] - 0s 923us/step - loss: 0.0369 - val_loss: 0.0367\n",
      "Epoch 32/100\n",
      "199/199 [==============================] - 0s 877us/step - loss: 0.0368 - val_loss: 0.0367\n",
      "Epoch 33/100\n",
      "199/199 [==============================] - 0s 921us/step - loss: 0.0368 - val_loss: 0.0366\n",
      "Epoch 34/100\n",
      "199/199 [==============================] - 0s 936us/step - loss: 0.0367 - val_loss: 0.0365\n",
      "Epoch 35/100\n",
      "199/199 [==============================] - 0s 871us/step - loss: 0.0367 - val_loss: 0.0364\n",
      "Epoch 36/100\n",
      "199/199 [==============================] - 0s 917us/step - loss: 0.0366 - val_loss: 0.0364\n",
      "Epoch 37/100\n",
      "199/199 [==============================] - 0s 871us/step - loss: 0.0365 - val_loss: 0.0363\n",
      "Epoch 38/100\n",
      "199/199 [==============================] - 0s 968us/step - loss: 0.0365 - val_loss: 0.0365\n",
      "Epoch 39/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0364 - val_loss: 0.0363\n",
      "Epoch 40/100\n",
      "199/199 [==============================] - 0s 888us/step - loss: 0.0364 - val_loss: 0.0364\n",
      "Epoch 41/100\n",
      "199/199 [==============================] - 0s 979us/step - loss: 0.0364 - val_loss: 0.0362\n",
      "Epoch 42/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0364 - val_loss: 0.0362\n",
      "Epoch 43/100\n",
      "199/199 [==============================] - 0s 907us/step - loss: 0.0363 - val_loss: 0.0362\n",
      "Epoch 44/100\n",
      "199/199 [==============================] - 0s 919us/step - loss: 0.0363 - val_loss: 0.0361\n",
      "Epoch 45/100\n",
      "199/199 [==============================] - 0s 945us/step - loss: 0.0363 - val_loss: 0.0362\n",
      "Epoch 46/100\n",
      "199/199 [==============================] - 0s 900us/step - loss: 0.0362 - val_loss: 0.0362\n",
      "Epoch 47/100\n",
      "199/199 [==============================] - 0s 890us/step - loss: 0.0363 - val_loss: 0.0364\n",
      "Epoch 48/100\n",
      "199/199 [==============================] - 0s 950us/step - loss: 0.0362 - val_loss: 0.0360\n",
      "Epoch 49/100\n",
      "199/199 [==============================] - 0s 909us/step - loss: 0.0362 - val_loss: 0.0360\n",
      "Epoch 50/100\n",
      "199/199 [==============================] - 0s 877us/step - loss: 0.0362 - val_loss: 0.0361\n",
      "Epoch 51/100\n",
      "199/199 [==============================] - 0s 893us/step - loss: 0.0362 - val_loss: 0.0360\n",
      "Epoch 52/100\n",
      "199/199 [==============================] - 0s 948us/step - loss: 0.0361 - val_loss: 0.0360\n",
      "Epoch 53/100\n",
      "199/199 [==============================] - 0s 879us/step - loss: 0.0361 - val_loss: 0.0360\n",
      "Epoch 54/100\n",
      "199/199 [==============================] - 0s 916us/step - loss: 0.0361 - val_loss: 0.0360\n",
      "Epoch 55/100\n",
      "199/199 [==============================] - 0s 929us/step - loss: 0.0361 - val_loss: 0.0362\n",
      "Epoch 56/100\n",
      "199/199 [==============================] - 0s 909us/step - loss: 0.0361 - val_loss: 0.0359\n",
      "Epoch 57/100\n",
      "199/199 [==============================] - 0s 885us/step - loss: 0.0361 - val_loss: 0.0360\n",
      "Epoch 58/100\n",
      "199/199 [==============================] - 0s 886us/step - loss: 0.0361 - val_loss: 0.0360\n",
      "Epoch 59/100\n",
      "199/199 [==============================] - 0s 915us/step - loss: 0.0360 - val_loss: 0.0359\n",
      "Epoch 60/100\n",
      "199/199 [==============================] - 0s 977us/step - loss: 0.0360 - val_loss: 0.0359\n",
      "Epoch 61/100\n",
      "199/199 [==============================] - 0s 951us/step - loss: 0.0360 - val_loss: 0.0359\n",
      "Epoch 62/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0360 - val_loss: 0.0359\n",
      "Epoch 63/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0360 - val_loss: 0.0360\n",
      "Epoch 64/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0360 - val_loss: 0.0358\n",
      "Epoch 65/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0360 - val_loss: 0.0358\n",
      "Epoch 66/100\n",
      "199/199 [==============================] - 0s 992us/step - loss: 0.0360 - val_loss: 0.0358\n",
      "Epoch 67/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0360 - val_loss: 0.0358\n",
      "Epoch 68/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0359 - val_loss: 0.0360\n",
      "Epoch 69/100\n",
      "199/199 [==============================] - 0s 972us/step - loss: 0.0359 - val_loss: 0.0359\n",
      "Epoch 70/100\n",
      "199/199 [==============================] - 0s 935us/step - loss: 0.0360 - val_loss: 0.0358\n",
      "Epoch 71/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0359 - val_loss: 0.0358\n",
      "Epoch 72/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0359 - val_loss: 0.0358\n",
      "Epoch 73/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0359 - val_loss: 0.0358\n",
      "Epoch 74/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0359 - val_loss: 0.0358\n",
      "Epoch 75/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0359 - val_loss: 0.0358\n",
      "Epoch 76/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0359 - val_loss: 0.0363\n",
      "Epoch 77/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0360 - val_loss: 0.0358\n",
      "Epoch 78/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0358 - val_loss: 0.0358\n",
      "Epoch 79/100\n",
      "199/199 [==============================] - 0s 989us/step - loss: 0.0359 - val_loss: 0.0357\n",
      "Epoch 80/100\n",
      "199/199 [==============================] - 0s 971us/step - loss: 0.0359 - val_loss: 0.0361\n",
      "Epoch 81/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0359 - val_loss: 0.0360\n",
      "Epoch 82/100\n",
      "199/199 [==============================] - 0s 948us/step - loss: 0.0359 - val_loss: 0.0358\n",
      "Epoch 83/100\n",
      "199/199 [==============================] - 0s 932us/step - loss: 0.0359 - val_loss: 0.0357\n",
      "Epoch 84/100\n",
      "199/199 [==============================] - 0s 913us/step - loss: 0.0358 - val_loss: 0.0360\n",
      "Epoch 85/100\n",
      "199/199 [==============================] - 0s 924us/step - loss: 0.0359 - val_loss: 0.0358\n",
      "Epoch 86/100\n",
      "199/199 [==============================] - 0s 927us/step - loss: 0.0359 - val_loss: 0.0357\n",
      "Epoch 87/100\n",
      "199/199 [==============================] - 0s 917us/step - loss: 0.0358 - val_loss: 0.0357\n",
      "Epoch 88/100\n",
      "199/199 [==============================] - 0s 917us/step - loss: 0.0358 - val_loss: 0.0357\n",
      "Epoch 89/100\n",
      "199/199 [==============================] - 0s 943us/step - loss: 0.0358 - val_loss: 0.0356\n",
      "Epoch 90/100\n",
      "199/199 [==============================] - 0s 916us/step - loss: 0.0358 - val_loss: 0.0357\n",
      "Epoch 91/100\n",
      "199/199 [==============================] - 0s 958us/step - loss: 0.0358 - val_loss: 0.0358\n",
      "Epoch 92/100\n",
      "199/199 [==============================] - 0s 936us/step - loss: 0.0358 - val_loss: 0.0357\n",
      "Epoch 93/100\n",
      "199/199 [==============================] - 0s 935us/step - loss: 0.0358 - val_loss: 0.0358\n",
      "Epoch 94/100\n",
      "199/199 [==============================] - 0s 929us/step - loss: 0.0359 - val_loss: 0.0361\n",
      "Epoch 95/100\n",
      "199/199 [==============================] - 0s 946us/step - loss: 0.0358 - val_loss: 0.0360\n",
      "Epoch 96/100\n",
      "199/199 [==============================] - 0s 947us/step - loss: 0.0358 - val_loss: 0.0359\n",
      "Epoch 97/100\n",
      "199/199 [==============================] - 0s 958us/step - loss: 0.0357 - val_loss: 0.0356\n",
      "Epoch 98/100\n",
      "199/199 [==============================] - 0s 909us/step - loss: 0.0356 - val_loss: 0.0358\n",
      "Epoch 99/100\n",
      "199/199 [==============================] - 0s 940us/step - loss: 0.0357 - val_loss: 0.0355\n",
      "Epoch 100/100\n",
      "199/199 [==============================] - 0s 928us/step - loss: 0.0357 - val_loss: 0.0354\n",
      "This round is 19\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_63917/2731616321.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  para_dfm = para_dfm.append({\"reg_param\": reg_param, \"number_units_layers\": numbers_units_layers, \"number_units_bottleneck\": numbers_units_bottleneck, \"dropout_rate\": dropout_rate, \"number_layers\": numbers_layers, \"whether_dropout\": whether_dropout, \"whether_regularizer\": whether_regularizer, \"overfit_metric\": overfit_metric, \"val2_avg_recon_error\": val2_avg_recon_error,'val1_loss':val1_loss}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 0s 1ms/step - loss: 1.4046 - val_loss: 0.5018\n",
      "Epoch 2/100\n",
      "199/199 [==============================] - 0s 899us/step - loss: 0.2438 - val_loss: 0.1055\n",
      "Epoch 3/100\n",
      "199/199 [==============================] - 0s 951us/step - loss: 0.0735 - val_loss: 0.0586\n",
      "Epoch 4/100\n",
      "199/199 [==============================] - 0s 924us/step - loss: 0.0562 - val_loss: 0.0552\n",
      "Epoch 5/100\n",
      "199/199 [==============================] - 0s 919us/step - loss: 0.0551 - val_loss: 0.0550\n",
      "Epoch 6/100\n",
      "199/199 [==============================] - 0s 945us/step - loss: 0.0551 - val_loss: 0.0550\n",
      "Epoch 7/100\n",
      "199/199 [==============================] - 0s 909us/step - loss: 0.0550 - val_loss: 0.0549\n",
      "Epoch 8/100\n",
      "199/199 [==============================] - 0s 896us/step - loss: 0.0550 - val_loss: 0.0550\n",
      "Epoch 9/100\n",
      "199/199 [==============================] - 0s 907us/step - loss: 0.0550 - val_loss: 0.0549\n",
      "Epoch 10/100\n",
      "199/199 [==============================] - 0s 905us/step - loss: 0.0548 - val_loss: 0.0546\n",
      "Epoch 11/100\n",
      "199/199 [==============================] - 0s 902us/step - loss: 0.0544 - val_loss: 0.0536\n",
      "Epoch 12/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0513 - val_loss: 0.0477\n",
      "Epoch 13/100\n",
      "199/199 [==============================] - 0s 917us/step - loss: 0.0450 - val_loss: 0.0426\n",
      "Epoch 14/100\n",
      "199/199 [==============================] - 0s 910us/step - loss: 0.0418 - val_loss: 0.0408\n",
      "Epoch 15/100\n",
      "199/199 [==============================] - 0s 922us/step - loss: 0.0405 - val_loss: 0.0397\n",
      "Epoch 16/100\n",
      "199/199 [==============================] - 0s 908us/step - loss: 0.0397 - val_loss: 0.0391\n",
      "Epoch 17/100\n",
      "199/199 [==============================] - 0s 918us/step - loss: 0.0391 - val_loss: 0.0386\n",
      "Epoch 18/100\n",
      "199/199 [==============================] - 0s 918us/step - loss: 0.0386 - val_loss: 0.0381\n",
      "Epoch 19/100\n",
      "199/199 [==============================] - 0s 920us/step - loss: 0.0382 - val_loss: 0.0377\n",
      "Epoch 20/100\n",
      "199/199 [==============================] - 0s 947us/step - loss: 0.0379 - val_loss: 0.0375\n",
      "Epoch 21/100\n",
      "199/199 [==============================] - 0s 954us/step - loss: 0.0376 - val_loss: 0.0372\n",
      "Epoch 22/100\n",
      "199/199 [==============================] - 0s 938us/step - loss: 0.0373 - val_loss: 0.0370\n",
      "Epoch 23/100\n",
      "199/199 [==============================] - 0s 917us/step - loss: 0.0372 - val_loss: 0.0368\n",
      "Epoch 24/100\n",
      "199/199 [==============================] - 0s 914us/step - loss: 0.0370 - val_loss: 0.0367\n",
      "Epoch 25/100\n",
      "199/199 [==============================] - 0s 922us/step - loss: 0.0369 - val_loss: 0.0366\n",
      "Epoch 26/100\n",
      "199/199 [==============================] - 0s 952us/step - loss: 0.0368 - val_loss: 0.0365\n",
      "Epoch 27/100\n",
      "199/199 [==============================] - 0s 919us/step - loss: 0.0368 - val_loss: 0.0364\n",
      "Epoch 28/100\n",
      "199/199 [==============================] - 0s 915us/step - loss: 0.0367 - val_loss: 0.0365\n",
      "Epoch 29/100\n",
      "199/199 [==============================] - 0s 963us/step - loss: 0.0366 - val_loss: 0.0363\n",
      "Epoch 30/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0366 - val_loss: 0.0364\n",
      "Epoch 31/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0365 - val_loss: 0.0362\n",
      "Epoch 32/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0365 - val_loss: 0.0366\n",
      "Epoch 33/100\n",
      "199/199 [==============================] - 0s 966us/step - loss: 0.0364 - val_loss: 0.0362\n",
      "Epoch 34/100\n",
      "199/199 [==============================] - 0s 994us/step - loss: 0.0364 - val_loss: 0.0362\n",
      "Epoch 35/100\n",
      "199/199 [==============================] - 0s 957us/step - loss: 0.0364 - val_loss: 0.0362\n",
      "Epoch 36/100\n",
      "199/199 [==============================] - 0s 962us/step - loss: 0.0363 - val_loss: 0.0361\n",
      "Epoch 37/100\n",
      "199/199 [==============================] - 0s 932us/step - loss: 0.0363 - val_loss: 0.0361\n",
      "Epoch 38/100\n",
      "199/199 [==============================] - 0s 942us/step - loss: 0.0362 - val_loss: 0.0360\n",
      "Epoch 39/100\n",
      "199/199 [==============================] - 0s 957us/step - loss: 0.0362 - val_loss: 0.0360\n",
      "Epoch 40/100\n",
      "199/199 [==============================] - 0s 957us/step - loss: 0.0362 - val_loss: 0.0360\n",
      "Epoch 41/100\n",
      "199/199 [==============================] - 0s 943us/step - loss: 0.0362 - val_loss: 0.0360\n",
      "Epoch 42/100\n",
      "199/199 [==============================] - 0s 952us/step - loss: 0.0362 - val_loss: 0.0359\n",
      "Epoch 43/100\n",
      "199/199 [==============================] - 0s 937us/step - loss: 0.0361 - val_loss: 0.0359\n",
      "Epoch 44/100\n",
      "199/199 [==============================] - 0s 935us/step - loss: 0.0362 - val_loss: 0.0359\n",
      "Epoch 45/100\n",
      "199/199 [==============================] - 0s 940us/step - loss: 0.0361 - val_loss: 0.0359\n",
      "Epoch 46/100\n",
      "199/199 [==============================] - 0s 943us/step - loss: 0.0361 - val_loss: 0.0359\n",
      "Epoch 47/100\n",
      "199/199 [==============================] - 0s 963us/step - loss: 0.0361 - val_loss: 0.0360\n",
      "Epoch 48/100\n",
      "199/199 [==============================] - 0s 956us/step - loss: 0.0361 - val_loss: 0.0360\n",
      "Epoch 49/100\n",
      "199/199 [==============================] - 0s 962us/step - loss: 0.0361 - val_loss: 0.0359\n",
      "Epoch 50/100\n",
      "199/199 [==============================] - 0s 947us/step - loss: 0.0361 - val_loss: 0.0358\n",
      "Epoch 51/100\n",
      "199/199 [==============================] - 0s 971us/step - loss: 0.0360 - val_loss: 0.0358\n",
      "Epoch 52/100\n",
      "199/199 [==============================] - 0s 956us/step - loss: 0.0360 - val_loss: 0.0358\n",
      "Epoch 53/100\n",
      "199/199 [==============================] - 0s 927us/step - loss: 0.0360 - val_loss: 0.0358\n",
      "Epoch 54/100\n",
      "199/199 [==============================] - 0s 925us/step - loss: 0.0360 - val_loss: 0.0358\n",
      "Epoch 55/100\n",
      "199/199 [==============================] - 0s 934us/step - loss: 0.0360 - val_loss: 0.0358\n",
      "Epoch 56/100\n",
      "199/199 [==============================] - 0s 923us/step - loss: 0.0360 - val_loss: 0.0357\n",
      "Epoch 57/100\n",
      "199/199 [==============================] - 0s 940us/step - loss: 0.0360 - val_loss: 0.0358\n",
      "Epoch 58/100\n",
      "199/199 [==============================] - 0s 937us/step - loss: 0.0360 - val_loss: 0.0359\n",
      "Epoch 59/100\n",
      "199/199 [==============================] - 0s 921us/step - loss: 0.0360 - val_loss: 0.0357\n",
      "Epoch 60/100\n",
      "199/199 [==============================] - 0s 935us/step - loss: 0.0359 - val_loss: 0.0358\n",
      "Epoch 61/100\n",
      "199/199 [==============================] - 0s 927us/step - loss: 0.0359 - val_loss: 0.0358\n",
      "Epoch 62/100\n",
      "199/199 [==============================] - 0s 933us/step - loss: 0.0359 - val_loss: 0.0357\n",
      "Epoch 63/100\n",
      "199/199 [==============================] - 0s 934us/step - loss: 0.0359 - val_loss: 0.0357\n",
      "Epoch 64/100\n",
      "199/199 [==============================] - 0s 936us/step - loss: 0.0359 - val_loss: 0.0357\n",
      "Epoch 65/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0359 - val_loss: 0.0359\n",
      "Epoch 66/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0359 - val_loss: 0.0358\n",
      "Epoch 67/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0359 - val_loss: 0.0357\n",
      "Epoch 68/100\n",
      "199/199 [==============================] - 0s 981us/step - loss: 0.0358 - val_loss: 0.0358\n",
      "Epoch 69/100\n",
      "199/199 [==============================] - 0s 957us/step - loss: 0.0358 - val_loss: 0.0357\n",
      "Epoch 70/100\n",
      "199/199 [==============================] - 0s 910us/step - loss: 0.0358 - val_loss: 0.0357\n",
      "Epoch 71/100\n",
      "199/199 [==============================] - 0s 950us/step - loss: 0.0358 - val_loss: 0.0357\n",
      "Epoch 72/100\n",
      "199/199 [==============================] - 0s 918us/step - loss: 0.0358 - val_loss: 0.0356\n",
      "Epoch 73/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0358 - val_loss: 0.0356\n",
      "Epoch 74/100\n",
      "199/199 [==============================] - 0s 952us/step - loss: 0.0359 - val_loss: 0.0356\n",
      "Epoch 75/100\n",
      "199/199 [==============================] - 0s 938us/step - loss: 0.0358 - val_loss: 0.0356\n",
      "Epoch 76/100\n",
      "199/199 [==============================] - 0s 951us/step - loss: 0.0358 - val_loss: 0.0356\n",
      "Epoch 77/100\n",
      "199/199 [==============================] - 0s 943us/step - loss: 0.0358 - val_loss: 0.0357\n",
      "Epoch 78/100\n",
      "199/199 [==============================] - 0s 930us/step - loss: 0.0358 - val_loss: 0.0356\n",
      "Epoch 79/100\n",
      "199/199 [==============================] - 0s 933us/step - loss: 0.0357 - val_loss: 0.0355\n",
      "Epoch 80/100\n",
      "199/199 [==============================] - 0s 934us/step - loss: 0.0357 - val_loss: 0.0355\n",
      "Epoch 81/100\n",
      "199/199 [==============================] - 0s 954us/step - loss: 0.0358 - val_loss: 0.0356\n",
      "Epoch 82/100\n",
      "199/199 [==============================] - 0s 957us/step - loss: 0.0357 - val_loss: 0.0356\n",
      "Epoch 83/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0357 - val_loss: 0.0355\n",
      "Epoch 84/100\n",
      "199/199 [==============================] - 0s 944us/step - loss: 0.0357 - val_loss: 0.0361\n",
      "Epoch 85/100\n",
      "199/199 [==============================] - 0s 965us/step - loss: 0.0357 - val_loss: 0.0356\n",
      "Epoch 86/100\n",
      "199/199 [==============================] - 0s 986us/step - loss: 0.0357 - val_loss: 0.0355\n",
      "Epoch 87/100\n",
      "199/199 [==============================] - 0s 976us/step - loss: 0.0357 - val_loss: 0.0355\n",
      "Epoch 88/100\n",
      "199/199 [==============================] - 0s 954us/step - loss: 0.0357 - val_loss: 0.0355\n",
      "Epoch 89/100\n",
      "199/199 [==============================] - 0s 935us/step - loss: 0.0357 - val_loss: 0.0356\n",
      "Epoch 90/100\n",
      "199/199 [==============================] - 0s 950us/step - loss: 0.0357 - val_loss: 0.0355\n",
      "Epoch 91/100\n",
      "199/199 [==============================] - 0s 942us/step - loss: 0.0358 - val_loss: 0.0355\n",
      "Epoch 92/100\n",
      "199/199 [==============================] - 0s 938us/step - loss: 0.0356 - val_loss: 0.0355\n",
      "Epoch 93/100\n",
      "199/199 [==============================] - 0s 963us/step - loss: 0.0356 - val_loss: 0.0354\n",
      "Epoch 94/100\n",
      "199/199 [==============================] - 0s 947us/step - loss: 0.0356 - val_loss: 0.0355\n",
      "Epoch 95/100\n",
      "199/199 [==============================] - 0s 921us/step - loss: 0.0356 - val_loss: 0.0355\n",
      "Epoch 96/100\n",
      "199/199 [==============================] - 0s 940us/step - loss: 0.0356 - val_loss: 0.0354\n",
      "Epoch 97/100\n",
      "199/199 [==============================] - 0s 943us/step - loss: 0.0356 - val_loss: 0.0354\n",
      "Epoch 98/100\n",
      "199/199 [==============================] - 0s 962us/step - loss: 0.0356 - val_loss: 0.0355\n",
      "Epoch 99/100\n",
      "199/199 [==============================] - 0s 964us/step - loss: 0.0357 - val_loss: 0.0355\n",
      "Epoch 100/100\n",
      "199/199 [==============================] - 0s 938us/step - loss: 0.0356 - val_loss: 0.0354\n",
      "This round is 20\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_63917/2731616321.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  para_dfm = para_dfm.append({\"reg_param\": reg_param, \"number_units_layers\": numbers_units_layers, \"number_units_bottleneck\": numbers_units_bottleneck, \"dropout_rate\": dropout_rate, \"number_layers\": numbers_layers, \"whether_dropout\": whether_dropout, \"whether_regularizer\": whether_regularizer, \"overfit_metric\": overfit_metric, \"val2_avg_recon_error\": val2_avg_recon_error,'val1_loss':val1_loss}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0699 - val_loss: 0.0373\n",
      "Epoch 2/100\n",
      "199/199 [==============================] - 0s 896us/step - loss: 0.0300 - val_loss: 0.0243\n",
      "Epoch 3/100\n",
      "199/199 [==============================] - 0s 943us/step - loss: 0.0210 - val_loss: 0.0180\n",
      "Epoch 4/100\n",
      "199/199 [==============================] - 0s 931us/step - loss: 0.0160 - val_loss: 0.0140\n",
      "Epoch 5/100\n",
      "199/199 [==============================] - 0s 933us/step - loss: 0.0127 - val_loss: 0.0116\n",
      "Epoch 6/100\n",
      "199/199 [==============================] - 0s 924us/step - loss: 0.0109 - val_loss: 0.0101\n",
      "Epoch 7/100\n",
      "199/199 [==============================] - 0s 923us/step - loss: 0.0092 - val_loss: 0.0086\n",
      "Epoch 8/100\n",
      "199/199 [==============================] - 0s 943us/step - loss: 0.0078 - val_loss: 0.0075\n",
      "Epoch 9/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0067 - val_loss: 0.0065\n",
      "Epoch 10/100\n",
      "199/199 [==============================] - 0s 956us/step - loss: 0.0058 - val_loss: 0.0057\n",
      "Epoch 11/100\n",
      "199/199 [==============================] - 0s 929us/step - loss: 0.0052 - val_loss: 0.0052\n",
      "Epoch 12/100\n",
      "199/199 [==============================] - 0s 934us/step - loss: 0.0048 - val_loss: 0.0048\n",
      "Epoch 13/100\n",
      "199/199 [==============================] - 0s 933us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 14/100\n",
      "199/199 [==============================] - 0s 945us/step - loss: 0.0041 - val_loss: 0.0042\n",
      "Epoch 15/100\n",
      "199/199 [==============================] - 0s 954us/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 16/100\n",
      "199/199 [==============================] - 0s 948us/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 17/100\n",
      "199/199 [==============================] - 0s 935us/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 18/100\n",
      "199/199 [==============================] - 0s 954us/step - loss: 0.0030 - val_loss: 0.0032\n",
      "Epoch 19/100\n",
      "199/199 [==============================] - 0s 936us/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 20/100\n",
      "199/199 [==============================] - 0s 948us/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 21/100\n",
      "199/199 [==============================] - 0s 941us/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 22/100\n",
      "199/199 [==============================] - 0s 954us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 23/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 24/100\n",
      "199/199 [==============================] - 0s 963us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 25/100\n",
      "199/199 [==============================] - 0s 947us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 26/100\n",
      "199/199 [==============================] - 0s 950us/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 27/100\n",
      "199/199 [==============================] - 0s 973us/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 28/100\n",
      "199/199 [==============================] - 0s 954us/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 29/100\n",
      "199/199 [==============================] - 0s 942us/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 30/100\n",
      "199/199 [==============================] - 0s 950us/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 31/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 32/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 33/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 34/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 9.9530e-04 - val_loss: 0.0014\n",
      "Epoch 35/100\n",
      "199/199 [==============================] - 0s 972us/step - loss: 9.5024e-04 - val_loss: 0.0013\n",
      "Epoch 36/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 9.2213e-04 - val_loss: 0.0013\n",
      "Epoch 37/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 8.9119e-04 - val_loss: 0.0013\n",
      "Epoch 38/100\n",
      "199/199 [==============================] - 0s 970us/step - loss: 8.6771e-04 - val_loss: 0.0012\n",
      "Epoch 39/100\n",
      "199/199 [==============================] - 0s 967us/step - loss: 8.4018e-04 - val_loss: 0.0012\n",
      "Epoch 40/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 8.1063e-04 - val_loss: 0.0012\n",
      "Epoch 41/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 7.8480e-04 - val_loss: 0.0012\n",
      "Epoch 42/100\n",
      "199/199 [==============================] - 0s 950us/step - loss: 7.6504e-04 - val_loss: 0.0012\n",
      "Epoch 43/100\n",
      "199/199 [==============================] - 0s 950us/step - loss: 7.4178e-04 - val_loss: 0.0011\n",
      "Epoch 44/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 7.1204e-04 - val_loss: 0.0011\n",
      "Epoch 45/100\n",
      "199/199 [==============================] - 0s 977us/step - loss: 6.7293e-04 - val_loss: 0.0011\n",
      "Epoch 46/100\n",
      "199/199 [==============================] - 0s 967us/step - loss: 6.2471e-04 - val_loss: 9.5763e-04\n",
      "Epoch 47/100\n",
      "199/199 [==============================] - 0s 968us/step - loss: 5.8229e-04 - val_loss: 9.3758e-04\n",
      "Epoch 48/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 5.5633e-04 - val_loss: 9.2038e-04\n",
      "Epoch 49/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 5.4654e-04 - val_loss: 9.0787e-04\n",
      "Epoch 50/100\n",
      "199/199 [==============================] - 0s 965us/step - loss: 5.2879e-04 - val_loss: 9.1672e-04\n",
      "Epoch 51/100\n",
      "199/199 [==============================] - 0s 975us/step - loss: 5.0119e-04 - val_loss: 9.0391e-04\n",
      "Epoch 52/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 4.8843e-04 - val_loss: 8.5025e-04\n",
      "Epoch 53/100\n",
      "199/199 [==============================] - 0s 968us/step - loss: 4.7490e-04 - val_loss: 8.2480e-04\n",
      "Epoch 54/100\n",
      "199/199 [==============================] - 0s 951us/step - loss: 4.6087e-04 - val_loss: 8.4040e-04\n",
      "Epoch 55/100\n",
      "199/199 [==============================] - 0s 947us/step - loss: 4.4193e-04 - val_loss: 8.4178e-04\n",
      "Epoch 56/100\n",
      "199/199 [==============================] - 0s 965us/step - loss: 4.3911e-04 - val_loss: 8.0614e-04\n",
      "Epoch 57/100\n",
      "199/199 [==============================] - 0s 967us/step - loss: 4.2882e-04 - val_loss: 7.9939e-04\n",
      "Epoch 58/100\n",
      "199/199 [==============================] - 0s 953us/step - loss: 4.1695e-04 - val_loss: 7.9969e-04\n",
      "Epoch 59/100\n",
      "199/199 [==============================] - 0s 966us/step - loss: 4.1676e-04 - val_loss: 7.6326e-04\n",
      "Epoch 60/100\n",
      "199/199 [==============================] - 0s 962us/step - loss: 4.0108e-04 - val_loss: 7.9102e-04\n",
      "Epoch 61/100\n",
      "199/199 [==============================] - 0s 961us/step - loss: 3.9839e-04 - val_loss: 7.4041e-04\n",
      "Epoch 62/100\n",
      "199/199 [==============================] - 0s 961us/step - loss: 3.9402e-04 - val_loss: 7.5520e-04\n",
      "Epoch 63/100\n",
      "199/199 [==============================] - 0s 961us/step - loss: 3.9158e-04 - val_loss: 7.7321e-04\n",
      "Epoch 64/100\n",
      "199/199 [==============================] - 0s 960us/step - loss: 3.8238e-04 - val_loss: 7.3286e-04\n",
      "Epoch 65/100\n",
      "199/199 [==============================] - 0s 968us/step - loss: 3.6796e-04 - val_loss: 7.5213e-04\n",
      "Epoch 66/100\n",
      "199/199 [==============================] - 0s 952us/step - loss: 3.5677e-04 - val_loss: 7.4517e-04\n",
      "Epoch 67/100\n",
      "199/199 [==============================] - 0s 965us/step - loss: 3.4930e-04 - val_loss: 7.3294e-04\n",
      "Epoch 68/100\n",
      "199/199 [==============================] - 0s 968us/step - loss: 3.3880e-04 - val_loss: 7.0683e-04\n",
      "Epoch 69/100\n",
      "199/199 [==============================] - 0s 960us/step - loss: 3.3460e-04 - val_loss: 7.0374e-04\n",
      "Epoch 70/100\n",
      "199/199 [==============================] - 0s 961us/step - loss: 3.2458e-04 - val_loss: 6.8036e-04\n",
      "Epoch 71/100\n",
      "199/199 [==============================] - 0s 969us/step - loss: 3.1666e-04 - val_loss: 6.8726e-04\n",
      "Epoch 72/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 3.1422e-04 - val_loss: 6.7975e-04\n",
      "Epoch 73/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 3.1384e-04 - val_loss: 7.0105e-04\n",
      "Epoch 74/100\n",
      "199/199 [==============================] - 0s 970us/step - loss: 3.0801e-04 - val_loss: 7.0062e-04\n",
      "Epoch 75/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 3.0664e-04 - val_loss: 6.7449e-04\n",
      "Epoch 76/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 2.9859e-04 - val_loss: 6.6884e-04\n",
      "Epoch 77/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 2.9297e-04 - val_loss: 6.6115e-04\n",
      "Epoch 78/100\n",
      "199/199 [==============================] - 0s 967us/step - loss: 2.8745e-04 - val_loss: 6.5642e-04\n",
      "Epoch 79/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 3.0058e-04 - val_loss: 6.5495e-04\n",
      "Epoch 80/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 3.0079e-04 - val_loss: 6.5450e-04\n",
      "Epoch 81/100\n",
      "199/199 [==============================] - 0s 961us/step - loss: 2.8054e-04 - val_loss: 6.9135e-04\n",
      "Epoch 82/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 2.7884e-04 - val_loss: 6.4445e-04\n",
      "Epoch 83/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 2.7465e-04 - val_loss: 6.2991e-04\n",
      "Epoch 84/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 2.7014e-04 - val_loss: 6.4011e-04\n",
      "Epoch 85/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 2.6960e-04 - val_loss: 6.5187e-04\n",
      "Epoch 86/100\n",
      "199/199 [==============================] - 0s 978us/step - loss: 2.6902e-04 - val_loss: 6.4111e-04\n",
      "Epoch 87/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 2.6500e-04 - val_loss: 6.4859e-04\n",
      "Epoch 88/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 2.7203e-04 - val_loss: 6.4057e-04\n",
      "Epoch 89/100\n",
      "199/199 [==============================] - 0s 975us/step - loss: 2.6745e-04 - val_loss: 6.3452e-04\n",
      "Epoch 90/100\n",
      "199/199 [==============================] - 0s 971us/step - loss: 2.5767e-04 - val_loss: 6.2085e-04\n",
      "Epoch 91/100\n",
      "199/199 [==============================] - 0s 963us/step - loss: 2.5498e-04 - val_loss: 6.4868e-04\n",
      "Epoch 92/100\n",
      "199/199 [==============================] - 0s 977us/step - loss: 2.5418e-04 - val_loss: 6.8624e-04\n",
      "Epoch 93/100\n",
      "199/199 [==============================] - 0s 964us/step - loss: 2.4864e-04 - val_loss: 6.1653e-04\n",
      "Epoch 94/100\n",
      "199/199 [==============================] - 0s 963us/step - loss: 2.4570e-04 - val_loss: 6.1198e-04\n",
      "Epoch 95/100\n",
      "199/199 [==============================] - 0s 973us/step - loss: 2.4445e-04 - val_loss: 6.2902e-04\n",
      "Epoch 96/100\n",
      "199/199 [==============================] - 0s 985us/step - loss: 2.4799e-04 - val_loss: 6.1011e-04\n",
      "Epoch 97/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 2.4190e-04 - val_loss: 6.8089e-04\n",
      "Epoch 98/100\n",
      "199/199 [==============================] - 0s 963us/step - loss: 2.4667e-04 - val_loss: 6.5833e-04\n",
      "Epoch 99/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 2.4726e-04 - val_loss: 6.5733e-04\n",
      "Epoch 100/100\n",
      "199/199 [==============================] - 0s 970us/step - loss: 2.9672e-04 - val_loss: 6.4177e-04\n",
      "This round is 21\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_63917/2731616321.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  para_dfm = para_dfm.append({\"reg_param\": reg_param, \"number_units_layers\": numbers_units_layers, \"number_units_bottleneck\": numbers_units_bottleneck, \"dropout_rate\": dropout_rate, \"number_layers\": numbers_layers, \"whether_dropout\": whether_dropout, \"whether_regularizer\": whether_regularizer, \"overfit_metric\": overfit_metric, \"val2_avg_recon_error\": val2_avg_recon_error,'val1_loss':val1_loss}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0723 - val_loss: 0.0396\n",
      "Epoch 2/100\n",
      "199/199 [==============================] - 0s 911us/step - loss: 0.0341 - val_loss: 0.0292\n",
      "Epoch 3/100\n",
      "199/199 [==============================] - 0s 890us/step - loss: 0.0242 - val_loss: 0.0202\n",
      "Epoch 4/100\n",
      "199/199 [==============================] - 0s 914us/step - loss: 0.0184 - val_loss: 0.0166\n",
      "Epoch 5/100\n",
      "199/199 [==============================] - 0s 900us/step - loss: 0.0153 - val_loss: 0.0138\n",
      "Epoch 6/100\n",
      "199/199 [==============================] - 0s 966us/step - loss: 0.0125 - val_loss: 0.0117\n",
      "Epoch 7/100\n",
      "199/199 [==============================] - 0s 904us/step - loss: 0.0111 - val_loss: 0.0107\n",
      "Epoch 8/100\n",
      "199/199 [==============================] - 0s 916us/step - loss: 0.0101 - val_loss: 0.0098\n",
      "Epoch 9/100\n",
      "199/199 [==============================] - 0s 920us/step - loss: 0.0093 - val_loss: 0.0092\n",
      "Epoch 10/100\n",
      "199/199 [==============================] - 0s 929us/step - loss: 0.0087 - val_loss: 0.0085\n",
      "Epoch 11/100\n",
      "199/199 [==============================] - 0s 921us/step - loss: 0.0078 - val_loss: 0.0076\n",
      "Epoch 12/100\n",
      "199/199 [==============================] - 0s 920us/step - loss: 0.0070 - val_loss: 0.0069\n",
      "Epoch 13/100\n",
      "199/199 [==============================] - 0s 931us/step - loss: 0.0065 - val_loss: 0.0065\n",
      "Epoch 14/100\n",
      "199/199 [==============================] - 0s 920us/step - loss: 0.0060 - val_loss: 0.0061\n",
      "Epoch 15/100\n",
      "199/199 [==============================] - 0s 927us/step - loss: 0.0056 - val_loss: 0.0057\n",
      "Epoch 16/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0051 - val_loss: 0.0052\n",
      "Epoch 17/100\n",
      "199/199 [==============================] - 0s 957us/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 18/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0043 - val_loss: 0.0045\n",
      "Epoch 19/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0040 - val_loss: 0.0042\n",
      "Epoch 20/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0038 - val_loss: 0.0040\n",
      "Epoch 21/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 22/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0033 - val_loss: 0.0037\n",
      "Epoch 23/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0032 - val_loss: 0.0034\n",
      "Epoch 24/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0030 - val_loss: 0.0033\n",
      "Epoch 25/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 26/100\n",
      "199/199 [==============================] - 0s 971us/step - loss: 0.0027 - val_loss: 0.0030\n",
      "Epoch 27/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 28/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 29/100\n",
      "199/199 [==============================] - 0s 977us/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 30/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 31/100\n",
      "199/199 [==============================] - 0s 976us/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 32/100\n",
      "199/199 [==============================] - 0s 944us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 33/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 34/100\n",
      "199/199 [==============================] - 0s 987us/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 35/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 36/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 37/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 38/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0016 - val_loss: 0.0020\n",
      "Epoch 39/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 40/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 41/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 42/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 43/100\n",
      "199/199 [==============================] - 0s 951us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 44/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 45/100\n",
      "199/199 [==============================] - 0s 961us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 46/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 47/100\n",
      "199/199 [==============================] - 0s 912us/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 48/100\n",
      "199/199 [==============================] - 0s 977us/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 49/100\n",
      "199/199 [==============================] - 0s 876us/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 50/100\n",
      "199/199 [==============================] - 0s 929us/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 51/100\n",
      "199/199 [==============================] - 0s 896us/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 52/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0010 - val_loss: 0.0015\n",
      "Epoch 53/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0010 - val_loss: 0.0015\n",
      "Epoch 54/100\n",
      "199/199 [==============================] - 0s 982us/step - loss: 9.9641e-04 - val_loss: 0.0015\n",
      "Epoch 55/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 9.8029e-04 - val_loss: 0.0014\n",
      "Epoch 56/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 9.5297e-04 - val_loss: 0.0014\n",
      "Epoch 57/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 9.3077e-04 - val_loss: 0.0014\n",
      "Epoch 58/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 9.0306e-04 - val_loss: 0.0014\n",
      "Epoch 59/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 8.8699e-04 - val_loss: 0.0013\n",
      "Epoch 60/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 8.6784e-04 - val_loss: 0.0013\n",
      "Epoch 61/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 8.4569e-04 - val_loss: 0.0013\n",
      "Epoch 62/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 8.3157e-04 - val_loss: 0.0013\n",
      "Epoch 63/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 8.0720e-04 - val_loss: 0.0013\n",
      "Epoch 64/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 7.8756e-04 - val_loss: 0.0013\n",
      "Epoch 65/100\n",
      "199/199 [==============================] - 0s 966us/step - loss: 7.7249e-04 - val_loss: 0.0012\n",
      "Epoch 66/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 7.4773e-04 - val_loss: 0.0012\n",
      "Epoch 67/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 7.3805e-04 - val_loss: 0.0012\n",
      "Epoch 68/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 7.3476e-04 - val_loss: 0.0012\n",
      "Epoch 69/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 7.3122e-04 - val_loss: 0.0012\n",
      "Epoch 70/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 7.1295e-04 - val_loss: 0.0012\n",
      "Epoch 71/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 7.1759e-04 - val_loss: 0.0012\n",
      "Epoch 72/100\n",
      "199/199 [==============================] - 0s 946us/step - loss: 6.9211e-04 - val_loss: 0.0011\n",
      "Epoch 73/100\n",
      "199/199 [==============================] - 0s 960us/step - loss: 6.8093e-04 - val_loss: 0.0011\n",
      "Epoch 74/100\n",
      "199/199 [==============================] - 0s 953us/step - loss: 6.7822e-04 - val_loss: 0.0011\n",
      "Epoch 75/100\n",
      "199/199 [==============================] - 0s 961us/step - loss: 6.6960e-04 - val_loss: 0.0011\n",
      "Epoch 76/100\n",
      "199/199 [==============================] - 0s 959us/step - loss: 6.6395e-04 - val_loss: 0.0011\n",
      "Epoch 77/100\n",
      "199/199 [==============================] - 0s 958us/step - loss: 6.4810e-04 - val_loss: 0.0011\n",
      "Epoch 78/100\n",
      "199/199 [==============================] - 0s 961us/step - loss: 6.4488e-04 - val_loss: 0.0011\n",
      "Epoch 79/100\n",
      "199/199 [==============================] - 0s 958us/step - loss: 6.5345e-04 - val_loss: 0.0011\n",
      "Epoch 80/100\n",
      "199/199 [==============================] - 0s 943us/step - loss: 6.3258e-04 - val_loss: 0.0010\n",
      "Epoch 81/100\n",
      "199/199 [==============================] - 0s 955us/step - loss: 6.2033e-04 - val_loss: 0.0011\n",
      "Epoch 82/100\n",
      "199/199 [==============================] - 0s 954us/step - loss: 6.1761e-04 - val_loss: 0.0010\n",
      "Epoch 83/100\n",
      "199/199 [==============================] - 0s 963us/step - loss: 6.0956e-04 - val_loss: 0.0011\n",
      "Epoch 84/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 5.9139e-04 - val_loss: 9.9530e-04\n",
      "Epoch 85/100\n",
      "199/199 [==============================] - 0s 947us/step - loss: 5.9697e-04 - val_loss: 0.0010\n",
      "Epoch 86/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 5.9040e-04 - val_loss: 0.0011\n",
      "Epoch 87/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 5.8650e-04 - val_loss: 0.0010\n",
      "Epoch 88/100\n",
      "199/199 [==============================] - 0s 981us/step - loss: 5.7137e-04 - val_loss: 9.9106e-04\n",
      "Epoch 89/100\n",
      "199/199 [==============================] - 0s 959us/step - loss: 5.7186e-04 - val_loss: 9.6608e-04\n",
      "Epoch 90/100\n",
      "199/199 [==============================] - 0s 967us/step - loss: 5.6515e-04 - val_loss: 9.5962e-04\n",
      "Epoch 91/100\n",
      "199/199 [==============================] - 0s 969us/step - loss: 5.6592e-04 - val_loss: 9.5572e-04\n",
      "Epoch 92/100\n",
      "199/199 [==============================] - 0s 977us/step - loss: 5.5454e-04 - val_loss: 9.7297e-04\n",
      "Epoch 93/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 5.5094e-04 - val_loss: 9.8676e-04\n",
      "Epoch 94/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 5.4292e-04 - val_loss: 9.2052e-04\n",
      "Epoch 95/100\n",
      "199/199 [==============================] - 0s 979us/step - loss: 5.4498e-04 - val_loss: 9.6061e-04\n",
      "Epoch 96/100\n",
      "199/199 [==============================] - 0s 971us/step - loss: 5.3209e-04 - val_loss: 9.5815e-04\n",
      "Epoch 97/100\n",
      "199/199 [==============================] - 0s 952us/step - loss: 5.4000e-04 - val_loss: 9.2419e-04\n",
      "Epoch 98/100\n",
      "199/199 [==============================] - 0s 955us/step - loss: 5.2965e-04 - val_loss: 9.2235e-04\n",
      "Epoch 99/100\n",
      "199/199 [==============================] - 0s 981us/step - loss: 5.3237e-04 - val_loss: 8.6845e-04\n",
      "Epoch 100/100\n",
      "199/199 [==============================] - 0s 948us/step - loss: 4.7133e-04 - val_loss: 7.6499e-04\n",
      "This round is 22\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_63917/2731616321.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  para_dfm = para_dfm.append({\"reg_param\": reg_param, \"number_units_layers\": numbers_units_layers, \"number_units_bottleneck\": numbers_units_bottleneck, \"dropout_rate\": dropout_rate, \"number_layers\": numbers_layers, \"whether_dropout\": whether_dropout, \"whether_regularizer\": whether_regularizer, \"overfit_metric\": overfit_metric, \"val2_avg_recon_error\": val2_avg_recon_error,'val1_loss':val1_loss}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 0s 1ms/step - loss: 1.0965 - val_loss: 0.2797\n",
      "Epoch 2/100\n",
      "199/199 [==============================] - 0s 955us/step - loss: 0.1287 - val_loss: 0.0654\n",
      "Epoch 3/100\n",
      "199/199 [==============================] - 0s 943us/step - loss: 0.0578 - val_loss: 0.0552\n",
      "Epoch 4/100\n",
      "199/199 [==============================] - 0s 969us/step - loss: 0.0551 - val_loss: 0.0550\n",
      "Epoch 5/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0551 - val_loss: 0.0551\n",
      "Epoch 6/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0551 - val_loss: 0.0550\n",
      "Epoch 7/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0550 - val_loss: 0.0550\n",
      "Epoch 8/100\n",
      "199/199 [==============================] - 0s 964us/step - loss: 0.0550 - val_loss: 0.0550\n",
      "Epoch 9/100\n",
      "199/199 [==============================] - 0s 968us/step - loss: 0.0546 - val_loss: 0.0533\n",
      "Epoch 10/100\n",
      "199/199 [==============================] - 0s 964us/step - loss: 0.0476 - val_loss: 0.0422\n",
      "Epoch 11/100\n",
      "199/199 [==============================] - 0s 945us/step - loss: 0.0409 - val_loss: 0.0396\n",
      "Epoch 12/100\n",
      "199/199 [==============================] - 0s 942us/step - loss: 0.0393 - val_loss: 0.0386\n",
      "Epoch 13/100\n",
      "199/199 [==============================] - 0s 955us/step - loss: 0.0384 - val_loss: 0.0379\n",
      "Epoch 14/100\n",
      "199/199 [==============================] - 0s 951us/step - loss: 0.0379 - val_loss: 0.0375\n",
      "Epoch 15/100\n",
      "199/199 [==============================] - 0s 948us/step - loss: 0.0375 - val_loss: 0.0372\n",
      "Epoch 16/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0372 - val_loss: 0.0370\n",
      "Epoch 17/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0370 - val_loss: 0.0368\n",
      "Epoch 18/100\n",
      "199/199 [==============================] - 0s 945us/step - loss: 0.0369 - val_loss: 0.0366\n",
      "Epoch 19/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0368 - val_loss: 0.0366\n",
      "Epoch 20/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0367 - val_loss: 0.0364\n",
      "Epoch 21/100\n",
      "199/199 [==============================] - 0s 969us/step - loss: 0.0366 - val_loss: 0.0364\n",
      "Epoch 22/100\n",
      "199/199 [==============================] - 0s 990us/step - loss: 0.0365 - val_loss: 0.0364\n",
      "Epoch 23/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0365 - val_loss: 0.0362\n",
      "Epoch 24/100\n",
      "199/199 [==============================] - 0s 994us/step - loss: 0.0364 - val_loss: 0.0362\n",
      "Epoch 25/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0364 - val_loss: 0.0362\n",
      "Epoch 26/100\n",
      "199/199 [==============================] - 0s 971us/step - loss: 0.0363 - val_loss: 0.0361\n",
      "Epoch 27/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0363 - val_loss: 0.0362\n",
      "Epoch 28/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0362 - val_loss: 0.0360\n",
      "Epoch 29/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0362 - val_loss: 0.0360\n",
      "Epoch 30/100\n",
      "199/199 [==============================] - 0s 998us/step - loss: 0.0363 - val_loss: 0.0360\n",
      "Epoch 31/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0361 - val_loss: 0.0359\n",
      "Epoch 32/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0361 - val_loss: 0.0364\n",
      "Epoch 33/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0361 - val_loss: 0.0360\n",
      "Epoch 34/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0361 - val_loss: 0.0364\n",
      "Epoch 35/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0360 - val_loss: 0.0359\n",
      "Epoch 36/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0360 - val_loss: 0.0358\n",
      "Epoch 37/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0360 - val_loss: 0.0358\n",
      "Epoch 38/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0360 - val_loss: 0.0365\n",
      "Epoch 39/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0359 - val_loss: 0.0357\n",
      "Epoch 40/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0359 - val_loss: 0.0358\n",
      "Epoch 41/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0359 - val_loss: 0.0357\n",
      "Epoch 42/100\n",
      "199/199 [==============================] - 0s 981us/step - loss: 0.0359 - val_loss: 0.0359\n",
      "Epoch 43/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0359 - val_loss: 0.0357\n",
      "Epoch 44/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0358 - val_loss: 0.0358\n",
      "Epoch 45/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0358 - val_loss: 0.0356\n",
      "Epoch 46/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0358 - val_loss: 0.0357\n",
      "Epoch 47/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0358 - val_loss: 0.0358\n",
      "Epoch 48/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0357 - val_loss: 0.0356\n",
      "Epoch 49/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0358 - val_loss: 0.0356\n",
      "Epoch 50/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0357 - val_loss: 0.0357\n",
      "Epoch 51/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0357 - val_loss: 0.0356\n",
      "Epoch 52/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0357 - val_loss: 0.0356\n",
      "Epoch 53/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0356 - val_loss: 0.0355\n",
      "Epoch 54/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0356 - val_loss: 0.0356\n",
      "Epoch 55/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0356 - val_loss: 0.0355\n",
      "Epoch 56/100\n",
      "199/199 [==============================] - 0s 972us/step - loss: 0.0355 - val_loss: 0.0353\n",
      "Epoch 57/100\n",
      "199/199 [==============================] - 0s 963us/step - loss: 0.0355 - val_loss: 0.0354\n",
      "Epoch 58/100\n",
      "199/199 [==============================] - 0s 964us/step - loss: 0.0356 - val_loss: 0.0358\n",
      "Epoch 59/100\n",
      "199/199 [==============================] - 0s 963us/step - loss: 0.0355 - val_loss: 0.0356\n",
      "Epoch 60/100\n",
      "199/199 [==============================] - 0s 964us/step - loss: 0.0355 - val_loss: 0.0353\n",
      "Epoch 61/100\n",
      "199/199 [==============================] - 0s 949us/step - loss: 0.0355 - val_loss: 0.0353\n",
      "Epoch 62/100\n",
      "199/199 [==============================] - 0s 968us/step - loss: 0.0354 - val_loss: 0.0352\n",
      "Epoch 63/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0354 - val_loss: 0.0352\n",
      "Epoch 64/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0353 - val_loss: 0.0351\n",
      "Epoch 65/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0352 - val_loss: 0.0352\n",
      "Epoch 66/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0351 - val_loss: 0.0349\n",
      "Epoch 67/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0351 - val_loss: 0.0351\n",
      "Epoch 68/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0349 - val_loss: 0.0349\n",
      "Epoch 69/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0348 - val_loss: 0.0347\n",
      "Epoch 70/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0347 - val_loss: 0.0345\n",
      "Epoch 71/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0347 - val_loss: 0.0344\n",
      "Epoch 72/100\n",
      "199/199 [==============================] - 0s 913us/step - loss: 0.0345 - val_loss: 0.0343\n",
      "Epoch 73/100\n",
      "199/199 [==============================] - 0s 977us/step - loss: 0.0344 - val_loss: 0.0342\n",
      "Epoch 74/100\n",
      "199/199 [==============================] - 0s 904us/step - loss: 0.0340 - val_loss: 0.0335\n",
      "Epoch 75/100\n",
      "199/199 [==============================] - 0s 916us/step - loss: 0.0331 - val_loss: 0.0328\n",
      "Epoch 76/100\n",
      "199/199 [==============================] - 0s 933us/step - loss: 0.0324 - val_loss: 0.0318\n",
      "Epoch 77/100\n",
      "199/199 [==============================] - 0s 935us/step - loss: 0.0319 - val_loss: 0.0318\n",
      "Epoch 78/100\n",
      "199/199 [==============================] - 0s 913us/step - loss: 0.0313 - val_loss: 0.0311\n",
      "Epoch 79/100\n",
      "199/199 [==============================] - 0s 934us/step - loss: 0.0309 - val_loss: 0.0307\n",
      "Epoch 80/100\n",
      "199/199 [==============================] - 0s 914us/step - loss: 0.0306 - val_loss: 0.0303\n",
      "Epoch 81/100\n",
      "199/199 [==============================] - 0s 955us/step - loss: 0.0301 - val_loss: 0.0297\n",
      "Epoch 82/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0299 - val_loss: 0.0301\n",
      "Epoch 83/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0297 - val_loss: 0.0292\n",
      "Epoch 84/100\n",
      "199/199 [==============================] - 0s 973us/step - loss: 0.0293 - val_loss: 0.0291\n",
      "Epoch 85/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0292 - val_loss: 0.0292\n",
      "Epoch 86/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0289 - val_loss: 0.0290\n",
      "Epoch 87/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0288 - val_loss: 0.0285\n",
      "Epoch 88/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0287 - val_loss: 0.0285\n",
      "Epoch 89/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0285 - val_loss: 0.0282\n",
      "Epoch 90/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0283 - val_loss: 0.0280\n",
      "Epoch 91/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0281 - val_loss: 0.0280\n",
      "Epoch 92/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0280 - val_loss: 0.0278\n",
      "Epoch 93/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0283 - val_loss: 0.0280\n",
      "Epoch 94/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0279 - val_loss: 0.0281\n",
      "Epoch 95/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0278 - val_loss: 0.0276\n",
      "Epoch 96/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0276 - val_loss: 0.0276\n",
      "Epoch 97/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0276 - val_loss: 0.0274\n",
      "Epoch 98/100\n",
      "199/199 [==============================] - 0s 926us/step - loss: 0.0276 - val_loss: 0.0276\n",
      "Epoch 99/100\n",
      "199/199 [==============================] - 0s 906us/step - loss: 0.0274 - val_loss: 0.0272\n",
      "Epoch 100/100\n",
      "199/199 [==============================] - 0s 975us/step - loss: 0.0275 - val_loss: 0.0271\n",
      "This round is 23\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_63917/2731616321.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  para_dfm = para_dfm.append({\"reg_param\": reg_param, \"number_units_layers\": numbers_units_layers, \"number_units_bottleneck\": numbers_units_bottleneck, \"dropout_rate\": dropout_rate, \"number_layers\": numbers_layers, \"whether_dropout\": whether_dropout, \"whether_regularizer\": whether_regularizer, \"overfit_metric\": overfit_metric, \"val2_avg_recon_error\": val2_avg_recon_error,'val1_loss':val1_loss}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 1s 1ms/step - loss: 1.3052 - val_loss: 0.4881\n",
      "Epoch 2/100\n",
      "199/199 [==============================] - 0s 879us/step - loss: 0.2452 - val_loss: 0.1110\n",
      "Epoch 3/100\n",
      "199/199 [==============================] - 0s 915us/step - loss: 0.0769 - val_loss: 0.0600\n",
      "Epoch 4/100\n",
      "199/199 [==============================] - 0s 875us/step - loss: 0.0568 - val_loss: 0.0553\n",
      "Epoch 5/100\n",
      "199/199 [==============================] - 0s 900us/step - loss: 0.0552 - val_loss: 0.0551\n",
      "Epoch 6/100\n",
      "199/199 [==============================] - 0s 906us/step - loss: 0.0551 - val_loss: 0.0550\n",
      "Epoch 7/100\n",
      "199/199 [==============================] - 0s 902us/step - loss: 0.0550 - val_loss: 0.0550\n",
      "Epoch 8/100\n",
      "199/199 [==============================] - 0s 978us/step - loss: 0.0550 - val_loss: 0.0551\n",
      "Epoch 9/100\n",
      "199/199 [==============================] - 0s 890us/step - loss: 0.0550 - val_loss: 0.0550\n",
      "Epoch 10/100\n",
      "199/199 [==============================] - 0s 891us/step - loss: 0.0549 - val_loss: 0.0546\n",
      "Epoch 11/100\n",
      "199/199 [==============================] - 0s 954us/step - loss: 0.0539 - val_loss: 0.0519\n",
      "Epoch 12/100\n",
      "199/199 [==============================] - 0s 867us/step - loss: 0.0485 - val_loss: 0.0451\n",
      "Epoch 13/100\n",
      "199/199 [==============================] - 0s 919us/step - loss: 0.0437 - val_loss: 0.0422\n",
      "Epoch 14/100\n",
      "199/199 [==============================] - 0s 889us/step - loss: 0.0417 - val_loss: 0.0408\n",
      "Epoch 15/100\n",
      "199/199 [==============================] - 0s 905us/step - loss: 0.0406 - val_loss: 0.0399\n",
      "Epoch 16/100\n",
      "199/199 [==============================] - 0s 871us/step - loss: 0.0399 - val_loss: 0.0394\n",
      "Epoch 17/100\n",
      "199/199 [==============================] - 0s 895us/step - loss: 0.0394 - val_loss: 0.0389\n",
      "Epoch 18/100\n",
      "199/199 [==============================] - 0s 914us/step - loss: 0.0390 - val_loss: 0.0385\n",
      "Epoch 19/100\n",
      "199/199 [==============================] - 0s 890us/step - loss: 0.0386 - val_loss: 0.0382\n",
      "Epoch 20/100\n",
      "199/199 [==============================] - 0s 911us/step - loss: 0.0383 - val_loss: 0.0380\n",
      "Epoch 21/100\n",
      "199/199 [==============================] - 0s 876us/step - loss: 0.0381 - val_loss: 0.0378\n",
      "Epoch 22/100\n",
      "199/199 [==============================] - 0s 882us/step - loss: 0.0378 - val_loss: 0.0375\n",
      "Epoch 23/100\n",
      "199/199 [==============================] - 0s 923us/step - loss: 0.0377 - val_loss: 0.0374\n",
      "Epoch 24/100\n",
      "199/199 [==============================] - 0s 872us/step - loss: 0.0375 - val_loss: 0.0372\n",
      "Epoch 25/100\n",
      "199/199 [==============================] - 0s 863us/step - loss: 0.0373 - val_loss: 0.0370\n",
      "Epoch 26/100\n",
      "199/199 [==============================] - 0s 883us/step - loss: 0.0372 - val_loss: 0.0369\n",
      "Epoch 27/100\n",
      "199/199 [==============================] - 0s 858us/step - loss: 0.0371 - val_loss: 0.0368\n",
      "Epoch 28/100\n",
      "199/199 [==============================] - 0s 867us/step - loss: 0.0370 - val_loss: 0.0369\n",
      "Epoch 29/100\n",
      "199/199 [==============================] - 0s 920us/step - loss: 0.0369 - val_loss: 0.0367\n",
      "Epoch 30/100\n",
      "199/199 [==============================] - 0s 881us/step - loss: 0.0368 - val_loss: 0.0366\n",
      "Epoch 31/100\n",
      "199/199 [==============================] - 0s 937us/step - loss: 0.0368 - val_loss: 0.0365\n",
      "Epoch 32/100\n",
      "199/199 [==============================] - 0s 943us/step - loss: 0.0367 - val_loss: 0.0366\n",
      "Epoch 33/100\n",
      "199/199 [==============================] - 0s 904us/step - loss: 0.0367 - val_loss: 0.0365\n",
      "Epoch 34/100\n",
      "199/199 [==============================] - 0s 927us/step - loss: 0.0366 - val_loss: 0.0365\n",
      "Epoch 35/100\n",
      "199/199 [==============================] - 0s 954us/step - loss: 0.0366 - val_loss: 0.0363\n",
      "Epoch 36/100\n",
      "199/199 [==============================] - 0s 910us/step - loss: 0.0365 - val_loss: 0.0363\n",
      "Epoch 37/100\n",
      "199/199 [==============================] - 0s 941us/step - loss: 0.0365 - val_loss: 0.0363\n",
      "Epoch 38/100\n",
      "199/199 [==============================] - 0s 917us/step - loss: 0.0364 - val_loss: 0.0364\n",
      "Epoch 39/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0364 - val_loss: 0.0362\n",
      "Epoch 40/100\n",
      "199/199 [==============================] - 0s 946us/step - loss: 0.0364 - val_loss: 0.0363\n",
      "Epoch 41/100\n",
      "199/199 [==============================] - 0s 941us/step - loss: 0.0364 - val_loss: 0.0362\n",
      "Epoch 42/100\n",
      "199/199 [==============================] - 0s 929us/step - loss: 0.0363 - val_loss: 0.0361\n",
      "Epoch 43/100\n",
      "199/199 [==============================] - 0s 947us/step - loss: 0.0363 - val_loss: 0.0361\n",
      "Epoch 44/100\n",
      "199/199 [==============================] - 0s 881us/step - loss: 0.0363 - val_loss: 0.0362\n",
      "Epoch 45/100\n",
      "199/199 [==============================] - 0s 868us/step - loss: 0.0363 - val_loss: 0.0361\n",
      "Epoch 46/100\n",
      "199/199 [==============================] - 0s 866us/step - loss: 0.0362 - val_loss: 0.0360\n",
      "Epoch 47/100\n",
      "199/199 [==============================] - 0s 918us/step - loss: 0.0362 - val_loss: 0.0361\n",
      "Epoch 48/100\n",
      "199/199 [==============================] - 0s 866us/step - loss: 0.0362 - val_loss: 0.0360\n",
      "Epoch 49/100\n",
      "199/199 [==============================] - 0s 912us/step - loss: 0.0362 - val_loss: 0.0360\n",
      "Epoch 50/100\n",
      "199/199 [==============================] - 0s 884us/step - loss: 0.0362 - val_loss: 0.0360\n",
      "Epoch 51/100\n",
      "199/199 [==============================] - 0s 928us/step - loss: 0.0362 - val_loss: 0.0359\n",
      "Epoch 52/100\n",
      "199/199 [==============================] - 0s 868us/step - loss: 0.0361 - val_loss: 0.0359\n",
      "Epoch 53/100\n",
      "199/199 [==============================] - 0s 955us/step - loss: 0.0361 - val_loss: 0.0360\n",
      "Epoch 54/100\n",
      "199/199 [==============================] - 0s 903us/step - loss: 0.0361 - val_loss: 0.0359\n",
      "Epoch 55/100\n",
      "199/199 [==============================] - 0s 980us/step - loss: 0.0361 - val_loss: 0.0360\n",
      "Epoch 56/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0361 - val_loss: 0.0359\n",
      "Epoch 57/100\n",
      "199/199 [==============================] - 0s 942us/step - loss: 0.0361 - val_loss: 0.0358\n",
      "Epoch 58/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0361 - val_loss: 0.0360\n",
      "Epoch 59/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0360 - val_loss: 0.0358\n",
      "Epoch 60/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0360 - val_loss: 0.0360\n",
      "Epoch 61/100\n",
      "199/199 [==============================] - 0s 996us/step - loss: 0.0360 - val_loss: 0.0359\n",
      "Epoch 62/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0360 - val_loss: 0.0359\n",
      "Epoch 63/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0360 - val_loss: 0.0358\n",
      "Epoch 64/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0360 - val_loss: 0.0358\n",
      "Epoch 65/100\n",
      "199/199 [==============================] - 0s 954us/step - loss: 0.0360 - val_loss: 0.0358\n",
      "Epoch 66/100\n",
      "199/199 [==============================] - 0s 910us/step - loss: 0.0360 - val_loss: 0.0358\n",
      "Epoch 67/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0360 - val_loss: 0.0361\n",
      "Epoch 68/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0359 - val_loss: 0.0360\n",
      "Epoch 69/100\n",
      "199/199 [==============================] - 0s 918us/step - loss: 0.0359 - val_loss: 0.0358\n",
      "Epoch 70/100\n",
      "199/199 [==============================] - 0s 924us/step - loss: 0.0359 - val_loss: 0.0358\n",
      "Epoch 71/100\n",
      "199/199 [==============================] - 0s 926us/step - loss: 0.0359 - val_loss: 0.0358\n",
      "Epoch 72/100\n",
      "199/199 [==============================] - 0s 962us/step - loss: 0.0359 - val_loss: 0.0358\n",
      "Epoch 73/100\n",
      "199/199 [==============================] - 0s 942us/step - loss: 0.0359 - val_loss: 0.0358\n",
      "Epoch 74/100\n",
      "199/199 [==============================] - 0s 928us/step - loss: 0.0359 - val_loss: 0.0357\n",
      "Epoch 75/100\n",
      "199/199 [==============================] - 0s 917us/step - loss: 0.0359 - val_loss: 0.0358\n",
      "Epoch 76/100\n",
      "199/199 [==============================] - 0s 916us/step - loss: 0.0359 - val_loss: 0.0359\n",
      "Epoch 77/100\n",
      "199/199 [==============================] - 0s 925us/step - loss: 0.0359 - val_loss: 0.0359\n",
      "Epoch 78/100\n",
      "199/199 [==============================] - 0s 915us/step - loss: 0.0358 - val_loss: 0.0357\n",
      "Epoch 79/100\n",
      "199/199 [==============================] - 0s 936us/step - loss: 0.0358 - val_loss: 0.0357\n",
      "Epoch 80/100\n",
      "199/199 [==============================] - 0s 912us/step - loss: 0.0358 - val_loss: 0.0360\n",
      "Epoch 81/100\n",
      "199/199 [==============================] - 0s 925us/step - loss: 0.0358 - val_loss: 0.0357\n",
      "Epoch 82/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0358 - val_loss: 0.0358\n",
      "Epoch 83/100\n",
      "199/199 [==============================] - 0s 939us/step - loss: 0.0358 - val_loss: 0.0356\n",
      "Epoch 84/100\n",
      "199/199 [==============================] - 0s 940us/step - loss: 0.0357 - val_loss: 0.0365\n",
      "Epoch 85/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0358 - val_loss: 0.0354\n",
      "Epoch 86/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0355 - val_loss: 0.0354\n",
      "Epoch 87/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0353 - val_loss: 0.0351\n",
      "Epoch 88/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0350 - val_loss: 0.0346\n",
      "Epoch 89/100\n",
      "199/199 [==============================] - 0s 951us/step - loss: 0.0346 - val_loss: 0.0342\n",
      "Epoch 90/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0342 - val_loss: 0.0336\n",
      "Epoch 91/100\n",
      "199/199 [==============================] - 0s 937us/step - loss: 0.0335 - val_loss: 0.0330\n",
      "Epoch 92/100\n",
      "199/199 [==============================] - 0s 926us/step - loss: 0.0330 - val_loss: 0.0327\n",
      "Epoch 93/100\n",
      "199/199 [==============================] - 0s 970us/step - loss: 0.0327 - val_loss: 0.0323\n",
      "Epoch 94/100\n",
      "199/199 [==============================] - 0s 942us/step - loss: 0.0325 - val_loss: 0.0321\n",
      "Epoch 95/100\n",
      "199/199 [==============================] - 0s 935us/step - loss: 0.0322 - val_loss: 0.0321\n",
      "Epoch 96/100\n",
      "199/199 [==============================] - 0s 937us/step - loss: 0.0321 - val_loss: 0.0318\n",
      "Epoch 97/100\n",
      "199/199 [==============================] - 0s 937us/step - loss: 0.0319 - val_loss: 0.0317\n",
      "Epoch 98/100\n",
      "199/199 [==============================] - 0s 931us/step - loss: 0.0318 - val_loss: 0.0315\n",
      "Epoch 99/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0316 - val_loss: 0.0313\n",
      "Epoch 100/100\n",
      "199/199 [==============================] - 0s 954us/step - loss: 0.0315 - val_loss: 0.0310\n",
      "This round is 24\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_63917/2731616321.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  para_dfm = para_dfm.append({\"reg_param\": reg_param, \"number_units_layers\": numbers_units_layers, \"number_units_bottleneck\": numbers_units_bottleneck, \"dropout_rate\": dropout_rate, \"number_layers\": numbers_layers, \"whether_dropout\": whether_dropout, \"whether_regularizer\": whether_regularizer, \"overfit_metric\": overfit_metric, \"val2_avg_recon_error\": val2_avg_recon_error,'val1_loss':val1_loss}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0699 - val_loss: 0.0373\n",
      "Epoch 2/100\n",
      "199/199 [==============================] - 0s 934us/step - loss: 0.0300 - val_loss: 0.0243\n",
      "Epoch 3/100\n",
      "199/199 [==============================] - 0s 940us/step - loss: 0.0210 - val_loss: 0.0180\n",
      "Epoch 4/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0160 - val_loss: 0.0140\n",
      "Epoch 5/100\n",
      "199/199 [==============================] - 0s 950us/step - loss: 0.0127 - val_loss: 0.0116\n",
      "Epoch 6/100\n",
      "199/199 [==============================] - 0s 943us/step - loss: 0.0109 - val_loss: 0.0101\n",
      "Epoch 7/100\n",
      "199/199 [==============================] - 0s 948us/step - loss: 0.0092 - val_loss: 0.0086\n",
      "Epoch 8/100\n",
      "199/199 [==============================] - 0s 951us/step - loss: 0.0078 - val_loss: 0.0075\n",
      "Epoch 9/100\n",
      "199/199 [==============================] - 0s 962us/step - loss: 0.0067 - val_loss: 0.0065\n",
      "Epoch 10/100\n",
      "199/199 [==============================] - 0s 942us/step - loss: 0.0058 - val_loss: 0.0057\n",
      "Epoch 11/100\n",
      "199/199 [==============================] - 0s 997us/step - loss: 0.0052 - val_loss: 0.0052\n",
      "Epoch 12/100\n",
      "199/199 [==============================] - 0s 997us/step - loss: 0.0048 - val_loss: 0.0048\n",
      "Epoch 13/100\n",
      "199/199 [==============================] - 0s 968us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 14/100\n",
      "199/199 [==============================] - 0s 950us/step - loss: 0.0041 - val_loss: 0.0042\n",
      "Epoch 15/100\n",
      "199/199 [==============================] - 0s 956us/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 16/100\n",
      "199/199 [==============================] - 0s 971us/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 17/100\n",
      "199/199 [==============================] - 0s 944us/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 18/100\n",
      "199/199 [==============================] - 0s 965us/step - loss: 0.0030 - val_loss: 0.0032\n",
      "Epoch 19/100\n",
      "199/199 [==============================] - 0s 966us/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 20/100\n",
      "199/199 [==============================] - 0s 953us/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 21/100\n",
      "199/199 [==============================] - 0s 959us/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 22/100\n",
      "199/199 [==============================] - 0s 952us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 23/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 24/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 25/100\n",
      "199/199 [==============================] - 0s 963us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 26/100\n",
      "199/199 [==============================] - 0s 979us/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 27/100\n",
      "199/199 [==============================] - 0s 959us/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 28/100\n",
      "199/199 [==============================] - 0s 958us/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 29/100\n",
      "199/199 [==============================] - 0s 958us/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 30/100\n",
      "199/199 [==============================] - 0s 976us/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 31/100\n",
      "199/199 [==============================] - 0s 961us/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 32/100\n",
      "199/199 [==============================] - 0s 964us/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 33/100\n",
      "199/199 [==============================] - 0s 958us/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 34/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 9.9530e-04 - val_loss: 0.0014\n",
      "Epoch 35/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 9.5024e-04 - val_loss: 0.0013\n",
      "Epoch 36/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 9.2213e-04 - val_loss: 0.0013\n",
      "Epoch 37/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 8.9119e-04 - val_loss: 0.0013\n",
      "Epoch 38/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 8.6771e-04 - val_loss: 0.0012\n",
      "Epoch 39/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 8.4018e-04 - val_loss: 0.0012\n",
      "Epoch 40/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 8.1063e-04 - val_loss: 0.0012\n",
      "Epoch 41/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 7.8480e-04 - val_loss: 0.0012\n",
      "Epoch 42/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 7.6504e-04 - val_loss: 0.0012\n",
      "Epoch 43/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 7.4178e-04 - val_loss: 0.0011\n",
      "Epoch 44/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 7.1204e-04 - val_loss: 0.0011\n",
      "Epoch 45/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 6.7293e-04 - val_loss: 0.0011\n",
      "Epoch 46/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 6.2471e-04 - val_loss: 9.5763e-04\n",
      "Epoch 47/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 5.8229e-04 - val_loss: 9.3758e-04\n",
      "Epoch 48/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 5.5633e-04 - val_loss: 9.2038e-04\n",
      "Epoch 49/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 5.4654e-04 - val_loss: 9.0787e-04\n",
      "Epoch 50/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 5.2879e-04 - val_loss: 9.1672e-04\n",
      "Epoch 51/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 5.0119e-04 - val_loss: 9.0391e-04\n",
      "Epoch 52/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 4.8843e-04 - val_loss: 8.5025e-04\n",
      "Epoch 53/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 4.7490e-04 - val_loss: 8.2480e-04\n",
      "Epoch 54/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 4.6087e-04 - val_loss: 8.4040e-04\n",
      "Epoch 55/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 4.4193e-04 - val_loss: 8.4178e-04\n",
      "Epoch 56/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 4.3911e-04 - val_loss: 8.0614e-04\n",
      "Epoch 57/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 4.2882e-04 - val_loss: 7.9939e-04\n",
      "Epoch 58/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 4.1695e-04 - val_loss: 7.9969e-04\n",
      "Epoch 59/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 4.1676e-04 - val_loss: 7.6326e-04\n",
      "Epoch 60/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 4.0108e-04 - val_loss: 7.9102e-04\n",
      "Epoch 61/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 3.9839e-04 - val_loss: 7.4041e-04\n",
      "Epoch 62/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 3.9402e-04 - val_loss: 7.5520e-04\n",
      "Epoch 63/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 3.9158e-04 - val_loss: 7.7321e-04\n",
      "Epoch 64/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 3.8238e-04 - val_loss: 7.3286e-04\n",
      "Epoch 65/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 3.6796e-04 - val_loss: 7.5213e-04\n",
      "Epoch 66/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 3.5677e-04 - val_loss: 7.4517e-04\n",
      "Epoch 67/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 3.4930e-04 - val_loss: 7.3294e-04\n",
      "Epoch 68/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 3.3880e-04 - val_loss: 7.0683e-04\n",
      "Epoch 69/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 3.3460e-04 - val_loss: 7.0374e-04\n",
      "Epoch 70/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 3.2458e-04 - val_loss: 6.8036e-04\n",
      "Epoch 71/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 3.1666e-04 - val_loss: 6.8726e-04\n",
      "Epoch 72/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 3.1422e-04 - val_loss: 6.7975e-04\n",
      "Epoch 73/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 3.1384e-04 - val_loss: 7.0105e-04\n",
      "Epoch 74/100\n",
      "199/199 [==============================] - 1s 4ms/step - loss: 3.0801e-04 - val_loss: 7.0062e-04\n",
      "Epoch 75/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 3.0664e-04 - val_loss: 6.7449e-04\n",
      "Epoch 76/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 2.9859e-04 - val_loss: 6.6884e-04\n",
      "Epoch 77/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 2.9297e-04 - val_loss: 6.6115e-04\n",
      "Epoch 78/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 2.8745e-04 - val_loss: 6.5642e-04\n",
      "Epoch 79/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 3.0058e-04 - val_loss: 6.5495e-04\n",
      "Epoch 80/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 3.0079e-04 - val_loss: 6.5450e-04\n",
      "Epoch 81/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 2.8054e-04 - val_loss: 6.9135e-04\n",
      "Epoch 82/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 2.7884e-04 - val_loss: 6.4445e-04\n",
      "Epoch 83/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 2.7465e-04 - val_loss: 6.2991e-04\n",
      "Epoch 84/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 2.7014e-04 - val_loss: 6.4011e-04\n",
      "Epoch 85/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 2.6960e-04 - val_loss: 6.5187e-04\n",
      "Epoch 86/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 2.6902e-04 - val_loss: 6.4111e-04\n",
      "Epoch 87/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 2.6500e-04 - val_loss: 6.4859e-04\n",
      "Epoch 88/100\n",
      "199/199 [==============================] - 0s 978us/step - loss: 2.7203e-04 - val_loss: 6.4057e-04\n",
      "Epoch 89/100\n",
      "199/199 [==============================] - 0s 945us/step - loss: 2.6745e-04 - val_loss: 6.3452e-04\n",
      "Epoch 90/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 2.5767e-04 - val_loss: 6.2085e-04\n",
      "Epoch 91/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 2.5498e-04 - val_loss: 6.4868e-04\n",
      "Epoch 92/100\n",
      "199/199 [==============================] - 0s 990us/step - loss: 2.5418e-04 - val_loss: 6.8624e-04\n",
      "Epoch 93/100\n",
      "199/199 [==============================] - 0s 963us/step - loss: 2.4864e-04 - val_loss: 6.1653e-04\n",
      "Epoch 94/100\n",
      "199/199 [==============================] - 0s 965us/step - loss: 2.4570e-04 - val_loss: 6.1198e-04\n",
      "Epoch 95/100\n",
      "199/199 [==============================] - 0s 978us/step - loss: 2.4445e-04 - val_loss: 6.2902e-04\n",
      "Epoch 96/100\n",
      "199/199 [==============================] - 0s 964us/step - loss: 2.4799e-04 - val_loss: 6.1011e-04\n",
      "Epoch 97/100\n",
      "199/199 [==============================] - 0s 967us/step - loss: 2.4190e-04 - val_loss: 6.8089e-04\n",
      "Epoch 98/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 2.4667e-04 - val_loss: 6.5833e-04\n",
      "Epoch 99/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 2.4726e-04 - val_loss: 6.5733e-04\n",
      "Epoch 100/100\n",
      "199/199 [==============================] - 0s 968us/step - loss: 2.9672e-04 - val_loss: 6.4177e-04\n",
      "This round is 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_63917/2731616321.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  para_dfm = para_dfm.append({\"reg_param\": reg_param, \"number_units_layers\": numbers_units_layers, \"number_units_bottleneck\": numbers_units_bottleneck, \"dropout_rate\": dropout_rate, \"number_layers\": numbers_layers, \"whether_dropout\": whether_dropout, \"whether_regularizer\": whether_regularizer, \"overfit_metric\": overfit_metric, \"val2_avg_recon_error\": val2_avg_recon_error,'val1_loss':val1_loss}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "199/199 [==============================] - 1s 1ms/step - loss: 0.0723 - val_loss: 0.0396\n",
      "Epoch 2/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0341 - val_loss: 0.0292\n",
      "Epoch 3/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0242 - val_loss: 0.0202\n",
      "Epoch 4/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0184 - val_loss: 0.0166\n",
      "Epoch 5/100\n",
      "199/199 [==============================] - 0s 934us/step - loss: 0.0153 - val_loss: 0.0138\n",
      "Epoch 6/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0125 - val_loss: 0.0117\n",
      "Epoch 7/100\n",
      "199/199 [==============================] - 0s 939us/step - loss: 0.0111 - val_loss: 0.0107\n",
      "Epoch 8/100\n",
      "199/199 [==============================] - 0s 943us/step - loss: 0.0101 - val_loss: 0.0098\n",
      "Epoch 9/100\n",
      "199/199 [==============================] - 0s 919us/step - loss: 0.0093 - val_loss: 0.0092\n",
      "Epoch 10/100\n",
      "199/199 [==============================] - 0s 941us/step - loss: 0.0087 - val_loss: 0.0085\n",
      "Epoch 11/100\n",
      "199/199 [==============================] - 0s 929us/step - loss: 0.0078 - val_loss: 0.0076\n",
      "Epoch 12/100\n",
      "199/199 [==============================] - 0s 938us/step - loss: 0.0070 - val_loss: 0.0069\n",
      "Epoch 13/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0065 - val_loss: 0.0065\n",
      "Epoch 14/100\n",
      "199/199 [==============================] - 0s 955us/step - loss: 0.0060 - val_loss: 0.0061\n",
      "Epoch 15/100\n",
      "199/199 [==============================] - 0s 940us/step - loss: 0.0056 - val_loss: 0.0057\n",
      "Epoch 16/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0051 - val_loss: 0.0052\n",
      "Epoch 17/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 18/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0043 - val_loss: 0.0045\n",
      "Epoch 19/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0040 - val_loss: 0.0042\n",
      "Epoch 20/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0038 - val_loss: 0.0040\n",
      "Epoch 21/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 22/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0033 - val_loss: 0.0037\n",
      "Epoch 23/100\n",
      "199/199 [==============================] - 0s 973us/step - loss: 0.0032 - val_loss: 0.0034\n",
      "Epoch 24/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0030 - val_loss: 0.0033\n",
      "Epoch 25/100\n",
      "199/199 [==============================] - 0s 966us/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 26/100\n",
      "199/199 [==============================] - 0s 996us/step - loss: 0.0027 - val_loss: 0.0030\n",
      "Epoch 27/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 28/100\n",
      "199/199 [==============================] - 0s 965us/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 29/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 30/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 31/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 32/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 33/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 34/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 35/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 36/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 37/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 38/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0016 - val_loss: 0.0020\n",
      "Epoch 39/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 40/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 41/100\n",
      "199/199 [==============================] - 0s 985us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 42/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 43/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 44/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 45/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 46/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 47/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 48/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 49/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 50/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 51/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 52/100\n",
      "199/199 [==============================] - 1s 4ms/step - loss: 0.0010 - val_loss: 0.0015\n",
      "Epoch 53/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 0.0015\n",
      "Epoch 54/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 9.9641e-04 - val_loss: 0.0015\n",
      "Epoch 55/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 9.8029e-04 - val_loss: 0.0014\n",
      "Epoch 56/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 9.5297e-04 - val_loss: 0.0014\n",
      "Epoch 57/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 9.3077e-04 - val_loss: 0.0014\n",
      "Epoch 58/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 9.0306e-04 - val_loss: 0.0014\n",
      "Epoch 59/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 8.8699e-04 - val_loss: 0.0013\n",
      "Epoch 60/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 8.6784e-04 - val_loss: 0.0013\n",
      "Epoch 61/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 8.4569e-04 - val_loss: 0.0013\n",
      "Epoch 62/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 8.3157e-04 - val_loss: 0.0013\n",
      "Epoch 63/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 8.0720e-04 - val_loss: 0.0013\n",
      "Epoch 64/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 7.8756e-04 - val_loss: 0.0013\n",
      "Epoch 65/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 7.7249e-04 - val_loss: 0.0012\n",
      "Epoch 66/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 7.4773e-04 - val_loss: 0.0012\n",
      "Epoch 67/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 7.3805e-04 - val_loss: 0.0012\n",
      "Epoch 68/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 7.3476e-04 - val_loss: 0.0012\n",
      "Epoch 69/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 7.3122e-04 - val_loss: 0.0012\n",
      "Epoch 70/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 7.1295e-04 - val_loss: 0.0012\n",
      "Epoch 71/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 7.1759e-04 - val_loss: 0.0012\n",
      "Epoch 72/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 6.9211e-04 - val_loss: 0.0011\n",
      "Epoch 73/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 6.8093e-04 - val_loss: 0.0011\n",
      "Epoch 74/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 6.7822e-04 - val_loss: 0.0011\n",
      "Epoch 75/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 6.6960e-04 - val_loss: 0.0011\n",
      "Epoch 76/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 6.6395e-04 - val_loss: 0.0011\n",
      "Epoch 77/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 6.4810e-04 - val_loss: 0.0011\n",
      "Epoch 78/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 6.4488e-04 - val_loss: 0.0011\n",
      "Epoch 79/100\n",
      "199/199 [==============================] - 0s 988us/step - loss: 6.5345e-04 - val_loss: 0.0011\n",
      "Epoch 80/100\n",
      "199/199 [==============================] - 0s 960us/step - loss: 6.3258e-04 - val_loss: 0.0010\n",
      "Epoch 81/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 6.2033e-04 - val_loss: 0.0011\n",
      "Epoch 82/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 6.1761e-04 - val_loss: 0.0010\n",
      "Epoch 83/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 6.0956e-04 - val_loss: 0.0011\n",
      "Epoch 84/100\n",
      "199/199 [==============================] - 0s 963us/step - loss: 5.9139e-04 - val_loss: 9.9530e-04\n",
      "Epoch 85/100\n",
      "199/199 [==============================] - 0s 946us/step - loss: 5.9697e-04 - val_loss: 0.0010\n",
      "Epoch 86/100\n",
      "199/199 [==============================] - 0s 968us/step - loss: 5.9040e-04 - val_loss: 0.0011\n",
      "Epoch 87/100\n",
      "199/199 [==============================] - 0s 976us/step - loss: 5.8650e-04 - val_loss: 0.0010\n",
      "Epoch 88/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 5.7137e-04 - val_loss: 9.9106e-04\n",
      "Epoch 89/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 5.7186e-04 - val_loss: 9.6608e-04\n",
      "Epoch 90/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 5.6515e-04 - val_loss: 9.5962e-04\n",
      "Epoch 91/100\n",
      "199/199 [==============================] - 0s 978us/step - loss: 5.6592e-04 - val_loss: 9.5572e-04\n",
      "Epoch 92/100\n",
      "199/199 [==============================] - 0s 993us/step - loss: 5.5454e-04 - val_loss: 9.7297e-04\n",
      "Epoch 93/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 5.5094e-04 - val_loss: 9.8676e-04\n",
      "Epoch 94/100\n",
      "199/199 [==============================] - 0s 955us/step - loss: 5.4292e-04 - val_loss: 9.2052e-04\n",
      "Epoch 95/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 5.4498e-04 - val_loss: 9.6061e-04\n",
      "Epoch 96/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 5.3209e-04 - val_loss: 9.5815e-04\n",
      "Epoch 97/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 5.4000e-04 - val_loss: 9.2419e-04\n",
      "Epoch 98/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 5.2965e-04 - val_loss: 9.2235e-04\n",
      "Epoch 99/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 5.3237e-04 - val_loss: 8.6845e-04\n",
      "Epoch 100/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 4.7133e-04 - val_loss: 7.6499e-04\n",
      "This round is 26\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_63917/2731616321.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  para_dfm = para_dfm.append({\"reg_param\": reg_param, \"number_units_layers\": numbers_units_layers, \"number_units_bottleneck\": numbers_units_bottleneck, \"dropout_rate\": dropout_rate, \"number_layers\": numbers_layers, \"whether_dropout\": whether_dropout, \"whether_regularizer\": whether_regularizer, \"overfit_metric\": overfit_metric, \"val2_avg_recon_error\": val2_avg_recon_error,'val1_loss':val1_loss}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 1s 1ms/step - loss: 1.5582 - val_loss: 0.5798\n",
      "Epoch 2/100\n",
      "199/199 [==============================] - 0s 958us/step - loss: 0.2855 - val_loss: 0.1228\n",
      "Epoch 3/100\n",
      "199/199 [==============================] - 0s 972us/step - loss: 0.0815 - val_loss: 0.0610\n",
      "Epoch 4/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0572 - val_loss: 0.0554\n",
      "Epoch 5/100\n",
      "199/199 [==============================] - 0s 962us/step - loss: 0.0552 - val_loss: 0.0551\n",
      "Epoch 6/100\n",
      "199/199 [==============================] - 0s 966us/step - loss: 0.0551 - val_loss: 0.0550\n",
      "Epoch 7/100\n",
      "199/199 [==============================] - 0s 964us/step - loss: 0.0550 - val_loss: 0.0550\n",
      "Epoch 8/100\n",
      "199/199 [==============================] - 0s 947us/step - loss: 0.0550 - val_loss: 0.0551\n",
      "Epoch 9/100\n",
      "199/199 [==============================] - 0s 930us/step - loss: 0.0550 - val_loss: 0.0550\n",
      "Epoch 10/100\n",
      "199/199 [==============================] - 0s 971us/step - loss: 0.0550 - val_loss: 0.0549\n",
      "Epoch 11/100\n",
      "199/199 [==============================] - 0s 964us/step - loss: 0.0549 - val_loss: 0.0546\n",
      "Epoch 12/100\n",
      "199/199 [==============================] - 0s 974us/step - loss: 0.0540 - val_loss: 0.0526\n",
      "Epoch 13/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0496 - val_loss: 0.0462\n",
      "Epoch 14/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0444 - val_loss: 0.0427\n",
      "Epoch 15/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0421 - val_loss: 0.0411\n",
      "Epoch 16/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0409 - val_loss: 0.0402\n",
      "Epoch 17/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0401 - val_loss: 0.0395\n",
      "Epoch 18/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0395 - val_loss: 0.0390\n",
      "Epoch 19/100\n",
      "199/199 [==============================] - 0s 977us/step - loss: 0.0391 - val_loss: 0.0386\n",
      "Epoch 20/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0387 - val_loss: 0.0383\n",
      "Epoch 21/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0384 - val_loss: 0.0380\n",
      "Epoch 22/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0381 - val_loss: 0.0378\n",
      "Epoch 23/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0379 - val_loss: 0.0376\n",
      "Epoch 24/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0377 - val_loss: 0.0374\n",
      "Epoch 25/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0375 - val_loss: 0.0372\n",
      "Epoch 26/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0373 - val_loss: 0.0371\n",
      "Epoch 27/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0372 - val_loss: 0.0369\n",
      "Epoch 28/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0371 - val_loss: 0.0369\n",
      "Epoch 29/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0370 - val_loss: 0.0369\n",
      "Epoch 30/100\n",
      "199/199 [==============================] - 0s 974us/step - loss: 0.0369 - val_loss: 0.0367\n",
      "Epoch 31/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0368 - val_loss: 0.0366\n",
      "Epoch 32/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0368 - val_loss: 0.0366\n",
      "Epoch 33/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0367 - val_loss: 0.0365\n",
      "Epoch 34/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0366 - val_loss: 0.0365\n",
      "Epoch 35/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0366 - val_loss: 0.0364\n",
      "Epoch 36/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0365 - val_loss: 0.0363\n",
      "Epoch 37/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0365 - val_loss: 0.0364\n",
      "Epoch 38/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0365 - val_loss: 0.0364\n",
      "Epoch 39/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0364 - val_loss: 0.0362\n",
      "Epoch 40/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0364 - val_loss: 0.0364\n",
      "Epoch 41/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0364 - val_loss: 0.0362\n",
      "Epoch 42/100\n",
      "199/199 [==============================] - 0s 997us/step - loss: 0.0363 - val_loss: 0.0362\n",
      "Epoch 43/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0363 - val_loss: 0.0361\n",
      "Epoch 44/100\n",
      "199/199 [==============================] - 0s 981us/step - loss: 0.0363 - val_loss: 0.0361\n",
      "Epoch 45/100\n",
      "199/199 [==============================] - 0s 985us/step - loss: 0.0363 - val_loss: 0.0362\n",
      "Epoch 46/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0362 - val_loss: 0.0361\n",
      "Epoch 47/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0362 - val_loss: 0.0361\n",
      "Epoch 48/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0362 - val_loss: 0.0360\n",
      "Epoch 49/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0362 - val_loss: 0.0360\n",
      "Epoch 50/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0362 - val_loss: 0.0361\n",
      "Epoch 51/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0362 - val_loss: 0.0359\n",
      "Epoch 52/100\n",
      "199/199 [==============================] - 0s 931us/step - loss: 0.0361 - val_loss: 0.0359\n",
      "Epoch 53/100\n",
      "199/199 [==============================] - 0s 928us/step - loss: 0.0361 - val_loss: 0.0359\n",
      "Epoch 54/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0361 - val_loss: 0.0360\n",
      "Epoch 55/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0361 - val_loss: 0.0361\n",
      "Epoch 56/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0361 - val_loss: 0.0359\n",
      "Epoch 57/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0361 - val_loss: 0.0360\n",
      "Epoch 58/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0360 - val_loss: 0.0360\n",
      "Epoch 59/100\n",
      "199/199 [==============================] - 0s 958us/step - loss: 0.0361 - val_loss: 0.0358\n",
      "Epoch 60/100\n",
      "199/199 [==============================] - 0s 932us/step - loss: 0.0360 - val_loss: 0.0358\n",
      "Epoch 61/100\n",
      "199/199 [==============================] - 0s 933us/step - loss: 0.0360 - val_loss: 0.0359\n",
      "Epoch 62/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0360 - val_loss: 0.0358\n",
      "Epoch 63/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0360 - val_loss: 0.0358\n",
      "Epoch 64/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0360 - val_loss: 0.0358\n",
      "Epoch 65/100\n",
      "199/199 [==============================] - 0s 952us/step - loss: 0.0360 - val_loss: 0.0358\n",
      "Epoch 66/100\n",
      "199/199 [==============================] - 0s 920us/step - loss: 0.0360 - val_loss: 0.0359\n",
      "Epoch 67/100\n",
      "199/199 [==============================] - 0s 982us/step - loss: 0.0360 - val_loss: 0.0358\n",
      "Epoch 68/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0359 - val_loss: 0.0359\n",
      "Epoch 69/100\n",
      "199/199 [==============================] - 0s 938us/step - loss: 0.0360 - val_loss: 0.0358\n",
      "Epoch 70/100\n",
      "199/199 [==============================] - 0s 920us/step - loss: 0.0360 - val_loss: 0.0359\n",
      "Epoch 71/100\n",
      "199/199 [==============================] - 0s 939us/step - loss: 0.0359 - val_loss: 0.0358\n",
      "Epoch 72/100\n",
      "199/199 [==============================] - 0s 971us/step - loss: 0.0359 - val_loss: 0.0358\n",
      "Epoch 73/100\n",
      "199/199 [==============================] - 0s 941us/step - loss: 0.0359 - val_loss: 0.0359\n",
      "Epoch 74/100\n",
      "199/199 [==============================] - 0s 923us/step - loss: 0.0359 - val_loss: 0.0358\n",
      "Epoch 75/100\n",
      "199/199 [==============================] - 0s 966us/step - loss: 0.0359 - val_loss: 0.0359\n",
      "This round is 27\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_63917/2731616321.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  para_dfm = para_dfm.append({\"reg_param\": reg_param, \"number_units_layers\": numbers_units_layers, \"number_units_bottleneck\": numbers_units_bottleneck, \"dropout_rate\": dropout_rate, \"number_layers\": numbers_layers, \"whether_dropout\": whether_dropout, \"whether_regularizer\": whether_regularizer, \"overfit_metric\": overfit_metric, \"val2_avg_recon_error\": val2_avg_recon_error,'val1_loss':val1_loss}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0699 - val_loss: 0.0373\n",
      "Epoch 2/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0300 - val_loss: 0.0243\n",
      "Epoch 3/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0210 - val_loss: 0.0180\n",
      "Epoch 4/100\n",
      "199/199 [==============================] - 0s 973us/step - loss: 0.0160 - val_loss: 0.0140\n",
      "Epoch 5/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0127 - val_loss: 0.0116\n",
      "Epoch 6/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0109 - val_loss: 0.0101\n",
      "Epoch 7/100\n",
      "199/199 [==============================] - 0s 976us/step - loss: 0.0092 - val_loss: 0.0086\n",
      "Epoch 8/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0078 - val_loss: 0.0075\n",
      "Epoch 9/100\n",
      "199/199 [==============================] - 0s 992us/step - loss: 0.0067 - val_loss: 0.0065\n",
      "Epoch 10/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0057\n",
      "Epoch 11/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0052 - val_loss: 0.0052\n",
      "Epoch 12/100\n",
      "199/199 [==============================] - 0s 984us/step - loss: 0.0048 - val_loss: 0.0048\n",
      "Epoch 13/100\n",
      "199/199 [==============================] - 0s 975us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 14/100\n",
      "199/199 [==============================] - 0s 941us/step - loss: 0.0041 - val_loss: 0.0042\n",
      "Epoch 15/100\n",
      "199/199 [==============================] - 0s 959us/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 16/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 17/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 18/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0030 - val_loss: 0.0032\n",
      "Epoch 19/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 20/100\n",
      "199/199 [==============================] - 1s 3ms/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 21/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 22/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 23/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 24/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 25/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 26/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 27/100\n",
      "199/199 [==============================] - 0s 978us/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 28/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 29/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 30/100\n",
      "199/199 [==============================] - 0s 960us/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 31/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 32/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 33/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 34/100\n",
      "199/199 [==============================] - 0s 984us/step - loss: 9.9530e-04 - val_loss: 0.0014\n",
      "Epoch 35/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 9.5024e-04 - val_loss: 0.0013\n",
      "Epoch 36/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 9.2213e-04 - val_loss: 0.0013\n",
      "Epoch 37/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 8.9119e-04 - val_loss: 0.0013\n",
      "Epoch 38/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 8.6771e-04 - val_loss: 0.0012\n",
      "Epoch 39/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 8.4018e-04 - val_loss: 0.0012\n",
      "Epoch 40/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 8.1063e-04 - val_loss: 0.0012\n",
      "Epoch 41/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 7.8480e-04 - val_loss: 0.0012\n",
      "Epoch 42/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 7.6504e-04 - val_loss: 0.0012\n",
      "Epoch 43/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 7.4178e-04 - val_loss: 0.0011\n",
      "Epoch 44/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 7.1204e-04 - val_loss: 0.0011\n",
      "Epoch 45/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 6.7293e-04 - val_loss: 0.0011\n",
      "Epoch 46/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 6.2471e-04 - val_loss: 9.5763e-04\n",
      "Epoch 47/100\n",
      "199/199 [==============================] - 1s 3ms/step - loss: 5.8229e-04 - val_loss: 9.3758e-04\n",
      "Epoch 48/100\n",
      "199/199 [==============================] - 1s 3ms/step - loss: 5.5633e-04 - val_loss: 9.2038e-04\n",
      "Epoch 49/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 5.4654e-04 - val_loss: 9.0787e-04\n",
      "Epoch 50/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 5.2879e-04 - val_loss: 9.1672e-04\n",
      "Epoch 51/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 5.0119e-04 - val_loss: 9.0391e-04\n",
      "Epoch 52/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 4.8843e-04 - val_loss: 8.5025e-04\n",
      "Epoch 53/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 4.7490e-04 - val_loss: 8.2480e-04\n",
      "Epoch 54/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 4.6087e-04 - val_loss: 8.4040e-04\n",
      "Epoch 55/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 4.4193e-04 - val_loss: 8.4178e-04\n",
      "Epoch 56/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 4.3911e-04 - val_loss: 8.0614e-04\n",
      "Epoch 57/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 4.2882e-04 - val_loss: 7.9939e-04\n",
      "Epoch 58/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 4.1695e-04 - val_loss: 7.9969e-04\n",
      "Epoch 59/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 4.1676e-04 - val_loss: 7.6326e-04\n",
      "Epoch 60/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 4.0108e-04 - val_loss: 7.9102e-04\n",
      "Epoch 61/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 3.9839e-04 - val_loss: 7.4041e-04\n",
      "Epoch 62/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 3.9402e-04 - val_loss: 7.5520e-04\n",
      "Epoch 63/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 3.9158e-04 - val_loss: 7.7321e-04\n",
      "Epoch 64/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 3.8238e-04 - val_loss: 7.3286e-04\n",
      "Epoch 65/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 3.6796e-04 - val_loss: 7.5213e-04\n",
      "Epoch 66/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 3.5677e-04 - val_loss: 7.4517e-04\n",
      "Epoch 67/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 3.4930e-04 - val_loss: 7.3294e-04\n",
      "Epoch 68/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 3.3880e-04 - val_loss: 7.0683e-04\n",
      "Epoch 69/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 3.3460e-04 - val_loss: 7.0374e-04\n",
      "Epoch 70/100\n",
      "199/199 [==============================] - 0s 965us/step - loss: 3.2458e-04 - val_loss: 6.8036e-04\n",
      "Epoch 71/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 3.1666e-04 - val_loss: 6.8726e-04\n",
      "Epoch 72/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 3.1422e-04 - val_loss: 6.7975e-04\n",
      "Epoch 73/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 3.1384e-04 - val_loss: 7.0105e-04\n",
      "Epoch 74/100\n",
      "199/199 [==============================] - 0s 978us/step - loss: 3.0801e-04 - val_loss: 7.0062e-04\n",
      "Epoch 75/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 3.0664e-04 - val_loss: 6.7449e-04\n",
      "Epoch 76/100\n",
      "199/199 [==============================] - 0s 980us/step - loss: 2.9859e-04 - val_loss: 6.6884e-04\n",
      "Epoch 77/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 2.9297e-04 - val_loss: 6.6115e-04\n",
      "Epoch 78/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 2.8745e-04 - val_loss: 6.5642e-04\n",
      "Epoch 79/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 3.0058e-04 - val_loss: 6.5495e-04\n",
      "Epoch 80/100\n",
      "199/199 [==============================] - 0s 962us/step - loss: 3.0079e-04 - val_loss: 6.5450e-04\n",
      "Epoch 81/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 2.8054e-04 - val_loss: 6.9135e-04\n",
      "Epoch 82/100\n",
      "199/199 [==============================] - 0s 942us/step - loss: 2.7884e-04 - val_loss: 6.4445e-04\n",
      "Epoch 83/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 2.7465e-04 - val_loss: 6.2991e-04\n",
      "Epoch 84/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 2.7014e-04 - val_loss: 6.4011e-04\n",
      "Epoch 85/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 2.6960e-04 - val_loss: 6.5187e-04\n",
      "Epoch 86/100\n",
      "199/199 [==============================] - 0s 983us/step - loss: 2.6902e-04 - val_loss: 6.4111e-04\n",
      "Epoch 87/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 2.6500e-04 - val_loss: 6.4859e-04\n",
      "Epoch 88/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 2.7203e-04 - val_loss: 6.4057e-04\n",
      "Epoch 89/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 2.6745e-04 - val_loss: 6.3452e-04\n",
      "Epoch 90/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 2.5767e-04 - val_loss: 6.2085e-04\n",
      "Epoch 91/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 2.5498e-04 - val_loss: 6.4868e-04\n",
      "Epoch 92/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 2.5418e-04 - val_loss: 6.8624e-04\n",
      "Epoch 93/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 2.4864e-04 - val_loss: 6.1653e-04\n",
      "Epoch 94/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 2.4570e-04 - val_loss: 6.1198e-04\n",
      "Epoch 95/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 2.4445e-04 - val_loss: 6.2902e-04\n",
      "Epoch 96/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 2.4799e-04 - val_loss: 6.1011e-04\n",
      "Epoch 97/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 2.4190e-04 - val_loss: 6.8089e-04\n",
      "Epoch 98/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 2.4667e-04 - val_loss: 6.5833e-04\n",
      "Epoch 99/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 2.4726e-04 - val_loss: 6.5733e-04\n",
      "Epoch 100/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 2.9672e-04 - val_loss: 6.4177e-04\n",
      "This round is 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_63917/2731616321.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  para_dfm = para_dfm.append({\"reg_param\": reg_param, \"number_units_layers\": numbers_units_layers, \"number_units_bottleneck\": numbers_units_bottleneck, \"dropout_rate\": dropout_rate, \"number_layers\": numbers_layers, \"whether_dropout\": whether_dropout, \"whether_regularizer\": whether_regularizer, \"overfit_metric\": overfit_metric, \"val2_avg_recon_error\": val2_avg_recon_error,'val1_loss':val1_loss}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "199/199 [==============================] - 1s 1ms/step - loss: 1.5015 - val_loss: 0.3871\n",
      "Epoch 2/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.1672 - val_loss: 0.0720\n",
      "Epoch 3/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0598 - val_loss: 0.0554\n",
      "Epoch 4/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0551 - val_loss: 0.0550\n",
      "Epoch 5/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0550 - val_loss: 0.0549\n",
      "Epoch 6/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0549 - val_loss: 0.0545\n",
      "Epoch 7/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0533 - val_loss: 0.0504\n",
      "Epoch 8/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0455 - val_loss: 0.0416\n",
      "Epoch 9/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0407 - val_loss: 0.0396\n",
      "Epoch 10/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0394 - val_loss: 0.0387\n",
      "Epoch 11/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0386 - val_loss: 0.0381\n",
      "Epoch 12/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0381 - val_loss: 0.0378\n",
      "Epoch 13/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0378 - val_loss: 0.0374\n",
      "Epoch 14/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0375 - val_loss: 0.0371\n",
      "Epoch 15/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0372 - val_loss: 0.0370\n",
      "Epoch 16/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0371 - val_loss: 0.0368\n",
      "Epoch 17/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0369 - val_loss: 0.0367\n",
      "Epoch 18/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0368 - val_loss: 0.0366\n",
      "Epoch 19/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0367 - val_loss: 0.0365\n",
      "Epoch 20/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0367 - val_loss: 0.0365\n",
      "Epoch 21/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0366 - val_loss: 0.0364\n",
      "Epoch 22/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0365 - val_loss: 0.0363\n",
      "Epoch 23/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0365 - val_loss: 0.0363\n",
      "Epoch 24/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0365 - val_loss: 0.0362\n",
      "Epoch 25/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0364 - val_loss: 0.0363\n",
      "Epoch 26/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0364 - val_loss: 0.0362\n",
      "Epoch 27/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0363 - val_loss: 0.0361\n",
      "Epoch 28/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0363 - val_loss: 0.0362\n",
      "Epoch 29/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0363 - val_loss: 0.0361\n",
      "Epoch 30/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0363 - val_loss: 0.0361\n",
      "Epoch 31/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0362 - val_loss: 0.0360\n",
      "Epoch 32/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0362 - val_loss: 0.0360\n",
      "Epoch 33/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0362 - val_loss: 0.0360\n",
      "Epoch 34/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0363 - val_loss: 0.0363\n",
      "Epoch 35/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0361 - val_loss: 0.0359\n",
      "Epoch 36/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0361 - val_loss: 0.0360\n",
      "Epoch 37/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0361 - val_loss: 0.0360\n",
      "Epoch 38/100\n",
      "199/199 [==============================] - 0s 968us/step - loss: 0.0361 - val_loss: 0.0362\n",
      "Epoch 39/100\n",
      "199/199 [==============================] - 0s 966us/step - loss: 0.0360 - val_loss: 0.0360\n",
      "Epoch 40/100\n",
      "199/199 [==============================] - 0s 988us/step - loss: 0.0361 - val_loss: 0.0360\n",
      "Epoch 41/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0360 - val_loss: 0.0358\n",
      "Epoch 42/100\n",
      "199/199 [==============================] - 0s 977us/step - loss: 0.0361 - val_loss: 0.0360\n",
      "Epoch 43/100\n",
      "199/199 [==============================] - 0s 971us/step - loss: 0.0361 - val_loss: 0.0359\n",
      "Epoch 44/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0360 - val_loss: 0.0358\n",
      "Epoch 45/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0361 - val_loss: 0.0358\n",
      "Epoch 46/100\n",
      "199/199 [==============================] - 0s 996us/step - loss: 0.0360 - val_loss: 0.0362\n",
      "Epoch 47/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0360 - val_loss: 0.0360\n",
      "Epoch 48/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0360 - val_loss: 0.0361\n",
      "Epoch 49/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0359 - val_loss: 0.0357\n",
      "Epoch 50/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0360 - val_loss: 0.0360\n",
      "Epoch 51/100\n",
      "199/199 [==============================] - 0s 970us/step - loss: 0.0360 - val_loss: 0.0359\n",
      "Epoch 52/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0359 - val_loss: 0.0357\n",
      "Epoch 53/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0359 - val_loss: 0.0357\n",
      "Epoch 54/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0359 - val_loss: 0.0359\n",
      "Epoch 55/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0359 - val_loss: 0.0358\n",
      "Epoch 56/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0358 - val_loss: 0.0356\n",
      "Epoch 57/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0358 - val_loss: 0.0358\n",
      "Epoch 58/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0358 - val_loss: 0.0356\n",
      "Epoch 59/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0358 - val_loss: 0.0355\n",
      "Epoch 60/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0357 - val_loss: 0.0357\n",
      "Epoch 61/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0356 - val_loss: 0.0355\n",
      "Epoch 62/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0356 - val_loss: 0.0357\n",
      "Epoch 63/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0355 - val_loss: 0.0353\n",
      "Epoch 64/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0354 - val_loss: 0.0352\n",
      "Epoch 65/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0353 - val_loss: 0.0354\n",
      "Epoch 66/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0353 - val_loss: 0.0353\n",
      "Epoch 67/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0353 - val_loss: 0.0354\n",
      "Epoch 68/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0351 - val_loss: 0.0354\n",
      "Epoch 69/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0351 - val_loss: 0.0350\n",
      "Epoch 70/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0350 - val_loss: 0.0348\n",
      "Epoch 71/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0350 - val_loss: 0.0349\n",
      "Epoch 72/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0349 - val_loss: 0.0348\n",
      "Epoch 73/100\n",
      "199/199 [==============================] - 0s 979us/step - loss: 0.0348 - val_loss: 0.0346\n",
      "Epoch 74/100\n",
      "199/199 [==============================] - 0s 969us/step - loss: 0.0348 - val_loss: 0.0346\n",
      "Epoch 75/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0346 - val_loss: 0.0345\n",
      "Epoch 76/100\n",
      "199/199 [==============================] - 0s 996us/step - loss: 0.0346 - val_loss: 0.0345\n",
      "Epoch 77/100\n",
      "199/199 [==============================] - 0s 974us/step - loss: 0.0346 - val_loss: 0.0346\n",
      "Epoch 78/100\n",
      "199/199 [==============================] - 0s 965us/step - loss: 0.0345 - val_loss: 0.0343\n",
      "Epoch 79/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0344 - val_loss: 0.0343\n",
      "Epoch 80/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0344 - val_loss: 0.0342\n",
      "Epoch 81/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0344 - val_loss: 0.0342\n",
      "Epoch 82/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0343 - val_loss: 0.0342\n",
      "Epoch 83/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0342 - val_loss: 0.0342\n",
      "Epoch 84/100\n",
      "199/199 [==============================] - 0s 999us/step - loss: 0.0343 - val_loss: 0.0343\n",
      "Epoch 85/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0341 - val_loss: 0.0339\n",
      "Epoch 86/100\n",
      "199/199 [==============================] - 0s 969us/step - loss: 0.0341 - val_loss: 0.0343\n",
      "Epoch 87/100\n",
      "199/199 [==============================] - 0s 959us/step - loss: 0.0340 - val_loss: 0.0339\n",
      "Epoch 88/100\n",
      "199/199 [==============================] - 0s 979us/step - loss: 0.0340 - val_loss: 0.0339\n",
      "Epoch 89/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0340 - val_loss: 0.0337\n",
      "Epoch 90/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0339 - val_loss: 0.0341\n",
      "Epoch 91/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0340 - val_loss: 0.0336\n",
      "Epoch 92/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0337 - val_loss: 0.0335\n",
      "Epoch 93/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0337 - val_loss: 0.0334\n",
      "Epoch 94/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0336 - val_loss: 0.0339\n",
      "Epoch 95/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0336 - val_loss: 0.0335\n",
      "Epoch 96/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0335 - val_loss: 0.0337\n",
      "Epoch 97/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0334 - val_loss: 0.0335\n",
      "Epoch 98/100\n",
      "199/199 [==============================] - 0s 964us/step - loss: 0.0335 - val_loss: 0.0337\n",
      "Epoch 99/100\n",
      "199/199 [==============================] - 0s 952us/step - loss: 0.0333 - val_loss: 0.0331\n",
      "Epoch 100/100\n",
      "199/199 [==============================] - 0s 978us/step - loss: 0.0332 - val_loss: 0.0330\n",
      "This round is 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_63917/2731616321.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  para_dfm = para_dfm.append({\"reg_param\": reg_param, \"number_units_layers\": numbers_units_layers, \"number_units_bottleneck\": numbers_units_bottleneck, \"dropout_rate\": dropout_rate, \"number_layers\": numbers_layers, \"whether_dropout\": whether_dropout, \"whether_regularizer\": whether_regularizer, \"overfit_metric\": overfit_metric, \"val2_avg_recon_error\": val2_avg_recon_error,'val1_loss':val1_loss}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.1091 - val_loss: 0.0546\n",
      "Epoch 2/100\n",
      "199/199 [==============================] - 0s 916us/step - loss: 0.0495 - val_loss: 0.0434\n",
      "Epoch 3/100\n",
      "199/199 [==============================] - 0s 955us/step - loss: 0.0405 - val_loss: 0.0385\n",
      "Epoch 4/100\n",
      "199/199 [==============================] - 0s 953us/step - loss: 0.0377 - val_loss: 0.0366\n",
      "Epoch 5/100\n",
      "199/199 [==============================] - 0s 931us/step - loss: 0.0359 - val_loss: 0.0350\n",
      "Epoch 6/100\n",
      "199/199 [==============================] - 0s 913us/step - loss: 0.0341 - val_loss: 0.0326\n",
      "Epoch 7/100\n",
      "199/199 [==============================] - 0s 913us/step - loss: 0.0310 - val_loss: 0.0285\n",
      "Epoch 8/100\n",
      "199/199 [==============================] - 0s 932us/step - loss: 0.0268 - val_loss: 0.0245\n",
      "Epoch 9/100\n",
      "199/199 [==============================] - 0s 952us/step - loss: 0.0236 - val_loss: 0.0222\n",
      "Epoch 10/100\n",
      "199/199 [==============================] - 0s 908us/step - loss: 0.0221 - val_loss: 0.0211\n",
      "Epoch 11/100\n",
      "199/199 [==============================] - 0s 910us/step - loss: 0.0208 - val_loss: 0.0195\n",
      "Epoch 12/100\n",
      "199/199 [==============================] - 0s 921us/step - loss: 0.0192 - val_loss: 0.0181\n",
      "Epoch 13/100\n",
      "199/199 [==============================] - 0s 914us/step - loss: 0.0180 - val_loss: 0.0170\n",
      "Epoch 14/100\n",
      "199/199 [==============================] - 0s 915us/step - loss: 0.0171 - val_loss: 0.0162\n",
      "Epoch 15/100\n",
      "199/199 [==============================] - 0s 933us/step - loss: 0.0162 - val_loss: 0.0154\n",
      "Epoch 16/100\n",
      "199/199 [==============================] - 0s 948us/step - loss: 0.0155 - val_loss: 0.0147\n",
      "Epoch 17/100\n",
      "199/199 [==============================] - 0s 950us/step - loss: 0.0149 - val_loss: 0.0141\n",
      "Epoch 18/100\n",
      "199/199 [==============================] - 0s 924us/step - loss: 0.0143 - val_loss: 0.0136\n",
      "Epoch 19/100\n",
      "199/199 [==============================] - 0s 935us/step - loss: 0.0138 - val_loss: 0.0132\n",
      "Epoch 20/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0134 - val_loss: 0.0127\n",
      "Epoch 21/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0129 - val_loss: 0.0123\n",
      "Epoch 22/100\n",
      "199/199 [==============================] - 0s 929us/step - loss: 0.0124 - val_loss: 0.0119\n",
      "Epoch 23/100\n",
      "199/199 [==============================] - 0s 927us/step - loss: 0.0120 - val_loss: 0.0116\n",
      "Epoch 24/100\n",
      "199/199 [==============================] - 0s 938us/step - loss: 0.0118 - val_loss: 0.0113\n",
      "Epoch 25/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.0110\n",
      "Epoch 26/100\n",
      "199/199 [==============================] - 0s 928us/step - loss: 0.0112 - val_loss: 0.0107\n",
      "Epoch 27/100\n",
      "199/199 [==============================] - 0s 933us/step - loss: 0.0109 - val_loss: 0.0105\n",
      "Epoch 28/100\n",
      "199/199 [==============================] - 0s 943us/step - loss: 0.0107 - val_loss: 0.0103\n",
      "Epoch 29/100\n",
      "199/199 [==============================] - 0s 958us/step - loss: 0.0106 - val_loss: 0.0101\n",
      "Epoch 30/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0104 - val_loss: 0.0100\n",
      "Epoch 31/100\n",
      "199/199 [==============================] - 0s 962us/step - loss: 0.0102 - val_loss: 0.0098\n",
      "Epoch 32/100\n",
      "199/199 [==============================] - 0s 942us/step - loss: 0.0100 - val_loss: 0.0096\n",
      "Epoch 33/100\n",
      "199/199 [==============================] - 0s 957us/step - loss: 0.0099 - val_loss: 0.0095\n",
      "Epoch 34/100\n",
      "199/199 [==============================] - 0s 950us/step - loss: 0.0098 - val_loss: 0.0094\n",
      "Epoch 35/100\n",
      "199/199 [==============================] - 0s 941us/step - loss: 0.0097 - val_loss: 0.0093\n",
      "Epoch 36/100\n",
      "199/199 [==============================] - 0s 950us/step - loss: 0.0095 - val_loss: 0.0091\n",
      "Epoch 37/100\n",
      "199/199 [==============================] - 0s 945us/step - loss: 0.0093 - val_loss: 0.0090\n",
      "Epoch 38/100\n",
      "199/199 [==============================] - 0s 937us/step - loss: 0.0092 - val_loss: 0.0089\n",
      "Epoch 39/100\n",
      "199/199 [==============================] - 0s 934us/step - loss: 0.0091 - val_loss: 0.0087\n",
      "Epoch 40/100\n",
      "199/199 [==============================] - 0s 963us/step - loss: 0.0090 - val_loss: 0.0087\n",
      "Epoch 41/100\n",
      "199/199 [==============================] - 0s 943us/step - loss: 0.0089 - val_loss: 0.0086\n",
      "Epoch 42/100\n",
      "199/199 [==============================] - 0s 986us/step - loss: 0.0087 - val_loss: 0.0084\n",
      "Epoch 43/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0084\n",
      "Epoch 44/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0083\n",
      "Epoch 45/100\n",
      "199/199 [==============================] - 0s 942us/step - loss: 0.0084 - val_loss: 0.0082\n",
      "Epoch 46/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0081\n",
      "Epoch 47/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0080\n",
      "Epoch 48/100\n",
      "199/199 [==============================] - 0s 977us/step - loss: 0.0082 - val_loss: 0.0080\n",
      "Epoch 49/100\n",
      "199/199 [==============================] - 0s 962us/step - loss: 0.0082 - val_loss: 0.0079\n",
      "Epoch 50/100\n",
      "199/199 [==============================] - 0s 991us/step - loss: 0.0081 - val_loss: 0.0078\n",
      "Epoch 51/100\n",
      "199/199 [==============================] - 0s 964us/step - loss: 0.0080 - val_loss: 0.0078\n",
      "Epoch 52/100\n",
      "199/199 [==============================] - 0s 958us/step - loss: 0.0079 - val_loss: 0.0077\n",
      "Epoch 53/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0078 - val_loss: 0.0076\n",
      "Epoch 54/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0077 - val_loss: 0.0075\n",
      "Epoch 55/100\n",
      "199/199 [==============================] - 0s 974us/step - loss: 0.0076 - val_loss: 0.0074\n",
      "Epoch 56/100\n",
      "199/199 [==============================] - 0s 976us/step - loss: 0.0075 - val_loss: 0.0073\n",
      "Epoch 57/100\n",
      "199/199 [==============================] - 0s 981us/step - loss: 0.0074 - val_loss: 0.0072\n",
      "Epoch 58/100\n",
      "199/199 [==============================] - 0s 947us/step - loss: 0.0073 - val_loss: 0.0071\n",
      "Epoch 59/100\n",
      "199/199 [==============================] - 0s 960us/step - loss: 0.0072 - val_loss: 0.0070\n",
      "Epoch 60/100\n",
      "199/199 [==============================] - 0s 968us/step - loss: 0.0071 - val_loss: 0.0069\n",
      "Epoch 61/100\n",
      "199/199 [==============================] - 0s 951us/step - loss: 0.0070 - val_loss: 0.0068\n",
      "Epoch 62/100\n",
      "199/199 [==============================] - 0s 950us/step - loss: 0.0069 - val_loss: 0.0067\n",
      "Epoch 63/100\n",
      "199/199 [==============================] - 0s 944us/step - loss: 0.0068 - val_loss: 0.0066\n",
      "Epoch 64/100\n",
      "199/199 [==============================] - 0s 952us/step - loss: 0.0067 - val_loss: 0.0065\n",
      "Epoch 65/100\n",
      "199/199 [==============================] - 0s 945us/step - loss: 0.0066 - val_loss: 0.0064\n",
      "Epoch 66/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0063\n",
      "Epoch 67/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0062\n",
      "Epoch 68/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0062\n",
      "Epoch 69/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 0.0061\n",
      "Epoch 70/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 0.0061\n",
      "Epoch 71/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0060\n",
      "Epoch 72/100\n",
      "199/199 [==============================] - 0s 945us/step - loss: 0.0061 - val_loss: 0.0060\n",
      "Epoch 73/100\n",
      "199/199 [==============================] - 0s 961us/step - loss: 0.0061 - val_loss: 0.0059\n",
      "Epoch 74/100\n",
      "199/199 [==============================] - 0s 939us/step - loss: 0.0061 - val_loss: 0.0059\n",
      "Epoch 75/100\n",
      "199/199 [==============================] - 0s 934us/step - loss: 0.0060 - val_loss: 0.0058\n",
      "Epoch 76/100\n",
      "199/199 [==============================] - 0s 962us/step - loss: 0.0060 - val_loss: 0.0058\n",
      "Epoch 77/100\n",
      "199/199 [==============================] - 0s 946us/step - loss: 0.0059 - val_loss: 0.0058\n",
      "Epoch 78/100\n",
      "199/199 [==============================] - 0s 938us/step - loss: 0.0059 - val_loss: 0.0057\n",
      "Epoch 79/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0057\n",
      "Epoch 80/100\n",
      "199/199 [==============================] - 0s 950us/step - loss: 0.0059 - val_loss: 0.0057\n",
      "Epoch 81/100\n",
      "199/199 [==============================] - 0s 936us/step - loss: 0.0058 - val_loss: 0.0056\n",
      "Epoch 82/100\n",
      "199/199 [==============================] - 0s 930us/step - loss: 0.0057 - val_loss: 0.0056\n",
      "Epoch 83/100\n",
      "199/199 [==============================] - 0s 929us/step - loss: 0.0057 - val_loss: 0.0056\n",
      "Epoch 84/100\n",
      "199/199 [==============================] - 0s 956us/step - loss: 0.0056 - val_loss: 0.0055\n",
      "Epoch 85/100\n",
      "199/199 [==============================] - 0s 946us/step - loss: 0.0057 - val_loss: 0.0055\n",
      "Epoch 86/100\n",
      "199/199 [==============================] - 0s 936us/step - loss: 0.0056 - val_loss: 0.0055\n",
      "Epoch 87/100\n",
      "199/199 [==============================] - 0s 926us/step - loss: 0.0055 - val_loss: 0.0055\n",
      "Epoch 88/100\n",
      "199/199 [==============================] - 0s 936us/step - loss: 0.0056 - val_loss: 0.0055\n",
      "Epoch 89/100\n",
      "199/199 [==============================] - 0s 940us/step - loss: 0.0056 - val_loss: 0.0054\n",
      "Epoch 90/100\n",
      "199/199 [==============================] - 0s 945us/step - loss: 0.0055 - val_loss: 0.0054\n",
      "Epoch 91/100\n",
      "199/199 [==============================] - 0s 963us/step - loss: 0.0055 - val_loss: 0.0054\n",
      "Epoch 92/100\n",
      "199/199 [==============================] - 0s 955us/step - loss: 0.0054 - val_loss: 0.0054\n",
      "Epoch 93/100\n",
      "199/199 [==============================] - 0s 939us/step - loss: 0.0055 - val_loss: 0.0054\n",
      "Epoch 94/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0055 - val_loss: 0.0053\n",
      "Epoch 95/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0054 - val_loss: 0.0053\n",
      "Epoch 96/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0054 - val_loss: 0.0053\n",
      "Epoch 97/100\n",
      "199/199 [==============================] - 0s 993us/step - loss: 0.0053 - val_loss: 0.0053\n",
      "Epoch 98/100\n",
      "199/199 [==============================] - 0s 971us/step - loss: 0.0053 - val_loss: 0.0052\n",
      "Epoch 99/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0053 - val_loss: 0.0052\n",
      "Epoch 100/100\n",
      "199/199 [==============================] - 0s 957us/step - loss: 0.0053 - val_loss: 0.0052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_63917/2731616321.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  para_dfm = para_dfm.append({\"reg_param\": reg_param, \"number_units_layers\": numbers_units_layers, \"number_units_bottleneck\": numbers_units_bottleneck, \"dropout_rate\": dropout_rate, \"number_layers\": numbers_layers, \"whether_dropout\": whether_dropout, \"whether_regularizer\": whether_regularizer, \"overfit_metric\": overfit_metric, \"val2_avg_recon_error\": val2_avg_recon_error,'val1_loss':val1_loss}, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(48)\n",
    "round = 30\n",
    "model_list = [] # list of to save model\n",
    "class_list = []\n",
    "log_list = []\n",
    "para_dfm = pd.DataFrame(columns=['reg_param', 'number_units_layers', 'number_units_bottleneck', 'dropout_rate', 'number_layers', 'whether_dropout', 'whether_regularizer','overfit_metric', 'val1_loss','val2_avg_recon_error'])\n",
    "for i in range(round):\n",
    "    print(f\"This round is {i}\")\n",
    "    # generate a list of hyperparameters\n",
    "    reg_param = np.random.uniform(low=0.1, high=0.3)\n",
    "    numbers_units_layers = np.random.choice(np.arange(30, 61, 15))\n",
    "    numbers_units_bottleneck = np.random.choice(np.arange(5, 16, 5))\n",
    "    dropout_rate = np.random.uniform(low=0.01, high=0.05)\n",
    "    numbers_layers = np.random.choice(np.arange(1, 4, 1))\n",
    "    whether_dropout = np.random.choice([True, False])\n",
    "    whether_regularizer = np.random.choice([True, False])\n",
    "    autoencoder = AutoEncodingModel(reg_param, numbers_units_layers, numbers_units_bottleneck, dropout_rate, numbers_layers, whether_dropout, whether_regularizer)\n",
    "    \n",
    "    # get the result of the model\n",
    "    res = autoencoder.run()\n",
    "    overfit_metric  = res['overfit_metric']\n",
    "    val2_avg_recon_error = res['val2_avg_recon_error']\n",
    "    model = res['model']\n",
    "    val1_loss = res['val1_loss']\n",
    "\n",
    "    # fill the value into the dataframe\n",
    "    para_dfm = para_dfm.append({\"reg_param\": reg_param, \"number_units_layers\": numbers_units_layers, \"number_units_bottleneck\": numbers_units_bottleneck, \"dropout_rate\": dropout_rate, \"number_layers\": numbers_layers, \"whether_dropout\": whether_dropout, \"whether_regularizer\": whether_regularizer, \"overfit_metric\": overfit_metric, \"val2_avg_recon_error\": val2_avg_recon_error,'val1_loss':val1_loss}, ignore_index=True)\n",
    "    \n",
    "    # add model into model_list\n",
    "    model_list.append(model)\n",
    "\n",
    "    # add initalized class into class_list\n",
    "    class_list.append(autoencoder)\n",
    "\n",
    "    # add log into log_list\n",
    "    log_list.append(res['log'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   reg_param number_units_layers number_units_bottleneck dropout_rate  \\\n",
      "0   0.101602                  30                      15     0.029854   \n",
      "1   0.169976                  60                      15     0.043196   \n",
      "2    0.29184                  60                      15     0.037134   \n",
      "3   0.208285                  60                      15     0.035386   \n",
      "4   0.151367                  60                      10      0.01004   \n",
      "5   0.246855                  30                       5     0.034967   \n",
      "6   0.113334                  60                      15     0.025236   \n",
      "7   0.225222                  60                      15     0.035572   \n",
      "8   0.256244                  30                       5     0.044798   \n",
      "9   0.117365                  30                      15     0.016045   \n",
      "10  0.279561                  30                      10     0.017169   \n",
      "11  0.112228                  60                      10     0.022143   \n",
      "12  0.270359                  60                       5     0.040252   \n",
      "13   0.21149                  45                      10     0.042887   \n",
      "14  0.170593                  45                       5     0.029782   \n",
      "15  0.208831                  30                      10     0.021429   \n",
      "16  0.207591                  45                       5     0.030184   \n",
      "17  0.212975                  60                      10     0.022023   \n",
      "18  0.265454                  30                      10     0.010218   \n",
      "19  0.132887                  30                      15     0.048864   \n",
      "20  0.100584                  60                      15     0.017069   \n",
      "21  0.152931                  45                       5     0.035677   \n",
      "22   0.10706                  60                      15      0.03311   \n",
      "23  0.168572                  30                      10     0.026794   \n",
      "24  0.157197                  60                      10     0.044873   \n",
      "25  0.224813                  45                       5     0.019175   \n",
      "26  0.204617                  30                      10     0.021588   \n",
      "27  0.135619                  60                      10     0.012703   \n",
      "28  0.206679                  60                      10     0.030689   \n",
      "29  0.216825                  30                      15     0.021524   \n",
      "\n",
      "   number_layers whether_dropout whether_regularizer overfit_metric val1_loss  \\\n",
      "0              2           False                True       0.000596  0.001596   \n",
      "1              2            True               False       0.000102  0.002467   \n",
      "2              3            True               False       0.000165  0.002311   \n",
      "3              2            True                True      -0.000215  0.033051   \n",
      "4              3            True               False       0.000678  0.004677   \n",
      "5              2           False               False       0.000596  0.001596   \n",
      "6              1           False               False       0.000345  0.000642   \n",
      "7              1            True               False       0.000191  0.002542   \n",
      "8              3            True               False      -0.000246  0.011342   \n",
      "9              2           False               False       0.000596  0.001596   \n",
      "10             3           False               False       0.000596  0.001596   \n",
      "11             2            True                True      -0.000306   0.02712   \n",
      "12             2            True               False       0.000423  0.010118   \n",
      "13             3            True               False      -0.000104  0.005038   \n",
      "14             3            True               False       0.000372  0.009312   \n",
      "15             1           False               False       0.000596  0.001596   \n",
      "16             1           False                True       0.000294  0.000765   \n",
      "17             1            True               False       0.000461  0.004515   \n",
      "18             2            True                True      -0.000267  0.035437   \n",
      "19             2            True                True       -0.00017  0.035392   \n",
      "20             1           False                True       0.000345  0.000642   \n",
      "21             2           False                True       0.000294  0.000765   \n",
      "22             2            True                True      -0.000364  0.027109   \n",
      "23             1            True                True      -0.000485  0.031048   \n",
      "24             2           False                True       0.000345  0.000642   \n",
      "25             1           False               False       0.000294  0.000765   \n",
      "26             1            True                True           -0.0  0.035899   \n",
      "27             3           False               False       0.000345  0.000642   \n",
      "28             2            True                True      -0.000196   0.03303   \n",
      "29             2            True               False      -0.000034  0.005243   \n",
      "\n",
      "   val2_avg_recon_error model_score  \n",
      "0              0.001463    0.000868  \n",
      "1               0.00249    0.002389  \n",
      "2                0.0024    0.002235  \n",
      "3              0.033201    0.033415  \n",
      "4              0.004623    0.003945  \n",
      "5              0.001463    0.000868  \n",
      "6              0.000512    0.000167  \n",
      "7              0.002599    0.002408  \n",
      "8              0.011377    0.011623  \n",
      "9              0.001463    0.000868  \n",
      "10             0.001463    0.000868  \n",
      "11             0.026403    0.026709  \n",
      "12             0.010393     0.00997  \n",
      "13              0.00509    0.005194  \n",
      "14             0.009472      0.0091  \n",
      "15             0.001463    0.000868  \n",
      "16             0.000703     0.00041  \n",
      "17             0.004515    0.004055  \n",
      "18             0.035608    0.035875  \n",
      "19             0.035738    0.035907  \n",
      "20             0.000512    0.000167  \n",
      "21             0.000703     0.00041  \n",
      "22             0.026418    0.026782  \n",
      "23             0.030631    0.031116  \n",
      "24             0.000512    0.000167  \n",
      "25             0.000703     0.00041  \n",
      "26             0.036242    0.036243  \n",
      "27             0.000512    0.000167  \n",
      "28             0.032856    0.033052  \n",
      "29             0.004979    0.005013  \n"
     ]
    }
   ],
   "source": [
    "# calculate the model score according to the val2_avg_recon_error and overfit_metric\n",
    "para_dfm[\"model_score\"] = para_dfm[\"val2_avg_recon_error\"] - para_dfm[\"overfit_metric\"] \n",
    "print(para_dfm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go through all the models we have trained and look into the relationship of the model_score and the performance of model.\n",
    "In the table, we are going to record the model_score, the sensitivity(select the mean of reconstruction_error as threshold), accuracy_rate and AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model_score is: 0.0008676041507403893\n",
      "0.39285714285714285\n",
      "The model_score is: 0.0023886228744438103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_63917/3198456538.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_performance_diff_sens = df_performance_diff_sens.append({\"model_score\": row['model_score'], \"sensitivity\": sensitivity,'accuracy_rate':accuracy_rate,'roc':roc}, ignore_index=True)\n",
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_63917/3198456538.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_performance_diff_sens = df_performance_diff_sens.append({\"model_score\": row['model_score'], \"sensitivity\": sensitivity,'accuracy_rate':accuracy_rate,'roc':roc}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4642857142857143\n",
      "The model_score is: 0.0022351069002796223\n",
      "0.5357142857142857\n",
      "The model_score is: 0.033415333434955945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_63917/3198456538.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_performance_diff_sens = df_performance_diff_sens.append({\"model_score\": row['model_score'], \"sensitivity\": sensitivity,'accuracy_rate':accuracy_rate,'roc':roc}, ignore_index=True)\n",
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_63917/3198456538.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_performance_diff_sens = df_performance_diff_sens.append({\"model_score\": row['model_score'], \"sensitivity\": sensitivity,'accuracy_rate':accuracy_rate,'roc':roc}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7321428571428571\n",
      "The model_score is: 0.003945142258028455\n",
      "0.5535714285714286\n",
      "The model_score is: 0.0008676041507403893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_63917/3198456538.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_performance_diff_sens = df_performance_diff_sens.append({\"model_score\": row['model_score'], \"sensitivity\": sensitivity,'accuracy_rate':accuracy_rate,'roc':roc}, ignore_index=True)\n",
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_63917/3198456538.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_performance_diff_sens = df_performance_diff_sens.append({\"model_score\": row['model_score'], \"sensitivity\": sensitivity,'accuracy_rate':accuracy_rate,'roc':roc}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39285714285714285\n",
      "The model_score is: 0.00016663334475956542\n",
      "0.48214285714285715\n",
      "The model_score is: 0.002408337703888161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_63917/3198456538.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_performance_diff_sens = df_performance_diff_sens.append({\"model_score\": row['model_score'], \"sensitivity\": sensitivity,'accuracy_rate':accuracy_rate,'roc':roc}, ignore_index=True)\n",
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_63917/3198456538.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_performance_diff_sens = df_performance_diff_sens.append({\"model_score\": row['model_score'], \"sensitivity\": sensitivity,'accuracy_rate':accuracy_rate,'roc':roc}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4642857142857143\n",
      "The model_score is: 0.011623159664101039\n",
      "0.6071428571428571\n",
      "The model_score is: 0.0008676041507403893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_63917/3198456538.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_performance_diff_sens = df_performance_diff_sens.append({\"model_score\": row['model_score'], \"sensitivity\": sensitivity,'accuracy_rate':accuracy_rate,'roc':roc}, ignore_index=True)\n",
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_63917/3198456538.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_performance_diff_sens = df_performance_diff_sens.append({\"model_score\": row['model_score'], \"sensitivity\": sensitivity,'accuracy_rate':accuracy_rate,'roc':roc}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39285714285714285\n",
      "The model_score is: 0.0008676041507403893\n",
      "0.39285714285714285\n",
      "The model_score is: 0.026708692158117064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_63917/3198456538.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_performance_diff_sens = df_performance_diff_sens.append({\"model_score\": row['model_score'], \"sensitivity\": sensitivity,'accuracy_rate':accuracy_rate,'roc':roc}, ignore_index=True)\n",
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_63917/3198456538.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_performance_diff_sens = df_performance_diff_sens.append({\"model_score\": row['model_score'], \"sensitivity\": sensitivity,'accuracy_rate':accuracy_rate,'roc':roc}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7857142857142857\n",
      "The model_score is: 0.009969656824345708\n",
      "0.6785714285714286\n",
      "The model_score is: 0.0051938996897175765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_63917/3198456538.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_performance_diff_sens = df_performance_diff_sens.append({\"model_score\": row['model_score'], \"sensitivity\": sensitivity,'accuracy_rate':accuracy_rate,'roc':roc}, ignore_index=True)\n",
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_63917/3198456538.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_performance_diff_sens = df_performance_diff_sens.append({\"model_score\": row['model_score'], \"sensitivity\": sensitivity,'accuracy_rate':accuracy_rate,'roc':roc}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5535714285714286\n",
      "The model_score is: 0.009099958126197528\n",
      "0.6607142857142857\n",
      "The model_score is: 0.0008676041507403893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_63917/3198456538.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_performance_diff_sens = df_performance_diff_sens.append({\"model_score\": row['model_score'], \"sensitivity\": sensitivity,'accuracy_rate':accuracy_rate,'roc':roc}, ignore_index=True)\n",
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_63917/3198456538.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_performance_diff_sens = df_performance_diff_sens.append({\"model_score\": row['model_score'], \"sensitivity\": sensitivity,'accuracy_rate':accuracy_rate,'roc':roc}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39285714285714285\n",
      "The model_score is: 0.00040964425163789284\n",
      "0.4642857142857143\n",
      "The model_score is: 0.004054913551557495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_63917/3198456538.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_performance_diff_sens = df_performance_diff_sens.append({\"model_score\": row['model_score'], \"sensitivity\": sensitivity,'accuracy_rate':accuracy_rate,'roc':roc}, ignore_index=True)\n",
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_63917/3198456538.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_performance_diff_sens = df_performance_diff_sens.append({\"model_score\": row['model_score'], \"sensitivity\": sensitivity,'accuracy_rate':accuracy_rate,'roc':roc}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39285714285714285\n",
      "The model_score is: 0.03587468476734742\n",
      "0.8928571428571429\n",
      "The model_score is: 0.03590731608577212\n",
      "0.8928571428571429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_63917/3198456538.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_performance_diff_sens = df_performance_diff_sens.append({\"model_score\": row['model_score'], \"sensitivity\": sensitivity,'accuracy_rate':accuracy_rate,'roc':roc}, ignore_index=True)\n",
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_63917/3198456538.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_performance_diff_sens = df_performance_diff_sens.append({\"model_score\": row['model_score'], \"sensitivity\": sensitivity,'accuracy_rate':accuracy_rate,'roc':roc}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model_score is: 0.00016663334475956542\n",
      "0.48214285714285715\n",
      "The model_score is: 0.00040964425163789284\n",
      "0.4642857142857143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_63917/3198456538.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_performance_diff_sens = df_performance_diff_sens.append({\"model_score\": row['model_score'], \"sensitivity\": sensitivity,'accuracy_rate':accuracy_rate,'roc':roc}, ignore_index=True)\n",
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_63917/3198456538.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_performance_diff_sens = df_performance_diff_sens.append({\"model_score\": row['model_score'], \"sensitivity\": sensitivity,'accuracy_rate':accuracy_rate,'roc':roc}, ignore_index=True)\n",
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_63917/3198456538.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_performance_diff_sens = df_performance_diff_sens.append({\"model_score\": row['model_score'], \"sensitivity\": sensitivity,'accuracy_rate':accuracy_rate,'roc':roc}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model_score is: 0.026782213627248874\n",
      "0.7678571428571429\n",
      "The model_score is: 0.031115910998164794\n",
      "0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_63917/3198456538.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_performance_diff_sens = df_performance_diff_sens.append({\"model_score\": row['model_score'], \"sensitivity\": sensitivity,'accuracy_rate':accuracy_rate,'roc':roc}, ignore_index=True)\n",
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_63917/3198456538.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_performance_diff_sens = df_performance_diff_sens.append({\"model_score\": row['model_score'], \"sensitivity\": sensitivity,'accuracy_rate':accuracy_rate,'roc':roc}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model_score is: 0.00016663334475956542\n",
      "0.48214285714285715\n",
      "The model_score is: 0.00040964425163789284\n",
      "0.4642857142857143\n",
      "The model_score is: 0.03624265270535881\n",
      "0.8928571428571429\n",
      "The model_score is: 0.00016663334475956542\n",
      "0.48214285714285715\n",
      "The model_score is: 0.03305234825505061\n",
      "0.8035714285714286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_63917/3198456538.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_performance_diff_sens = df_performance_diff_sens.append({\"model_score\": row['model_score'], \"sensitivity\": sensitivity,'accuracy_rate':accuracy_rate,'roc':roc}, ignore_index=True)\n",
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_63917/3198456538.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_performance_diff_sens = df_performance_diff_sens.append({\"model_score\": row['model_score'], \"sensitivity\": sensitivity,'accuracy_rate':accuracy_rate,'roc':roc}, ignore_index=True)\n",
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_63917/3198456538.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_performance_diff_sens = df_performance_diff_sens.append({\"model_score\": row['model_score'], \"sensitivity\": sensitivity,'accuracy_rate':accuracy_rate,'roc':roc}, ignore_index=True)\n",
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_63917/3198456538.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_performance_diff_sens = df_performance_diff_sens.append({\"model_score\": row['model_score'], \"sensitivity\": sensitivity,'accuracy_rate':accuracy_rate,'roc':roc}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model_score is: 0.005013101425471561\n",
      "0.5535714285714286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_63917/3198456538.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_performance_diff_sens = df_performance_diff_sens.append({\"model_score\": row['model_score'], \"sensitivity\": sensitivity,'accuracy_rate':accuracy_rate,'roc':roc}, ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_score</th>\n",
       "      <th>sensitivity</th>\n",
       "      <th>accuracy_rate</th>\n",
       "      <th>roc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000868</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>0.755497</td>\n",
       "      <td>0.61712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002389</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.713281</td>\n",
       "      <td>0.618871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002235</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.712401</td>\n",
       "      <td>0.634119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.033415</td>\n",
       "      <td>0.732143</td>\n",
       "      <td>0.620932</td>\n",
       "      <td>0.752065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.003945</td>\n",
       "      <td>0.553571</td>\n",
       "      <td>0.643799</td>\n",
       "      <td>0.649217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000868</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>0.755497</td>\n",
       "      <td>0.61712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000167</td>\n",
       "      <td>0.482143</td>\n",
       "      <td>0.734389</td>\n",
       "      <td>0.66681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.002408</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.711522</td>\n",
       "      <td>0.641403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.011623</td>\n",
       "      <td>0.607143</td>\n",
       "      <td>0.626209</td>\n",
       "      <td>0.682305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000868</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>0.755497</td>\n",
       "      <td>0.61712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000868</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>0.755497</td>\n",
       "      <td>0.61712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.026709</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.577836</td>\n",
       "      <td>0.726807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.00997</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.626209</td>\n",
       "      <td>0.704754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.005194</td>\n",
       "      <td>0.553571</td>\n",
       "      <td>0.673703</td>\n",
       "      <td>0.692464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0091</td>\n",
       "      <td>0.660714</td>\n",
       "      <td>0.652595</td>\n",
       "      <td>0.709991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.000868</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>0.755497</td>\n",
       "      <td>0.61712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.00041</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.763412</td>\n",
       "      <td>0.62989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.004055</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>0.672823</td>\n",
       "      <td>0.623447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.035875</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.575198</td>\n",
       "      <td>0.759812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.035907</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.560246</td>\n",
       "      <td>0.76414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.000167</td>\n",
       "      <td>0.482143</td>\n",
       "      <td>0.734389</td>\n",
       "      <td>0.66681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.00041</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.763412</td>\n",
       "      <td>0.62989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.026782</td>\n",
       "      <td>0.767857</td>\n",
       "      <td>0.576957</td>\n",
       "      <td>0.726625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.031116</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.569041</td>\n",
       "      <td>0.708091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.000167</td>\n",
       "      <td>0.482143</td>\n",
       "      <td>0.734389</td>\n",
       "      <td>0.66681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.00041</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.763412</td>\n",
       "      <td>0.62989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.036243</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.560246</td>\n",
       "      <td>0.755088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.000167</td>\n",
       "      <td>0.482143</td>\n",
       "      <td>0.734389</td>\n",
       "      <td>0.66681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.033052</td>\n",
       "      <td>0.803571</td>\n",
       "      <td>0.596306</td>\n",
       "      <td>0.749752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.005013</td>\n",
       "      <td>0.553571</td>\n",
       "      <td>0.674582</td>\n",
       "      <td>0.627015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model_score sensitivity accuracy_rate       roc\n",
       "0     0.000868    0.392857      0.755497   0.61712\n",
       "1     0.002389    0.464286      0.713281  0.618871\n",
       "2     0.002235    0.535714      0.712401  0.634119\n",
       "3     0.033415    0.732143      0.620932  0.752065\n",
       "4     0.003945    0.553571      0.643799  0.649217\n",
       "5     0.000868    0.392857      0.755497   0.61712\n",
       "6     0.000167    0.482143      0.734389   0.66681\n",
       "7     0.002408    0.464286      0.711522  0.641403\n",
       "8     0.011623    0.607143      0.626209  0.682305\n",
       "9     0.000868    0.392857      0.755497   0.61712\n",
       "10    0.000868    0.392857      0.755497   0.61712\n",
       "11    0.026709    0.785714      0.577836  0.726807\n",
       "12     0.00997    0.678571      0.626209  0.704754\n",
       "13    0.005194    0.553571      0.673703  0.692464\n",
       "14      0.0091    0.660714      0.652595  0.709991\n",
       "15    0.000868    0.392857      0.755497   0.61712\n",
       "16     0.00041    0.464286      0.763412   0.62989\n",
       "17    0.004055    0.392857      0.672823  0.623447\n",
       "18    0.035875    0.892857      0.575198  0.759812\n",
       "19    0.035907    0.892857      0.560246   0.76414\n",
       "20    0.000167    0.482143      0.734389   0.66681\n",
       "21     0.00041    0.464286      0.763412   0.62989\n",
       "22    0.026782    0.767857      0.576957  0.726625\n",
       "23    0.031116        0.75      0.569041  0.708091\n",
       "24    0.000167    0.482143      0.734389   0.66681\n",
       "25     0.00041    0.464286      0.763412   0.62989\n",
       "26    0.036243    0.892857      0.560246  0.755088\n",
       "27    0.000167    0.482143      0.734389   0.66681\n",
       "28    0.033052    0.803571      0.596306  0.749752\n",
       "29    0.005013    0.553571      0.674582  0.627015"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_performance_diff_sens = pd.DataFrame(columns=['model_score', 'sensitivity','accuracy_rate','roc'])\n",
    "for ind, row in para_dfm.iterrows():\n",
    "    print(f\"The model_score is: {row['model_score']}\")\n",
    "    model_pred = model_list[ind]\n",
    "    X_pred = model_pred.predict(X_val)\n",
    "    mse = np.mean(np.power(X_val.flatten() - X_pred.flatten(), 2))\n",
    "    reconstructions = model_pred.predict(X_val)\n",
    "    val_loss = tf.keras.losses.mae(reconstructions, X_val)\n",
    "    # sns.histplot(x=val_loss,y=y_val.flatten(),hue=y_val.flatten())\n",
    "    # plt.show()\n",
    "    df_tmp = pd.DataFrame({\"val_loss\": val_loss, \"y_val\": y_val.flatten()})\n",
    "    df_tmp_fraud = df_tmp[df_tmp[\"y_val\"] == 1]\n",
    "    df_tmp_non_fraud = df_tmp[df_tmp[\"y_val\"] == 0]\n",
    "    mse = np.mean(np.power(X_val.flatten() - X_pred.flatten(), 2))\n",
    "    error_df = pd.DataFrame({'Reconstruction_error': mse, 'True_class': y_val.flatten()})\n",
    "    df_temp = pd.DataFrame({'Reconstruction_error': val_loss, 'True_class': y_val.flatten()})\n",
    "    roc = roc_auc_score(y_val.flatten(), val_loss)\n",
    "    threshold = np.mean(df_temp[\"Reconstruction_error\"])\n",
    "    pred_y = np.where(val_loss > threshold, 1, 0)\n",
    "    cm = confusion_matrix(y_val.flatten(), pred_y)\n",
    "    accuracy_rate = (cm[0,0] + cm[1,1])/np.sum(cm)\n",
    "    # calculate the sensitivity \n",
    "    sensitivity = cm[1,1]/(cm[1,1] + cm[1,0])\n",
    "    print(sensitivity)\n",
    "    df_performance_diff_sens = df_performance_diff_sens.append({\"model_score\": row['model_score'], \"sensitivity\": sensitivity,'accuracy_rate':accuracy_rate,'roc':roc}, ignore_index=True)\n",
    "df_performance_diff_sens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to explore the distubution of the fraud cases in the test set of each model. Usually, the higher the model score, the fraud cases are more likely to be concentrated at a large number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model_score is: 0.0008676041507403893\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model_score is: 0.0023886228744438103\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model_score is: 0.0022351069002796223\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model_score is: 0.033415333434955945\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model_score is: 0.003945142258028455\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model_score is: 0.0008676041507403893\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model_score is: 0.00016663334475956542\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model_score is: 0.002408337703888161\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model_score is: 0.011623159664101039\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model_score is: 0.0008676041507403893\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model_score is: 0.0008676041507403893\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model_score is: 0.026708692158117064\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model_score is: 0.009969656824345708\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model_score is: 0.0051938996897175765\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model_score is: 0.009099958126197528\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model_score is: 0.0008676041507403893\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model_score is: 0.00040964425163789284\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model_score is: 0.004054913551557495\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model_score is: 0.03587468476734742\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model_score is: 0.03590731608577212\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model_score is: 0.00016663334475956542\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model_score is: 0.00040964425163789284\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model_score is: 0.026782213627248874\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model_score is: 0.031115910998164794\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model_score is: 0.00016663334475956542\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAORUlEQVR4nO3cb8jd5X3H8fdn0TqZLdUZJSRxcSWMRdmshizQMTIcM/NJLFSID2oeOLKKQgvdA91gvfcg4AbtmFCFdIpxdEqgLebB3CahQQZWe9tZTbTWrHaaJph0bqt74qr97sG5sp3dnvtP7j8n99n1fsGP8zvf33Wdc11et5/8zu/8SVUhSerDz53vAUiSxsfQl6SOGPqS1BFDX5I6YuhLUkcuON8DmM/ll19emzZtOt/DkKSJ8vzzz/+4qtbOrK/60N+0aRPT09PnexiSNFGS/Muoupd3JKkjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI6v+G7lLMjU1931J6oxn+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHZk39JNsTPLNJK8kOZbks61+WZKnkrzWbi8d6nNvkuNJXk1y01D9hiQvtWP3J8nKTEuSNMpCzvTfAz5fVb8KbAfuSrIFuAc4XFWbgcPtPu3YbuAaYCfwQJI17bEeBPYCm9u2cxnnIkmax7yhX1Wnquo7bf8d4BVgPbALONCaHQBuafu7gMer6t2qeh04DmxLsg74SFU9U1UFPDrUR5I0Bud0TT/JJuDjwLPAlVV1Cgb/MABXtGbrgTeHup1otfVtf2Z91PPsTTKdZPrMmTPnMkRJ0hwWHPpJLgG+Bnyuqn4yV9MRtZqj/sFi1f6q2lpVW9euXbvQIUqS5rGg0E9yIYPA/2pVfb2V32qXbGi3p1v9BLBxqPsG4GSrbxhRlySNyUI+vRPgIeCVqvrS0KFDwJ62vwd4Yqi+O8lFSa5m8Ibtc+0S0DtJtrfHvH2ojyRpDC5YQJtPAJ8GXkryQqv9EXAfcDDJHcAbwK0AVXUsyUHgZQaf/Lmrqt5v/e4EHgEuBp5smyRpTOYN/ar6R0Zfjwe4cZY++4B9I+rTwLXnMkBJ0vLxG7mS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOjJv6Cd5OMnpJEeHalNJfpTkhbbdPHTs3iTHk7ya5Kah+g1JXmrH7k+S5Z+OJGkuCznTfwTYOaL+F1V1Xdv+FiDJFmA3cE3r80CSNa39g8BeYHPbRj2mJGkFzRv6VfU08PYCH28X8HhVvVtVrwPHgW1J1gEfqapnqqqAR4FbFjlmSdIiXbCEvncnuR2YBj5fVf8GrAe+NdTmRKv9tO3PrI+UZC+DVwVcddVVix7g1JEdMwrtZmrRDylJE22xb+Q+CHwMuA44BXyx1Uddp6856iNV1f6q2lpVW9euXbvIIUqSZlpU6FfVW1X1flX9DPgKsK0dOgFsHGq6ATjZ6htG1CVJY7So0G/X6M/6JHD2kz2HgN1JLkpyNYM3bJ+rqlPAO0m2t0/t3A48sYRxS5IWYd5r+kkeA3YAlyc5AXwB2JHkOgaXaH4I/AFAVR1LchB4GXgPuKuq3m8PdSeDTwJdDDzZNknSGM0b+lV124jyQ3O03wfsG1GfBq49p9FJkpaV38iVpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6Mm/oJ3k4yekkR4dqlyV5Kslr7fbSoWP3Jjme5NUkNw3Vb0jyUjt2f5Is/3QkSXNZyJn+I8DOGbV7gMNVtRk43O6TZAuwG7im9XkgyZrW50FgL7C5bTMfU5K0wuYN/ap6Gnh7RnkXcKDtHwBuGao/XlXvVtXrwHFgW5J1wEeq6pmqKuDRoT6SpDFZ7DX9K6vqFEC7vaLV1wNvDrU70Wrr2/7M+khJ9iaZTjJ95syZRQ5RkjTTcr+RO+o6fc1RH6mq9lfV1qraunbt2mUbnCT1brGh/1a7ZEO7Pd3qJ4CNQ+02ACdbfcOIuiRpjBYb+oeAPW1/D/DEUH13kouSXM3gDdvn2iWgd5Jsb5/auX2ojyRpTC6Yr0GSx4AdwOVJTgBfAO4DDia5A3gDuBWgqo4lOQi8DLwH3FVV77eHupPBJ4EuBp5smyRpjOYN/aq6bZZDN87Sfh+wb0R9Grj2nEYnSVpWfiNXkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkeWFPpJfpjkpSQvJJlutcuSPJXktXZ76VD7e5McT/JqkpuWOnhJ0rlZjjP9366q66pqa7t/D3C4qjYDh9t9kmwBdgPXADuBB5KsWYbnlyQt0Epc3tkFHGj7B4BbhuqPV9W7VfU6cBzYtgLPL0maxVJDv4B/SPJ8kr2tdmVVnQJot1e0+nrgzaG+J1rtA5LsTTKdZPrMmTNLHKIk6awLltj/E1V1MskVwFNJvjdH24yo1aiGVbUf2A+wdevWkW0kSeduSWf6VXWy3Z4GvsHgcs1bSdYBtNvTrfkJYONQ9w3AyaU8vyTp3Cw69JP8QpIPn90Hfhc4ChwC9rRme4An2v4hYHeSi5JcDWwGnlvs80uSzt1SLu9cCXwjydnH+Zuq+rsk3wYOJrkDeAO4FaCqjiU5CLwMvAfcVVXvL2n0kqRzsujQr6ofAL8+ov6vwI2z9NkH7Fvsc0qSlsZv5EpSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR3pK/SPHBlsU1PneSCSdH70FfqS1DlDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHbngfA9g1ZuaGr2vPs31N7DQvw//pnQeeaYvSR0Z+5l+kp3AXwJrgL+qqvvGPYapIztgakR9RE2S/j8Z65l+kjXAl4HfA7YAtyXZMs4xSFLPxn2mvw04XlU/AEjyOLALeHnM4xhp5Jn+kR1M7Tiy8PaLqM93bDksZkwa+D//jY7smKPhiPbSKpOqGt+TJZ8CdlbV77f7nwZ+o6runtFuL7C33f0V4NVFPuXlwI8X2Xe1cA6rg3NYHZzDwv1SVa2dWRz3mX5G1D7wr05V7Qf2L/nJkumq2rrUxzmfnMPq4BxWB+ewdOP+9M4JYOPQ/Q3AyTGPQZK6Ne7Q/zawOcnVST4E7AYOjXkMktStsV7eqar3ktwN/D2Dj2w+XFXHVvApl3yJaBVwDquDc1gdnMMSjfWNXEnS+eU3ciWpI4a+JHVkYkI/yc4kryY5nuSeEceT5P52/MUk18/XN8llSZ5K8lq7vXQC5zCV5EdJXmjbzat4Dg8nOZ3k6Iw+k7QOs81hItYhycYk30zySpJjST471Gci1mGeOUzKOvx8kueSfLfN4U+H+qzsOlTVqt8YvOn7z8AvAx8CvgtsmdHmZuBJBt8F2A48O19f4M+Be9r+PcCfTeAcpoA/XO3r0I79FnA9cHRGn4lYh3nmMBHrAKwDrm/7Hwa+P4H/P8w1h0lZhwCXtP0LgWeB7eNYh0k50/+fn2+oqv8Czv58w7BdwKM18C3go0nWzdN3F3Cg7R8AbpnAOYzTUuZAVT0NvD3icSdlHeaawzgteg5VdaqqvgNQVe8ArwDrh/qs+nWYZw7jtJQ5VFX9Z2tzYdtqqM+KrcOkhP564M2h+yf44CLP1mauvldW1SmAdnvFMo55ppWaA8Dd7aXjwyv8knwpc5jLpKzDfCZqHZJsAj7O4CwTJnAdRswBJmQdkqxJ8gJwGniqqsayDpMS+gv5+YbZ2izopx/GYKXm8CDwMeA64BTwxUWObyGWMofVYqXmMFHrkOQS4GvA56rqJ8s4toVaqTlMzDpU1ftVdR2DXybYluTa5R3eaJMS+gv5+YbZ2szV962zL9vb7ellHPNMKzKHqnqr/fH8DPgKg5ecK2Upc5jLpKzDrCZpHZJcyCAsv1pVXx9qMzHrMNscJmkdzqqqfweOADtbaUXXYVJCfyE/33AIuL29W74d+I/20miuvoeAPW1/D/DEpM3h7B9H80ngKCtnKXOYy6Ssw6wmZR2SBHgIeKWqvjSiz6pfh7nmMEHrsDbJR9uYLwZ+B/jeUJ+VW4flfFd4JTcG74J/n8G75X/cap8BPlP/+274l9vxl4Ctc/Vt9V8EDgOvtdvLJnAOf93avsjgj2XdKp7DYwxecv+UwRnQHRO4DrPNYSLWAfhNBpcXXgReaNvNk7QO88xhUtbh14B/auM8CvzJ0GOu6Dr4MwyS1JFJubwjSVoGhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqyH8DQ3/3pA2rVw8AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model_score is: 0.00040964425163789284\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAQYElEQVR4nO3df6zddX3H8efLFhFlBAgX0rXNWpPGDcg28aZjIzFkbKFRYvljLDVRG8fSaHDitsRR9wfdH01ItixqMlwaYJbIYI0/QmNkSjobt0SpF/EHpSKdOHpHR69zTjYTXOt7f5wvcrzctvee7+253H6ej+TkfL/v7+dzvp/z6b2v873f7zmnqSokSW141VIPQJI0Poa+JDXE0Jekhhj6ktQQQ1+SGrJyqQdwOpdcckmtW7duqYchScvKo48++v2qmphdf8WH/rp165iamlrqYUjSspLk3+aqe3pHkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5Ia8or/RG4vO3acel2SGuORviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGnDb0k9yT5FiSx4dqf5nk20m+meQzSS4c2rY9yeEkTya5fqj+piTf6rZ9NEkW/dlIkk5pPkf6Hwc2zao9DFxZVb8KfAfYDpDkcmALcEXX584kK7o+HwO2ARu62+zHlCSdYacN/ar6EvCDWbUvVNXxbvUrwJpueTPwQFW9UFVPA4eBjUlWARdU1ZerqoB7gRsX6TlIkuZpMc7p/wHwULe8GjgytG26q63ulmfX55RkW5KpJFMzMzOLMERJEvQM/SR/DhwH7nuxNEezOkV9TlW1q6omq2pyYmKizxAlSUNG/j79JFuBG4DrulM2MDiCXzvUbA3wbFdfM0ddkjRGIx3pJ9kE/Bnwtqr68dCmvcCWJOcmWc/ggu2BqjoKPJ/k6u5dO+8CHuw5dknSAp32SD/J/cC1wCVJpoHbGbxb51zg4e6dl1+pqvdU1cEke4AnGJz2uaWqTnQP9V4G7wQ6j8E1gIeQJI3VaUO/qt4+R/nuU7TfCeycoz4FXLmg0UmSFpWfyJWkhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIStP1yDJPcANwLGqurKrXQz8A7AO+B7w+1X1X9227cDNwAng/VX1+a7+JuDjwHnA54Bbq6oW9+n8vB37r51V6O52nMm9StIr13yO9D8ObJpVuw3YV1UbgH3dOkkuB7YAV3R97kyyouvzMWAbsKG7zX5MSdIZdtrQr6ovAT+YVd4M7O6WdwM3DtUfqKoXqupp4DCwMckq4IKq+nJ3dH/vUB9J0piMek7/sqo6CtDdX9rVVwNHhtpNd7XV3fLsuiRpjBb7Qm7mqNUp6nM/SLItyVSSqZmZmUUbnCS1btTQf647ZUN3f6yrTwNrh9qtAZ7t6mvmqM+pqnZV1WRVTU5MTIw4REnSbKOG/l5ga7e8FXhwqL4lyblJ1jO4YHugOwX0fJKrkwR411AfSdKYzOctm/cD1wKXJJkGbgfuAPYkuRl4BrgJoKoOJtkDPAEcB26pqhPdQ72Xl96y+VB3kySN0WlDv6refpJN152k/U5g5xz1KeDKBY1OkrSo/ESuJDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ3pFfpJ/jjJwSSPJ7k/yWuSXJzk4SRPdfcXDbXfnuRwkieTXN9/+JKkhRg59JOsBt4PTFbVlcAKYAtwG7CvqjYA+7p1klzebb8C2ATcmWRFv+FLkhai7+mdlcB5SVYCrwWeBTYDu7vtu4Ebu+XNwANV9UJVPQ0cBjb23L8kaQFGDv2q+nfgr4BngKPAf1fVF4DLqupo1+YocGnXZTVwZOghpruaJGlM+pzeuYjB0ft64BeB1yV5x6m6zFGrkzz2tiRTSaZmZmZGHaIkaZY+p3d+B3i6qmaq6v+ATwO/BTyXZBVAd3+saz8NrB3qv4bB6aCXqapdVTVZVZMTExM9hihJGtYn9J8Brk7y2iQBrgMOAXuBrV2brcCD3fJeYEuSc5OsBzYAB3rsX5K0QCtH7VhVjyT5JPA14DjwGLALOB/Yk+RmBi8MN3XtDybZAzzRtb+lqk70HL8kaQFGDn2AqroduH1W+QUGR/1ztd8J7OyzT0nS6PxEriQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kN6RX6SS5M8skk305yKMlvJrk4ycNJnuruLxpqvz3J4SRPJrm+//AlSQvR90j/I8A/VtUvA78GHAJuA/ZV1QZgX7dOksuBLcAVwCbgziQreu5fkrQAI4d+kguANwN3A1TVT6rqh8BmYHfXbDdwY7e8GXigql6oqqeBw8DGUfcvSVq4Pkf6rwdmgL9L8liSu5K8Drisqo4CdPeXdu1XA0eG+k93NUnSmPQJ/ZXAVcDHquqNwP/Snco5icxRqzkbJtuSTCWZmpmZ6TFESdKwPqE/DUxX1SPd+icZvAg8l2QVQHd/bKj92qH+a4Bn53rgqtpVVZNVNTkxMdFjiJKkYSOHflX9B3AkyRu60nXAE8BeYGtX2wo82C3vBbYkOTfJemADcGDU/UuSFm5lz/5/BNyX5NXAd4F3M3gh2ZPkZuAZ4CaAqjqYZA+DF4bjwC1VdaLn/iVJC9Ar9Kvq68DkHJuuO0n7ncDOPvuUJI3OT+RKUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5Ia0jv0k6xI8liSz3brFyd5OMlT3f1FQ223Jzmc5Mkk1/fdtyRpYRbjSP9W4NDQ+m3AvqraAOzr1klyObAFuALYBNyZZMUi7F+SNE+9Qj/JGuCtwF1D5c3A7m55N3DjUP2Bqnqhqp4GDgMb++xfkrQwfY/0Pwx8EPjpUO2yqjoK0N1f2tVXA0eG2k13tZdJsi3JVJKpmZmZnkOUJL1o5NBPcgNwrKoenW+XOWo1V8Oq2lVVk1U1OTExMeoQJUmzrOzR9xrgbUneArwGuCDJJ4DnkqyqqqNJVgHHuvbTwNqh/muAZ3vsX5K0QCMf6VfV9qpaU1XrGFyg/aeqegewF9jaNdsKPNgt7wW2JDk3yXpgA3Bg5JFLkhasz5H+ydwB7ElyM/AMcBNAVR1Msgd4AjgO3FJVJ87A/iVJJ7EooV9V+4H93fJ/AtedpN1OYOdi7FOStHB+IleSGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhowc+knWJvlikkNJDia5tatfnOThJE919xcN9dme5HCSJ5NcvxhPQJI0f32O9I8Df1pVvwJcDdyS5HLgNmBfVW0A9nXrdNu2AFcAm4A7k6zoM3hJ0sKMHPpVdbSqvtYtPw8cAlYDm4HdXbPdwI3d8mbggap6oaqeBg4DG0fdvyRp4RblnH6SdcAbgUeAy6rqKAxeGIBLu2argSND3aa72lyPty3JVJKpmZmZxRiiJIlFCP0k5wOfAj5QVT86VdM5ajVXw6raVVWTVTU5MTHRd4iSpE6v0E9yDoPAv6+qPt2Vn0uyqtu+CjjW1aeBtUPd1wDP9tm/JGlh+rx7J8DdwKGq+uuhTXuBrd3yVuDBofqWJOcmWQ9sAA6Mun9J0sKt7NH3GuCdwLeSfL2rfQi4A9iT5GbgGeAmgKo6mGQP8ASDd/7cUlUneuxfkrRAI4d+Vf0Lc5+nB7juJH12AjtH3ackqR8/kStJDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kN6fPfJbZrx4751STpFcYjfUlqiKEvSQ0x9CWpIYa+JDWkrQu5+/cP7nfsf6k2+wKsF2l/3nzmZ5yPo1cu/42XhbGHfpJNwEeAFcBdVXXHuMewY/+1QytDizuQpLPaWEM/yQrgb4DfBaaBrybZW1VPjHMcJ7NjBzD8gvBifczjkKQzZdxH+huBw1X1XYAkDwCbgVdE6J/My/4CmOOFYT5/MZzqL4mF9lnoXyVL9Tg/q8+es0Uaj6SFSVWNb2fJ7wGbquoPu/V3Ar9RVe+b1W4bsK1bfQPw5Ii7vAT4/oh9zybOw4DzMOA8vORsnotfqqqJ2cVxH+lnjtrLXnWqahewq/fOkqmqmuz7OMud8zDgPAw4Dy9pcS7G/ZbNaWDt0Poa4Nkxj0GSmjXu0P8qsCHJ+iSvBrYAe8c8Bklq1lhP71TV8STvAz7P4C2b91TVwTO4y96niM4SzsOA8zDgPLykubkY64VcSdLS8msYJKkhhr4kNWRZhn6STUmeTHI4yW1zbE+Sj3bbv5nkqvn2XU56zsM9SY4leXy8oz4zRp2LJGuTfDHJoSQHk9w6/tEvnh7z8JokB5J8o5uHvxj/6BdPn9+NbvuKJI8l+ez4Rj0mVbWsbgwuAP8r8Hrg1cA3gMtntXkL8BCDzwVcDTwy377L5dZnHrptbwauAh5f6ueyxD8Tq4CruuVfAL7T4s9Et35+t3wO8Ahw9VI/p3HPw9D2PwH+HvjsUj+fxb4txyP9n32VQ1X9BHjxqxyGbQburYGvABcmWTXPvstFn3mgqr4E/GCsIz5zRp6LqjpaVV8DqKrngUPA6nEOfhH1mYeqqv/p2pzT3Zbruzx6/W4kWQO8FbhrnIMel+UY+quBI0Pr07z8l/RkbebTd7noMw9nm0WZiyTrgDcyOMpdjnrNQ3dK4+vAMeDhqmpyHoAPAx8EfnqGxreklmPoz+erHE7WZl5fA7FM9JmHs03vuUhyPvAp4ANV9aNFHNs49ZqHqjpRVb/O4JPyG5NcubjDG5uR5yHJDcCxqnp08Yf1yrAcQ38+X+VwsjZn09dA9JmHs02vuUhyDoPAv6+qPn0Gx3mmLcrPRFX9ENgPbFr0EY5Hn3m4Bnhbku8xOC3020k+ceaGugSW+qLCQm8MPkX8XWA9L12kuWJWm7fy8xdpDsy373K59ZmHoe3rODsu5Pb5mQhwL/DhpX4eSzwPE8CF3fJ5wD8DNyz1cxr3PMxqcy1n4YXcZfffJdZJvsohyXu67X8LfI7B1fnDwI+Bd5+q7xI8jd76zANAkvsZ/FBfkmQauL2q7h7vs1gcPefiGuCdwLe689kAH6qqz43xKSyKnvOwCtjd/UdHrwL2VNWyfLti39+Ns51fwyBJDVmO5/QlSSMy9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JD/h/nZkT2ywPlcQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model_score is: 0.03624265270535881\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAQsElEQVR4nO3dbYxmZX3H8e+vrFRADUuZ3a4iXU02WGMi0KlFaQx1paFK3H1RDCbabYPZmNRWbY1Z2xeOL5rQxBht0phsUDutilLE7sakVjJKmiaWMiAquCg+ICLr7khFrCYK+u+L+6wsw8zOmfthZi7m+0km55zrPmfv/zWz+9trrvs8pKqQJLXn19a7AEnScAxwSWqUAS5JjTLAJalRBrgkNWrLWr7ZueeeWzt37lzLt5Sk5t1+++0/qKqpxe1rGuA7d+5kfn5+Ld9SkpqX5DtLtTuFIkmNMsAlqVEGuCQ1ygCXpEYZ4JLUKANckhplgEtSowxwSWqUAS5JjVrTKzH1FDEzs/S6pDXlCFySGmWAS1KjegV4krcluTvJXUmuT/L0JOckuTnJvd1y66SLlSQ9bsUAT/Ic4C+B6ap6EXAacDVwAJirql3AXLctSVojfadQtgBnJNkCnAk8COwBZrvXZ4G9Y69OkrSsFQO8qr4HvAe4HzgK/KiqPgtsr6qj3T5HgW1LHZ9kf5L5JPMLCwvjq1ySNrk+UyhbGYy2nwc8Gzgryev7vkFVHayq6aqanpp60gMlJElD6jOF8krg21W1UFWPAjcBLwOOJdkB0C2PT65MSdJifQL8fuCSJGcmCbAbOAIcBvZ1++wDDk2mREnSUla8ErOqbk1yI3AH8BjwReAg8AzghiTXMAj5qyZZqCTpiXpdSl9V7wLetaj5ZwxG45KkdeCVmJLUKANckhplgEtSowxwSWqUAS5JjTLAJalRBrgkNcoAl6RGGeCS1CgDXJIaZYBLUqMMcElqlAEuSY0ywCWpUQa4JDXKAJekRvV5qPEFSe486euRJG9Nck6Sm5Pc2y23rkXBkqSBFQO8qr5WVRdW1YXA7wA/BT4FHADmqmoXMNdtS5LWyGqnUHYD36yq7wB7gNmufRbYO8a6JEkrWG2AXw1c361vr6qjAN1y21IHJNmfZD7J/MLCwvCVSpKeoHeAJzkdeA3wr6t5g6o6WFXTVTU9NTW12vokSctYzQj8j4A7qupYt30syQ6Abnl83MVJkpa3mgB/HY9PnwAcBvZ16/uAQ+MqSpK0sl4BnuRM4HLgppOarwUuT3Jv99q14y9PkrScLX12qqqfAr+xqO0hBmelSJLWgVdiSlKjDHBJapQBLkmNMsAlqVEGuCQ1ygCXpEYZ4JLUKANckhplgEtSowxwSWqUAS5JjTLAJalRBrgkNcoAl6RGGeCS1CgDXJIa1feJPGcnuTHJPUmOJHlpknOS3Jzk3m65ddLFSpIe13cE/n7gM1X1AuDFwBHgADBXVbuAuW5bkrRGVgzwJM8CXg58EKCqfl5VDwN7gNlut1lg72RKlCQtpc8I/PnAAvDhJF9Mcl2Ss4DtVXUUoFtuW+rgJPuTzCeZX1hYGFvhkrTZ9QnwLcDFwAeq6iLgJ6xiuqSqDlbVdFVNT01NDVmmJGmxPgH+APBAVd3abd/IINCPJdkB0C2PT6ZESdJSVgzwqvo+8N0kF3RNu4GvAoeBfV3bPuDQRCqUJC1pS8/9/gL4aJLTgW8Bf8Yg/G9Icg1wP3DVZEqUJC2lV4BX1Z3A9BIv7R5rNZKk3rwSU5IaZYBLUqMMcElqlAEuSY0ywCWpUQa4JDXKAJekRvW9kGdzm5lZel2S1pEjcElqlAEuSY0ywCWpUQa4JDXKAJekRhngktQoA1ySGmWAS1Kjel3Ik+Q+4MfAL4DHqmo6yTnAJ4CdwH3Aa6vqh5MpU5K02GpG4H9QVRdW1Ykn8xwA5qpqFzDHKp5UL0ka3ShTKHuA2W59Ftg7cjWSpN76BngBn01ye5L9Xdv2qjoK0C23TaJASdLS+t7M6tKqejDJNuDmJPf0fYMu8PcDnH/++UOUKElaSq8ReFU92C2PA58CXgIcS7IDoFseX+bYg1U1XVXTU1NT46lakrRygCc5K8kzT6wDfwjcBRwG9nW77QMOTapISdKT9ZlC2Q58KsmJ/T9WVZ9JchtwQ5JrgPuBqyZXpiRpsRUDvKq+Bbx4ifaHgN2TKEqStDKvxJSkRhngktQoA1ySGmWAS1KjDHBJapQBLkmNMsAlqVEGuCQ1ygCXpEYZ4JLUKANckhplgEtSowxwSWqUAS5JjTLAJalRBrgkNarvQ41JchowD3yvqq5Mcg7wCWAncB/w2qr64SSK3JRmZpZeX+m1ze5U3yvpKWY1I/C3AEdO2j4AzFXVLmCu25YkrZFeAZ7kPODVwHUnNe8BZrv1WWDvWCuTJJ1S3xH4+4B3AL88qW17VR0F6JbbxluaJOlUVgzwJFcCx6vq9mHeIMn+JPNJ5hcWFob5IyRJS+gzAr8UeE2S+4CPA69I8hHgWJIdAN3y+FIHV9XBqpququmpqakxlS1JWjHAq+qdVXVeVe0ErgY+V1WvBw4D+7rd9gGHJlalJOlJRjkP/Frg8iT3Apd325KkNdL7PHCAqroFuKVbfwjYPf6SJEl9eCWmJDXKAJekRhngktQoA1ySGmWAS1KjDHBJapQBLkmNMsAlqVEGuCQ1ygCXpEYZ4JLUKANckhplgEtSowxwSWqUAS5JjTLAJalRfR5q/PQk/5PkS0nuTvLurv2cJDcnubdbbp18uZKkE/qMwH8GvKKqXgxcCFyR5BLgADBXVbuAuW5bkrRG+jzUuKrq/7rNp3VfBewBZrv2WWDvJAqUJC2t1xx4ktOS3AkcB26uqluB7VV1FKBbbptYlZKkJ+kV4FX1i6q6EDgPeEmSF/V9gyT7k8wnmV9YWBiyTEnSYqs6C6WqHmbwVPorgGNJdgB0y+PLHHOwqqaranpqamq0aiVJv7JlpR2STAGPVtXDSc4AXgn8PXAY2Adc2y0PTbLQjWhmZrLtknQqKwY4sAOYTXIagxH7DVX16SRfAG5Icg1wP3DVBOuUJC2yYoBX1ZeBi5ZofwjYPYmiJEkr80pMSWpUnykUrYVWJ8IX170e/dhI37uVatlItap5BvgGNnPLZd3KovY1rkPSxuQUiiQ1yhF4D78aCYPDX0kbhiNwSWqUAS5JjTLAJalRBrgkNcoPMSfAU30lrQVH4JLUKANckhplgEtSo5wD3wBmZoCTLxaSpB6aD/DN+JCE5a4MfSr3WdKTOYUiSY0ywCWpUSsGeJLnJvl8kiNJ7k7ylq79nCQ3J7m3W26dfLmSpBP6jMAfA/66qn4buAT48yQvBA4Ac1W1C5jrtiVJa2TFAK+qo1V1R7f+Y+AI8BxgDzDb7TYL7J1QjZKkJaxqDjzJTgYPOL4V2F5VR2EQ8sC2ZY7Zn2Q+yfzCwsKI5UqSTugd4EmeAXwSeGtVPdL3uKo6WFXTVTU9NTU1TI2SpCX0CvAkT2MQ3h+tqpu65mNJdnSv7wCOT6ZESdJSVryQJ0mADwJHquq9J710GNgHXNstD02kwiFtxgt8JG0ufa7EvBR4A/CVJHd2bX/DILhvSHINcD9w1UQqlCQtacUAr6r/ArLMy7vHW44kqS+vxJSkRhngktQoA1ySGtX87WQ1fqc6U8ezeKSNY9MFuAH0uGG+F8s9fGLmsltGK0bSqjmFIkmNMsAlqVGbbgrlqcyrT6XNxRG4JDXKEXgLbrlluNdOmFlmnyU+jBzZ4uH+sKe0jOtUmI3868ewta30PT55ezU/DzXHEbgkNcoRuMZiZpnR/MyaViFtLo7AJalRjsA3geVGx5LaZoBrXXhFpzQ6p1AkqVF9Hqn2IeBK4HhVvahrOwf4BLATuA94bVX9cHJlqlWTPmtt2Q9PHclrE+gzAv8n4IpFbQeAuaraBcx125KkNbRigFfVfwL/u6h5DzDbrc8Ce8dbliRpJcN+iLm9qo4CVNXRJNuW2zHJfmA/wPnnnz/k22mz+NWUyMyi9kXbktbgLJSqOggcBJienq5Jv58Ezo1rcxj2LJRjSXYAdMvj4ytJktTHsAF+GNjXre8DDo2nHElSX31OI7weuAw4N8kDwLuAa4EbklwD3A9cNckipSfMgXtlqQT0CPCqet0yL+0ecy2n5IdYkvREXokpSY0ywCWpUQa4JDXKAJekRnk7WekUTnUvdS8K0npzBC5JjXIErk3FpxPpqcQRuCQ1yhG4NKTV3jBr5pbLnniXxe5459I1LEfgktQoA1ySGuUUijRmflCqteIIXJIaZYBLUqOcQpGeIpZ8nuji6ZyTXvMWze1zBC5JjRppBJ7kCuD9wGnAdVV17ViqkjaRVX/oObNoe8wfmi43Ml9t+0qvaXRDB3iS04B/BC4HHgBuS3K4qr46ruIkbRzjDOPV/lnj/E/lqWSUEfhLgG9U1bcAknwc2AMY4JLW1XoF+1r/NpKqGu7A5I+BK6rqjd32G4Dfq6o3L9pvP7C/27wA+Nrw5a67c4EfrHcRE2Lf2mTf2rWa/v1WVU0tbhxlBJ4l2p70v0FVHQQOjvA+G0aS+aqaXu86JsG+tcm+tWsc/RvlLJQHgOeetH0e8OAoxUiS+hslwG8DdiV5XpLTgauBw+MpS5K0kqGnUKrqsSRvBv6DwWmEH6qqu8dW2cb0lJgKWoZ9a5N9a9fI/Rv6Q0xJ0vrySkxJapQBLkmNMsAZ3BIgydeSfCPJgSVeT5J/6F7/cpKLu/bnJvl8kiNJ7k7ylrWv/tSG7dtJr5+W5ItJPr12VfczSt+SnJ3kxiT3dD+/l65t9SsbsX9v6/5O3pXk+iRPX9vqT61H316Q5AtJfpbk7as5dr0N27eh8qSqNvUXgw9gvwk8Hzgd+BLwwkX7vAr4dwbnvl8C3Nq17wAu7tafCXx98bGt9u2k1/8K+Bjw6fXuzzj7BswCb+zWTwfOXu8+jfHv5XOAbwNndNs3AH+63n1aZd+2Ab8L/B3w9tUc23DfVp0njsBPuiVAVf0cOHFLgJPtAf65Bv4bODvJjqo6WlV3AFTVj4EjDP7xbBRD9w0gyXnAq4Hr1rLonobuW5JnAS8HPghQVT+vqofXsPY+RvrZMTjD7IwkW4Az2VjXaKzYt6o6XlW3AY+u9th1NnTfhskTA3zwDfruSdsP8ORv2or7JNkJXATcOv4ShzZq394HvAP45YTqG8UofXs+sAB8uJseui7JWZMsdghD96+qvge8B7gfOAr8qKo+O8FaV6tP3yZx7FoYS31988QA73dLgFPuk+QZwCeBt1bVI2OsbVRD9y3JlcDxqrp9/GWNxSg/ty3AxcAHquoi4CfARptLHeVnt5XBqO95wLOBs5K8fsz1jaLXbTgmcOxaGLm+1eSJAd7vlgDL7pPkaQy+2R+tqpsmWOcwRunbpcBrktzH4NfAVyT5yORKXbVR+vYA8EBVnRjd3Mgg0DeSUfr3SuDbVbVQVY8CNwEvm2CtqzXKbTg2+i08RqpvtXligPe7JcBh4E+6T/0vYfAr6dEkYTCPeqSq3ru2ZfcydN+q6p1VdV5V7eyO+1xVbaRR3Ch9+z7w3SQXdPvtZuPdBnno/jGYOrkkyZnd39HdDOZTN4pRbsOx0W/hMXR9Q+XJen9quxG+GHya/3UGnx7/bdf2JuBN3XoYPLzim8BXgOmu/fcZ/Hr0ZeDO7utV692fcfRt0Z9xGRvsLJRR+wZcCMx3P7t/A7aud3/G3L93A/cAdwH/Avz6evdnlX37TQaj2UeAh7v1Zy137Eb6GrZvw+SJl9JLUqOcQpGkRhngktQoA1ySGmWAS1KjDHBJapQBLkmNMsAlqVH/D6I5tPCKhUkRAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model_score is: 0.00016663334475956542\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAORUlEQVR4nO3cb8jd5X3H8fdn0TqZLdUZJSRxcSWMRdmshizQMTIcM/NJLFSID2oeOLKKQgvdA91gvfcg4AbtmFCFdIpxdEqgLebB3CahQQZWe9tZTbTWrHaaJph0bqt74qr97sG5sp3dnvtP7j8n99n1fsGP8zvf33Wdc11et5/8zu/8SVUhSerDz53vAUiSxsfQl6SOGPqS1BFDX5I6YuhLUkcuON8DmM/ll19emzZtOt/DkKSJ8vzzz/+4qtbOrK/60N+0aRPT09PnexiSNFGS/Muoupd3JKkjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI6v+G7lLMjU1931J6oxn+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHZk39JNsTPLNJK8kOZbks61+WZKnkrzWbi8d6nNvkuNJXk1y01D9hiQvtWP3J8nKTEuSNMpCzvTfAz5fVb8KbAfuSrIFuAc4XFWbgcPtPu3YbuAaYCfwQJI17bEeBPYCm9u2cxnnIkmax7yhX1Wnquo7bf8d4BVgPbALONCaHQBuafu7gMer6t2qeh04DmxLsg74SFU9U1UFPDrUR5I0Bud0TT/JJuDjwLPAlVV1Cgb/MABXtGbrgTeHup1otfVtf2Z91PPsTTKdZPrMmTPnMkRJ0hwWHPpJLgG+Bnyuqn4yV9MRtZqj/sFi1f6q2lpVW9euXbvQIUqS5rGg0E9yIYPA/2pVfb2V32qXbGi3p1v9BLBxqPsG4GSrbxhRlySNyUI+vRPgIeCVqvrS0KFDwJ62vwd4Yqi+O8lFSa5m8Ibtc+0S0DtJtrfHvH2ojyRpDC5YQJtPAJ8GXkryQqv9EXAfcDDJHcAbwK0AVXUsyUHgZQaf/Lmrqt5v/e4EHgEuBp5smyRpTOYN/ar6R0Zfjwe4cZY++4B9I+rTwLXnMkBJ0vLxG7mS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOjJv6Cd5OMnpJEeHalNJfpTkhbbdPHTs3iTHk7ya5Kah+g1JXmrH7k+S5Z+OJGkuCznTfwTYOaL+F1V1Xdv+FiDJFmA3cE3r80CSNa39g8BeYHPbRj2mJGkFzRv6VfU08PYCH28X8HhVvVtVrwPHgW1J1gEfqapnqqqAR4FbFjlmSdIiXbCEvncnuR2YBj5fVf8GrAe+NdTmRKv9tO3PrI+UZC+DVwVcddVVix7g1JEdMwrtZmrRDylJE22xb+Q+CHwMuA44BXyx1Uddp6856iNV1f6q2lpVW9euXbvIIUqSZlpU6FfVW1X1flX9DPgKsK0dOgFsHGq6ATjZ6htG1CVJY7So0G/X6M/6JHD2kz2HgN1JLkpyNYM3bJ+rqlPAO0m2t0/t3A48sYRxS5IWYd5r+kkeA3YAlyc5AXwB2JHkOgaXaH4I/AFAVR1LchB4GXgPuKuq3m8PdSeDTwJdDDzZNknSGM0b+lV124jyQ3O03wfsG1GfBq49p9FJkpaV38iVpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6Mm/oJ3k4yekkR4dqlyV5Kslr7fbSoWP3Jjme5NUkNw3Vb0jyUjt2f5Is/3QkSXNZyJn+I8DOGbV7gMNVtRk43O6TZAuwG7im9XkgyZrW50FgL7C5bTMfU5K0wuYN/ap6Gnh7RnkXcKDtHwBuGao/XlXvVtXrwHFgW5J1wEeq6pmqKuDRoT6SpDFZ7DX9K6vqFEC7vaLV1wNvDrU70Wrr2/7M+khJ9iaZTjJ95syZRQ5RkjTTcr+RO+o6fc1RH6mq9lfV1qraunbt2mUbnCT1brGh/1a7ZEO7Pd3qJ4CNQ+02ACdbfcOIuiRpjBYb+oeAPW1/D/DEUH13kouSXM3gDdvn2iWgd5Jsb5/auX2ojyRpTC6Yr0GSx4AdwOVJTgBfAO4DDia5A3gDuBWgqo4lOQi8DLwH3FVV77eHupPBJ4EuBp5smyRpjOYN/aq6bZZDN87Sfh+wb0R9Grj2nEYnSVpWfiNXkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkeWFPpJfpjkpSQvJJlutcuSPJXktXZ76VD7e5McT/JqkpuWOnhJ0rlZjjP9366q66pqa7t/D3C4qjYDh9t9kmwBdgPXADuBB5KsWYbnlyQt0Epc3tkFHGj7B4BbhuqPV9W7VfU6cBzYtgLPL0maxVJDv4B/SPJ8kr2tdmVVnQJot1e0+nrgzaG+J1rtA5LsTTKdZPrMmTNLHKIk6awLltj/E1V1MskVwFNJvjdH24yo1aiGVbUf2A+wdevWkW0kSeduSWf6VXWy3Z4GvsHgcs1bSdYBtNvTrfkJYONQ9w3AyaU8vyTp3Cw69JP8QpIPn90Hfhc4ChwC9rRme4An2v4hYHeSi5JcDWwGnlvs80uSzt1SLu9cCXwjydnH+Zuq+rsk3wYOJrkDeAO4FaCqjiU5CLwMvAfcVVXvL2n0kqRzsujQr6ofAL8+ov6vwI2z9NkH7Fvsc0qSlsZv5EpSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR3pK/SPHBlsU1PneSCSdH70FfqS1DlDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHbngfA9g1ZuaGr2vPs31N7DQvw//pnQeeaYvSR0Z+5l+kp3AXwJrgL+qqvvGPYapIztgakR9RE2S/j8Z65l+kjXAl4HfA7YAtyXZMs4xSFLPxn2mvw04XlU/AEjyOLALeHnM4xhp5Jn+kR1M7Tiy8PaLqM93bDksZkwa+D//jY7smKPhiPbSKpOqGt+TJZ8CdlbV77f7nwZ+o6runtFuL7C33f0V4NVFPuXlwI8X2Xe1cA6rg3NYHZzDwv1SVa2dWRz3mX5G1D7wr05V7Qf2L/nJkumq2rrUxzmfnMPq4BxWB+ewdOP+9M4JYOPQ/Q3AyTGPQZK6Ne7Q/zawOcnVST4E7AYOjXkMktStsV7eqar3ktwN/D2Dj2w+XFXHVvApl3yJaBVwDquDc1gdnMMSjfWNXEnS+eU3ciWpI4a+JHVkYkI/yc4kryY5nuSeEceT5P52/MUk18/XN8llSZ5K8lq7vXQC5zCV5EdJXmjbzat4Dg8nOZ3k6Iw+k7QOs81hItYhycYk30zySpJjST471Gci1mGeOUzKOvx8kueSfLfN4U+H+qzsOlTVqt8YvOn7z8AvAx8CvgtsmdHmZuBJBt8F2A48O19f4M+Be9r+PcCfTeAcpoA/XO3r0I79FnA9cHRGn4lYh3nmMBHrAKwDrm/7Hwa+P4H/P8w1h0lZhwCXtP0LgWeB7eNYh0k50/+fn2+oqv8Czv58w7BdwKM18C3go0nWzdN3F3Cg7R8AbpnAOYzTUuZAVT0NvD3icSdlHeaawzgteg5VdaqqvgNQVe8ArwDrh/qs+nWYZw7jtJQ5VFX9Z2tzYdtqqM+KrcOkhP564M2h+yf44CLP1mauvldW1SmAdnvFMo55ppWaA8Dd7aXjwyv8knwpc5jLpKzDfCZqHZJsAj7O4CwTJnAdRswBJmQdkqxJ8gJwGniqqsayDpMS+gv5+YbZ2izopx/GYKXm8CDwMeA64BTwxUWObyGWMofVYqXmMFHrkOQS4GvA56rqJ8s4toVaqTlMzDpU1ftVdR2DXybYluTa5R3eaJMS+gv5+YbZ2szV962zL9vb7ellHPNMKzKHqnqr/fH8DPgKg5ecK2Upc5jLpKzDrCZpHZJcyCAsv1pVXx9qMzHrMNscJmkdzqqqfweOADtbaUXXYVJCfyE/33AIuL29W74d+I/20miuvoeAPW1/D/DEpM3h7B9H80ngKCtnKXOYy6Ssw6wmZR2SBHgIeKWqvjSiz6pfh7nmMEHrsDbJR9uYLwZ+B/jeUJ+VW4flfFd4JTcG74J/n8G75X/cap8BPlP/+274l9vxl4Ctc/Vt9V8EDgOvtdvLJnAOf93avsjgj2XdKp7DYwxecv+UwRnQHRO4DrPNYSLWAfhNBpcXXgReaNvNk7QO88xhUtbh14B/auM8CvzJ0GOu6Dr4MwyS1JFJubwjSVoGhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqyH8DQ3/3pA2rVw8AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model_score is: 0.03305234825505061\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model_score is: 0.005013101425471561\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for ind, row in para_dfm.iterrows():\n",
    "    print(f\"The model_score is: {row['model_score']}\")\n",
    "    model_pred = model_list[ind]\n",
    "    X_pred = model_pred.predict(X_val)\n",
    "    mse = np.mean(np.power(X_val.flatten() - X_pred.flatten(), 2))\n",
    "    reconstructions = model_pred.predict(X_val)\n",
    "    val_loss = tf.keras.losses.mse(reconstructions, X_val)\n",
    "    df_tmp = pd.DataFrame({\"val_loss\": val_loss, \"y_val\": y_val.flatten()})\n",
    "    df_tmp_fraud = df_tmp[df_tmp[\"y_val\"] == 1]\n",
    "    df_tmp_non_fraud = df_tmp[df_tmp[\"y_val\"] == 0]\n",
    "    plt.hist(df_tmp_fraud[\"val_loss\"], bins=50, alpha=0.5, label=\"fraud\", color=\"red\",density=True)\n",
    "    plt.hist(df_tmp_non_fraud[\"val_loss\"], bins=50, alpha=0.5, label=\"non_fraud\", color=\"blue\",density=True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the relationship between model_score and other columns, we can find a very significant linear relationship between these columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_performance_diff_sens.plot(x='model_score', y='sensitivity', kind='scatter',title='Sensitivity_model_score')\n",
    "plt.show()\n",
    "df_performance_diff_sens.plot(x='model_score', y='roc', kind='scatter',title='ROC_model_score')\n",
    "plt.show()\n",
    "df_performance_diff_sens.plot(x='model_score', y='accuracy_rate', kind='scatter',title='Accuracy_model_score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use statsmodel to test whether it is significant. We can find the p-value of the model is very low, which means the model is significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statsmodels linear regression betwen model_score and sensitivity\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.887\n",
      "Model:                            OLS   Adj. R-squared:                  0.883\n",
      "Method:                 Least Squares   F-statistic:                     220.8\n",
      "Date:                Wed, 09 Mar 2022   Prob (F-statistic):           8.27e-15\n",
      "Time:                        11:59:09   Log-Likelihood:                 44.392\n",
      "No. Observations:                  30   AIC:                            -84.78\n",
      "Df Residuals:                      28   BIC:                            -81.98\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.4530      0.013     34.100      0.000       0.426       0.480\n",
      "x1            11.4472      0.770     14.858      0.000       9.869      13.025\n",
      "==============================================================================\n",
      "Omnibus:                        0.488   Durbin-Watson:                   2.306\n",
      "Prob(Omnibus):                  0.783   Jarque-Bera (JB):                0.619\n",
      "Skew:                          -0.219   Prob(JB):                        0.734\n",
      "Kurtosis:                       2.449   Cond. No.                         74.0\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "Statsmodels linear regression betwen model_score and accuracy_rate\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.822\n",
      "Model:                            OLS   Adj. R-squared:                  0.815\n",
      "Method:                 Least Squares   F-statistic:                     129.2\n",
      "Date:                Wed, 09 Mar 2022   Prob (F-statistic):           5.32e-12\n",
      "Time:                        11:59:09   Log-Likelihood:                 62.216\n",
      "No. Observations:                  30   AIC:                            -120.4\n",
      "Df Residuals:                      28   BIC:                            -117.6\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.7301      0.007     99.551      0.000       0.715       0.745\n",
      "x1            -4.8333      0.425    -11.365      0.000      -5.705      -3.962\n",
      "==============================================================================\n",
      "Omnibus:                        1.789   Durbin-Watson:                   2.316\n",
      "Prob(Omnibus):                  0.409   Jarque-Bera (JB):                1.496\n",
      "Skew:                          -0.395   Prob(JB):                        0.473\n",
      "Kurtosis:                       2.243   Cond. No.                         74.0\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "-------------------------------------------------------\n",
      "Statsmodels linear regression betwen model_score and roc\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.815\n",
      "Model:                            OLS   Adj. R-squared:                  0.809\n",
      "Method:                 Least Squares   F-statistic:                     123.5\n",
      "Date:                Wed, 09 Mar 2022   Prob (F-statistic):           8.92e-12\n",
      "Time:                        11:59:09   Log-Likelihood:                 72.338\n",
      "No. Observations:                  30   AIC:                            -140.7\n",
      "Df Residuals:                      28   BIC:                            -137.9\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.6362      0.005    121.556      0.000       0.625       0.647\n",
      "x1             3.3728      0.304     11.113      0.000       2.751       3.995\n",
      "==============================================================================\n",
      "Omnibus:                        2.817   Durbin-Watson:                   1.716\n",
      "Prob(Omnibus):                  0.245   Jarque-Bera (JB):                2.083\n",
      "Skew:                           0.480   Prob(JB):                        0.353\n",
      "Kurtosis:                       2.137   Cond. No.                         74.0\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "-------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# linear regression #TODO more linear regression test\n",
    "import statsmodels.api as sm\n",
    "X  = np.array(df_performance_diff_sens['model_score'], dtype=float)\n",
    "y = np.array(df_performance_diff_sens['sensitivity'], dtype=float)\n",
    "X = sm.add_constant(X)\n",
    "print(\"Statsmodels linear regression betwen model_score and sensitivity\")\n",
    "model = sm.OLS(y, X).fit()\n",
    "print(model.summary())\n",
    "\n",
    "X = np.array(df_performance_diff_sens['model_score'], dtype=float)\n",
    "y = np.array(df_performance_diff_sens['accuracy_rate'], dtype=float)\n",
    "X = sm.add_constant(X)\n",
    "print(\"Statsmodels linear regression betwen model_score and accuracy_rate\")\n",
    "model = sm.OLS(y, X).fit()\n",
    "print(model.summary())\n",
    "print('-------------------------------------------------------')\n",
    "\n",
    "X = np.array(df_performance_diff_sens['model_score'], dtype=float)\n",
    "y = np.array(df_performance_diff_sens['roc'], dtype=float)\n",
    "X = sm.add_constant(X)\n",
    "print(\"Statsmodels linear regression betwen model_score and roc\")\n",
    "model = sm.OLS(y, X).fit()\n",
    "print(model.summary())\n",
    "print('-------------------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 8\n",
    "Based on the results of the previous question, we can use the model_score to select the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAjLklEQVR4nO3df3RU9Z3/8ec7M5mEAEICsaJIwV0EAUPASNmlFVDLgnbr6vq1WN2qp5bVtrtr96tftN+taLs9x+1Sl3WrctBFd7ce0Vq1bqXq0kKp32oVLFIQVFQqKSrhRxAIgSTz/v5xZyaTZJIMycDMTV6Pc0Jm7v3MnXcS8spnPvczn2vujoiIhF9RvgsQEZHcUKCLiPQRCnQRkT5CgS4i0kco0EVE+ohovp54+PDhPnr06Hw9vYhIKK1fv363u1dm2pe3QB89ejTr1q3L19OLiISSmf2+s33dDrmY2XIz22Vmm7poM8vMNpjZZjP7ZU8LFRGRnstmDP1hYG5nO81sKHAf8Hl3nwj8r5xUJiIix6TbQHf3tcDeLpp8EXjS3d9PtN+Vo9pEROQY5GIM/Uyg2MzWAIOBf3X3/8zU0MwWAAsARo0alYOnFpFj0dTURG1tLY2NjfkuRbpRWlrKyJEjKS4uzvoxuQj0KHAOcAEwAHjJzF5297faN3T3ZcAygJqaGi0iI3KC1dbWMnjwYEaPHo2Z5bsc6YS7s2fPHmpraxkzZkzWj8vFPPRa4Dl3P+Tuu4G1wOQcHFdEcqyxsZFhw4YpzAucmTFs2LBjfiWVi0D/CfAZM4uaWRnwKWBLDo4rIseBwjwcevJzymba4qPAS8A4M6s1sy+b2Q1mdgOAu28BngM2Aq8AD7p7p1Mce2vTHzbxrae/Rd2BuuP1FCIioZTNLJcr3X2Euxe7+0h3/3d3X+ruS9Pa/LO7T3D3Se6+5HgWvPXDrfzjs//IRx9/dDyfRkSOg/r6eu67774ePfaiiy6ivr6+yza33347q1at6tHx2xs9ejS7d+/OybFOlNCt5RKLxAA40nwkz5WIyLHqKtBbWlq6fOzKlSsZOnRol22+/e1vc+GFF/a0vNALX6BHg0A/2nw0z5WIyLG69dZbeeedd6iuruaWW25hzZo1zJ49my9+8YucffbZAPzFX/wF55xzDhMnTmTZsmWpxyZ7zNu3b+ess87iK1/5ChMnTmTOnDkcPnwYgGuvvZYnnngi1X7RokVMnTqVs88+m61btwJQV1fHZz/7WaZOncpf//Vf88lPfrLbnvjdd9/NpEmTmDRpEkuWLAHg0KFDXHzxxUyePJlJkybx2GOPpb7GCRMmUFVVxc0335zT71938raWS0+VREsABbpIb9204iY27NiQ02NWn17NkvlLOt1/1113sWnTJjZsCJ53zZo1vPLKK2zatCk1PW/58uVUVFRw+PBhzj33XP7yL/+SYcOGtTnO22+/zaOPPsoDDzzAFVdcwY9//GOuvvrqDs83fPhwXnvtNe677z4WL17Mgw8+yJ133sn555/PbbfdxnPPPdfmj0Ym69ev56GHHuI3v/kN7s6nPvUpZs6cybvvvsupp57Ks88+C8D+/fvZu3cvTz31FFu3bsXMuh0iyrXQ9tA15CLSN0ybNq3NXOt77rmHyZMnM336dHbs2MHbb7/d4TFjxoyhuroagHPOOYft27dnPPZll13Woc2LL77I/PnzAZg7dy7l5eVd1vfiiy9y6aWXMnDgQAYNGsRll13Gr371K84++2xWrVrFwoUL+dWvfsWQIUM46aSTKC0t5frrr+fJJ5+krKzsGL8bvRO6HnpyDF09dJHe6aonfSINHDgwdXvNmjWsWrWKl156ibKyMmbNmpVxLnZJSUnqdiQSSQ25dNYuEonQ3NwMBG/aORadtT/zzDNZv349K1eu5LbbbmPOnDncfvvtvPLKK/z85z9nxYoV/OAHP+AXv/jFMT1fb4Suh15SnBhyaVGgi4TN4MGDOXDgQKf79+/fT3l5OWVlZWzdupWXX3455zV8+tOf5vHHHwfghRdeYN++fV22P++883j66adpaGjg0KFDPPXUU3zmM59h586dlJWVcfXVV3PzzTfz2muvcfDgQfbv389FF13EkiVLUkNLJ0poe+hHmjTkIhI2w4YNY8aMGUyaNIl58+Zx8cUXt9k/d+5cli5dSlVVFePGjWP69Ok5r2HRokVceeWVPPbYY8ycOZMRI0YwePDgTttPnTqVa6+9lmnTpgFw/fXXM2XKFJ5//nluueUWioqKKC4u5v777+fAgQNccsklNDY24u78y7/8S87r74od68uPXKmpqfGeXODivbr3OOObZ/DwdQ9zzZ9ecxwqE+m7tmzZwllnnZXvMvLqyJEjRCIRotEoL730EjfeeOMJ70lnK9PPy8zWu3tNpvbh66HrpKiI9ML777/PFVdcQTweJxaL8cADD+S7pJwJbaDrpKiI9MTYsWP57W9/m+8yjovwnRTVPHQRkYxCF+gachERySx8ga556CIiGYUu0IuKiohGopqHLiLSTugCHYJeuoZcRPqHQYMGAbBz504uv/zyjG1mzZpFd9OglyxZQkNDQ+p+NsvxZuOOO+5g8eLFvT5OLoQy0EuiJRpyEelnTj311NRKij3RPtCzWY43bEIZ6LGoeugiYbRw4cI266HfcccdfP/73+fgwYNccMEFqaVuf/KTn3R47Pbt25k0aRIAhw8fZv78+VRVVfGFL3yhzVouN954IzU1NUycOJFFixYBwYJfO3fuZPbs2cyePRtoewGLTMvjdrVMb2c2bNjA9OnTqaqq4tJLL00tK3DPPfekltRNLgz2y1/+kurqaqqrq5kyZUqXSyJkq9t56Ga2HPgcsMvdJ3XR7lzgZeAL7t7zP6NZiEVj6qGL9NJNN/2CDRt25fSY1dUns2TJ+Z3unz9/PjfddBNf/epXAXj88cd57rnnKC0t5amnnuKkk05i9+7dTJ8+nc9//vOdXlfz/vvvp6ysjI0bN7Jx40amTp2a2vfd736XiooKWlpauOCCC9i4cSN/+7d/y913383q1asZPnx4m2N1tjxueXl51sv0Jn3pS1/i3/7t35g5cya33347d955J0uWLOGuu+7ivffeo6SkJDXMs3jxYu69915mzJjBwYMHKS0tzfbb3KlseugPA3O7amBmEeCfgOd7XVEWNOQiEk5Tpkxh165d7Ny5k9dff53y8nJGjRqFu/PNb36TqqoqLrzwQv7whz/w0UedX2Zy7dq1qWCtqqqiqqoqte/xxx9n6tSpTJkyhc2bN/PGG290WVNny+NC9sv0QrCwWH19PTNnzgTgmmuuYe3atakar7rqKn74wx8SjQb96BkzZvD3f//33HPPPdTX16e290a3R3D3tWY2uptmfwP8GDi31xVlQSdFRXqvq5708XT55ZfzxBNP8OGHH6aGHx555BHq6upYv349xcXFjB49OuOyueky9d7fe+89Fi9ezKuvvkp5eTnXXnttt8fpaj2rbJfp7c6zzz7L2rVreeaZZ/jOd77D5s2bufXWW7n44otZuXIl06dPZ9WqVYwfP75Hx0/q9Ri6mZ0GXAoszaLtAjNbZ2br6urqevycsWhM0xZFQmr+/PmsWLGCJ554IjVrZf/+/Zx88skUFxezevVqfv/733d5jPPOO49HHnkEgE2bNrFx40YAPv74YwYOHMiQIUP46KOP+NnPfpZ6TGdL93a2PO6xGjJkCOXl5ane/X/9138xc+ZM4vE4O3bsYPbs2Xzve9+jvr6egwcP8s4773D22WezcOFCampqUpfI641crOWyBFjo7i2djXclufsyYBkEqy329Ak15CISXhMnTuTAgQOcdtppjBgxAoCrrrqKP//zP6empobq6upue6o33ngj1113HVVVVVRXV6eWtp08eTJTpkxh4sSJnHHGGcyYMSP1mAULFjBv3jxGjBjB6tWrU9s7Wx63q+GVzvzHf/wHN9xwAw0NDZxxxhk89NBDtLS0cPXVV7N//37cnW984xsMHTqUb33rW6xevZpIJMKECROYN2/eMT9fe1ktn5sYcvlpppOiZvYekEzy4UADsMDdn+7qmD1dPhfgvO+dR6QowuqbV3ffWERStHxuuJzw5XPdPXUxQDN7mCD4n+7tcbtSEi2h4WhD9w1FRPqRbKYtPgrMAoabWS2wCCgGcPdux82Ph1g0xr6Gri8bJSLS32Qzy+XKbA/m7tf2qposxSKahy7SU+7e6fxuKRw9uZpcKN8pWlJcolkuIj1QWlrKnj17ehQWcuK4O3v27DnmNxuF7opFkJiHrotEixyzkSNHUltbS2+mDcuJUVpaysiRI4/pMeEMdM1DF+mR4uJixowZ031DCaVwDrloHrqISAehDHSttigi0lEoA109dBGRjkIZ6Mkeus7Ui4i0CmegJy4U3dzSnOdKREQKRygDvaQ4WNJSM11ERFqFMtCTPXSdGBURaRXOQI8Gga4ToyIirUIZ6CXRxJCLAl1EJCWUgZ7soWvIRUSkVSgDXT10EZGOQhno6qGLiHQUzkCP6KSoiEh7oQz01JCL5qGLiKR0G+hmttzMdpnZpk72X2VmGxMfvzazybkvsy0NuYiIdJRND/1hYG4X+98DZrp7FfAdYFkO6uqS5qGLiHSUzTVF15rZ6C72/zrt7svAsV1iowc0y0VEpKNcj6F/GfhZZzvNbIGZrTOzdb25BJaGXEREOspZoJvZbIJAX9hZG3df5u417l5TWVnZ4+dSD11EpKOcXFPUzKqAB4F57r4nF8fsihbnEhHpqNc9dDMbBTwJ/JW7v9X7krqXOimqaYsiIind9tDN7FFgFjDczGqBRUAxgLsvBW4HhgH3mRlAs7vXHK+CQUMuIiKZZDPL5cpu9l8PXJ+zirKgk6IiIh2F8p2imocuItJRKAM9UhQhUhRRoIuIpAlloEPQS9eQi4hIq9AGekm0RLNcRETShDbQY5EYR5rUQxcRSQpvoEdj6qGLiKQJbaCXREt0UlREJE1oA10nRUVE2gpvoEdi6qGLiKQJbaCXFGuWi4hIutAGuma5iIi0FdpAVw9dRKSt0Aa6eugiIm2FN9A1D11EpI3QBrrmoYuItBXaQNc8dBGRtsIb6JqHLiLSRreBbmbLzWyXmW3qZL+Z2T1mts3MNprZ1NyX2ZFmuYiItJVND/1hYG4X++cBYxMfC4D7e19W92IRDbmIiKTrNtDdfS2wt4smlwD/6YGXgaFmNiJXBXZGJ0VFRNrKxRj6acCOtPu1iW0dmNkCM1tnZuvq6up69aTJk6Lu3qvjiIj0FbkIdMuwLWPKuvsyd69x95rKyspePWksGsPdaYm39Oo4IiJ9RS4CvRY4Pe3+SGBnDo7bpZJoCYCGXUREEnIR6M8AX0rMdpkO7Hf3D3Jw3C7FojEAnRgVEUmIdtfAzB4FZgHDzawWWAQUA7j7UmAlcBGwDWgArjtexaaLRYJA19RFEZFAt4Hu7ld2s9+Br+WsoixpyEVEpK3wvlNUQy4iIm2EPtDVQxcRCYQ20JNDLuqhi4gEQhvo6qGLiLQV2kDXSVERkbZCG+jJaYsachERCYQ30KOahy4iki60gZ46KaoLRYuIACEOdPXQRUTaCn+g66SoiAgQ4kDXPHQRkbZCG+jqoYuItBXaQE/NQ9cYuogIEOJAT81D1ywXEREgzIGuWS4iIm2ENtCjkShFVqQeuohIQmgDHYJeunroIiKBrALdzOaa2Ztmts3Mbs2wf4iZ/beZvW5mm83sxFyGLhrTLBcRkYRuA93MIsC9wDxgAnClmU1o1+xrwBvuPpng+qPfN7NYjmvtoCRaonnoIiIJ2fTQpwHb3P1ddz8KrAAuadfGgcFmZsAgYC/QnNNKM4hF1EMXEUnKJtBPA3ak3a9NbEv3A+AsYCfwO+Dv3D3e/kBmtsDM1pnZurq6uh6W3KqkuERj6CIiCdkEumXY5u3u/xmwATgVqAZ+YGYndXiQ+zJ3r3H3msrKymMstaNYJKZZLiIiCdkEei1wetr9kQQ98XTXAU96YBvwHjA+NyV2TrNcRERaZRPorwJjzWxM4kTnfOCZdm3eBy4AMLNPAOOAd3NZaCY6KSoi0iraXQN3bzazrwPPAxFgubtvNrMbEvuXAt8BHjaz3xEM0Sx0993HsW5A0xZFRNJ1G+gA7r4SWNlu29K02zuBObktrXua5SIi0irU7xQtKdaQi4hIUqgDXT10EZFWoQ70kqjmoYuIJIU60GPRmIZcREQSQh/oGnIREQmEOtA1D11EpFWoA109dBGRVuEO9Ije+i8ikhTqQC+JlmhxLhGRhFAHeiwaI+5xWuIt+S5FRCTvQh3oJdESAI2ji4gQ8kCPRYOr3Gmmi4hIHwl09dBFREIe6MkhF/XQRURCHuixiHroIiJJ4Q705JCL5qKLiGQX6GY218zeNLNtZnZrJ21mmdkGM9tsZr/MbZmZpYZcNBddRKT7KxaZWQS4F/gswQWjXzWzZ9z9jbQ2Q4H7gLnu/r6ZnXyc6m1DPXQRkVbZ9NCnAdvc/V13PwqsAC5p1+aLwJPu/j6Au+/KbZmZaR66iEirbAL9NGBH2v3axLZ0ZwLlZrbGzNab2ZdyVWBXNA9dRKRVNheJtgzbPMNxzgEuAAYAL5nZy+7+VpsDmS0AFgCMGjXq2KttR7NcRERaZdNDrwVOT7s/EtiZoc1z7n7I3XcDa4HJ7Q/k7svcvcbdayorK3tU8JYte/jud19m797DlBRrHrqISFI2gf4qMNbMxphZDJgPPNOuzU+Az5hZ1MzKgE8BW3JbamDLlj38wz+8yI4dB9RDFxFJ0+2Qi7s3m9nXgeeBCLDc3Teb2Q2J/UvdfYuZPQdsBOLAg+6+6XgUXF5eCsDevY2MPEWzXEREkrIZQ8fdVwIr221b2u7+PwP/nLvSMquoCAJ9375G/iga3NY8dBGREL5TNBnoe/c2ah66iEiaUAe65qGLiLQKXaCXlRVTXFzUpoeuWS4iIiEMdDOjoqKUffsaNctFRCRN6AIdgmGXvXsbiUaimJl66CIihDbQB7B3byNmRiwSUw9dRISQBnp5eQl79zYCwXoumuUiIhLSQE+OoUOw4qKGXEREQhvoA9r20DXkIiIS1kAv5cCBozQ1tVASLVGgi4gQ0kAvLw/eULRvXzAXXUMuIiIhDfSKigEA7Nt3RLNcREQSQhrobd/+rx66iEhIA711Cd3DmrYoIpIQykBvv+KihlxEREIe6Pv2HdGQi4hIQigDfejQYJZLashFPXQRkewC3czmmtmbZrbNzG7tot25ZtZiZpfnrsSOIpEihgwpSZ0UVaCLiGQR6GYWAe4F5gETgCvNbEIn7f6J4Nqjx11yxcVYRPPQRUQgux76NGCbu7/r7keBFcAlGdr9DfBjYFcO6+tUak10zXIREQGyC/TTgB1p92sT21LM7DTgUqDNhaOPp2QPvSRaootEi4iQXaBbhm3e7v4SYKG7t3R5ILMFZrbOzNbV1dVlWWJm5eWlrdMW1UMXESGaRZta4PS0+yOBne3a1AArzAxgOHCRmTW7+9Ppjdx9GbAMoKampv0fhWOSGkPXLBcRESC7QH8VGGtmY4A/APOBL6Y3cPcxydtm9jDw0/Zhnmut1xXVPHQREcgi0N292cy+TjB7JQIsd/fNZnZDYv8JGzdPV1FRSkuL40djtMRbaIm3ECmK5KMUEZGCkE0PHXdfCaxsty1jkLv7tb0vq3vJ9VzijcGbjJpamhToItKvhfKdotD69v+mQ8UAmukiIv1e+AP9cPAiQzNdRKS/C32gH1UPXUQECHGgJ8fQjxwKvgT10EWkvwttoCd76I0HE4Guuegi0s+FNtAHDCimtDRK46Hgjayaiy4i/V1oAx2CXnrDgeC2eugi0t+FOtDLy0to+DhYQUBj6CLS34U60CsqBnAwEeia5SIi/V3IA72UQwfiABw8cjDP1YiI5FfoA73hQNBD37ZrW56rERHJr1AHenl5CfX7jjJ80HC2frg13+WIiORVqAO9omIADQ3NjB1+lgJdRPq9kAd68Oai0YMU6CIioQ705Nv/TxswlroDdew9tDfPFYmI5E+oAz3ZQx8eGwXAmx++mc9yRETyqk8E+pCiUwA07CIi/VpWgW5mc83sTTPbZma3Zth/lZltTHz82swm577UjpKBHmsZSnGkmK0fKNBFpP/qNtDNLALcC8wDJgBXmtmEds3eA2a6exXwHWBZrgvNJDmGvr/+KGNPHsubH2nIRUT6r2x66NOAbe7+rrsfBVYAl6Q3cPdfu/u+xN2XgZG5LTOzIUNKMIO9exsZP2K8hlxEpF/LJtBPA3ak3a9NbOvMl4Gf9aaobBUVGeXlpezd28i4T4zjnbp3aGpuOhFPLSJScLIJdMuwzTM2NJtNEOgLO9m/wMzWmdm6urq67KvsQkVFKfv2NTL+lPE0tzTz7u53c3JcEZGwySbQa4HT0+6PBHa2b2RmVcCDwCXuvifTgdx9mbvXuHtNZWVlT+rtINlDHz9iPKCZLiLSf2UT6K8CY81sjJnFgPnAM+kNzGwU8CTwV+7+Vu7L7FxFReuQC6CZLiLSb0W7a+DuzWb2deB5IAIsd/fNZnZDYv9S4HZgGHCfmQE0u3vN8Su7VUVFKdu21TOkbAinDDlFPXQR6be6DXQAd18JrGy3bWna7euB63NbWnaSY+gA408Zr6mLItJvhfqdohCMoe/b10g87ow/ZTxbP9iKe8ZztiIifVroA72iohR32L//CONPGc++hn3UHcjNDBoRkTDpE4EOwZuLxp2SODGqcXQR6Yf6QKAPAEjNRQetuigi/VPoA3348CDQ33prH6MqRlFaXKoeuoj0S6EP9HPPPYUzzyznrrt+AxjjPjFOgS4i/VLoAz0aLWLRoj/ld7/bzY9+9CbjTlGgi0j/FPpAB/jCF8YxceIw7rjj15xZOZ7tu7fT2NSY77JERE6oPhHokUgRd945g61b97Jn4yjiHmfbrm35LktE5ITqE4EOcOmlY6muPpn/frgR4kWs2rIq3yWJiJxQfSbQi4qMb397BrW/P8wZ+67gG499g1t+dAvNLc35Lk1E5IToM4EO8LnPncG0aafQtH4WX/nTr7L4hcWc//3z+aD+g3yXJiJy3Fm+1j2pqanxdevW5fy4L7ywnT/7sycoLY0yYrTxPr9hwCf2M/2sKgaVlFFWWsag0jJi0WIg6NmDUZR+GQ+zxCU8DDJ9f4IVJSkqCpoYhhUFx0p+RCPGSUNKqCgfQEX5ACqHDeKPRnySkwefTGJFShGRY2Zm6ztbzTar1RbDZM6c0TzzzKWsWfM+Gzfu5uPXp7Nn61FW/TLZwoFD+Slu8B6in/iAk8cc5Y8nDmDyhFOpOWsck06fwPhTxlNWUpafukSkT+hzPfRM6uoaOHjwKE1NLRw4fJB9h/bT1NxE3B0H4vF4h8e4O6mOdHqHOvHtiscd96CdJ+4HH3Fa4k7T0Rbq9zdSX99Iff0Rdu8+zBub9/HulqN8XJf2d9TiMOBjGLSf4rJmSstgwMAIgwYWUzYwyoDSKKWlUUpLixlQWkwsFqEkFqUkVkxJLEIsFiVWHCVWHCEWjRKNRigujhKNFFEcjVBcHKE4GiUaiVAcjRCNRohG0j5HiogUBfsikSKiRRGsyIhGiohGkrcjRIqMoqIiIpEiiqyIaDTxORKhqMiIFBVRVFREkQXtzCx45ZL2GWi7Xa9URI5Zv+qhZ1JZWUZlZbL3OyyvtQDs3t3Aa6/t4u1te/jdW+/z5rsf8f6OwXxc30zj7jj1tcbuxgjxpgh4ptMcceDIiS67B+KJP4ZZdBqK4kE787Q/oGm32x/C0vdnPr6l7+twm9ZhtYwPDhpYsp5EW2/zGA9utak507E8431zay0j/WlTbewYvm7r/OtJ1GfZ/BzaP1niIYmvNDiG0fFrSpXTyfOnf+74LN2WkeGJun6AA976FVvqH2/bJtOxO/s/11mxnf4/Svv/ljpW0G7OZUP56QM3d/VF9Ei/CPRCM3x4GXPmjGbOnNHAOZ22c3eam+McOdLC4cNNHGo4SkNjIw2NR2g4coTDjUdoPNrE0aPNNB5t4siRozTH4zQ1tdDU3ExzcwtNLXFamltoam6huaWFlhanOd5CS0uc5uY47k5LS/CqoqU5Ttw98eojeG7H8Xj6KxAPXtl46zZP3vc4Hk/8LiVfweDgyVMR3voZUr/g8bhDHOIO8Zbk1x608lSeepvfC3cPfmE9dbS0XxrHvfUXLFlf8rhp32Ha/NKlbXcn+FrcUuvrW5GnBUPw0OBrbX9MMjyfpe1OHNM8LcBbj5d8XCqOkkGYDKjU97NtiAR/wBJ/RC29XbLGtknlDukvktrfp93zW/KUUvL73qE9wSvONg9vrRnvGHqeFqrBqSvHUn84W0toW1G7otsWADhWlGhtaXmarMHSf+5p39v050yrqcNTZfxDEG99+jZ1t//DEfx8xowqb3+AnMgq0M1sLvCvBJege9Dd72q33xL7LwIagGvd/bUc19rvmFkwZFIcYdCgGJUMzHdJIlLAup22aGYR4F5gHjABuNLMJrRrNg8Ym/hYANyf4zpFRKQb2cxDnwZsc/d33f0osAK4pF2bS4D/9MDLwFAzG5HjWkVEpAvZBPppwI60+7WJbcfaRkREjqNsAr2L07fH1AYzW2Bm68xsXV2drvspIpJL2QR6LXB62v2RwM4etMHdl7l7jbvXVFZWHmutIiLShWwC/VVgrJmNMbMYMB94pl2bZ4AvWWA6sN/dtYCKiMgJ1O20RXdvNrOvA88TTFtc7u6bzeyGxP6lwEqCKYvbCKYtXnf8ShYRkUyymofu7isJQjt929K02w58LbeliYjIscjbWi5mVgf8vocPHw7szmE5x0sY6lSNuaEac0M1du+T7p7xJGTeAr03zGxdZ4vTFJIw1Kkac0M15oZq7J0+dYELEZH+TIEuItJHhDXQl+W7gCyFoU7VmBuqMTdUYy+EcgxdREQ6CmsPXURE2lGgi4j0EaELdDOba2Zvmtk2M7s13/UAmNlyM9tlZpvStlWY2f+Y2duJz8fnEiXZ13i6ma02sy1mttnM/q7Q6jSzUjN7xcxeT9R4Z6HVmFZrxMx+a2Y/LeAat5vZ78xsg5mtK8Q6zWyomT1hZlsT/zf/pJBqNLNxie9f8uNjM7upkGpMF6pAz/JiG/nwMDC33bZbgZ+7+1jg54n7+dQM/G93PwuYDnwt8b0rpDqPAOe7+2SgGpibWBuokGpM+jtgS9r9QqwRYLa7V6fNmy60Ov8VeM7dxwOTCb6nBVOju7+Z+P5VE1wvsgF4qpBqbCO43mI4PoA/AZ5Pu38bcFu+60rUMhrYlHb/TWBE4vYI4M1819iu3p8Any3UOoEy4DXgU4VWI8Fqoj8Hzgd+Wqg/b2A7MLzdtoKpEzgJeI/E5IxCrLFdXXOA/1fINYaqh064LqTxCU+sOJn4fHKe60kxs9HAFOA3FFidiaGMDcAu4H/cveBqBJYA/4fUlYGBwqsRgmsSvGBm681sQWJbIdV5BlAHPJQYvnrQzAYWWI3p5gOPJm4XZI1hC/SsLqQhnTOzQcCPgZvc/eN819Oeu7d48PJ2JDDNzCbluaQ2zOxzwC53X5/vWrIww92nEgxRfs3Mzst3Qe1EganA/e4+BThEoQxdtJNYOvzzwI/yXUtXwhboWV1Io0B8lLyuauLzrjzXg5kVE4T5I+7+ZGJzwdUJ4O71wBqCcxOFVOMM4PNmtp3g+rrnm9kPKawaAXD3nYnPuwjGfadRWHXWArWJV2EATxAEfCHVmDQPeM3dP0rcL8QaQxfo2Vxso1A8A1yTuH0NwZh13piZAf8ObHH3u9N2FUydZlZpZkMTtwcAFwJbKaAa3f02dx/p7qMJ/v/9wt2vpoBqBDCzgWY2OHmbYPx3EwVUp7t/COwws3GJTRcAb1BANaa5ktbhFijMGsN1UjRxAuIi4C3gHeD/5rueRE2PAh8ATQS9ji8DwwhOnL2d+FyR5xo/TTA8tRHYkPi4qJDqBKqA3yZq3ATcntheMDW2q3cWrSdFC6pGgvHp1xMfm5O/KwVYZzWwLvEzfxooL8Aay4A9wJC0bQVVY/JDb/0XEekjwjbkIiIinVCgi4j0EQp0EZE+QoEuItJHKNBFRPoIBbqISB+hQBcR6SP+P0Y1tn/G74aRAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get the index of largest model_score row\n",
    "para_dfm_max_index = para_dfm[para_dfm[\"model_score\"]==max(para_dfm[\"model_score\"])].index[0]\n",
    "# get the loss function of the best model\n",
    "def create_plot(log,limit=None):\n",
    "    if limit:\n",
    "    # plt.plot(log.history['accuracy'],label = \"training accuracy\",color='green')\n",
    "        plt.plot(log.history['loss'][-limit:],label = \"training loss\",color='darkgreen')\n",
    "        # plt.plot(log.history['val_accuracy'], label = \"validation accuracy\",color='grey')\n",
    "        plt.plot(log.history['val_loss'][-limit:], label = \"validation loss\",color='darkblue')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.plot(log.history['loss'],label = \"training loss\",color='darkgreen')\n",
    "        plt.plot(log.history['val_loss'], label = \"validation loss\",color='darkblue')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "create_plot(log_list[para_dfm_max_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the index of largest model_score row\n",
    "autoencoder_best = model_list[int(para_dfm_max_index)]\n",
    "# autoencoder_best.save('./models/autoencoder_best.h5') # save the best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to reset the weight and train the model again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_weights(model, weights=None):\n",
    "    \"\"\"Randomly permute the weights in `model`, or the given `weights`.\n",
    "\n",
    "    This is a fast approximation of re-initializing the weights of a model.\n",
    "\n",
    "    Assumes weights are distributed independently of the dimensions of the weight tensors\n",
    "      (i.e., the weights have the same distribution along each dimension).\n",
    "\n",
    "    :param Model model: Modify the weights of the given model.\n",
    "    :param list(ndarray) weights: The model's weights will be replaced by a random permutation of these weights.\n",
    "      If `None`, permute the model's current weights.\n",
    "    \"\"\"\n",
    "    if weights is None:\n",
    "        weights = model.get_weights()\n",
    "    weights = [np.random.permutation(w.flat).reshape(w.shape) for w in weights]\n",
    "    # Faster, but less random: only permutes along the first dimension\n",
    "    # weights = [np.random.permutation(w) for w in weights]\n",
    "    model.set_weights(weights)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "285/285 [==============================] - 1s 1ms/step - loss: 0.0655 - val_loss: 0.0471\n",
      "Epoch 2/200\n",
      "285/285 [==============================] - 0s 970us/step - loss: 0.0450 - val_loss: 0.0423\n",
      "Epoch 3/200\n",
      "285/285 [==============================] - 0s 909us/step - loss: 0.0324 - val_loss: 0.0274\n",
      "Epoch 4/200\n",
      "285/285 [==============================] - 0s 897us/step - loss: 0.0272 - val_loss: 0.0264\n",
      "Epoch 5/200\n",
      "285/285 [==============================] - 0s 923us/step - loss: 0.0260 - val_loss: 0.0247\n",
      "Epoch 6/200\n",
      "285/285 [==============================] - 0s 891us/step - loss: 0.0250 - val_loss: 0.0237\n",
      "Epoch 7/200\n",
      "285/285 [==============================] - 0s 951us/step - loss: 0.0242 - val_loss: 0.0235\n",
      "Epoch 8/200\n",
      "285/285 [==============================] - 0s 956us/step - loss: 0.0235 - val_loss: 0.0224\n",
      "Epoch 9/200\n",
      "285/285 [==============================] - 0s 936us/step - loss: 0.0229 - val_loss: 0.0224\n",
      "Epoch 10/200\n",
      "285/285 [==============================] - 0s 931us/step - loss: 0.0225 - val_loss: 0.0220\n",
      "Epoch 11/200\n",
      "285/285 [==============================] - 0s 952us/step - loss: 0.0222 - val_loss: 0.0212\n",
      "Epoch 12/200\n",
      "285/285 [==============================] - 0s 918us/step - loss: 0.0217 - val_loss: 0.0216\n",
      "Epoch 13/200\n",
      "285/285 [==============================] - 0s 947us/step - loss: 0.0213 - val_loss: 0.0208\n",
      "Epoch 14/200\n",
      "285/285 [==============================] - 0s 966us/step - loss: 0.0209 - val_loss: 0.0200\n",
      "Epoch 15/200\n",
      "285/285 [==============================] - 0s 936us/step - loss: 0.0207 - val_loss: 0.0197\n",
      "Epoch 16/200\n",
      "285/285 [==============================] - 0s 894us/step - loss: 0.0203 - val_loss: 0.0193\n",
      "Epoch 17/200\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0200 - val_loss: 0.0196\n",
      "Epoch 18/200\n",
      "285/285 [==============================] - 0s 975us/step - loss: 0.0198 - val_loss: 0.0188\n",
      "Epoch 19/200\n",
      "285/285 [==============================] - 0s 921us/step - loss: 0.0196 - val_loss: 0.0190\n",
      "Epoch 20/200\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0192 - val_loss: 0.0187\n",
      "Epoch 21/200\n",
      "285/285 [==============================] - 0s 902us/step - loss: 0.0192 - val_loss: 0.0187\n",
      "Epoch 22/200\n",
      "285/285 [==============================] - 0s 934us/step - loss: 0.0188 - val_loss: 0.0179\n",
      "Epoch 23/200\n",
      "285/285 [==============================] - 0s 897us/step - loss: 0.0185 - val_loss: 0.0176\n",
      "Epoch 24/200\n",
      "285/285 [==============================] - 0s 924us/step - loss: 0.0182 - val_loss: 0.0170\n",
      "Epoch 25/200\n",
      "285/285 [==============================] - 0s 946us/step - loss: 0.0180 - val_loss: 0.0175\n",
      "Epoch 26/200\n",
      "285/285 [==============================] - 0s 918us/step - loss: 0.0178 - val_loss: 0.0170\n",
      "Epoch 27/200\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 0.0177 - val_loss: 0.0174\n",
      "Epoch 28/200\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0174 - val_loss: 0.0174\n",
      "Epoch 29/200\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0173 - val_loss: 0.0166\n",
      "Epoch 30/200\n",
      "285/285 [==============================] - 0s 967us/step - loss: 0.0172 - val_loss: 0.0168\n",
      "Epoch 31/200\n",
      "285/285 [==============================] - 0s 960us/step - loss: 0.0170 - val_loss: 0.0169\n",
      "Epoch 32/200\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0170 - val_loss: 0.0160\n",
      "Epoch 33/200\n",
      "285/285 [==============================] - 0s 924us/step - loss: 0.0167 - val_loss: 0.0161\n",
      "Epoch 34/200\n",
      "285/285 [==============================] - 0s 908us/step - loss: 0.0166 - val_loss: 0.0161\n",
      "Epoch 35/200\n",
      "285/285 [==============================] - 0s 914us/step - loss: 0.0166 - val_loss: 0.0160\n",
      "Epoch 36/200\n",
      "285/285 [==============================] - 0s 901us/step - loss: 0.0167 - val_loss: 0.0163\n",
      "Epoch 37/200\n",
      "285/285 [==============================] - 0s 880us/step - loss: 0.0163 - val_loss: 0.0154\n",
      "Epoch 38/200\n",
      "285/285 [==============================] - 0s 886us/step - loss: 0.0162 - val_loss: 0.0158\n",
      "Epoch 39/200\n",
      "285/285 [==============================] - 0s 934us/step - loss: 0.0161 - val_loss: 0.0158\n",
      "Epoch 40/200\n",
      "285/285 [==============================] - 0s 896us/step - loss: 0.0163 - val_loss: 0.0165\n",
      "Epoch 41/200\n",
      "285/285 [==============================] - 0s 925us/step - loss: 0.0160 - val_loss: 0.0156\n",
      "Epoch 42/200\n",
      "285/285 [==============================] - 0s 916us/step - loss: 0.0158 - val_loss: 0.0157\n",
      "Epoch 43/200\n",
      "285/285 [==============================] - 0s 955us/step - loss: 0.0158 - val_loss: 0.0150\n",
      "Epoch 44/200\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0159 - val_loss: 0.0156\n",
      "Epoch 45/200\n",
      "285/285 [==============================] - 0s 947us/step - loss: 0.0159 - val_loss: 0.0151\n",
      "Epoch 46/200\n",
      "285/285 [==============================] - 0s 866us/step - loss: 0.0157 - val_loss: 0.0151\n",
      "Epoch 47/200\n",
      "285/285 [==============================] - 0s 870us/step - loss: 0.0157 - val_loss: 0.0158\n",
      "Epoch 48/200\n",
      "285/285 [==============================] - 0s 852us/step - loss: 0.0155 - val_loss: 0.0160\n",
      "Epoch 49/200\n",
      "285/285 [==============================] - 0s 880us/step - loss: 0.0157 - val_loss: 0.0153\n",
      "Epoch 50/200\n",
      "285/285 [==============================] - 0s 932us/step - loss: 0.0153 - val_loss: 0.0148\n",
      "Epoch 51/200\n",
      "285/285 [==============================] - 0s 977us/step - loss: 0.0152 - val_loss: 0.0151\n",
      "Epoch 52/200\n",
      "285/285 [==============================] - 0s 946us/step - loss: 0.0151 - val_loss: 0.0144\n",
      "Epoch 53/200\n",
      "285/285 [==============================] - 0s 933us/step - loss: 0.0151 - val_loss: 0.0143\n",
      "Epoch 54/200\n",
      "285/285 [==============================] - 0s 934us/step - loss: 0.0152 - val_loss: 0.0146\n",
      "Epoch 55/200\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0150 - val_loss: 0.0143\n",
      "Epoch 56/200\n",
      "285/285 [==============================] - 0s 961us/step - loss: 0.0150 - val_loss: 0.0145\n",
      "Epoch 57/200\n",
      "285/285 [==============================] - 0s 842us/step - loss: 0.0149 - val_loss: 0.0150\n",
      "Epoch 58/200\n",
      "285/285 [==============================] - 0s 902us/step - loss: 0.0148 - val_loss: 0.0147\n",
      "Epoch 59/200\n",
      "285/285 [==============================] - 0s 929us/step - loss: 0.0149 - val_loss: 0.0154\n",
      "Epoch 60/200\n",
      "285/285 [==============================] - 0s 914us/step - loss: 0.0148 - val_loss: 0.0142\n",
      "Epoch 61/200\n",
      "285/285 [==============================] - 0s 925us/step - loss: 0.0146 - val_loss: 0.0145\n",
      "Epoch 62/200\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0145 - val_loss: 0.0141\n",
      "Epoch 63/200\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0144 - val_loss: 0.0147\n",
      "Epoch 64/200\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0146 - val_loss: 0.0146\n",
      "Epoch 65/200\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0146 - val_loss: 0.0142\n",
      "Epoch 66/200\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0145 - val_loss: 0.0140\n",
      "Epoch 67/200\n",
      "285/285 [==============================] - 0s 930us/step - loss: 0.0145 - val_loss: 0.0142\n",
      "Epoch 68/200\n",
      "285/285 [==============================] - 0s 923us/step - loss: 0.0142 - val_loss: 0.0138\n",
      "Epoch 69/200\n",
      "285/285 [==============================] - 0s 852us/step - loss: 0.0143 - val_loss: 0.0137\n",
      "Epoch 70/200\n",
      "285/285 [==============================] - 0s 920us/step - loss: 0.0145 - val_loss: 0.0144\n",
      "Epoch 71/200\n",
      "285/285 [==============================] - 0s 828us/step - loss: 0.0145 - val_loss: 0.0147\n",
      "Epoch 72/200\n",
      "285/285 [==============================] - 0s 887us/step - loss: 0.0142 - val_loss: 0.0143\n",
      "Epoch 73/200\n",
      "285/285 [==============================] - 0s 952us/step - loss: 0.0142 - val_loss: 0.0134\n",
      "Epoch 74/200\n",
      "285/285 [==============================] - 0s 893us/step - loss: 0.0140 - val_loss: 0.0146\n",
      "Epoch 75/200\n",
      "285/285 [==============================] - 0s 855us/step - loss: 0.0141 - val_loss: 0.0135\n",
      "Epoch 76/200\n",
      "285/285 [==============================] - 0s 855us/step - loss: 0.0140 - val_loss: 0.0138\n",
      "Epoch 77/200\n",
      "285/285 [==============================] - 0s 861us/step - loss: 0.0140 - val_loss: 0.0141\n",
      "Epoch 78/200\n",
      "285/285 [==============================] - 0s 840us/step - loss: 0.0140 - val_loss: 0.0136\n",
      "Epoch 79/200\n",
      "285/285 [==============================] - 0s 875us/step - loss: 0.0139 - val_loss: 0.0138\n",
      "Epoch 80/200\n",
      "285/285 [==============================] - 0s 897us/step - loss: 0.0138 - val_loss: 0.0137\n",
      "Epoch 81/200\n",
      "285/285 [==============================] - 0s 921us/step - loss: 0.0139 - val_loss: 0.0139\n",
      "Epoch 82/200\n",
      "285/285 [==============================] - 0s 860us/step - loss: 0.0139 - val_loss: 0.0140\n",
      "Epoch 83/200\n",
      "285/285 [==============================] - 0s 876us/step - loss: 0.0138 - val_loss: 0.0137\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "# reset the all the weight of autoencoder model\n",
    "autoencoder_best = shuffle_weights(autoencoder_best)\n",
    "log = autoencoder_best.fit(x=X_train, y=X_train, epochs=200, validation_data=(X_val, X_val), callbacks=[early_stopping_cb])\n",
    "\n",
    "create_plot(log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC:  0.7550878815911193\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f8db46357f0>]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAQiklEQVR4nO3df6ieZ33H8fdnqYWJ1qqJUtNmyUb9EcGKHlsdc6vKZtMhQRDWVpQVJXaz4p8tg1mG/ygyULGahVKKf9QKs9g6omUwtANt1hT6Ky2VrMU0TaGpHZbVP0ra7/44J93TJ+fHnZP7eZ7zXPf7BYFz3/eVc74XJ3z77fe5rvtKVSFJmn9/MOsAJEn9MKFLUiNM6JLUCBO6JDXChC5JjThrVj948+bNtX379ln9eEmaS/fdd9+zVbVluWczS+jbt2/n4MGDs/rxkjSXkvxmpWe2XCSpESZ0SWqECV2SGmFCl6RGmNAlqRFrJvQkNyd5JsnDKzxPkm8nOZzkwSTv6z9MSdJaulTotwCXrfJ8F3Dh0p89wPfOPCxJ0ulacx16Vd2dZPsqQ3YD36/F9/Dek+TcJOdV1dN9BSkN2a0HjnDH/U/NOgz1aOfbzuGGT7y79+/bRw99K/DkyPXRpXunSLInycEkB48fP97Dj5bad8f9T/HI08/POgzNgT52imaZe8uemlFV+4B9AAsLC56sIXW087xz+OEXPjTrMLTB9VGhHwUuGLk+HzjWw/eVJJ2GPhL6ncBnl1a7fBD4nf1z6czdeuAIf/Mvv7Ldos7WbLkk+QFwKbA5yVHgBuA1AFW1F9gPXA4cBn4PXD2pYKUhOdk733neOex+77IfS0mv0mWVy5VrPC/gi71FJOkV9s51Omb2+lxJpxpdoniyOpe6cuu/tIGMLlG01aLTZYUubTC2WbReVuiS1AgrdGmGxrf12zfXmbBCl2ZofFu/fXOdCSt0acbsmasvJnSJ2b3R0BaL+mTLRWJ2bzS0xaI+WaFLS2x9aN5ZoUtSI0zoktQIE7okNcKELkmN8ENRNWc9SxBdPqgWWKGrOetZgujyQbXACl1NcgmihsgKXZIaYYWuubRan9x+uIbKCl1zabU+uf1wDZUVuuaWfXLp1UzomhseoCytzpaL5oYHKEurs0LXXLHNIq3MCl2SGmFCl6RGmNAlqREmdElqhAldkhphQtdcuPXAEQ488dysw5A2NBO65sLJDUWuPZdW1imhJ7ksyWNJDie5fpnnb0jykyQPJDmU5Or+Q9XQXbLjTVx1ybZZhyFtWGsm9CSbgBuBXcBO4MokO8eGfRF4pKouAi4F/jnJ2T3HqoGy3SJ106VCvxg4XFWPV9WLwG3A7rExBbw+SYDXAc8BJ3qNVINlu0XqpktC3wo8OXJ9dOneqO8A7wKOAQ8BX66ql8e/UZI9SQ4mOXj8+PF1hqwhst0ira1LQs8y92rs+uPA/cDbgPcC30lyyqvwqmpfVS1U1cKWLVtOM1RJ0mq6JPSjwAUj1+ezWImPuhq4vRYdBp4A3tlPiBoy++dSd10S+r3AhUl2LH3QeQVw59iYI8DHAJK8FXgH8HifgWqY7J9L3a35+tyqOpHkWuAuYBNwc1UdSnLN0vO9wFeBW5I8xGKL5rqqenaCcWtA7J9L3XR6H3pV7Qf2j93bO/L1MeCv+g1NQ+XJRNL6uFNUG44nE0nr44lF2pA8mUg6fVboktQIE7o2FJcpSutnQteG4jJFaf1M6NpwXKYorY8fimpmRpcnnuQyRWn9rNA1M6PLE09ymaK0flbomimXJ0r9sUKXpEZYoWtqxnvm9sulflmha2rGe+b2y6V+WaFrquyZS5NjQlfvlluOCLZYpEmz5aLeLbccEWyxSJNmha6JsLUiTZ8VuiQ1wgpdvTnZO7dXLs2GFbp6M5rM7ZVL02eFrl7ZO5dmx4SuVa20BHE5tlqk2bLlolWttARxObZapNmyQteabKNI88EKXZIaYYWuU4z2ze2LS/PDCl2nGO2b2xeX5ocVupZl31yaPyZ0AbZZpBbYchFgm0VqgRW6XmGbRZpvnSr0JJcleSzJ4STXrzDm0iT3JzmU5Bf9hilJWsuaFXqSTcCNwF8CR4F7k9xZVY+MjDkX+C5wWVUdSfKWCcWrHiy3nd++uTT/ulToFwOHq+rxqnoRuA3YPTbmKuD2qjoCUFXP9Bum+rTcdn775tL869JD3wo8OXJ9FLhkbMzbgdck+TnweuBbVfX98W+UZA+wB2Dbtm3riVc9sV8utadLhZ5l7tXY9VnA+4G/Bj4O/GOSt5/yl6r2VdVCVS1s2bLltIOVJK2sS4V+FLhg5Pp84NgyY56tqheAF5LcDVwE/LqXKCVJa+pSod8LXJhkR5KzgSuAO8fG3AF8OMlZSV7LYkvm0X5DlSStZs0KvapOJLkWuAvYBNxcVYeSXLP0fG9VPZrkZ8CDwMvATVX18CQDlyS9WqeNRVW1H9g/dm/v2PU3gG/0F5r65iHOUtvc+j8gHuIstc2t/wPjckWpXVboktQIE7okNcKELkmNMKFLUiNM6ANx64EjHHjiuVmHIWmCTOgDcfJ1uS5XlNplQh+QS3a8iasu8S2XUqtM6JLUCBP6ANg/l4bBhD4A9s+lYTChD4T9c6l9vsulMR4ALQ2XFXpjPABaGi4r9Ab5RkVpmKzQJakRJvSGuDxRGjYTekNcnigNmwm9MS5PlIbLhN4I2y2STOiNsN0iyYTeENst0rCZ0CWpEW4smhPLbekf5fZ+SVboc2K5Lf2j3N4vyQp9jrilX9JqTOhTtFbbZDW2VCStxZbLFK3VNlmNLRVJa7FCnzLbJpImxQpdkhrRKaEnuSzJY0kOJ7l+lXEfSPJSkk/1F2Ib3JovadLWTOhJNgE3AruAncCVSXauMO7rwF19B9kCt+ZLmrQuFfrFwOGqeryqXgRuA3YvM+5LwI+AZ3qMryluzZc0SV0+FN0KPDlyfRS4ZHRAkq3AJ4GPAh9Y6Rsl2QPsAdi2rf3ENrpM0WWHkiatS4WeZe7V2PU3geuq6qXVvlFV7auqhapa2LJlS8cQ59foMkWXHUqatC4V+lHggpHr84FjY2MWgNuSAGwGLk9yoqp+3EeQ88xlipKmpUtCvxe4MMkO4CngCuCq0QFVtePk10luAf7NZC5J07VmQq+qE0muZXH1yibg5qo6lOSaped7JxyjJKmDTjtFq2o/sH/s3rKJvKr+9szDkiSdLneKSlIjTOgT4s5QSdNmQp8Qd4ZKmjYT+gS5M1TSNJnQJakRJvQJsH8uaRZM6BNg/1zSLJjQJ8T+uaRpM6FLUiNM6JLUCBO6JDXChC5Jjej0cq6hGT1paD08nUjSLFihL2P0pKH18HQiSbNghb4CTxqSNG+s0Me4y1PSvDKhj3GXp6R5ZUJfhrs8Jc0jE7okNcKEPsL+uaR5ZkIfYf9c0jwzoY+xfy5pXrkOnf/fGeoOT0nzzAodXpXMbbdImldW6EvcGSpp3lmhS1IjBp/QXaooqRWDT+guVZTUisEndHCpoqQ2mNAlqRGdVrkkuQz4FrAJuKmqvjb2/NPAdUuX/wv8XVU90GegfRo9kci155JasWaFnmQTcCOwC9gJXJlk59iwJ4C/qKr3AF8F9vUdaJ9GTyRy7bmkVnSp0C8GDlfV4wBJbgN2A4+cHFBVvxwZfw9wfp9BToLrziW1pksPfSvw5Mj10aV7K/kc8NPlHiTZk+RgkoPHjx/vHmWPXKYoqVVdEnqWuVfLDkw+wmJCv26551W1r6oWqmphy5Yt3aPskcsUJbWqS8vlKHDByPX5wLHxQUneA9wE7Kqq3/YT3mS4TFFSi7pU6PcCFybZkeRs4ArgztEBSbYBtwOfqapf9x+mJGkta1boVXUiybXAXSwuW7y5qg4luWbp+V7gK8Cbge8mAThRVQuTC1uSNK7TOvSq2g/sH7u3d+TrzwOf7zc0SdLpcKeoJDViUAndJYuSWjaohO6SRUktG1RCB5csSmrX4BK6JLVqMAnd/rmk1g0mods/l9S6wSR0sH8uqW2DSuiS1DITuiQ1woQuSY0woUtSI0zoktQIE7okNcKELkmN6PQ+9Hl264Ej3HH/Uzzy9PPsPO+cWYcjSRPTfIU+mszdJSqpZc1X6AA7zzuHH37hQ7MOQ5ImqvkKXZKGotkK3d65pKFptkK3dy5paJqt0MHeuaRhabJC9zALSUPUZEL3MAtJQ9RkQgcPs5A0PM0mdEkamqY+FHWpoqQha6pCd6mipCFrqkIHlypKGq5mKnSXKkoaumYSuksVJQ1dp4Se5LIkjyU5nOT6ZZ4nybeXnj+Y5H39h7o2lypKGrI1E3qSTcCNwC5gJ3Blkp1jw3YBFy792QN8r+c4JUlr6PKh6MXA4ap6HCDJbcBu4JGRMbuB71dVAfckOTfJeVX1dN8B/9NPDvHIsedPue9SRUlD16XlshV4cuT66NK90x1Dkj1JDiY5ePz48dONdVUuVZQ0dF0q9Cxzr9YxhqraB+wDWFhYOOV5Fzd84t3r+WuS1LwuFfpR4IKR6/OBY+sYI0maoC4J/V7gwiQ7kpwNXAHcOTbmTuCzS6tdPgj8bhL9c0nSytZsuVTViSTXAncBm4Cbq+pQkmuWnu8F9gOXA4eB3wNXTy5kSdJyOm39r6r9LCbt0Xt7R74u4Iv9hiZJOh3N7BSVpKEzoUtSI0zoktQIE7okNSKLn2fO4Acnx4HfrPOvbwae7TGceeCch8E5D8OZzPmPqmrLcg9mltDPRJKDVbUw6zimyTkPg3MehknN2ZaLJDXChC5JjZjXhL5v1gHMgHMeBuc8DBOZ81z20CVJp5rXCl2SNMaELkmN2NAJfV4Op+5Thzl/emmuDyb5ZZKLZhFnn9aa88i4DyR5KcmnphnfJHSZc5JLk9yf5FCSX0w7xr51+Lf9hiQ/SfLA0pzn+q2tSW5O8kySh1d43n/+qqoN+YfFV/X+N/DHwNnAA8DOsTGXAz9l8cSkDwIHZh33FOb8p8Abl77eNYQ5j4z7Dxbf+vmpWcc9hd/zuSye27tt6fots457CnP+B+DrS19vAZ4Dzp517Gcw5z8H3gc8vMLz3vPXRq7QXzmcuqpeBE4eTj3qlcOpq+oe4Nwk50070B6tOeeq+mVV/c/S5T0sng41z7r8ngG+BPwIeGaawU1IlzlfBdxeVUcAqmre591lzgW8PkmA17GY0E9MN8z+VNXdLM5hJb3nr42c0Hs7nHqOnO58Psfif+Hn2ZpzTrIV+CSwlzZ0+T2/HXhjkp8nuS/JZ6cW3WR0mfN3gHexeHzlQ8CXq+rl6YQ3E73nr04HXMxIb4dTz5HO80nyERYT+p9NNKLJ6zLnbwLXVdVLi8Xb3Osy57OA9wMfA/4Q+FWSe6rq15MObkK6zPnjwP3AR4E/Af49yX9W1fMTjm1Wes9fGzmhD/Fw6k7zSfIe4CZgV1X9dkqxTUqXOS8Aty0l883A5UlOVNWPpxJh/7r+2362ql4AXkhyN3ARMK8Jvcucrwa+VosN5sNJngDeCfzXdEKcut7z10ZuuQzxcOo155xkG3A78Jk5rtZGrTnnqtpRVdurajvwr8Dfz3Eyh27/tu8APpzkrCSvBS4BHp1ynH3qMucjLP4fCUneCrwDeHyqUU5X7/lrw1boNcDDqTvO+SvAm4HvLlWsJ2qO31TXcc5N6TLnqno0yc+AB4GXgZuqatnlb/Og4+/5q8AtSR5isR1xXVXN7Wt1k/wAuBTYnOQocAPwGphc/nLrvyQ1YiO3XCRJp8GELkmNMKFLUiNM6JLUCBO6JDXChC5JjTChS1Ij/g94R9mL4OQFhQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# autoencoder_best.save('models/autoencoder_best.h5')\n",
    "autoencoder_best = tf.keras.models.load_model('./models/autoencoder_best.h5')\n",
    "X_pred = autoencoder_best.predict(X_val)\n",
    "mse = np.mean(np.power(X_val.flatten() - X_pred.flatten(), 2))\n",
    "reconstructions = autoencoder_best.predict(X_val)\n",
    "val_loss = tf.keras.losses.mae(reconstructions, X_val)\n",
    "# sns.histplot(x=val_loss,y=y_val.flatten(),hue=y_val.flatten())\n",
    "# plt.show()\n",
    "df_tmp = pd.DataFrame({\"val_loss\": val_loss, \"y_val\": y_val.flatten()})\n",
    "df_tmp_fraud = df_tmp[df_tmp[\"y_val\"] == 1]\n",
    "df_tmp_non_fraud = df_tmp[df_tmp[\"y_val\"] == 0]\n",
    "mse = np.mean(np.power(X_val.flatten() - X_pred.flatten(), 2))\n",
    "error_df = pd.DataFrame({'Reconstruction_error': mse, 'True_class': y_val.flatten()})\n",
    "df_temp = pd.DataFrame({'Reconstruction_error': val_loss, 'True_class': y_val.flatten()})\n",
    "roc = roc_auc_score(y_val.flatten(), val_loss)\n",
    "print(\"ROC: \", roc)\n",
    "#plot the roc curve\n",
    "fpr, tpr, thresholds = roc_curve(y_val.flatten(), val_loss)\n",
    "plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set the threshold for fraud\n",
    "We are going to use three method to set the threshold for fraud:\n",
    "1. Use the mean of the reconstruction error plus one standard deviation as the threshold\n",
    "2. Set the threshold to the minimum of the reconstruction error of fraud cases\n",
    "3. Set the threshold to the minimize the cost function we mentioned above, which is 10*FN + FP\n",
    "\n",
    "If it is real case, we would recommend to use the third method. Because it can have company to lower the cost.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1\n",
    "Use the mean of the reconstruction error plus one standard deviation as the threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold:  0.10620087638284344\n"
     ]
    }
   ],
   "source": [
    "# select the threshold with test dataset\n",
    "threshold = np.mean(val_loss) + np.std(val_loss)\n",
    "print(\"Threshold: \", threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix is :\n",
      "Accuracy rate is 0.8249780123131046\n",
      "Sensitivity is 0.4107142857142857\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# pred y based on the threshold\n",
    "test_loss = autoencoder_best.predict(X_test)\n",
    "reconstructions = autoencoder_best.predict(X_val)\n",
    "test_loss = tf.keras.losses.mae(reconstructions, X_val)\n",
    "pred_y = np.where(test_loss > threshold, 1, 0)\n",
    "cm = confusion_matrix(y_test.flatten().astype(int), pred_y)\n",
    "print(f\"Confusion matrix is :\" )\n",
    "sns.heatmap(cm, annot=True)\n",
    "accuracy_rate = (cm[0,0] + cm[1,1])/np.sum(cm)\n",
    "print(f\"Accuracy rate is {accuracy_rate}\")\n",
    "# calculate the sensitivity \n",
    "sensitivity = cm[1,1]/(cm[1,1] + cm[1,0])\n",
    "print(f\"Sensitivity is {sensitivity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2\n",
    "Set the threshold to the minimum of the reconstruction error of fraud cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show the distribution of the model_score\n",
    "import seaborn as sns\n",
    "sns.histplot(x=val_loss,y=y_val.flatten(),hue=y_val.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold:  0.0711917878068816\n"
     ]
    }
   ],
   "source": [
    "# select the threshold with test dataset\n",
    "df_temp = pd.DataFrame({'Reconstruction_error': val_loss, 'True_class': y_val.flatten()})\n",
    "df_temp_fraud = df_temp[df_temp['True_class']==1]\n",
    "threshold = df_temp_fraud[\"Reconstruction_error\"].min()\n",
    "print(\"Threshold: \", threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix is :\n",
      "Accuracy rate is 0.4098504837291117\n",
      "Sensitivity is 0.9821428571428571\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# pred y based on the threshold\n",
    "pred_y = np.where(test_loss > threshold, 1, 0)\n",
    "cm = confusion_matrix(y_test.flatten().astype(int), pred_y)\n",
    "print(f\"Confusion matrix is :\" )\n",
    "sns.heatmap(cm, annot=True)\n",
    "accuracy_rate = (cm[0,0] + cm[1,1])/np.sum(cm)\n",
    "print(f\"Accuracy rate is {accuracy_rate}\")\n",
    "# calculate the sensitivity \n",
    "sensitivity = cm[1,1]/(cm[1,1] + cm[1,0])\n",
    "print(f\"Sensitivity is {sensitivity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 3\n",
    "Set the threshold to the minimize the cost function we mentioned above, which is 10*FN + FP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold:  0.0707070707070707\n"
     ]
    }
   ],
   "source": [
    "# select the threshold with test dataset\n",
    "#  the cost function\n",
    "def calculate_cost(fn,fp):\n",
    "    return 100*fn+fp\n",
    "\n",
    "cost_lost = {}\n",
    "for i in np.linspace(0,0.1,100):\n",
    "    pred_y = np.where(val_loss > i, 1, 0)\n",
    "    cm = confusion_matrix(y_val.flatten(), pred_y)\n",
    "    fn,fp = cm[1][0],cm[0][1]\n",
    "    # cost_lost[\"Threshold: \"+str(i)] = calculate_cost(fn,fp)\n",
    "    cost_lost[i] = calculate_cost(fn,fp)\n",
    "\n",
    "threshold = min(cost_lost, key=cost_lost.get)\n",
    "print(\"Threshold: \", threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix is :\n",
      "Accuracy rate is 0.405452946350044\n",
      "Sensitivity is 1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# pred y based on the threshold\n",
    "pred_y = np.where(test_loss > threshold, 1, 0)\n",
    "cm = confusion_matrix(y_test.flatten().astype(int), pred_y)\n",
    "print(f\"Confusion matrix is :\" )\n",
    "sns.heatmap(cm, annot=True)\n",
    "accuracy_rate = (cm[0,0] + cm[1,1])/np.sum(cm)\n",
    "print(f\"Accuracy rate is {accuracy_rate}\")\n",
    "# calculate the sensitivity \n",
    "sensitivity = cm[1,1]/(cm[1,1] + cm[1,0])\n",
    "print(f\"Sensitivity is {sensitivity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "627f9b2e5272ed3cf653ffd46ee5493b7b24a386103372a1710032d6985d4cd7"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
