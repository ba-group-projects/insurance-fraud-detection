{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "### Question\n",
    "Briefly discuss why it is more difficult to find a good classifier on such a dataset than on one where, for example, 5,000 claims are fraudulent, and 5,000 are not. In particular, consider what happens when undetected fraudulent claims are very costly to the insurance company.\n",
    "\n",
    "### Answer\n",
    "When the dataset in highly unbalanced, like what in the car-insurance case, the machine learning algorithm can predict well in the majority class and predict poorly in minority class. Since most of machine learning algorithm always pursue to decrease error rate, thus they tend to predict the all the label to majority class one. In our scenario, the algorithm tends to predict all the claims non-fraudulent. However, the wrong prediction will increase the False-negative rate, which will increase the cost of fraudulent claims.\n",
    "Another issue related to the scarce minority data is that we might miss some key combination of variables that has high probability to be fraudulent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check how much NaN values in each column when the claim is frandulent.\n",
    "We can find when the claim is frandulent, most of the numerical variables are not missing, which means we could directly drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the range of all variables and drop unreasonable numbers\n",
    "# split first and scale with smote code\n",
    "# check scale first or smote first\n",
    "# validation loss and trainning loss\n",
    "# the batch size is 32\n",
    "# TODO train test validation\n",
    "# check the roc curve\n",
    "# hidden layer number\n",
    "# TODO smote oversampling issue(why the number is float)\n",
    "# claim involved cover\n",
    "# TODO clear session andv set seeds #FIXME\n",
    "# TODO sensebility_at_spec\n",
    "# TODO set seeds before \n",
    "# TODO model summary\n",
    "# TODO save model \n",
    "\n",
    "# TO ASK\n",
    "# How to select the best model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "\n",
    "### TODO    \n",
    "calculate the number of policyholdersnumber and vehicle number\n",
    "\n",
    "### Question\n",
    "Load the dataset \"Insurance_claims.csv\" and clean it as appropriate for use with machine learning algorithms. A description of the features can be found at the end of this document.\n",
    "\n",
    "### Principle\n",
    "1. Since the dataset is highly unbalanced, and the fraudulent dataset is very scarce, we don't want to drop the data label with 'fradulent'.\n",
    "2. When the variables is categorical varibles, we tend to keep the Nah value as a classificaiton value rather than drop it.\n",
    "3. When the variables is numerical variables, we will check how many NaN values is related to the fraudulent case. If few of them, we will drop the variable. Otherwise, we will find a way to fill in the NaN values.\n",
    "\n",
    "### Proprocess procedure\n",
    "1. load data and select useful columns\n",
    "2. drop duplicates\n",
    "3. drop unreasonable rows\n",
    "4. deal with nan data\n",
    "    - deal with the categorical nan data\n",
    "    - deal with the numerical nan data\n",
    "5. deal with date data\n",
    "6. get an insight of the distribution of dataset\n",
    "    - check whether there is a signicicant distribution difference in every column in fraud data and non-fraud data\n",
    "7. clean features\n",
    "    - dummy\n",
    "      - PolicyholderOccupation\n",
    "      - ClaimCause\n",
    "      - ClaimInvolvedCovers\n",
    "      - DamageImportance\n",
    "      - FirstPartyVehicleType \n",
    "      - ConnectionBetweenParties\n",
    "      - PolicyWasSubscribedOnInternet\n",
    "    - extract features in 'ClaimInvolvedCovers'\n",
    "    - outlier # TODO\n",
    "8. split data and scale\n",
    "9.  show the data structure after preprocess\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import imblearn\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Load data and select useful columns\n",
    "We are going to use the following features to predict the fraud cases:\n",
    "1. PolicyholderOccupation\n",
    "2. LossDate\n",
    "3. FirstPolicySubscriptionDate\n",
    "4. ClainType\n",
    "5. ClaimInvolvedCovers\n",
    "6. DamageImportance\n",
    "7. FirstPartyVehicleType\n",
    "8. ConnectionBetweenParties\n",
    "9. PolicyWasSubscribedOnInternet\n",
    "10. NumberOfPoliciesOfPolicyholder\n",
    "11. FpVehicleAgeMonths\n",
    "12. EasinessToStage\n",
    "13. ClaimWihoutIdentifiedThirdParty\n",
    "14. ClaimAmount\n",
    "15. LossHour\n",
    "16. PolicyHolderAge\n",
    "17. NumberOfBodilyInjuries\n",
    "18. FirstPartyLiability\n",
    "19. LossAndHolderPostCodeSame\n",
    "\n",
    "And we also need label:\n",
    "1. Fraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data sample:\n",
      "  PolicyholderOccupation  LossDate FirstPolicySubscriptionDate  \\\n",
      "0           CivilServant  02.01.19                    18.06.18   \n",
      "1                 Worker  02.01.19                    29.06.17   \n",
      "2                 Worker  02.01.19                    05.02.17   \n",
      "3           CivilServant  02.01.19                    21.01.17   \n",
      "4                 Farmer  02.01.19                    13.01.18   \n",
      "\n",
      "                         ClaimCause  \\\n",
      "0               CollisionWithAnimal   \n",
      "1                     LossOfControl   \n",
      "2  AccidentWithIdentifiedThirdParty   \n",
      "3  AccidentWithIdentifiedThirdParty   \n",
      "4  AccidentWithIdentifiedThirdParty   \n",
      "\n",
      "                               ClaimInvolvedCovers DamageImportance  \\\n",
      "0                     MaterialDamages ActLiability              NaN   \n",
      "1                     MaterialDamages ActLiability              NaN   \n",
      "2                     MaterialDamages ActLiability              NaN   \n",
      "3  MaterialDamages ActLiability ReplacementVehicle              NaN   \n",
      "4                                     ActLiability              NaN   \n",
      "\n",
      "  FirstPartyVehicleType ConnectionBetweenParties  \\\n",
      "0                   Car                      NaN   \n",
      "1                   Car                      NaN   \n",
      "2                   Car                      NaN   \n",
      "3                   Car                      NaN   \n",
      "4                   Car                      NaN   \n",
      "\n",
      "   PolicyWasSubscribedOnInternet  NumberOfPoliciesOfPolicyholder  \\\n",
      "0                              1                               1   \n",
      "1                              0                               3   \n",
      "2                              0                               9   \n",
      "3                              0                               2   \n",
      "4                              0                               4   \n",
      "\n",
      "   FpVehicleAgeMonths  EasinessToStage  ClaimWihoutIdentifiedThirdParty  \\\n",
      "0               104.0             0.25                                1   \n",
      "1               230.0             0.50                                1   \n",
      "2                93.0             0.25                                0   \n",
      "3                56.0             0.25                                0   \n",
      "4               110.0             0.25                                0   \n",
      "\n",
      "   ClaimAmount  LossHour  PolicyHolderAge  NumberOfBodilyInjuries  \\\n",
      "0      4624.73       8.0             45.0                       0   \n",
      "1      1606.81      11.0             20.0                       0   \n",
      "2       998.20      18.0             32.0                       0   \n",
      "3      2506.92      11.0             46.0                       0   \n",
      "4        12.00      12.0             28.0                       0   \n",
      "\n",
      "   FirstPartyLiability  LossAndHolderPostCodeSame  Fraud  \n",
      "0                  1.0                          1      0  \n",
      "1                  1.0                          0      0  \n",
      "2                  0.5                          1      0  \n",
      "3                  0.5                          1      0  \n",
      "4                  0.0                          0      0  \n",
      "-----------------------------------------------------\n",
      "Data Columns:\n",
      "Index(['PolicyholderOccupation', 'LossDate', 'FirstPolicySubscriptionDate',\n",
      "       'ClaimCause', 'ClaimInvolvedCovers', 'DamageImportance',\n",
      "       'FirstPartyVehicleType', 'ConnectionBetweenParties',\n",
      "       'PolicyWasSubscribedOnInternet', 'NumberOfPoliciesOfPolicyholder',\n",
      "       'FpVehicleAgeMonths', 'EasinessToStage',\n",
      "       'ClaimWihoutIdentifiedThirdParty', 'ClaimAmount', 'LossHour',\n",
      "       'PolicyHolderAge', 'NumberOfBodilyInjuries', 'FirstPartyLiability',\n",
      "       'LossAndHolderPostCodeSame', 'Fraud'],\n",
      "      dtype='object')\n",
      "-----------------------------------------------------\n",
      "Data description:\n",
      "       PolicyWasSubscribedOnInternet  NumberOfPoliciesOfPolicyholder  \\\n",
      "count                   11530.000000                    11530.000000   \n",
      "mean                        0.205551                        2.231830   \n",
      "std                         0.404121                        1.690804   \n",
      "min                         0.000000                        1.000000   \n",
      "25%                         0.000000                        1.000000   \n",
      "50%                         0.000000                        2.000000   \n",
      "75%                         0.000000                        3.000000   \n",
      "max                         1.000000                       18.000000   \n",
      "\n",
      "       FpVehicleAgeMonths  EasinessToStage  ClaimWihoutIdentifiedThirdParty  \\\n",
      "count        11518.000000     11530.000000                     11530.000000   \n",
      "mean           113.445390         0.377593                         0.685863   \n",
      "std             73.622026         0.139479                         0.464191   \n",
      "min             -4.000000         0.000000                         0.000000   \n",
      "25%             52.000000         0.250000                         0.000000   \n",
      "50%            108.000000         0.500000                         1.000000   \n",
      "75%            162.000000         0.500000                         1.000000   \n",
      "max            652.000000         0.500000                         1.000000   \n",
      "\n",
      "        ClaimAmount      LossHour  PolicyHolderAge  NumberOfBodilyInjuries  \\\n",
      "count  11530.000000  11436.000000     11494.000000            11530.000000   \n",
      "mean    1409.463023      8.265128        44.575083                0.028187   \n",
      "std     2672.349310      7.407462        15.218107                0.200147   \n",
      "min        0.000000      0.000000        18.000000                0.000000   \n",
      "25%      288.085000      0.000000        32.000000                0.000000   \n",
      "50%      755.900000      9.000000        43.000000                0.000000   \n",
      "75%     1500.000000     15.000000        56.000000                0.000000   \n",
      "max    64696.000000     23.000000        90.000000                5.000000   \n",
      "\n",
      "       FirstPartyLiability  LossAndHolderPostCodeSame         Fraud  \n",
      "count         11530.000000               11530.000000  11530.000000  \n",
      "mean              0.208066                   0.566609      0.009974  \n",
      "std               0.402509                   0.495565      0.099375  \n",
      "min               0.000000                   0.000000      0.000000  \n",
      "25%               0.000000                   0.000000      0.000000  \n",
      "50%               0.000000                   1.000000      0.000000  \n",
      "75%               0.000000                   1.000000      0.000000  \n",
      "max               1.000000                   1.000000      1.000000  \n",
      "-----------------------------------------------------\n",
      "Data duplicated rows:\n",
      "14\n",
      "-----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# read data and get a brief idea of the data\n",
    "df = pd.read_csv('./materials/Insurance_claims.csv')\n",
    "# get useful features that needed in the machine learning model\n",
    "# TODO using nlp to insurer notes data\n",
    "needed_columns = [ 'PolicyholderOccupation',\n",
    "       'LossDate', 'FirstPolicySubscriptionDate', 'ClaimCause',\n",
    "       'ClaimInvolvedCovers', 'DamageImportance', 'FirstPartyVehicleType',\n",
    "       'ConnectionBetweenParties', 'PolicyWasSubscribedOnInternet',\n",
    "       'NumberOfPoliciesOfPolicyholder', 'FpVehicleAgeMonths',\n",
    "       'EasinessToStage', 'ClaimWihoutIdentifiedThirdParty', 'ClaimAmount',\n",
    "       'LossHour', 'PolicyHolderAge', 'NumberOfBodilyInjuries',\n",
    "       'FirstPartyLiability', 'LossAndHolderPostCodeSame','Fraud']\n",
    "df = df[needed_columns]\n",
    "\n",
    "# show the first 5 rows, get some idea of the data structure\n",
    "print(f'Data sample:')\n",
    "print(df.head(5)) #TODO use sentiment analysis \n",
    "print('-----------------------------------------------------')\n",
    "\n",
    "# get the columns name\n",
    "print('Data Columns:')\n",
    "print(str(df.columns))\n",
    "print('-----------------------------------------------------')\n",
    "\n",
    "# get some basic information about the data, and we found that the min number \n",
    "# of FpVehicleAgeMonths is less than 0, which does't make sense. We are going \n",
    "# to detect whether these rows are fraud cases or not. If they are all non-fraud,\n",
    "# we can drop the rows with negative FpVehicleAgeMonths value. Otherwise, we will \n",
    "# create a new feature that record these abnormal rows since these unreasonable \n",
    "# values might be evidence of fraud cases.\n",
    "print('Data description:')\n",
    "print(df.describe())\n",
    "print('-----------------------------------------------------')\n",
    "\n",
    "# check whether there are any duplicated rows and we found there are 8 duplicated rows,\n",
    "# which we are going to drop.\n",
    "print('Data duplicated rows:')\n",
    "print(df.duplicated().sum())\n",
    "print('-----------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Drop the duplicated rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the data before dropping duplicated rows:\n",
      "(11530, 20)\n",
      "-----------------------------------------------------\n",
      "The shape of the data after dropping duplicated rows:\n",
      "(11516, 20)\n",
      "-----------------------------------------------------\n",
      "The number of rows that are dropped: 14\n"
     ]
    }
   ],
   "source": [
    "print('The shape of the data before dropping duplicated rows:')\n",
    "df_shape_before_drop = df.shape\n",
    "print(df.shape)\n",
    "print('-----------------------------------------------------')\n",
    "\n",
    "# drop the duplicated rows\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "print('The shape of the data after dropping duplicated rows:')\n",
    "df_shape_after_drop = df.shape\n",
    "print(df.shape)\n",
    "print('-----------------------------------------------------')\n",
    "\n",
    "print(f'The number of rows that are dropped: {df_shape_before_drop[0]-df_shape_after_drop[0]}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Drop unreasonable values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     PolicyholderOccupation  LossDate FirstPolicySubscriptionDate  \\\n",
      "8019                Retired  24.06.20                    22.10.19   \n",
      "8446                Retired  21.07.20                    26.02.20   \n",
      "8529                Retired  17.07.20                    26.02.20   \n",
      "\n",
      "            ClaimCause           ClaimInvolvedCovers DamageImportance  \\\n",
      "8019     LossOfControl  MaterialDamages ActLiability              NaN   \n",
      "8446     LossOfControl  MaterialDamages ActLiability              NaN   \n",
      "8529  WindscreenDamage                    Windscreen              NaN   \n",
      "\n",
      "     FirstPartyVehicleType ConnectionBetweenParties  \\\n",
      "8019                   Car                      NaN   \n",
      "8446                   Car                      NaN   \n",
      "8529                   Car                      NaN   \n",
      "\n",
      "      PolicyWasSubscribedOnInternet  NumberOfPoliciesOfPolicyholder  \\\n",
      "8019                              0                               2   \n",
      "8446                              0                               4   \n",
      "8529                              0                               4   \n",
      "\n",
      "      FpVehicleAgeMonths  EasinessToStage  ClaimWihoutIdentifiedThirdParty  \\\n",
      "8019                -1.0              0.5                                1   \n",
      "8446                -4.0              0.5                                1   \n",
      "8529                -4.0              0.5                                1   \n",
      "\n",
      "      ClaimAmount  LossHour  PolicyHolderAge  NumberOfBodilyInjuries  \\\n",
      "8019      3806.61      14.0             71.0                       0   \n",
      "8446      2819.11      14.0             72.0                       0   \n",
      "8529      1323.53       0.0             72.0                       0   \n",
      "\n",
      "      FirstPartyLiability  LossAndHolderPostCodeSame  Fraud  \n",
      "8019                  1.0                          1      0  \n",
      "8446                  1.0                          1      0  \n",
      "8529                  0.0                          1      0  \n",
      "-----------------------------------------------------\n",
      "The number of rows that are dropped: 3\n"
     ]
    }
   ],
   "source": [
    "# check whether unreasonable rows contain fraud cases\n",
    "df_unreasonable_rows = df[df['FpVehicleAgeMonths'] < 0]\n",
    "df_shape_before_drop = df_unreasonable_rows.shape\n",
    "print(df_unreasonable_rows)\n",
    "print('-----------------------------------------------------')\n",
    "# we can find that these three rows are not fraud cases. \n",
    "# Since we have enough non-fraud data, we can drop these rows.\n",
    "df_shape_before_drop = df.shape\n",
    "df.drop(df_unreasonable_rows.index, inplace=True)\n",
    "df_shape_after_drop = df.shape\n",
    "\n",
    "print(f'The number of rows that are dropped: {df_shape_before_drop[0]-df_shape_after_drop[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Deal with nan data\n",
    "Check how much NaN values in each column.\n",
    "\n",
    "We can find that except for 'FirstPartyVehicleNumber', 'ThirdPartyVehicleNumber', 'InsurerNotes', which we might not use in our models, most the NaN values are concentrated in the 'PolicyholderOccupation', 'ClaimCause',etc which are mainly categorical variables. In this case, we could turn these NaN values into a category value in order to take account the influence of missing variables, no mather what reason they are missing.\n",
    "\n",
    "In terms of the numeric variables, we will furtherly check how many of them are missing when the claim is fraudulent or not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaN values in each column:\n",
      "PolicyholderOccupation               340\n",
      "LossDate                               0\n",
      "FirstPolicySubscriptionDate            0\n",
      "ClaimCause                           191\n",
      "ClaimInvolvedCovers                  189\n",
      "DamageImportance                   10775\n",
      "FirstPartyVehicleType                 12\n",
      "ConnectionBetweenParties           11415\n",
      "PolicyWasSubscribedOnInternet          0\n",
      "NumberOfPoliciesOfPolicyholder         0\n",
      "FpVehicleAgeMonths                    12\n",
      "EasinessToStage                        0\n",
      "ClaimWihoutIdentifiedThirdParty        0\n",
      "ClaimAmount                            0\n",
      "LossHour                              94\n",
      "PolicyHolderAge                       36\n",
      "NumberOfBodilyInjuries                 0\n",
      "FirstPartyLiability                    0\n",
      "LossAndHolderPostCodeSame              0\n",
      "Fraud                                  0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check how much NaN values in each column.\n",
    "print(f'Number of NaN values in each column:') \n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can find that in the Fraud case, there are a lot of data missing in categorical columns, but few in numerical columns.\n",
    "\n",
    "Thus, we can set NaN as a category of categorical data and generate dummy variables. And we can drop the rows that contains NaN values in numerical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaN values in each column when Frand is True:\n",
      "PolicyholderOccupation               4\n",
      "LossDate                             0\n",
      "FirstPolicySubscriptionDate          0\n",
      "ClaimCause                           0\n",
      "ClaimInvolvedCovers                  0\n",
      "DamageImportance                    96\n",
      "FirstPartyVehicleType                2\n",
      "ConnectionBetweenParties           102\n",
      "PolicyWasSubscribedOnInternet        0\n",
      "NumberOfPoliciesOfPolicyholder       0\n",
      "FpVehicleAgeMonths                   2\n",
      "EasinessToStage                      0\n",
      "ClaimWihoutIdentifiedThirdParty      0\n",
      "ClaimAmount                          0\n",
      "LossHour                             1\n",
      "PolicyHolderAge                      0\n",
      "NumberOfBodilyInjuries               0\n",
      "FirstPartyLiability                  0\n",
      "LossAndHolderPostCodeSame            0\n",
      "Fraud                                0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check the number of missing data when Frand is True\n",
    "df_fraud = df[df[\"Fraud\"]==1]\n",
    "print(f'Number of NaN values in each column when Frand is True:')\n",
    "print(df_fraud.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaN values in each column when Frand is False:\n",
      "PolicyholderOccupation               336\n",
      "LossDate                               0\n",
      "FirstPolicySubscriptionDate            0\n",
      "ClaimCause                           191\n",
      "ClaimInvolvedCovers                  189\n",
      "DamageImportance                   10679\n",
      "FirstPartyVehicleType                 10\n",
      "ConnectionBetweenParties           11313\n",
      "PolicyWasSubscribedOnInternet          0\n",
      "NumberOfPoliciesOfPolicyholder         0\n",
      "FpVehicleAgeMonths                    10\n",
      "EasinessToStage                        0\n",
      "ClaimWihoutIdentifiedThirdParty        0\n",
      "ClaimAmount                            0\n",
      "LossHour                              93\n",
      "PolicyHolderAge                       36\n",
      "NumberOfBodilyInjuries                 0\n",
      "FirstPartyLiability                    0\n",
      "LossAndHolderPostCodeSame              0\n",
      "Fraud                                  0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_non_frand = df[df[\"Fraud\"]==0]\n",
    "print(f'Number of NaN values in each column when Frand is False:')\n",
    "print(df_non_frand.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill the missing data in categorical columns with string NaN and make it a category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_columns = ['PolicyholderOccupation', 'ClaimCause','ClaimInvolvedCovers', 'DamageImportance', 'FirstPartyVehicleType','ConnectionBetweenParties', 'PolicyWasSubscribedOnInternet']\n",
    "df[dummy_columns] = df[dummy_columns].fillna('NaN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop the missing data in numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of rows that are dropped: 142\n",
      "The number of rows that are dropped when Frand is True: 3\n"
     ]
    }
   ],
   "source": [
    "df_shape_before_drop = df.shape\n",
    "df_fraud_shape_before_drop = df[df[\"Fraud\"]==1].shape\n",
    "df.dropna(subset=[\"LossHour\",\"PolicyHolderAge\",\"FpVehicleAgeMonths\"],inplace=True)\n",
    "df_shape_after_drop = df.shape\n",
    "df_fraud_shape_after_drop = df[df[\"Fraud\"]==1].shape\n",
    "print(f'The number of rows that are dropped: {df_shape_before_drop[0]-df_shape_after_drop[0]}')\n",
    "print(f'The number of rows that are dropped when Frand is True: {df_fraud_shape_before_drop[0]-df_fraud_shape_after_drop[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After these steps, we don't have any missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of NaN values in each column:\n",
      "-----------------------------------------------------\n",
      "The shape of final datasets:\n",
      "(11371, 20)\n",
      "-----------------------------------------------------\n",
      "Data sample:\n",
      "  PolicyholderOccupation  LossDate FirstPolicySubscriptionDate  \\\n",
      "0           CivilServant  02.01.19                    18.06.18   \n",
      "1                 Worker  02.01.19                    29.06.17   \n",
      "2                 Worker  02.01.19                    05.02.17   \n",
      "3           CivilServant  02.01.19                    21.01.17   \n",
      "4                 Farmer  02.01.19                    13.01.18   \n",
      "\n",
      "                         ClaimCause  \\\n",
      "0               CollisionWithAnimal   \n",
      "1                     LossOfControl   \n",
      "2  AccidentWithIdentifiedThirdParty   \n",
      "3  AccidentWithIdentifiedThirdParty   \n",
      "4  AccidentWithIdentifiedThirdParty   \n",
      "\n",
      "                               ClaimInvolvedCovers DamageImportance  \\\n",
      "0                     MaterialDamages ActLiability              NaN   \n",
      "1                     MaterialDamages ActLiability              NaN   \n",
      "2                     MaterialDamages ActLiability              NaN   \n",
      "3  MaterialDamages ActLiability ReplacementVehicle              NaN   \n",
      "4                                     ActLiability              NaN   \n",
      "\n",
      "  FirstPartyVehicleType ConnectionBetweenParties  \\\n",
      "0                   Car                      NaN   \n",
      "1                   Car                      NaN   \n",
      "2                   Car                      NaN   \n",
      "3                   Car                      NaN   \n",
      "4                   Car                      NaN   \n",
      "\n",
      "   PolicyWasSubscribedOnInternet  NumberOfPoliciesOfPolicyholder  \\\n",
      "0                              1                               1   \n",
      "1                              0                               3   \n",
      "2                              0                               9   \n",
      "3                              0                               2   \n",
      "4                              0                               4   \n",
      "\n",
      "   FpVehicleAgeMonths  EasinessToStage  ClaimWihoutIdentifiedThirdParty  \\\n",
      "0               104.0             0.25                                1   \n",
      "1               230.0             0.50                                1   \n",
      "2                93.0             0.25                                0   \n",
      "3                56.0             0.25                                0   \n",
      "4               110.0             0.25                                0   \n",
      "\n",
      "   ClaimAmount  LossHour  PolicyHolderAge  NumberOfBodilyInjuries  \\\n",
      "0      4624.73       8.0             45.0                       0   \n",
      "1      1606.81      11.0             20.0                       0   \n",
      "2       998.20      18.0             32.0                       0   \n",
      "3      2506.92      11.0             46.0                       0   \n",
      "4        12.00      12.0             28.0                       0   \n",
      "\n",
      "   FirstPartyLiability  LossAndHolderPostCodeSame  Fraud  \n",
      "0                  1.0                          1      0  \n",
      "1                  1.0                          0      0  \n",
      "2                  0.5                          1      0  \n",
      "3                  0.5                          1      0  \n",
      "4                  0.0                          0      0  \n",
      "-----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('The number of NaN values in each column:')\n",
    "df.isna().sum()\n",
    "print('-----------------------------------------------------')\n",
    "\n",
    "print('The shape of final datasets:')\n",
    "print(df.shape)\n",
    "print('-----------------------------------------------------')\n",
    "\n",
    "print(\"Data sample:\")\n",
    "print(df.head(5))\n",
    "print('-----------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Deal with date data\n",
    "We tend to consider the date data as important features. Because we consider that in different time period, people might have different tendency to defraud. And this argument is supported by Pascal Blanque(2002), who asserted that the economic crisis is an important reason for the defraud.\n",
    "\n",
    "However, our date data is datetime format, which cannot be used in machine learning model. In hence, we will convert the date data into timestamp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn the date into timestamp\n",
    "df['LossDate'] = df['LossDate'].apply(lambda x:datetime.datetime.strptime(x,'%d.%M.%y').timestamp())\n",
    "df['FirstPolicySubscriptionDate'] = df['FirstPolicySubscriptionDate'].apply(lambda x:datetime.datetime.strptime(x,'%d.%M.%y').timestamp())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 Get an insight of the distribution of dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the distribution of the numerical data, we can see that there are some diffenece between the fraud and non-fraud cases, especially in the distribution of 'FpVehicleAgeMonths' and 'claimAmount'. In the fraud cases, they usually have a more disperse distribution in 'FpVehicleAgeMonths' and higher value in 'claimAmount'. \n",
    "\n",
    "And in the categorical data, we can find some interesting patterns. For example, in the fraud cases, the percentage of 'TotalLoss' is much higher than the non-fraud cases, which is understandable. And in the fraud cases, the fraud cases tend to be same address between two parties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the datasets that are fraud cases and non-fraud cases\n",
    "df_fraud = df[df['Fraud'] == 1]\n",
    "df_non_fraud = df[df['Fraud'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean of fraud datasets:\n",
      "-----------------------------------------------------\n",
      "LossDate                           1.557971e+09\n",
      "FirstPolicySubscriptionDate        1.546519e+09\n",
      "PolicyWasSubscribedOnInternet      2.857143e-01\n",
      "NumberOfPoliciesOfPolicyholder     1.625000e+00\n",
      "FpVehicleAgeMonths                 1.177143e+02\n",
      "EasinessToStage                    3.464286e-01\n",
      "ClaimWihoutIdentifiedThirdParty    5.625000e-01\n",
      "ClaimAmount                        3.647878e+03\n",
      "LossHour                           1.292857e+01\n",
      "PolicyHolderAge                    4.104464e+01\n",
      "NumberOfBodilyInjuries             3.571429e-02\n",
      "FirstPartyLiability                4.910714e-01\n",
      "LossAndHolderPostCodeSame          6.160714e-01\n",
      "Fraud                              1.000000e+00\n",
      "dtype: float64\n",
      "-----------------------------------------------------\n",
      "The mean of non-fraud datasets:\n",
      "-----------------------------------------------------\n",
      "LossDate                           1.564733e+09\n",
      "FirstPolicySubscriptionDate        1.523620e+09\n",
      "PolicyWasSubscribedOnInternet      2.037481e-01\n",
      "NumberOfPoliciesOfPolicyholder     2.242828e+00\n",
      "FpVehicleAgeMonths                 1.136111e+02\n",
      "EasinessToStage                    3.780842e-01\n",
      "ClaimWihoutIdentifiedThirdParty    6.861178e-01\n",
      "ClaimAmount                        1.383297e+03\n",
      "LossHour                           8.231815e+00\n",
      "PolicyHolderAge                    4.461249e+01\n",
      "NumberOfBodilyInjuries             2.788880e-02\n",
      "FirstPartyLiability                2.040146e-01\n",
      "LossAndHolderPostCodeSame          5.652367e-01\n",
      "Fraud                              0.000000e+00\n",
      "dtype: float64\n",
      "-----------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_90085/1158699191.py:4: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  df_fraud_mean = df_fraud.mean()\n",
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_90085/1158699191.py:10: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  df_non_fraud_mean = df_non_fraud.mean()\n"
     ]
    }
   ],
   "source": [
    "# get the mean of both datasets\n",
    "print('The mean of fraud datasets:')\n",
    "print('-----------------------------------------------------')\n",
    "df_fraud_mean = df_fraud.mean()\n",
    "print(df_fraud_mean)\n",
    "print('-----------------------------------------------------')\n",
    "\n",
    "print('The mean of non-fraud datasets:')\n",
    "print('-----------------------------------------------------')\n",
    "df_non_fraud_mean = df_non_fraud.mean()\n",
    "print(df_non_fraud_mean)\n",
    "print('-----------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The distribution numerical data of fraud datasets:\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x1080 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------\n",
      "The distribution numerical data of non-fraud datasets:\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x1080 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the distribution of fraud datasets\n",
    "print('The distribution numerical data of fraud datasets:')\n",
    "df_fraud.iloc[:,:-1].hist(bins=50, figsize=(20,15),density=True, xlabelsize=10, ylabelsize=10) #TODO add title\n",
    "plt.show()\n",
    "print('-----------------------------------------------------')\n",
    "\n",
    "# plot the distribution of non-fraud datasets\n",
    "print('The distribution numerical data of non-fraud datasets:')\n",
    "df_non_fraud.iloc[:,:-1].hist(bins=50, figsize=(20,15),density=True, xlabelsize=10, ylabelsize=10)\n",
    "plt.show()\n",
    "\n",
    "# TODO show the classification of categorical data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x1440 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABIEAAAJZCAYAAAA+iyW5AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAA/yUlEQVR4nO3de7hWdZ3//9eHDaIFpYWapwTzxGHDNjnYpLjNBjUNEyttnJSaQsbQxvpWdnUiR8tRa4yRUbCMHE98h7SMmKZhRMFTAbpVFE1LFJM8wNcDCim4fn8g+4eKspGNG1yPx3VxXfte97rXeu/b/cfds/VZd6mqKgAAAAC8tXXq6AEAAAAA2PhEIAAAAIAaEIEAAAAAakAEAgAAAKgBEQgAAACgBkQgAAAAgBoQgQAAkpRSlpZSduvoOQAANpbOHT0AAMCbqZSyIMn2SVausXnPqqq6bcAxqyTPJale2nRlVVWfe8NDAgBsBCIQAFBHH62qano7H3NAVVX3t/MxAQDajeVgAABZdTVPKWX3l35+dynlV6WUp0sps0spZ5RSbujoGQEANoQIBADwauOTPJvkPUlOeOnfuswspfyllHJVKaXnxhwOAOCNEIEAgDr6RSnlyZf+/WLNJ0opDUmOTvKdqqqeq6rq7iQ/W8fxDkzSM8neSR5JMrWUYtk9ALBJ8eEEAKijj73OPYG2zarPSAvX2LbwNfZNklRVNfOlH58vpXwxydNJeie5c0MHBQBoL64EAgB4uceTrEiy8xrbdlnPY1RJSrtNBADQDkQgAIA1VFW1MslVScaWUt5WStk7yfGvtX8ppW8ppamU0lBK6ZbkB0n+nGT+mzMxAEDbiEAAAK82Jsk7k/wlyX8kuSLJX19j3+2TTM6qJWB/yqp7Ax1RVdULG39MAIC2K1VVdfQMAACbtFLKvyR5T1VVbfmWMACATZIrgQAAXqGUsncppX9ZZXCSf0hydUfPBQCwIXw7GADAq3XPqiVgOyZ5LKvu8/PLDp0IAGADWQ4GAAAAUAOWgwEAAADUgAgEAAAAUAMddk+gHj16VD179uyo0wMAAAC85cydO/eJqqq2XdtzHRaBevbsmTlz5nTU6QEAAADeckopD77Wc5aDAQAAANSACAQAAABQAyIQAAAAQA2IQAAAAAA1IAIBAAAA1IAIBAAAAFADIhAAAABADYhAAAAAADUgAgEAAADUgAgEAAAAUAMiEAAAAEANiEAAAAAANSACAQAAANSACAQAAABQAyIQAAAAQA2IQAAAAAA1IAIBAAAA1IAIBAAAAFADIhAAAABADYhAAAAAADWwzghUSrm4lPJYKWXeazxfSinjSin3l1LuKKW8v/3HBAAAAGBDtOVKoElJDn2d5w9LssdL/0YluWDDxwIAAACgPa0zAlVVNTPJktfZ5cgkl1Sr3JJk61LKDu01IAAAAAAbrj3uCbRTkoVrPH74pW0AAAAAbCI6t8Mxylq2VWvdsZRRWbVkLO9973vb4dTUxth3dvQEwFvR2Kc6egLgLegHxxzR0SMAb0Ffnjy1o0fgLaA9rgR6OMkuazzeOckja9uxqqqJVVUNrKpq4LbbbtsOpwYAAACgLdojAl2T5PiXviVsvyRPVVW1qB2OCwAAAEA7WedysFLKFUmak/QopTyc5DtJuiRJVVUXJpmW5CNJ7k/yXJLPbKxhAQAAAHhj1hmBqqr61Dqer5J8od0mgrXoufzyjh4BeAta0NEDAG9JX+49q6NHAIC1ao/lYAAAAABs4kQgAAAAgBoQgQAAAABqQAQCAAAAqAERCAAAAKAGRCAAAACAGhCBAAAAAGpABAIAAACoAREIAAAAoAZEIAAAAIAaEIEAAAAAakAEAgAAAKgBEQgAAACgBkQgAAAAgBoQgQAAAABqQAQCAAAAqAERCAAAAKAGRCAAAACAGhCBAAAAAGpABAIAAACoAREIAAAAoAZEIAAAAIAaEIEAAAAAakAEAgAAAKgBEQgAAACgBkQgAAAAgBoQgQAAAABqQAQCAAAAqAERCAAAAKAGRCAAAACAGhCBAAAAAGpABAIAAACoAREIAAAAoAZEIAAAAIAaEIEAAAAAakAEAgAAAKgBEQgAAACgBkQgAAAAgBoQgQAAAABqQAQCAAAAqAERCAAAAKAGRCAAAACAGhCBAAAAAGpABAIAAACoAREIAAAAoAZEIAAAAIAaEIEAAAAAakAEAgAAAKgBEQgAAACgBkQgAAAAgBoQgQAAAABqQAQCAAAAqAERCAAAAKAGRCAAAACAGhCBAAAAAGqgc0cPAAAAbyU9l1/e0SMAb0ELOnoA3hJcCQQAAABQAyIQAAAAQA2IQAAAAAA1IAIBAAAA1IAIBAAAAFADIhAAAABADYhAAAAAADUgAgEAAADUgAgEAAAAUAMiEAAAAEANiEAAAAAANSACAQAAANSACAQAAABQAyIQAAAAQA2IQAAAAAA1IAIBAAAA1IAIBAAAAFADIhAAAABADYhAAAAAADUgAgEAAADUgAgEAAAAUAMiEAAAAEANiEAAAAAANSACAQAAANSACAQAAABQAyIQAAAAQA2IQAAAAAA1IAIBAAAA1IAIBAAAAFADIhAAAABADYhAAAAAADUgAgEAAADUgAgEAAAAUAMiEAAAAEANiEAAAAAANSACAQAAANSACAQAAABQAyIQAAAAQA2IQAAAAAA10KYIVEo5tJRybynl/lLKaWt5/p2llF+VUm4vpdxVSvlM+48KAAAAwBu1zghUSmlIMj7JYUn6JPlUKaXPK3b7QpK7q6oakKQ5yQ9KKVu086wAAAAAvEFtuRJocJL7q6r6U1VVzye5MsmRr9inStK9lFKSdEuyJMmKdp0UAAAAgDesLRFopyQL13j88Evb1nR+kt5JHklyZ5IvVlX14isPVEoZVUqZU0qZ8/jjj7/BkQEAAABYX22JQGUt26pXPD4kSUuSHZM0JTm/lPKOV72oqiZWVTWwqqqB22677XqOCgAAAMAb1ZYI9HCSXdZ4vHNWXfGzps8kuapa5f4kDyTZu31GBAAAAGBDtSUCzU6yRyml10s3ez42yTWv2OehJAcnSSll+yR7JflTew4KAAAAwBvXeV07VFW1opQyJsl/J2lIcnFVVXeVUka/9PyFSf45yaRSyp1ZtXzsa1VVPbER5wYAAABgPawzAiVJVVXTkkx7xbYL1/j5kSTD2nc0AAAAANpLW5aDAQAAALCZE4EAAAAAakAEAgAAAKgBEQgAAACgBkQgAAAAgBoQgQAAAABqQAQCAAAAqAERCAAAAKAGRCAAAACAGhCBAAAAAGpABAIAAACoAREIAAAAoAZEIAAAAIAaEIEAAAAAakAEAgAAAKgBEQgAAACgBkQgAAAAgBoQgQAAAABqQAQCAAAAqAERCAAAAKAGRCAAAACAGhCBAAAAAGpABAIAAACoAREIAAAAoAZEIAAAAIAaEIEAAAAAakAEAgAAAKgBEQgAAACgBkQgAAAAgBoQgQAAAABqQAQCAAAAqAERCAAAAKAGRCAAAACAGhCBAAAAAGpABAIAAACoAREIAAAAoAZEIAAAAIAaEIEAAAAAakAEAgAAAKgBEQgAAACgBkQgAAAAgBoQgQAAAABqQAQCAAAAqAERCAAAAKAGRCAAAACAGhCBAAAAAGpABAIAAACoAREIAAAAoAZEIAAAAIAaEIEAAAAAakAEAgAAAKgBEQgAAACgBkQgAAAAgBoQgQAAAABqQAQCAAAAqAERCAAAAKAGRCAAAACAGhCBAAAAAGpABAIAAACoAREIAAAAoAZEIAAAAIAaEIEAAAAAakAEAgAAAKgBEQgAAACgBkQgAAAAgBoQgQAAAABqQAQCAAAAqAERCAAAAKAGRCAAAACAGhCBAAAAAGpABAIAAACoAREIAAAAoAZEIAAAAIAaEIEAAAAAakAEAgAAAKgBEQgAAACgBkQgAAAAgBoQgQAAAABqQAQCAAAAqAERCAAAAKAGRCAAAACAGhCBAAAAAGpABAIAAACoAREIAAAAoAZEIAAAAIAaEIEAAAAAakAEAgAAAKgBEQgAAACgBkQgAAAAgBoQgQAAAABqQAQCAAAAqAERCAAAAKAGRCAAAACAGhCBAAAAAGqgTRGolHJoKeXeUsr9pZTTXmOf5lJKSynlrlLK9e07JgAAAAAbovO6diilNCQZn+RvkzycZHYp5Zqqqu5eY5+tk/x7kkOrqnqolLLdRpoXAAAAgDegLVcCDU5yf1VVf6qq6vkkVyY58hX7/F2Sq6qqeihJqqp6rH3HBAAAAGBDtCUC7ZRk4RqPH35p25r2TLJNKeW6UsrcUsrx7TUgAAAAABtuncvBkpS1bKvWcpx9kxycZKskN5dSbqmq6g8vO1Apo5KMSpL3vve96z8tAAAAAG9IW64EejjJLms83jnJI2vZ5zdVVT1bVdUTSWYmGfDKA1VVNbGqqoFVVQ3cdttt3+jMAAAAAKyntkSg2Un2KKX0KqVskeTYJNe8Yp9fJjmglNK5lPK2JEOSzG/fUQEAAAB4o9a5HKyqqhWllDFJ/jtJQ5KLq6q6q5Qy+qXnL6yqan4p5TdJ7kjyYpIfV1U1b2MODgAAAEDbteWeQKmqalqSaa/YduErHp+T5Jz2Gw0AAACA9tKW5WAAAAAAbOZEIAAAAIAaEIEAAAAAakAEAgAAAKgBEQgAAACgBkQgAAAAgBoQgQAAAABqQAQCAAAAqAERCAAAAKAGRCAAAACAGhCBAAAAAGpABAIAAACoAREIAAAAoAZEIAAAAIAaEIEAAAAAakAEAgAAAKgBEQgAAACgBkQgAAAAgBoQgQAAAABqQAQCAAAAqAERCAAAAKAGRCAAAACAGhCBAAAAAGpABAIAAACoAREIAAAAoAZEIAAAAIAaEIEAAAAAakAEAgAAAKgBEQgAAACgBkQgAAAAgBoQgQAAAABqQAQCAAAAqAERCAAAAKAGRCAAAACAGhCBAAAAAGpABAIAAACoAREIAAAAoAZEIAAAAIAaEIEAAAAAakAEAgAAAKgBEQgAAACgBkQgAAAAgBoQgQAAAABqQAQCAAAAqAERCAAAAKAGRCAAAACAGhCBAAAAAGpABAIAAACoAREIAAAAoAZEIAAAAIAaEIEAAAAAakAEAgAAAKgBEQgAAACgBkQgAAAAgBoQgQAAAABqQAQCAAAAqAERCAAAAKAGRCAAAACAGhCBAAAAAGpABAIAAACoAREIAAAAoAZEIAAAAIAaEIEAAAAAakAEAgAAAKgBEQgAAACgBkQgAAAAgBoQgQAAAABqQAQCAAAAqAERCAAAAKAGRCAAAACAGhCBAAAAAGpABAIAAACoAREIAAAAoAZEIAAAAIAaEIEAAAAAakAEAgAAAKgBEQgAAACgBkQgAAAAgBoQgQAAAABqQAQCAAAAqAERCAAAAKAGRCAAAACAGhCBAAAAAGpABAIAAACoAREIAAAAoAZEIAAAAIAaEIEAAAAAakAEAgAAAKgBEQgAAACgBkQgAAAAgBoQgQAAAABqQAQCAAAAqAERCAAAAKAGRCAAAACAGhCBAAAAAGqgTRGolHJoKeXeUsr9pZTTXme/QaWUlaWUj7ffiAAAAABsqHVGoFJKQ5LxSQ5L0ifJp0opfV5jv39J8t/tPSQAAAAAG6YtVwINTnJ/VVV/qqrq+SRXJjlyLfudnOTnSR5rx/kAAAAAaAdtiUA7JVm4xuOHX9rWqpSyU5Kjklz4egcqpYwqpcwppcx5/PHH13dWAAAAAN6gtkSgspZt1Ssen5fka1VVrXy9A1VVNbGqqoFVVQ3cdttt2zgiAAAAABuqcxv2eTjJLms83jnJI6/YZ2CSK0spSdIjyUdKKSuqqvpFewwJAAAAwIZpSwSanWSPUkqvJH9OcmySv1tzh6qqeq3+uZQyKclUAQgAAABg07HOCFRV1YpSypis+tavhiQXV1V1Vyll9EvPv+59gAAAAADoeG25EihVVU1LMu0V29Yaf6qqGrnhYwEAAADQntpyY2gAAAAANnMiEAAAAEANiEAAAAAANSACAQAAANSACAQAAABQAyIQAAAAQA2IQAAAAAA1IAIBAAAA1IAIBAAAAFADIhAAAABADYhAAAAAADUgAgEAAADUgAgEAAAAUAMiEAAAAEANiEAAAAAANSACAQAAANSACAQAAABQAyIQAAAAQA2IQAAAAAA1IAIBAAAA1IAIBAAAAFADIhAAAABADYhAAAAAADUgAgEAAADUgAgEAAAAUAMiEAAAAEANiEAAAAAANSACAQAAANSACAQAAABQAyIQAAAAQA2IQAAAAAA1IAIBAAAA1IAIBAAAAFADIhAAAABADYhAAAAAADUgAgEAAADUgAgEAAAAUAMiEAAAAEANiEAAAAAANSACAQAAANSACAQAAABQAyIQAAAAQA2IQAAAAAA1IAIBAAAA1IAIBAAAAFADIhAAAABADYhAAAAAADUgAgEAAADUgAgEAAAAUAMiEAAAAEANiEAAAAAANSACAQAAANSACAQAAABQAyIQAAAAQA2IQAAAAAA1IAIBAAAA1IAIBAAAAFADIhAAAABADYhAAAAAADUgAgEAAADUgAgEAAAAUAMiEAAAAEANiEAAAAAANSACAQAAANSACAQAAABQAyIQAAAAQA2IQAAAAAA1IAIBAAAA1IAIBAAAAFADIhAAAABADYhAAAAAADUgAgEAAADUgAgEAAAAUAMiEAAAAEANiEAAAAAANSACAQAAANSACAQAAABQAyIQAAAAQA2IQAAAAAA1IAIBAAAA1IAIBAAAAFADIhAAAABADYhAAAAAADUgAgEAAADUgAgEAAAAUAMiEAAAAEANiEAAAAAANSACAQAAANRA544eAADYNLzwwgt5+OGHs3z58o4ehc3ElltumZ133jldunTp6FEAgDYQgQCAJMnDDz+c7t27p2fPnimldPQ4bOKqqsrixYvz8MMPp1evXh09DgDQBpaDAQBJkuXLl+fd7363AESblFLy7ne/25VjALAZEYEAgFYCEOvD3wsAbF5EIAAAAIAaEIEAgNf1l7/8Jccee2ze9773pU+fPvnIRz6SP/zhDx02z3nnnZfnnnuu9fFHPvKRPPnkk2/oWCNHjkyvXr3S1NSUvffeO9/97nfX+ZpJkyblkUceeUPn21ANDQ1pampKv3798olPfOJl78O6tLS0ZNq0aa2Pr7nmmpx11lkbY0wAYBPVpghUSjm0lHJvKeX+Usppa3n+uFLKHS/9u6mUMqD9RwUA3mxVVeWoo45Kc3Nz/vjHP+buu+/O9773vTz66KMdNtMrI9C0adOy9dZbv+HjnXPOOWlpaUlLS0t+9rOf5YEHHnjd/TsyAm211VZpaWnJvHnzssUWW+TCCy9s0+tWrFjxqgg0fPjwnHbaqz7WAQBvYeuMQKWUhiTjkxyWpE+ST5VS+rxitweSHFhVVf8k/5xkYnsPCgC8+WbMmJEuXbpk9OjRrduampqy//775ytf+Ur69euXxsbGTJ48OUly3XXXpbm5OR//+Mez995757jjjktVVUmSnj175jvf+U7e//73p7GxMffcc0+S5Nlnn81nP/vZDBo0KPvss09++ctfJklWrlyZ//N//k8aGxvTv3///Nu//VvGjRuXRx55JAcddFAOOuig1uM+8cQTSZIf/vCH6devX/r165fzzjsvSbJgwYL07t07n//859O3b98MGzYsy5Yte9XvuvoGx29/+9uTJHPnzs2BBx6YfffdN4ccckgWLVqUKVOmZM6cOTnuuOPS1NSU66+/PiNGjEiS/PKXv8xWW22V559/PsuXL89uu+2WJPnjH/+YQw89NPvuu28OOOCA1t/78ccfz9FHH51BgwZl0KBBufHGG5MkY8eOzWc/+9k0Nzdnt912y7hx49b63+aAAw7I/fffn1/96lcZMmRI9tlnn3z4wx9uDXRjx47NqFGjMmzYsBx//PH59re/ncmTJ6epqSmTJ0/OpEmTMmbMmNed5frrr09TU1Oampqyzz775Jlnnmnrnw4AsAlqy1fED05yf1VVf0qSUsqVSY5McvfqHaqqummN/W9JsnN7DgkAdIx58+Zl3333fdX2q666Ki0tLbn99tvzxBNPZNCgQRk6dGiS5Lbbbstdd92VHXfcMR/84Adz4403Zv/990+S9OjRI7feemv+/d//Peeee25+/OMf58wzz8yHPvShXHzxxXnyySczePDgfPjDH84ll1ySBx54ILfddls6d+6cJUuW5F3veld++MMfZsaMGenRo8fLZpo7d25++tOf5ne/+12qqsqQIUNy4IEHZptttsl9992XK664IhdddFE++clP5uc//3n+/u//Pknyla98JWeccUbuv//+nHLKKdluu+3ywgsv5OSTT84vf/nLbLvttpk8eXK+8Y1v5OKLL87555+fc889NwMHDsyKFSsycuTIJMmsWbPSr1+/zJ49OytWrMiQIUOSJKNGjcqFF16YPfbYI7/73e9y0kkn5dprr80Xv/jFnHrqqdl///3z0EMP5ZBDDsn8+fOTJPfcc09mzJiRZ555JnvttVf+8R//MV26dGn9XVesWJH/+q//yqGHHpr9998/t9xyS0op+fGPf5yzzz47P/jBD1rfkxtuuCFbbbVVJk2alDlz5uT8889PsuqKptVea5Zzzz0348ePzwc/+MEsXbo0W2655Yb+SQEAHagtEWinJAvXePxwkiGvs/8/JPmvDRkKANi03XDDDfnUpz6VhoaGbL/99jnwwAMze/bsvOMd78jgwYOz886r/v+gpqamLFiwoDUCrb5qZt99981VV12VJPntb3+ba665Jueee26SVVfkPPTQQ5k+fXpGjx6dzp1XfVx517vetc6ZjjrqqNYreUaMGJFZs2Zl+PDhrff9WX3uBQsWtL7unHPOycc//vEsXbo0Bx98cG666aa84x3vyLx58/K3f/u3SVZdlbTDDju86pydO3fO7rvvnvnz5+f3v/99vvSlL2XmzJlZuXJlDjjggCxdujQ33XRTPvGJT7S+5q9//WuSZPr06bn77tb/Ty1PP/1065U2hx9+eLp27ZquXbtmu+22y6OPPpqdd945y5Yta/09DjjggPzDP/xD7r333hxzzDFZtGhRnn/++fTq1av1mMOHD89WW231uu/b683ywQ9+MF/60pdy3HHHZcSIEa3/XQGAzVNbItDavvuzWuuOpRyUVRFo/9d4flSSUUny3ve+t40jAgAdpW/fvpkyZcqrtq9e4rU2Xbt2bf25oaEhK1aseNVza26vqio///nPs9dee73qHOvzFeTrM9PaloN169Ytzc3NueGGG3LYYYelb9++ufnmm9d53gMOOCD/9V//lS5duuTDH/5wRo4cmZUrV+bcc8/Niy++mK233jotLS2vet2LL76Ym2++ea2R5rXew9X3BFrTySefnC996UsZPnx4rrvuuowdO7b1udVBbF1ea5bTTjsthx9+eKZNm5b99tsv06dPz957792mYwIAm5623Bj64SS7rPF45ySvuhtiKaV/kh8nObKqqsVrO1BVVROrqhpYVdXAbbfd9o3MCwC8iT70oQ/lr3/9ay666KLWbbNnz84222yTyZMnZ+XKlXn88cczc+bMDB48+A2d45BDDsm//du/tUac2267LUkybNiwXHjhha0BZMmSJUmS7t27r/XeNEOHDs0vfvGLPPfcc3n22Wdz9dVX54ADDmjzHCtWrMjvfve7vO9978tee+2Vxx9/vDUCvfDCC7nrrrvWev6hQ4fmvPPOywc+8IFsu+22Wbx4ce6555707ds373jHO9KrV6/853/+Z5JVoer2229v/f1WL81KstZQ1BZPPfVUdtpppyTJz372s9fc77Xet9eb5Y9//GMaGxvzta99LQMHDmy9nxEAsHlqSwSanWSPUkqvUsoWSY5Ncs2aO5RS3pvkqiSfrqqq474zFgBoV6WUXH311fmf//mfvO9970vfvn0zduzY/N3f/V369++fAQMG5EMf+lDOPvvsvOc973lD5/jWt76VF154If3790+/fv3yrW99K0nyuc99Lu9973tbz3P55ZcnWXWPncMOO6z1xtCrvf/978/IkSMzePDgDBkyJJ/73Oeyzz77rPP8X/nKV9LU1JT+/funsbExI0aMyBZbbJEpU6bka1/7WgYMGJCmpqbcdNOqWyCOHDkyo0ePTlNTU5YtW5YhQ4bk0Ucfbb0nUv/+/dO/f//Wq5guu+yy/OQnP8mAAQPSt2/f1htfjxs3LnPmzEn//v3Tp0+fNn/T1yuNHTs2n/jEJ3LAAQe86j5JazrooINy9913t94Yek2vNct5552Xfv36ZcCAAdlqq61y2GGHvaEZAYBNQ3m9S6dbdyrlI0nOS9KQ5OKqqs4spYxOkqqqLiyl/DjJ0UkefOklK6qqGvh6xxw4cGA1Z86cDZmdGul52q87egTgLWjBWYd39AiblPnz56d3794dPQabGX83r+ZzC7Ax+NxCW5VS5r5Wk2nLPYFSVdW0JNNese3CNX7+XJLPbciQAAAAAGw8bVkOBgAAAMBmTgQCAAAAqAERCAAAAKAGRCAAAACAGhCBAAAAAGqgTd8OBgCwWnt//XVbvvK2lJIvfelL+cEPfpAkOffcc7N06dKMHTv2NV8zadKkfPazn01LS0v69++fJOnXr1+mTp2anj17tsfoAACbFVcCAQCbvK5du+aqq67KE088sV6v23nnnXPmmWdupKkAADYvIhAAsMnr3LlzRo0alX/913991XO/+tWvMmTIkOyzzz758Ic/nEcffbT1uSOOOCJ33XVX7r333jdzXACATZIIBABsFr7whS/ksssuy1NPPfWy7fvvv39uueWW3HbbbTn22GNz9tlntz7XqVOnfPWrX833vve9N3tcAIBNjnsCAQCbhXe84x05/vjjM27cuGy11Vat2x9++OEcc8wxWbRoUZ5//vn06tXrZa/7u7/7u5x55pl54IEH3uyRAQA2Ka4EAgA2G//0T/+Un/zkJ3n22Wdbt5188skZM2ZM7rzzzkyYMCHLly9/2Ws6d+6cL3/5y/mXf/mXN3tcAIBNiggEAGw23vWud+WTn/xkfvKTn7Rue+qpp7LTTjslSX72s5+t9XUjR47M9OnT8/jjj78pcwIAbIosBwMA1ktbvtJ9Y/ryl7+c888/v/Xx2LFj84lPfCI77bRT9ttvv7Uu+9piiy1yyimn5Itf/OKbOSoAwCalVFXVISceOHBgNWfOnA45N5ufnqf9uqNHAN6COjpmbGrmz5+f3r17d/QYbGb83byazy3AxuBzC21VSplbVdXAtT1nORgAAABADYhAAAAAADUgAgEAAADUgAgEAAAAUAMiEAAAAEANiEAAAAAANdC5owcAADYzY9/Zzsd7qk27nXnmmbn88svT0NCQTp06ZcKECRkyZEj7zrKG2267Le9///vzm9/8Jocccsha9xk5cmSOOOKIfPzjH3/Z9uuuuy7nnntupk6dutHmAwBYXyIQALDJu/nmmzN16tTceuut6dq1a5544ok8//zzG/WcV1xxRfbff/9cccUVrxmB1teKFSvSubOPXwBAx7AcDADY5C1atCg9evRI165dkyQ9evTIjjvumNNPPz2DBg1Kv379MmrUqFRVlSRpbm7OqaeemqFDh6Z3796ZPXt2RowYkT322CPf/OY3W4976aWXZvDgwWlqasqJJ56YlStXJkmqqsqUKVMyadKk/Pa3v83y5ctbt48ZMyZ9+vTJ4Ycfnscee6z1WL/5zW+y9957Z//9989VV13Vun3s2LEZNWpUhg0bluOPPz6PP/54jj766AwaNCiDBg3KjTfemCS5/vrr09TUlKampuyzzz555plnsmjRogwdOjRNTU3p169fZs2atXHfaADgLU0EAgA2ecOGDcvChQuz55575qSTTsr111+fJBkzZkxmz56defPmZdmyZS9bfrXFFltk5syZGT16dI488siMHz8+8+bNy6RJk7J48eLMnz8/kydPzo033piWlpY0NDTksssuS5LceOON6dWrV973vvelubk506ZNS5JcffXVuffee3PnnXfmoosuyk033ZQkWb58eT7/+c/nV7/6VWbNmpW//OUvL5t/7ty5+eUvf5nLL788X/ziF3Pqqadm9uzZ+fnPf57Pfe5zSZJzzz0348ePT0tLS2bNmpWtttoql19+eQ455JC0tLTk9ttvT1NT08Z+qwGAtzDXIwMAm7xu3bpl7ty5mTVrVmbMmJFjjjkmZ511Vrp3756zzz47zz33XJYsWZK+ffvmox/9aJJk+PDhSZLGxsb07ds3O+ywQ5Jkt912y8KFC3PDDTdk7ty5GTRoUJJk2bJl2W677ZKsWgp27LHHJkmOPfbY/Md//EdGjBiRmTNn5lOf+lQaGhqy44475kMf+lCS5J577kmvXr2yxx57JEn+/u//PhMnTmydf/jw4dlqq62SJNOnT8/dd9/d+tzTTz+dZ555Jh/84AfzpS99Kccdd1xGjBiRnXfeOYMGDcpnP/vZvPDCC/nYxz4mAgEAG0QEAgA2Cw0NDWlubk5zc3MaGxszYcKE3HHHHZkzZ0522WWXjB07tnXZVpLWpWOdOnVq/Xn14xUrVqSqqpxwwgn5/ve//7LzrFy5Mj//+c9zzTXX5Mwzz0xVVVm8eHGeeeaZJEkpZa3zvdb2JHn729/e+vOLL76Ym2++uTUKrXbaaafl8MMPz7Rp07Lffvtl+vTpGTp0aGbOnJlf//rX+fSnP52vfOUrOf7449v4jgEAvJzlYADAJu/ee+/Nfffd1/q4paUle+21V5JV9wdaunRppkyZsl7HPPjggzNlypTW+/osWbIkDz74YKZPn54BAwZk4cKFWbBgQR588MEcffTR+cUvfpGhQ4fmyiuvzMqVK7No0aLMmDEjSbL33nvngQceyB//+Mckq64kei3Dhg3L+eef/7LfJUn++Mc/prGxMV/72tcycODA3HPPPXnwwQez3Xbb5fOf/3z+4R/+Ibfeeut6/Y4AAGtyJRAAsH7a+JXu7Wnp0qU5+eST8+STT6Zz587ZfffdM3HixGy99dZpbGxMz549W5d1tVWfPn1yxhlnZNiwYXnxxRfTpUuXjB8/PldccUWOOuqol+179NFH54ILLsi0adNy7bXXprGxMXvuuWcOPPDAJMmWW26ZiRMn5vDDD0+PHj2y//77Z968eWs977hx4/KFL3wh/fv3z4oVKzJ06NBceOGFOe+88zJjxow0NDSkT58+Oeyww3LllVfmnHPOSZcuXdKtW7dccsklb+wNBABIUlZ/i8abbeDAgdWcOXM65Nxsfnqe9uuOHgF4C1pw1uEdPcImZf78+endu3dHj8Fmxt/Nq/ncAmwMPrfQVqWUuVVVDVzbc5aDAQAAANSACAQAAABQAyIQAAAAQA2IQAAAAAA1IAIBAAAA1IAIBAAAAFADnTt6AABg89L4s8Z2Pd6dJ9zZpv3OPPPMXH755WloaEinTp0yYcKEDBkypF1nWa1nz57p3r17GhoasnLlypxxxhk58sgj39CxRo4cmSOOOCIf//jHX/Xc448/nh133DHnn39+TjzxxA0de4O0tLTkkUceyUc+8pEOnQMA2HhcCQQAbPJuvvnmTJ06NbfeemvuuOOOTJ8+PbvssstGPeeMGTPS0tKSKVOm5JRTTtko5/jP//zP7Lfffrniiis2yvHXR0tLS6ZNm9bRYwAAG5EIBABs8hYtWpQePXqka9euSZIePXpkxx13zOmnn55BgwalX79+GTVqVKqqSpI0Nzfn1FNPzdChQ9O7d+/Mnj07I0aMyB577JFvfvObrce99NJLM3jw4DQ1NeXEE0/MypUrX3Xup59+Ottss03r44997GPZd99907dv30ycOLF1e7du3fKNb3wjAwYMyH777ZdHH330Vcf61re+lZEjR+bFF19MklxxxRX5wQ9+kIcffjh//vOfW/e75JJL0r9//wwYMCCf/vSnkySPPvpojjrqqAwYMCADBgzITTfdlCT54Q9/mH79+qVfv34577zzkiQLFixIv379Wo937rnnZuzYsa3vzde+9rUMHjw4e+65Z2bNmpXnn38+3/72tzN58uQ0NTVl8uTJbf+PAwBsNkQgAGCTN2zYsCxcuDB77rlnTjrppFx//fVJkjFjxmT27NmZN29eli1blqlTp7a+ZosttsjMmTMzevToHHnkkRk/fnzmzZuXSZMmZfHixZk/f34mT56cG2+8MS0tLWloaMhll13W+vqDDjoo/fr1y4EHHpgzzjijdfvFF1+cuXPnZs6cORk3blwWL16cJHn22Wez33775fbbb8/QoUNz0UUXvex3+OpXv5rHHnssP/3pT9OpU6csXLgwf/nLXzJ48OB88pOfbA0vd911V84888xce+21uf322/OjH/0oSXLKKafkwAMPzO23355bb701ffv2zdy5c/PTn/40v/vd73LLLbfkoosuym233bbO93PFihX5/e9/n/POOy/f/e53s8UWW+T000/PMccck5aWlhxzzDFv8L8UALApE4EAgE1et27dMnfu3EycODHbbrttjjnmmEyaNCkzZszIkCFD0tjYmGuvvTZ33XVX62uGDx+eJGlsbEzfvn2zww47pGvXrtltt92ycOHC/O///m/mzp2bQYMGpampKf/7v/+bP/3pT62vnzFjRubNm5c777wzY8aMydKlS5Mk48aNa73aZ+HChbnvvvuSrIpORxxxRJJk3333zYIFC1qP9c///M958sknM2HChJRSkiRXXnllPvnJTyZJjj322NYlYddee20+/vGPp0ePHkmSd73rXa3b//Ef/zFJ0tDQkHe+85254YYbctRRR+Xtb397unXrlhEjRmTWrFnrfD9HjBix1jkBgLc2N4YGADYLDQ0NaW5uTnNzcxobGzNhwoTccccdmTNnTnbZZZeMHTs2y5cvb91/9dKxTp06tf68+vGKFStSVVVOOOGEfP/733/d877vfe/L9ttvn7vvvjvPPfdcpk+fnptvvjlve9vb0tzc3HrOLl26tAaehoaGrFixovUYgwYNyty5c7NkyZLWqHPFFVfk0Ucfbb366JFHHsl9992Xqqpaj7Muq5e/vVLnzp1bl5wledn7suZ788o5AYC3NlcCAQCbvHvvvbf1iptk1U2M99prrySr7g+0dOnSTJkyZb2OefDBB2fKlCl57LHHkiRLlizJgw8++Kr9HnvssTzwwAPZdddd89RTT2WbbbbJ2972ttxzzz255ZZb2nSuQw89NKeddloOP/zwPPPMM7n33nvz7LPP5s9//nMWLFiQBQsW5Otf/3quvPLKHHzwwfm///f/ti4zW7JkSeu8F1xwQZJk5cqVefrppzN06ND84he/yHPPPZdnn302V199dQ444IBsv/32eeyxx7J48eL89a9/fdkyudfSvXv3PPPMM236fQCAzZMrgQCA9dLWr3RvT0uXLs3JJ5+cJ598Mp07d87uu++eiRMnZuutt05jY2N69uyZQYMGrdcx+/TpkzPOOCPDhg3Liy++mC5dumT8+PHZddddk6y6J1BDQ0NeeOGFnHXWWdl+++1z6KGH5sILL0z//v2z1157Zb/99mvz+T7xiU/kmWeeyfDhwzN48OAcddRRL3v+6KOPzrHHHptvfetb+cY3vpEDDzwwDQ0N2WeffTJp0qT86Ec/yqhRo/KTn/wkDQ0NueCCC/KBD3wgI0eOzODBg5Mkn/vc57LPPvskSb797W9nyJAh6dWrV/bee+91znfQQQflrLPOSlNTU77+9a+7LxAAvAWV17qMeGMbOHBgNWfOnA45N5ufnqf9uqNHAN6CFpx1eEePsEmZP39+evfu3dFjsJnxd/NqPrcAG4PPLbRVKWVuVVUD1/ac5WAAAAAANSACAQAAANSACAQAAABQAyIQAAAAQA2IQAAAAAA1IAIBAAAA1EDnjh4AANi8zN+7fb8OvPc989u035lnnpnLL788DQ0N6dSpUyZMmJAhQ4a06yyr9ezZM927d09DQ0OSZOjQoRk3btwGH/cjH/lILr/88my99dbp1q1bli5dusHHBABoKxEIANjk3XzzzZk6dWpuvfXWdO3aNU888USef/75jXrOGTNmpEePHu16zGnTprXr8QAA1oflYADAJm/RokXp0aNHunbtmiTp0aNHdtxxx5x++ukZNGhQ+vXrl1GjRqWqqiRJc3NzTj311AwdOjS9e/fO7NmzM2LEiOyxxx755je/2XrcSy+9NIMHD05TU1NOPPHErFy58nXnaOtxP/axj2XfffdN3759M3HixNbtPXv2zBNPPNGebw0AQJuJQADAJm/YsGFZuHBh9txzz5x00km5/vrrkyRjxozJ7NmzM2/evCxbtixTp05tfc0WW2yRmTNnZvTo0TnyyCMzfvz4zJs3L5MmTcrixYszf/78TJ48OTfeeGNaWlrS0NCQyy67rPX1Bx10UJqamtLU1JR//dd/bfNxk+Tiiy/O3LlzM2fOnIwbN651OwBAR7IcDADY5HXr1i1z587NrFmzMmPGjBxzzDE566yz0r1795x99tl57rnnsmTJkvTt2zcf/ehHkyTDhw9PkjQ2NqZv377ZYYcdkiS77bZbFi5cmBtuuCFz587NoEGDkiTLli3Ldttt13rO11oOtq7jvvvd7864ceNy9dVXJ0kWLlyY++67L+9+97s30rsDANA2IhAAsFloaGhIc3Nzmpub09jYmAkTJuSOO+7InDlzsssuu2Ts2LFZvnx56/6rl4516tSp9efVj1esWJGqqnLCCSfk+9///nrNsa7jXnfddZk+fXpuvvnmvO1tb0tzc/PL5gIA6CiWgwEAm7x777039913X+vjlpaW7LXXXklW3R9o6dKlmTJlynod8+CDD86UKVPy2GOPJUmWLFmSBx98cINnfeqpp7LNNtvkbW97W+65557ccsstG3xMAID24EogAGC9tPUr3dvT0qVLc/LJJ+fJJ59M586ds/vuu2fixInZeuut09jYmJ49e7Yu62qrPn365IwzzsiwYcPy4osvpkuXLhk/fnx23XXXJKvuCbT6K+L79++fSy65pE3HPfTQQ3PhhRemf//+2WuvvbLffvut3y8LALCRlNXfovFmGzhwYDVnzpwOOTebn56n/bqjRwDeghacdXhHj7BJmT9/fnr37t3RY7CZ8Xfzaj63ABuDzy20VSllblVVA9f2nOVgAAAAADUgAgEAAADUgAgEAAAAUAMiEAAAAEANiEAAAAAANSACAQAAANRA544eAADYvIwffW27Hu8LF36oTfudeeaZufzyy9PQ0JBOnTplwoQJGTJkSLvOslrPnj3TvXv3dOrUKdtvv30uueSSvOc970m3bt2ydOnSjXJOAICNzZVAAMAm7+abb87UqVNz66235o477sj06dOzyy67bNRzzpgxI7fffnsGDhyY733vexv1XAAAbwYRCADY5C1atCg9evRI165dkyQ9evTIjjvumNNPPz2DBg1Kv379MmrUqFRVlSRpbm7OqaeemqFDh6Z3796ZPXt2RowYkT322CPf/OY3W4976aWXZvDgwWlqasqJJ56YlStXvurcQ4cOzf3339/6+Bvf+EYGDBiQ/fbbL48++miS5MEHH8zBBx+c/v375+CDD85DDz2UJBk5cmROOeWU/M3f/E122223TJkypfU455xzTgYNGpT+/fvnO9/5Tvu/aQAAryACAQCbvGHDhmXhwoXZc889c9JJJ+X6669PkowZMyazZ8/OvHnzsmzZskydOrX1NVtssUVmzpyZ0aNH58gjj8z48eMzb968TJo0KYsXL878+fMzefLk3HjjjWlpaUlDQ0Muu+yyV5176tSpaWxsTJI8++yz2W+//XL77bdn6NChueiii1rnOP7443PHHXfkuOOOyymnnNL6+kWLFuWGG27I1KlTc9pppyVJfvvb3+a+++7L73//+7S0tGTu3LmZOXPmRnv/AAAS9wQCADYD3bp1y9y5czNr1qzMmDEjxxxzTM4666x07949Z599dp577rksWbIkffv2zUc/+tEkyfDhw5MkjY2N6du3b3bYYYckyW677ZaFCxfmhhtuyNy5czNo0KAkybJly7Lddtu1nvOggw5KQ0ND+vfvnzPOOCPJqrB0xBFHJEn23Xff/M///E+SVcvVrrrqqiTJpz/96Xz1q19tPc7HPvaxdOrUKX369Gm9cui3v/1tfvvb32afffZJkixdujT33Xdfhg4dunHeQACAiEAAwGaioaEhzc3NaW5uTmNjYyZMmJA77rgjc+bMyS677JKxY8dm+fLlrfuvXjrWqVOn1p9XP16xYkWqqsoJJ5yQ73//+2s934wZM9KjR4+XbevSpUtKKa3zrFixYq2vXb3PmnMkaV2uVlVVvv71r+fEE09cn7cAAGCDWA4GAGzy7r333tx3332tj1taWrLXXnslWXV/oKVLl77sfjttcfDBB2fKlCl57LHHkiRLlizJgw8++Ibm+5u/+ZtceeWVSZLLLrss+++//+vuf8ghh+Tiiy9u/aaxP//5z61zAABsLK4EAgDWS1u/0r09LV26NCeffHKefPLJdO7cObvvvnsmTpyYrbfeOo2NjenZs2frsq626tOnT84444wMGzYsL774Yrp06ZLx48dn1113Xe/5xo0bl89+9rM555xzsu222+anP/3p6+4/bNiwzJ8/Px/4wAeSrFrudumll75sORoAQHsrqy9LfrMNHDiwmjNnToecm81Pz9N+3dEjAG9BC846vKNH2KTMnz8/vXv37ugx2Mz4u3k1n1uAjcHnFtqqlDK3qqqBa3vOcjAAAACAGhCBAAAAAGpABAIAAACoAREIAAAAoAZEIAAAAIAaEIEAAAAAaqBzRw8AAGxefnDMEe16vC9Pntqm/c4888xcfvnlaWhoSKdOnTJhwoQMGTKkXWdZrWfPnunevXs6deqU7bffPpdcckne8573rHXf6667Lueee26mTp2aa665JnfffXdOO+20jTIXAMCGcCUQALDJu/nmmzN16tTceuutueOOOzJ9+vTssssuG/WcM2bMyO23356BAwfme9/7XpteM3z4cAEIANhkiUAAwCZv0aJF6dGjR7p27Zok6dGjR3bcccecfvrpGTRoUPr165dRo0alqqokSXNzc0499dQMHTo0vXv3zuzZszNixIjsscce+eY3v9l63EsvvTSDBw9OU1NTTjzxxKxcufJV5x46dGjuv//+LF++PJ/5zGfS2NiYffbZJzNmzHjVvpMmTcqYMWOSJI8++miOOuqoDBgwIAMGDMhNN93U5nMCAGwMIhAAsMkbNmxYFi5cmD333DMnnXRSrr/++iTJmDFjMnv27MybNy/Lli3L1Kn//9KyLbbYIjNnzszo0aNz5JFHZvz48Zk3b14mTZqUxYsXZ/78+Zk8eXJuvPHGtLS0pKGhIZdddtmrzj116tQ0NjZm/PjxSZI777wzV1xxRU444YQsX778NWc+5ZRTcuCBB+b222/Prbfemr59+7b5nAAAG4N7AgEAm7xu3bpl7ty5mTVrVmbMmJFjjjkmZ511Vrp3756zzz47zz33XJYsWZK+ffvmox/9aJJVS7OSpLGxMX379s0OO+yQJNltt92ycOHC3HDDDZk7d24GDRqUJFm2bFm222671nMedNBBaWhoSP/+/XPGGWfkM5/5TE4++eQkyd57751dd901f/jDH15z5muvvTaXXHJJkqShoSHvfOc78x//8R+ve04AgI1JBAIANgsNDQ1pbm5Oc3NzGhsbM2HChNxxxx2ZM2dOdtlll4wdO/ZlV+asXjrWqVOn1p9XP16xYkWqqsoJJ5yQ73//+2s934wZM9KjR4/Wx6uXmm2IdZ0TAGBjshwMANjk3XvvvbnvvvtaH7e0tGSvvfZKsur+QEuXLs2UKVPW65gHH3xwpkyZksceeyxJsmTJkjz44IOvuf/QoUNbl2794Q9/yEMPPdQ6w2sd/4ILLkiSrFy5Mk8//fR6nxMAoD25EggAWC9t/Ur39rR06dKcfPLJefLJJ9O5c+fsvvvumThxYrbeeus0NjamZ8+erUus2qpPnz4544wzMmzYsLz44ovp0qVLxo8fn1133XWt+5900kkZPXp0Ghsb07lz50yaNOllVxi90o9+9KOMGjUqP/nJT9LQ0JALLrggH/jAB9brnAAA7am0x6XNb8TAgQOrOXPmdMi52fz0PO3XHT0C8Ba04KzDO3qETcr8+fPTu3fvjh6DzYy/m1fzuQXYGHxuoa1KKXOrqhq4tucsBwMAAACoAREIAAAAoAZEIACgVUctE2fz5O8FADYvIhAAkCTZcssts3jxYv/DnjapqiqLFy/Olltu2dGjAABt5NvBAIAkyc4775yHH344jz/+eEePwmZiyy23zM4779zRYwAAbSQCAQBJki5duqRXr14dPQYAABtJm5aDlVIOLaXcW0q5v5Ry2lqeL6WUcS89f0cp5f3tPyoAAAAAb9Q6I1AppSHJ+CSHJemT5FOllD6v2O2wJHu89G9UkgvaeU4AAAAANkBbrgQanOT+qqr+VFXV80muTHLkK/Y5Mskl1Sq3JNm6lLJDO88KAAAAwBvUlnsC7ZRk4RqPH04ypA377JRk0Zo7lVJGZdWVQkmytJRy73pNC7BuPZI80dFDsHko/9LREwBQcz630GY+t7Aedn2tJ9oSgcpatr3yu2Pbsk+qqpqYZGIbzgnwhpRS5lRVNbCj5wAAWBefW4A3W1uWgz2cZJc1Hu+c5JE3sA8AAAAAHaQtEWh2kj1KKb1KKVskOTbJNa/Y55okx7/0LWH7JXmqqqpFrzwQAAAAAB1jncvBqqpaUUoZk+S/kzQkubiqqrtKKaNfev7CJNOSfCTJ/UmeS/KZjTcywOuy5BQA2Fz43AK8qUpVverWPQAAAAC8xbRlORgAAAAAmzkRCAAAAKAGRCAAAACAGljnjaEBNmWllL2THJlkpyRVkkeSXFNV1fwOHQwAAGAT40ogYLNVSvlakiuTlCS/TzL7pZ+vKKWc1pGzAQC0VSnFtysDbwrfDgZstkopf0jSt6qqF16xfYskd1VVtUfHTAYA0HallIeqqnpvR88BvPVZDgZszl5MsmOSB1+xfYeXngMA2CSUUu54raeSbP9mzgLUlwgEbM7+Kcn/llLuS7LwpW3vTbJ7kjEdNRQAwFpsn+SQJP/vFdtLkpve/HGAOhKBgM1WVVW/KaXsmWRwVt0YuiR5OMnsqqpWduhwAAAvNzVJt6qqWl75RCnlujd9GqCW3BMIAAAAoAZ8OxgAAABADYhAAAAAADUgAgEAtVJKWVlKaVnjX8+NcI4FpZQe7X1cAIAN4cbQAEDdLKuqqmltT5RSSlbdM/HFN3ckAICNz5VAAECtlVJ6llLml1L+PcmtSXYppVxQSplTSrmrlPLdNfZtvcKnlDJw9Tf6lFLeXUr5bSnltlLKhKz6tkIAgE2KCAQA1M1WaywFu/qlbXsluaSqqn2qqnowyTeqqhqYpH+SA0sp/ddxzO8kuaGqqn2SXJPkvRttegCAN8hyMACgbl62HOylewI9WFXVLWvs88lSyqis+qy0Q5I+Se54nWMOTTIiSaqq+nUp5f+199AAABtKBAIASJ5d/UMppVeS/5NkUFVV/6+UMinJli89vSL//5XUW+blqo09JADAhrAcDADg5d6RVVHoqVLK9kkOW+O5BUn2fenno9fYPjPJcUlSSjksyTYbf0wAgPUjAgEArKGqqtuT3JbkriQXJ7lxjae/m+RHpZRZSVa+YvvQUsqtSYYleehNGhcAoM1KVblyGQAAAOCtzpVAAAAAADUgAgEAAADUgAgEAAAAUAMiEAAAAEANiEAAAAAANSACAQAAANSACAQAAABQAyIQAAAAQA38f5lOwa97X3w6AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABIEAAAJZCAYAAAA+iyW5AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAoeElEQVR4nO3dfZCfZX3v8c/VhBgRIRRSjQQMVAxJYLOSBAMo4VRFzFEeiu0RKRAQUyigZaZTMmOreHSs7ekZbAYk0jOICBI61AcOIp4DllNDQEgwiYQHSWMk4UEglIgghYTr/JGwXZY8bJJfsiHX6zWzw/7u+9p7v5vkj/Xtdd+/UmsNAAAAADu33xnoAQAAAADY9kQgAAAAgAaIQAAAAAANEIEAAAAAGiACAQAAADRABAIAAABogAgEAJCklPKbUsoBAz0HAMC2IgIBAE0ppSwrpfx2XfR55eNttdbdaq1Lt/Cag0opXyylPFpKebaU8tNSyrAOjw4AsFUGD/QAAAAD4CO11ls6eL3PJzkiyeFJHk4yLskLHbw+AMBWsxMIACBJKaWWUt6x7vO9Sin/u5Ty61LK3et2+czZwNftmeTPk3yy1vrLuta9tVYRCADYoYhAAACvdWmS55K8Ncnp6z425JAkq5N8tJTyeCnl56WUc7fDjAAAm8XtYABAi75bSlm97vPbaq0nvHKilDIoyUlJDq61Pp/kvlLKN5IcvYFrjUyyR5J3Jtk/yYFJbi2l/LzW+n+30fwAAJvNTiAAoEUn1FqHrfs4oc+54Vn7f5Qt73VseTbst+v++99rrb+ttS5KMjvJ1I5NCwDQASIQAMCrPZm1t3eN7HVs342sX7Tuv3WbTQQA0AEiEABAL7XWNUm+neSiUsqupZSDkpy2kfX/luTHST5TSnlDKWVMkv+W5MbtMjAAQD+JQAAAr3Ve1j7n5/Ek30xybZL/2Mj6k5O8PcnKJN9P8te11lu39ZAAAJuj1GrnMgDAxpRS/jbJW2utG3uXMACAHZqdQAAAfZRSDiqldJW1DkvyiSTfGei5AAC2hreIBwB4rTdn7S1gb0vyRJL/meR7AzoRAMBWcjsYAAAAQAPcDgYAAADQABEIAAAAoAED9kygvffeu44aNWqgvj0AAADATmf+/PlP1VqHr+/cgEWgUaNGZd68eQP17QEAAAB2OqWUX27onNvBAAAAABogAgEAAAA0QAQCAAAAaIAIBAAAANAAEQgAAACgASIQAAAAQANEIAAAAIAGiEAAAAAADRCBAAAAABogAgEAAAA0QAQCAAAAaIAIBAAAANAAEQgAAACgASIQAAAAQANEIAAAAIAGiEAAAAAADRCBAAAAABogAgEAAAA0QAQCAAAAaIAIBAAAANCATUagUsoVpZQnSin3buB8KaXMLKUsKaUsKqUc2vkxAQAAANga/dkJdGWSYzdy/kNJDlz3MT3JZVs/FgAAAACdtMkIVGv91yRPb2TJ8UmuqmvdmWRYKWVEpwYEAAAAYOt14plA+yRZ3uv1inXHAAAAANhBDO7ANcp6jtX1LixletbeMpb99tuvA9+aZly0x0BPAOyMLlo10BMAOyO/twDbgt9b6IBO7ARakWTfXq9HJnl0fQtrrZfXWifWWicOHz68A98aAAAAgP7oRAS6Iclp694lbHKSVbXWxzpwXQAAAAA6ZJO3g5VSrk1ydJK9SykrknwuyS5JUmudleSmJFOTLEnyfJIzttWwAAAAAGyZTUagWuvJmzhfk5zbsYkAAAAA6LhO3A4GAAAAwA5OBAIAAABogAgEAAAA0AARCAAAAKABIhAAAABAA0QgAAAAgAaIQAAAAAANEIEAAAAAGiACAQAAADRABAIAAABogAgEAAAA0AARCAAAAKABIhAAAABAA0QgAAAAgAaIQAAAAAANEIEAAAAAGiACAQAAADRABAIAAABogAgEAAAA0AARCAAAAKABIhAAAABAA0QgAAAAgAaIQAAAAAANEIEAAAAAGiACAQAAADRABAIAAABogAgEAAAA0AARCAAAAKABIhAAAABAA0QgAAAAgAaIQAAAAAANEIEAAAAAGiACAQAAADRABAIAAABogAgEAAAA0AARCAAAAKABIhAAAABAA0QgAAAAgAaIQAAAAAANEIEAAAAAGiACAQAAADRABAIAAABogAgEAAAA0AARCAAAAKABIhAAAABAA0QgAAAAgAaIQAAAAAANEIEAAAAAGiACAQAAADRABAIAAABogAgEAAAA0AARCAAAAKABIhAAAABAA0QgAAAAgAaIQAAAAAANEIEAAAAAGiACAQAAADRABAIAAABogAgEAAAA0AARCAAAAKABIhAAAABAA0QgAAAAgAaIQAAAAAANEIEAAAAAGiACAQAAADRABAIAAABogAgEAAAA0AARCAAAAKABIhAAAABAA0QgAAAAgAaIQAAAAAANEIEAAAAAGiACAQAAADRABAIAAABogAgEAAAA0AARCAAAAKABIhAAAABAA0QgAAAAgAaIQAAAAAANEIEAAAAAGiACAQAAADRABAIAAABogAgEAAAA0AARCAAAAKABIhAAAABAA0QgAAAAgAaIQAAAAAANEIEAAAAAGiACAQAAADRABAIAAABogAgEAAAA0AARCAAAAKABIhAAAABAA0QgAAAAgAaIQAAAAAAN6FcEKqUcW0p5sJSypJQyYz3n9yil/O9SysJSyuJSyhmdHxUAAACALbXJCFRKGZTk0iQfSjI2ycmllLF9lp2b5L5a6/gkRyf5n6WUIR2eFQAAAIAt1J+dQIclWVJrXVprfTHJ7CTH91lTk7y5lFKS7Jbk6SSrOzopAAAAAFusPxFonyTLe71ese5Yb5ckGZPk0SQ/S/LpWuvLfS9USpleSplXSpn35JNPbuHIAAAAAGyu/kSgsp5jtc/rDyZZkORtSbqTXFJK2f01X1Tr5bXWibXWicOHD9/MUQEAAADYUoP7sWZFkn17vR6ZtTt+ejsjyZdrrTXJklLKL5IclOSujkxJ80a98K2BHgHYCS0b6AEAAGA76s9OoLuTHFhK2X/dw54/luSGPmseTvK+JCmlvCXJ6CRLOzkoAAAAAFtukzuBaq2rSynnJflhkkFJrqi1Li6lnL3u/KwkX0hyZSnlZ1l7+9iFtdantuHcAAAAAGyG/twOllrrTUlu6nNsVq/PH01yTGdHAwAAAKBT+nM7GAAAAACvcyIQAAAAQANEIAAAAIAGiEAAAAAADRCBAAAAABogAgEAAAA0QAQCAAAAaIAIBAAAANAAEQgAAACgASIQAAAAQANEIAAAAIAGiEAAAAAADRCBAAAAABogAgEAAAA0QAQCAAAAaIAIBAAAANAAEQgAAACgASIQAAAAQANEIAAAAIAGiEAAAAAADRCBAAAAABogAgEAAAA0QAQCAAAAaIAIBAAAANAAEQgAAACgASIQAAAAQANEIAAAAIAGiEAAAAAADRCBAAAAABogAgEAAAA0QAQCAAAAaIAIBAAAANAAEQgAAACgASIQAAAAQANEIAAAAIAGiEAAAAAADRCBAAAAABogAgEAAAA0QAQCAAAAaMDggR4AAAB2JqNe+NZAjwDshJYN9ADsFOwEAgAAAGiACAQAAADQABEIAAAAoAEiEAAAAEADRCAAAACABohAAAAAAA0QgQAAAAAaIAIBAAAANEAEAgAAAGiACAQAAADQABEIAAAAoAEiEAAAAEADRCAAAACABohAAAAAAA0QgQAAAAAaIAIBAAAANEAEAgAAAGiACAQAAADQABEIAAAAoAEiEAAAAEADRCAAAACABohAAAAAAA0QgQAAAAAaIAIBAAAANEAEAgAAAGiACAQAAADQABEIAAAAoAEiEAAAAEADRCAAAACABohAAAAAAA0QgQAAAAAaIAIBAAAANEAEAgAAAGiACAQAAADQABEIAAAAoAEiEAAAAEADRCAAAACABohAAAAAAA0QgQAAAAAaIAIBAAAANEAEAgAAAGiACAQAAADQABEIAAAAoAEiEAAAAEADRCAAAACABohAAAAAAA0QgQAAAAAaIAIBAAAANEAEAgAAAGiACAQAAADQABEIAAAAoAEiEAAAAEADRCAAAACABohAAAAAAA3oVwQqpRxbSnmwlLKklDJjA2uOLqUsKKUsLqX8v86OCQAAAMDWGLypBaWUQUkuTfKBJCuS3F1KuaHWel+vNcOSfDXJsbXWh0spv7eN5gUAAABgC/RnJ9BhSZbUWpfWWl9MMjvJ8X3WfDzJt2utDydJrfWJzo4JAAAAwNboTwTaJ8nyXq9XrDvW2zuT7FlKua2UMr+UclqnBgQAAABg623ydrAkZT3H6nquMyHJ+5K8MckdpZQ7a60/f9WFSpmeZHqS7Lfffps/LQAAAABbpD87gVYk2bfX65FJHl3Pmptrrc/VWp9K8q9Jxve9UK318lrrxFrrxOHDh2/pzAAAAABspv5EoLuTHFhK2b+UMiTJx5Lc0GfN95K8t5QyuJSya5J3J7m/s6MCAAAAsKU2eTtYrXV1KeW8JD9MMijJFbXWxaWUs9edn1Vrvb+UcnOSRUleTvK/aq33bsvBAQAAAOi//jwTKLXWm5Lc1OfYrD6v/0eS/9G50QAAAADolP7cDgYAAADA65wIBAAAANAAEQgAAACgASIQAAAAQANEIAAAAIAGiEAAAAAADRCBAAAAABogAgEAAAA0QAQCAAAAaIAIBAAAANAAEQgAAACgASIQAAAAQANEIAAAAIAGiEAAAAAADRCBAAAAABogAgEAAAA0QAQCAAAAaIAIBAAAANAAEQgAAACgASIQAAAAQANEIAAAAIAGiEAAAAAADRCBAAAAABogAgEAAAA0QAQCAAAAaIAIBAAAANAAEQgAAACgASIQAAAAQANEIAAAAIAGiEAAAAAADRCBAAAAABogAgEAAAA0QAQCAAAAaIAIBAAAANAAEQgAAACgASIQAAAAQANEIAAAAIAGiEAAAAAADRCBAAAAABogAgEAAAA0QAQCAAAAaIAIBAAAANAAEQgAAACgASIQAAAAQANEIAAAAIAGiEAAAAAADRCBAAAAABogAgEAAAA0QAQCAAAAaIAIBAAAANAAEQgAAACgASIQAAAAQANEIAAAAIAGiEAAAAAADRCBAAAAABogAgEAAAA0QAQCAAAAaIAIBAAAANAAEQgAAACgASIQAAAAQANEIAAAAIAGiEAAAAAADRCBAAAAABogAgEAAAA0QAQCAAAAaIAIBAAAANAAEQgAAACgASIQAAAAQANEIAAAAIAGiEAAAAAADRCBAAAAABogAgEAAAA0QAQCAAAAaIAIBAAAANAAEQgAAACgASIQAAAAQANEIAAAAIAGiEAAAAAADRCBAAAAABogAgEAAAA0QAQCAAAAaIAIBAAAANAAEQgAAACgASIQAAAAQANEIAAAAIAGiEAAAAAADRCBAAAAABogAgEAAAA0QAQCAAAAaIAIBAAAANAAEQgAAACgASIQAAAAQANEIAAAAIAGiEAAAAAADRCBAAAAABrQrwhUSjm2lPJgKWVJKWXGRtZNKqWsKaV8tHMjAgAAALC1NhmBSimDklya5ENJxiY5uZQydgPr/jbJDzs9JAAAAABbpz87gQ5LsqTWurTW+mKS2UmOX8+685P8c5InOjgfAAAAAB3Qnwi0T5LlvV6vWHesRyllnyQnJpm1sQuVUqaXUuaVUuY9+eSTmzsrAAAAAFuoPxGorOdY7fP6K0kurLWu2diFaq2X11on1lonDh8+vJ8jAgAAALC1BvdjzYok+/Z6PTLJo33WTEwyu5SSJHsnmVpKWV1r/W4nhgQAAABg6/QnAt2d5MBSyv5JHknysSQf772g1rr/K5+XUq5McqMABAAAALDj2GQEqrWuLqWcl7Xv+jUoyRW11sWllLPXnd/oc4AAAAAAGHj92QmUWutNSW7qc2y98afWOm3rxwIAAACgk/rzYGgAAAAAXudEIAAAAIAGiEAAAAAADRCBAAAAABogAgEAAAA0QAQCAAAAaIAIBAAAANAAEQgAAACgASIQAAAAQANEIAAAAIAGiEAAAAAADRCBAAAAABogAgEAAAA0QAQCAAAAaIAIBAAAANAAEQgAAACgASIQAAAAQANEIAAAAIAGiEAAAAAADRCBAAAAABogAgEAAAA0QAQCAAAAaIAIBAAAANAAEQgAAACgASIQAAAAQANEIAAAAIAGiEAAAAAADRCBAAAAABogAgEAAAA0QAQCAAAAaIAIBAAAANAAEQgAAACgASIQAAAAQANEIAAAAIAGiEAAAAAADRCBAAAAABogAgEAAAA0QAQCAAAAaIAIBAAAANAAEQgAAACgASIQAAAAQANEIAAAAIAGiEAAAAAADRCBAAAAABogAgEAAAA0QAQCAAAAaIAIBAAAANAAEQgAAACgASIQAAAAQANEIAAAAIAGiEAAAAAADRCBAAAAABogAgEAAAA0QAQCAAAAaIAIBAAAANAAEQgAAACgASIQAAAAQANEIAAAAIAGiEAAAAAADRCBAAAAABogAgEAAAA0QAQCAAAAaIAIBAAAANAAEQgAAACgASIQAAAAQANEIAAAAIAGiEAAAAAADRCBAAAAABogAgEAAAA0QAQCAAAAaIAIBAAAANAAEQgAAACgASIQAAAAQANEIAAAAIAGiEAAAAAADRCBAAAAABogAgEAAAA0QAQCAAAAaIAIBAAAANAAEQgAAACgASIQAAAAQANEIAAAAIAGiEAAAAAADRCBAAAAABogAgEAAAA0QAQCAAAAaIAIBAAAANAAEQgAAACgASIQAAAAQANEIAAAAIAGiEAAAAAADRCBAAAAABogAgEAAAA0QAQCAAAAaEC/IlAp5dhSyoOllCWllBnrOX9KKWXRuo+5pZTxnR8VAAAAgC21yQhUShmU5NIkH0oyNsnJpZSxfZb9IsmUWmtXki8kubzTgwIAAACw5fqzE+iwJEtqrUtrrS8mmZ3k+N4Laq1za63/vu7lnUlGdnZMAAAAALZGfyLQPkmW93q9Yt2xDflEkh9szVAAAAAAdNbgfqwp6zlW17uwlP+StRHoPRs4Pz3J9CTZb7/9+jkiAAAAAFurPzuBViTZt9frkUke7buolNKV5H8lOb7WunJ9F6q1Xl5rnVhrnTh8+PAtmRcAAACALdCfCHR3kgNLKfuXUoYk+ViSG3ovKKXsl+TbSU6ttf6882MCAAAAsDU2eTtYrXV1KeW8JD9MMijJFbXWxaWUs9edn5Xks0n2SvLVUkqSrK61Ttx2YwMAAACwOfrzTKDUWm9KclOfY7N6fX5WkrM6OxoAAAAAndKf28EAAAAAeJ0TgQAAAAAaIAIBAAAANEAEAgAAAGiACAQAAADQABEIAAAAoAEiEAAAAEADRCAAAACABohAAAAAAA0QgQAAAAAaIAIBAAAANEAEAgAAAGiACAQAAADQABEIAAAAoAEiEAAAAEADRCAAAACABohAAAAAAA0QgQAAAAAaIAIBAAAANEAEAgAAAGiACAQAAADQABEIAAAAoAEiEAAAAEADRCAAAACABohAAAAAAA0QgQAAAAAaIAIBAAAANEAEAgAAAGiACAQAAADQABEIAAAAoAEiEAAAAEADRCAAAACABohAAAAAAA0QgQAAAAAaIAIBAAAANEAEAgAAAGiACAQAAADQABEIAAAAoAEiEAAAAEADRCAAAACABohAAAAAAA0QgQAAAAAaIAIBAAAANEAEAgAAAGiACAQAAADQgMEDPQAAsG289NJLWbFiRV544YWBHgWSJEOHDs3IkSOzyy67DPQoANAkEQgAdlIrVqzIm9/85owaNSqllIEeh8bVWrNy5cqsWLEi+++//0CPAwBNcjsYAOykXnjhhey1114CEDuEUkr22msvO9MAYACJQACwExOA2JH49wgAA0sEAgAAAGiACAQADRk0aFC6u7tz8MEH54/+6I/y/PPPb3DtlVdemfPOOy9JMmvWrFx11VWb/f3e9a53ZcGCBUmS1atX501velOuvvrqnvMTJkzIPffcs1nXvPPOO/Pud7873d3dGTNmTC666KKNrl+2bFkOPvjgzR19k6ZOnZpnnnlmq6/f9+vnzJmTww47LAcddFAOOuigXH755Zt9jQ350pe+tMVzbo7bbrstc+fO3S7fCwDoPxEIABryxje+MQsWLMi9996bIUOGZNasWf36urPPPjunnXbaZn+/I444oicGLFy4MKNHj+55/dxzz2Xp0qUZP378Zl3z9NNPz+WXX97zc/zxH//xZs+1NWqtefnll3PTTTdl2LBhHb32448/no9//OOZNWtWHnjggcyZMydf+9rX8v3vf78j19+SCLRmzZrN/hoRCAB2TCIQADTqve99b5YsWZKnn346J5xwQrq6ujJ58uQsWrToNWsvuuii/P3f/32SZMmSJXn/+9+f8ePH59BDD82//du/5dRTT833vve9nvWnnHJKbrjhhhx55JE9MWDu3Lk5++yze3YG3XXXXTn00EMzaNCgnHDCCZkwYULGjRvXs/NlzZo1mTZtWg4++OAccsghufjii5MkTzzxREaMGJFk7c6msWPHvmbGJDn44IOzbNmyJGt3IZ1++unp6urKRz/60Z4dUDNmzMjYsWPT1dWVv/iLv0iS/OpXv8qJJ56Y8ePHZ/z48Zk7d26WLVuWMWPG5M/+7M9y6KGHZvny5Rk1alSeeuqpjV5//vz5mTJlSiZMmJAPfvCDeeyxx3qOjx8/PocffnguvfTSnpkvvfTSTJs2LYceemiSZO+9987f/d3f5ctf/nKSZNq0afnUpz6VI444IgcccECuv/761/xdXXnllfnDP/zDHHvssTnwwAPzl3/5lz0/629/+9t0d3fnlFNOSZJcffXVOeyww9Ld3Z0//dM/7Qk+u+22Wz772c/m3e9+d+64447stttu+cxnPpPx48dn8uTJ+dWvfpUkefLJJ3PSSSdl0qRJmTRpUm6//fYsW7Yss2bNysUXX5zu7u78+Mc/Xt8/PwBgAIhAANCg1atX5wc/+EEOOeSQfO5zn8u73vWuLFq0KF/60pc2uePnlFNOybnnnpuFCxdm7ty5GTFiRM4666x8/etfT5KsWrUqc+fOzdSpU1+1E2ju3Lk56qij8oY3vCHPPvts5s6dmyOPPDJJcsUVV2T+/PmZN29eZs6cmZUrV2bBggV55JFHcu+99+ZnP/tZzjjjjCTJBRdckNGjR+fEE0/M1772tX6929SDDz6Y6dOnZ9GiRdl9993z1a9+NU8//XS+853vZPHixVm0aFH+6q/+KknyqU99KlOmTMnChQtzzz33ZNy4cT3XOO200/LTn/40b3/72zd5/Zdeeinnn39+rr/++syfPz9nnnlmPvOZzyRJzjjjjMycOTN33HHHq66zePHiTJgw4VXHJk6cmMWLF/e8fuyxxzJnzpzceOONmTFjxnp/3gULFuS6667Lz372s1x33XVZvnx5vvzlL/fsBLvmmmty//3357rrrsvtt9+eBQsWZNCgQbnmmmuSrN2ldfDBB+cnP/lJ3vOe9+S5557L5MmTs3Dhwhx11FH5x3/8xyTJpz/96VxwwQW5++6788///M8566yzMmrUqJx99tm54IILsmDBgrz3ve/d5N8PALB9iEAA0JBXdoJMnDgx++23Xz7xiU9kzpw5OfXUU5Mkf/AHf5CVK1dm1apV6/36Z599No888khOPPHEJMnQoUOz6667ZsqUKVmyZEmeeOKJXHvttTnppJMyePDgjBo1Ki+++GIef/zxPPDAAxk9enQmTZqUn/zkJ5k7d26OOOKIJMnMmTN7dpksX748Dz30UA444IAsXbo0559/fm6++ebsvvvuSZLPfvazmTdvXo455ph861vfyrHHHrvJn3vfffftCU5/8id/kjlz5mT33XfP0KFDc9ZZZ+Xb3/52dt111yTJj370o5xzzjlJ1u402mOPPZIkb3/72zN58uR+X//BBx/Mvffemw984APp7u7OF7/4xaxYsSKrVq3KM888kylTpiRJz599svZWs/W9g1bvYyeccEJ+53d+J2PHju3ZkdPX+973vuyxxx4ZOnRoxo4dm1/+8pevWXPrrbdm/vz5mTRpUrq7u3Prrbdm6dKlPT/3SSed1LN2yJAh+fCHP5xk7XOcXtlhdcstt+S8885Ld3d3jjvuuPz617/Os88+u96ZAICBN3igBwAAtp9XdoL0Vmt9zboNvZX3+ta+4tRTT80111yT2bNn54orrug5fvjhh+f666/PiBEjUkrJ5MmTc/vtt+euu+7K5MmTc9ttt+WWW27JHXfckV133TVHH310Xnjhhey5555ZuHBhfvjDH+bSSy/NP/3TP/Vc9/d///dzzjnn5JOf/GSGDx+elStXZvDgwXn55Zd7vm/vHUJ9f55SSgYPHpy77rort956a2bPnp1LLrkkP/rRjzb4873pTW/a4Ln1Xb/WmnHjxr1mt88zzzyzwT/fcePGZd68eTnuuON6js2fP7/nlrckecMb3tDz+Yb+PnqvGTRoUFavXv2aNbXWnH766fmbv/mb15wbOnRoBg0a1PN6l1126Zm59/Vefvnl3HHHHXnjG9+43jkAgB2LnUAA0Lijjjqq5zag2267LXvvvXfPrpu+dt9994wcOTLf/e53kyT/8R//0fP8m2nTpuUrX/lKkvTcQpUkRx55ZC6++OIcfvjhSdZGoauuuipvfetbM2zYsKxatSp77rlndt111zzwwAO58847kyRPPfVUXn755Zx00kn5whe+0PMuYt///vd74sdDDz2UQYMGZdiwYRk1alTPmnvuuSe/+MUvemZ4+OGHe2LMtddem/e85z35zW9+k1WrVmXq1Kn5yle+0hPH3ve+9+Wyyy5Lsva5RL/+9a83+We4vuuPHj06Tz75ZM/xl156KYsXL86wYcOyxx57ZM6cOUnS82efJOeee26uvPLKnllWrlyZCy+8sOe5Pltrl112yUsvvdTzc15//fV54oknkiRPP/30encMbcwxxxyTSy65pOf1K3O/+c1vtiMIAHZAIhAANO6iiy7KvHnz0tXVlRkzZuQb3/jGRtd/85vfzMyZM9PV1ZUjjjgijz/+eJLkLW95S8aMGdPz7J5XHHnkkVm6dGlPBBoxYkTWrFnTcyvYsccem9WrV6erqyt//dd/3XPL1SOPPJKjjz463d3dmTZtWs+OlW9+85sZPXp0uru7e3YfvXL70tNPP53u7u5cdtlleec739kzw5gxY/KNb3wjXV1defrpp3POOefk2WefzYc//OF0dXVlypQpPQ+e/od/+If8y7/8Sw455JBMmDDhVc/j2ZD1XX/IkCG5/vrrc+GFF2b8+PHp7u7ueT7S17/+9Zx77rk5/PDDX7WLZsSIEbn66qvzyU9+MgcddFCOOOKInHnmmfnIRz6yyRn6Y/r06enq6sopp5ySsWPH5otf/GKOOeaYdHV15QMf+EDPg6v7a+bMmT3/dsaOHdvzbnMf+chH8p3vfMeDoQFgB1M2tq17W5o4cWKdN2/egHxvXn9GzejMW+MC9Lbsy/91oEfYpu6///6MGTNmu32/559/PoccckjuueeenufoQF/b+9/lQPB7C7At7Oy/t9A5pZT5tdaJ6ztnJxAAsNVuueWWHHTQQTn//PMFIACAHZQHQwMAW+39739/Hn744YEeAwCAjbATCAAAAKABIhAAAABAA0QgAAAAgAaIQAAAAAAN8GBoAGCn1um36+7vW/TefPPN+fSnP501a9bkrLPOyowZMzo6BwDA5rITCACgw9asWZNzzz03P/jBD3Lffffl2muvzX333TfQYwEAjROBAAA67K677so73vGOHHDAARkyZEg+9rGP5Xvf+95AjwUANE4EAgDosEceeST77rtvz+uRI0fmkUceGcCJAABEIACAjqu1vuZYKWUAJgEA+E8iEABAh40cOTLLly/veb1ixYq87W1vG8CJAABEIACAjps0aVIeeuih/OIXv8iLL76Y2bNn57jjjhvosQCAxnmLeABgp9bft3TvpMGDB+eSSy7JBz/4waxZsyZnnnlmxo0bt93nAADoTQQCANgGpk6dmqlTpw70GAAAPdwOBgAAANAAEQgAAACgASIQAAAAQANEIAAAAIAGiEAAAAAADRCBAAAAABrgLeIBgJ3bRXt0+HqrNrnkzDPPzI033pjf+73fy7333tvZ7w8AsIXsBAIA6LBp06bl5ptvHugxAABeRQQCAOiwo446Kr/7u7870GMAALyKCAQAAADQABEIAAAAoAEiEAAAAEADRCAAAACABniLeABg59aPt3TvtJNPPjm33XZbnnrqqYwcOTKf//zn84lPfGK7zwEA0JsIBADQYddee+1AjwAA8BpuBwMAAABogAgEAAAA0AARCAB2YrXWgR4Bevj3CAADSwQCgJ3U0KFDs3LlSv/Dmx1CrTUrV67M0KFDB3oUAGiWB0MDwE5q5MiRWbFiRZ588smBHgWSrA2TI0eOHOgxAKBZIhAA7KR22WWX7L///gM9BgAAO4h+3Q5WSjm2lPJgKWVJKWXGes6XUsrMdecXlVIO7fyoAAAAAGypTUagUsqgJJcm+VCSsUlOLqWM7bPsQ0kOXPcxPcllHZ4TAAAAgK3Qn51AhyVZUmtdWmt9McnsJMf3WXN8kqvqWncmGVZKGdHhWQEAAADYQv15JtA+SZb3er0iybv7sWafJI/1XlRKmZ61O4WS5DellAc3a1qATds7yVMDPQSvD+VvB3oCABrn9xb6ze8tbIa3b+hEfyJQWc+xvu812581qbVenuTyfnxPgC1SSplXa5040HMAAGyK31uA7a0/t4OtSLJvr9cjkzy6BWsAAAAAGCD9iUB3JzmwlLJ/KWVIko8luaHPmhuSnLbuXcImJ1lVa32s74UAAAAAGBibvB2s1rq6lHJekh8mGZTkilrr4lLK2evOz0pyU5KpSZYkeT7JGdtuZICNcsspAPB64fcWYLsqtb7m0T0AAAAA7GT6czsYAAAAAK9zIhAAAABAA0QgAAAAgAZs8sHQADuyUspBSY5Psk+SmuTRJDfUWu8f0MEAAAB2MHYCAa9bpZQLk8xOUpLcleTudZ9fW0qZMZCzAQD0VynFuysD24V3BwNet0opP08yrtb6Up/jQ5IsrrUeODCTAQD0Xynl4VrrfgM9B7DzczsY8Hr2cpK3Jflln+Mj1p0DANghlFIWbehUkrdsz1mAdolAwOvZnye5tZTyUJLl647tl+QdSc4bqKEAANbjLUk+mOTf+xwvSeZu/3GAFolAwOtWrfXmUso7kxyWtQ+GLklWJLm71rpmQIcDAHi1G5PsVmtd0PdEKeW27T4N0CTPBAIAAABogHcHAwAAAGiACAQAAADQABEIAGhKKWVNKWVBr49R2+B7LCul7N3p6wIAbA0PhgYAWvPbWmv3+k6UUkrWPjPx5e07EgDAtmcnEADQtFLKqFLK/aWUrya5J8m+pZTLSinzSimLSymf77W2Z4dPKWXiK+/oU0rZq5Tyf0opPy2lfC1r360QAGCHIgIBAK15Y69bwb6z7tjoJFfVWt9Va/1lks/UWicm6UoypZTStYlrfi7JnFrru5LckGS/bTY9AMAWcjsYANCaV90Otu6ZQL+std7Za80fl1KmZ+3vSiOSjE2yaCPXPCrJHyZJrfX7pZR/7/TQAABbSwQCAEiee+WTUsr+Sf4iyaRa67+XUq5MMnTd6dX5z53UQ/NqdVsPCQCwNdwOBgDwartnbRRaVUp5S5IP9Tq3LMmEdZ+f1Ov4vyY5JUlKKR9Ksue2HxMAYPOIQAAAvdRaFyb5aZLFSa5Icnuv059P8g+llB8nWdPn+FGllHuSHJPk4e00LgBAv5Va7VwGAAAA2NnZCQQAAADQABEIAAAAoAEiEAAAAEADRCAAAACABohAAAAAAA0QgQAAAAAaIAIBAAAANEAEAgAAAGjA/wc3HtwA552HtwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dummy_columns = ['PolicyholderOccupation', 'ClaimCause', 'DamageImportance', 'FirstPartyVehicleType','ConnectionBetweenParties', 'PolicyWasSubscribedOnInternet']\n",
    "\n",
    "fig = plt.figure(figsize=(20,20))\n",
    "\n",
    "names = locals()\n",
    "for i, col in enumerate(dummy_columns):\n",
    "    names[f\"ax_{i}\"] = df.groupby(['Fraud'])[col].value_counts(normalize=True).unstack().plot(kind='bar', stacked=True, figsize=(20,10),title=f\"Fig {i+1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7 Clean features\n",
    "1. deal with outliers \n",
    "    The presence of outliers in the data is a major problem for machine learning algorithms (Chakravarty, et al., 2020). \n",
    "    TODO: deal with outliers, or at the end to illustrate the lackness of the research\n",
    "   \n",
    "     \n",
    "2. dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LossDate</th>\n",
       "      <th>FirstPolicySubscriptionDate</th>\n",
       "      <th>ClaimInvolvedCovers</th>\n",
       "      <th>NumberOfPoliciesOfPolicyholder</th>\n",
       "      <th>FpVehicleAgeMonths</th>\n",
       "      <th>EasinessToStage</th>\n",
       "      <th>ClaimWihoutIdentifiedThirdParty</th>\n",
       "      <th>ClaimAmount</th>\n",
       "      <th>LossHour</th>\n",
       "      <th>PolicyHolderAge</th>\n",
       "      <th>...</th>\n",
       "      <th>DamageImportance_TotalLoss</th>\n",
       "      <th>FirstPartyVehicleType_Caravan</th>\n",
       "      <th>FirstPartyVehicleType_Motorcycle</th>\n",
       "      <th>FirstPartyVehicleType_PrivateCar</th>\n",
       "      <th>ConnectionBetweenParties_SameAddress</th>\n",
       "      <th>ConnectionBetweenParties_SameBankAccount</th>\n",
       "      <th>ConnectionBetweenParties_SameEmail</th>\n",
       "      <th>ConnectionBetweenParties_SamePhone</th>\n",
       "      <th>ConnectionBetweenParties_SamePolice</th>\n",
       "      <th>PolicyWasSubscribedOnInternet_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.546387e+09</td>\n",
       "      <td>1.516234e+09</td>\n",
       "      <td>MaterialDamages ActLiability</td>\n",
       "      <td>1</td>\n",
       "      <td>104.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>4624.73</td>\n",
       "      <td>8.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.546387e+09</td>\n",
       "      <td>1.485648e+09</td>\n",
       "      <td>MaterialDamages ActLiability</td>\n",
       "      <td>3</td>\n",
       "      <td>230.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1</td>\n",
       "      <td>1606.81</td>\n",
       "      <td>11.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.546387e+09</td>\n",
       "      <td>1.483575e+09</td>\n",
       "      <td>MaterialDamages ActLiability</td>\n",
       "      <td>9</td>\n",
       "      <td>93.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0</td>\n",
       "      <td>998.20</td>\n",
       "      <td>18.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.546387e+09</td>\n",
       "      <td>1.484957e+09</td>\n",
       "      <td>MaterialDamages ActLiability ReplacementVehicle</td>\n",
       "      <td>2</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0</td>\n",
       "      <td>2506.92</td>\n",
       "      <td>11.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.546387e+09</td>\n",
       "      <td>1.515802e+09</td>\n",
       "      <td>ActLiability</td>\n",
       "      <td>4</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0</td>\n",
       "      <td>12.00</td>\n",
       "      <td>12.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11525</th>\n",
       "      <td>1.610842e+09</td>\n",
       "      <td>1.547511e+09</td>\n",
       "      <td>Windscreen</td>\n",
       "      <td>1</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1</td>\n",
       "      <td>1010.23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11526</th>\n",
       "      <td>1.609978e+09</td>\n",
       "      <td>1.484871e+09</td>\n",
       "      <td>Windscreen</td>\n",
       "      <td>3</td>\n",
       "      <td>119.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1</td>\n",
       "      <td>154.35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11527</th>\n",
       "      <td>1.610669e+09</td>\n",
       "      <td>1.580343e+09</td>\n",
       "      <td>Windscreen</td>\n",
       "      <td>4</td>\n",
       "      <td>139.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1</td>\n",
       "      <td>420.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11528</th>\n",
       "      <td>1.609891e+09</td>\n",
       "      <td>1.517098e+09</td>\n",
       "      <td>Windscreen</td>\n",
       "      <td>6</td>\n",
       "      <td>105.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1</td>\n",
       "      <td>96.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11529</th>\n",
       "      <td>1.610496e+09</td>\n",
       "      <td>1.483229e+09</td>\n",
       "      <td>Windscreen</td>\n",
       "      <td>2</td>\n",
       "      <td>124.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1</td>\n",
       "      <td>223.60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11371 rows  54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           LossDate  FirstPolicySubscriptionDate  \\\n",
       "0      1.546387e+09                 1.516234e+09   \n",
       "1      1.546387e+09                 1.485648e+09   \n",
       "2      1.546387e+09                 1.483575e+09   \n",
       "3      1.546387e+09                 1.484957e+09   \n",
       "4      1.546387e+09                 1.515802e+09   \n",
       "...             ...                          ...   \n",
       "11525  1.610842e+09                 1.547511e+09   \n",
       "11526  1.609978e+09                 1.484871e+09   \n",
       "11527  1.610669e+09                 1.580343e+09   \n",
       "11528  1.609891e+09                 1.517098e+09   \n",
       "11529  1.610496e+09                 1.483229e+09   \n",
       "\n",
       "                                   ClaimInvolvedCovers  \\\n",
       "0                         MaterialDamages ActLiability   \n",
       "1                         MaterialDamages ActLiability   \n",
       "2                         MaterialDamages ActLiability   \n",
       "3      MaterialDamages ActLiability ReplacementVehicle   \n",
       "4                                         ActLiability   \n",
       "...                                                ...   \n",
       "11525                                       Windscreen   \n",
       "11526                                       Windscreen   \n",
       "11527                                       Windscreen   \n",
       "11528                                       Windscreen   \n",
       "11529                                       Windscreen   \n",
       "\n",
       "       NumberOfPoliciesOfPolicyholder  FpVehicleAgeMonths  EasinessToStage  \\\n",
       "0                                   1               104.0             0.25   \n",
       "1                                   3               230.0             0.50   \n",
       "2                                   9                93.0             0.25   \n",
       "3                                   2                56.0             0.25   \n",
       "4                                   4               110.0             0.25   \n",
       "...                               ...                 ...              ...   \n",
       "11525                               1                85.0             0.50   \n",
       "11526                               3               119.0             0.50   \n",
       "11527                               4               139.0             0.50   \n",
       "11528                               6               105.0             0.50   \n",
       "11529                               2               124.0             0.50   \n",
       "\n",
       "       ClaimWihoutIdentifiedThirdParty  ClaimAmount  LossHour  \\\n",
       "0                                    1      4624.73       8.0   \n",
       "1                                    1      1606.81      11.0   \n",
       "2                                    0       998.20      18.0   \n",
       "3                                    0      2506.92      11.0   \n",
       "4                                    0        12.00      12.0   \n",
       "...                                ...          ...       ...   \n",
       "11525                                1      1010.23       0.0   \n",
       "11526                                1       154.35       0.0   \n",
       "11527                                1       420.25       0.0   \n",
       "11528                                1        96.40       0.0   \n",
       "11529                                1       223.60       0.0   \n",
       "\n",
       "       PolicyHolderAge  ...  DamageImportance_TotalLoss  \\\n",
       "0                 45.0  ...                           0   \n",
       "1                 20.0  ...                           0   \n",
       "2                 32.0  ...                           0   \n",
       "3                 46.0  ...                           0   \n",
       "4                 28.0  ...                           0   \n",
       "...                ...  ...                         ...   \n",
       "11525             56.0  ...                           0   \n",
       "11526             54.0  ...                           0   \n",
       "11527             34.0  ...                           0   \n",
       "11528             58.0  ...                           0   \n",
       "11529             55.0  ...                           0   \n",
       "\n",
       "       FirstPartyVehicleType_Caravan  FirstPartyVehicleType_Motorcycle  \\\n",
       "0                                  0                                 0   \n",
       "1                                  0                                 0   \n",
       "2                                  0                                 0   \n",
       "3                                  0                                 0   \n",
       "4                                  0                                 0   \n",
       "...                              ...                               ...   \n",
       "11525                              0                                 0   \n",
       "11526                              0                                 0   \n",
       "11527                              0                                 0   \n",
       "11528                              0                                 0   \n",
       "11529                              0                                 0   \n",
       "\n",
       "       FirstPartyVehicleType_PrivateCar  ConnectionBetweenParties_SameAddress  \\\n",
       "0                                     0                                     0   \n",
       "1                                     0                                     0   \n",
       "2                                     0                                     0   \n",
       "3                                     0                                     0   \n",
       "4                                     0                                     0   \n",
       "...                                 ...                                   ...   \n",
       "11525                                 0                                     0   \n",
       "11526                                 0                                     0   \n",
       "11527                                 0                                     0   \n",
       "11528                                 0                                     0   \n",
       "11529                                 0                                     0   \n",
       "\n",
       "       ConnectionBetweenParties_SameBankAccount  \\\n",
       "0                                             0   \n",
       "1                                             0   \n",
       "2                                             0   \n",
       "3                                             0   \n",
       "4                                             0   \n",
       "...                                         ...   \n",
       "11525                                         0   \n",
       "11526                                         0   \n",
       "11527                                         0   \n",
       "11528                                         0   \n",
       "11529                                         0   \n",
       "\n",
       "       ConnectionBetweenParties_SameEmail  ConnectionBetweenParties_SamePhone  \\\n",
       "0                                       0                                   0   \n",
       "1                                       0                                   0   \n",
       "2                                       0                                   0   \n",
       "3                                       0                                   0   \n",
       "4                                       0                                   0   \n",
       "...                                   ...                                 ...   \n",
       "11525                                   0                                   0   \n",
       "11526                                   0                                   0   \n",
       "11527                                   0                                   0   \n",
       "11528                                   0                                   0   \n",
       "11529                                   0                                   0   \n",
       "\n",
       "       ConnectionBetweenParties_SamePolice  PolicyWasSubscribedOnInternet_1  \n",
       "0                                        0                                1  \n",
       "1                                        0                                0  \n",
       "2                                        0                                0  \n",
       "3                                        0                                0  \n",
       "4                                        0                                0  \n",
       "...                                    ...                              ...  \n",
       "11525                                    0                                0  \n",
       "11526                                    0                                0  \n",
       "11527                                    0                                0  \n",
       "11528                                    0                                0  \n",
       "11529                                    0                                0  \n",
       "\n",
       "[11371 rows x 54 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get dummy variables for categorical data\n",
    "dummy_columns = ['PolicyholderOccupation', 'ClaimCause', 'DamageImportance', 'FirstPartyVehicleType','ConnectionBetweenParties', 'PolicyWasSubscribedOnInternet']\n",
    "# Dummy variables for categorical data\n",
    "df = pd.get_dummies(df,columns=dummy_columns,drop_first=True)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Burglary', 'MedicalCare', 'Theft', 'Accessories', 'MaterialDamages', 'ThirdParty', 'ThirdPartyMaterialDamages', 'NaN', 'Windscreen', 'ReplacementVehicle', 'NaturalCatastrophes', 'Fire', 'ActLiability'}\n"
     ]
    }
   ],
   "source": [
    "# Extract ClaimInvolvedCovers data\n",
    "# Get all covers\n",
    "all_unique =  df[\"ClaimInvolvedCovers\"].unique().tolist()\n",
    "all_covers = str.join(' ', all_unique) # join the string to list\n",
    "all_covers_set = set(all_covers.split()) # use set to drop duplicate covers\n",
    "print(all_covers_set)\n",
    "\n",
    "for cover in all_covers_set:\n",
    "    df[f\"ClaimInvolvedCovers_{cover}\"] = df[\"ClaimInvolvedCovers\"].apply(lambda x: 1 if cover in x else 0)\n",
    "df = df.drop(columns=['ClaimInvolvedCovers'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.8 Split the data and scale\n",
    "We are going to use MinMaxScaler in this case, since we can find the dataset not follow a Gaussian distribution. In addition, we will fit the MinMaxScaler model with trainning and validation dataset and apply the model to the test dataset to ensure we are blind to the data information before we test the data.\n",
    "Here is the process of split and scale data:\n",
    "1. Turn the dataframe into X and y array\n",
    "1. Split the train and test\n",
    "2. Fit the MinMaxScaler to train data and then apply the model to test data\n",
    "3. Split the train data into train and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of X:\n",
      "(11371, 65)\n",
      "-----------------------------------------------------\n",
      "The shape of y:\n",
      "(11371,)\n",
      "-----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Turn the dataframe into X and y array\n",
    "X = df.drop(['Fraud'],axis=1,inplace=False).to_numpy()\n",
    "y = df[['Fraud']].to_numpy().flatten()\n",
    "print('The shape of X:')\n",
    "print(X.shape)\n",
    "print('-----------------------------------------------------')\n",
    "print('The shape of y:')\n",
    "print(y.shape)\n",
    "print('-----------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the train and test datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=192,test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the train datasets into train and validation datasets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train,y_train,random_state=192,test_size=0.25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------\n",
      "Shape of X_train:\n",
      "(6822, 65)\n",
      "-----------------------------------------------------\n",
      "Shape of y_train:\n",
      "(6822,)\n",
      "-----------------------------------------------------\n",
      "Shape of X_val:\n",
      "(2274, 65)\n",
      "-----------------------------------------------------\n",
      "Shape of y_val:\n",
      "(2274,)\n",
      "-----------------------------------------------------\n",
      "Shape of X_test:\n",
      "(2275, 65)\n",
      "-----------------------------------------------------\n",
      "Shape of y_test:\n",
      "(2275,)\n",
      "-----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "## 2.9 Show the data structure of the data\n",
    "print('-----------------------------------------------------')\n",
    "print('Shape of X_train:')\n",
    "print(X_train.shape)\n",
    "print('-----------------------------------------------------')\n",
    "print('Shape of y_train:')\n",
    "print(y_train.shape)\n",
    "print('-----------------------------------------------------')\n",
    "print('Shape of X_val:')\n",
    "print(X_val.shape)\n",
    "print('-----------------------------------------------------')\n",
    "print('Shape of y_val:')\n",
    "print(y_val.shape)\n",
    "print('-----------------------------------------------------')\n",
    "print('Shape of X_test:')\n",
    "print(X_test.shape)\n",
    "print('-----------------------------------------------------')\n",
    "print('Shape of y_test:')\n",
    "print(y_test.shape)\n",
    "print('-----------------------------------------------------')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3\n",
    "#### TODO:\n",
    "1. record number of layer\n",
    "2. set the threshold\n",
    "\n",
    "\n",
    "### Question\n",
    "Start by creating a (deep) neural network in TensorFlow and train it on the data. Using training and validation sets, find a model with high accuracy, then evaluate it on the test set. In particular, record both the accuracy and AUC. Briefly discuss what issues you observe based on the metrics.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score,roc_auc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rm -rf ./logs100/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the range of hyperparameters\n",
    "We are going to explore the performance of dinstinct neural network when training with different hyperparameters. And we are going to use the following hyperparameters:\n",
    "1. Learning rate:\n",
    "    Usually, a lower learning rate will result in a better model and higher learning rate will accelerate the training process but result in a underfitting model. In this case, we set the range of learning rate from 10**(0.001) to 10**(0.1)\n",
    "2. Optimizer:\n",
    "    We are going to try both AdamOptimizer and sgd optimizer. In most case, SGD sacrifices the efficiency for better convergence quality.\n",
    "3. Dropout:\n",
    "    We are going to use HP_WHETHER_DROPOUT to decide whether to drop, and HP_DROPOUT to set the dropout rate. We set the range of dropout rate from 0.1 to 0.3 to see how the performance of the model changes.\n",
    "4. Number of neurons in the hidden layer:\n",
    "    In each hidden layer, we are going to use same number of neurons. In terms of the number of neurons, we are going to use a rule of thumb, in which we can calculate the number of neurons as:\n",
    "    \n",
    "    $N_h = \\frac{N_i}{\\alpha * (N_i+N_o))})$\n",
    "    \n",
    "    Ni = number of input neurons.\n",
    "    \n",
    "    No = number of output neurons.\n",
    "    \n",
    "    Ns = number of samples in training data set.\n",
    "    \n",
    "     = an arbitrary scaling factor usually 2-10.\n",
    "\n",
    "    In our case, we are going to set $\\alpha$ ramdonly to 2,3,4\n",
    "5. Number of hidden layers:\n",
    "    Normally, if the model is very simple, one hidden layer is enough according to Reed's argument (Reed, 1999).\n",
    "    ```\n",
    "    Since a single sufficiently large hidden layer is adequate for approximation of most functions, why would anyone ever use more? One reason hangs on the words sufficiently large. Although a single hidden layer is optimal for some functions, there are others for which a single-hidden-layer-solution is very inefficient compared to solutions with more layers.\n",
    "    ``` \n",
    "\n",
    "    However, in terms of a complex model, Bengio (2016) argued that \n",
    "    ```\n",
    "    Specifically, the universal approximation theorem states that a feedforward network with a linear output layer and at least one hidden layer with any squashing activation function (such as the logistic sigmoid activation function) can approximate any Borel measurable function from one finite-dimensional space to another with any desired non-zero amount of error, provided that the network is given enough hidden units.\n",
    "    Deep learning, 2016\n",
    "    ```\n",
    "    Since our model might not be able to be explained by a linear function, we are going to set the range of hidden layers from 1 to 3.\n",
    "6. Activation\n",
    "    We are going to compare the performance of the following activation functions:\n",
    "    1. sigmoid\n",
    "    2. relu\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "HP_LEARNING_RATE = hp.HParam('learning_rate', hp.RealInterval(0.001,0.1))\n",
    "HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam', 'sgd']))\n",
    "HP_WHETHER_DROPOUT = hp.HParam('whether_dropout', hp.Discrete([True, False]))\n",
    "HP_DROPOUT = hp.HParam('dropout', hp.RealInterval(0.1, 0.3))\n",
    "# the number of units in the hidden layer, 1 time, 2 times or 3 times of the unit number of input layer\n",
    "BASE_NUM_UNITS = X_train.shape[0]/(X_train.shape[1] + 1)\n",
    "HP_NUM_UNITS = hp.HParam('num_units', hp.Discrete([int(BASE_NUM_UNITS/2), int(BASE_NUM_UNITS/3), int(BASE_NUM_UNITS/4),int(BASE_NUM_UNITS/5)])) \n",
    "HP_ACTIVATION = hp.HParam('activation', hp.Discrete(['relu', 'sigmoid']))\n",
    "HP_HIDDEN_LAYER_NUMBER = hp.HParam('hidden_layer_number', hp.Discrete(range(1,4)))\n",
    "METRIC_CROSSENTROPY = 'binary_crossentropy'\n",
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have set up our parameters and metrics, we write those into our folder with the logs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.summary.create_file_writer('logs100/hparam_tuning').as_default():\n",
    "    hp.hparams_config(hparams=[HP_LEARNING_RATE, HP_OPTIMIZER, HP_DROPOUT, HP_NUM_UNITS,HP_ACTIVATION,HP_HIDDEN_LAYER_NUMBER],\n",
    "                      metrics = [hp.Metric(METRIC_CROSSENTROPY, display_name='CROSSENTROPY')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(hparams,X_train=X_train,y_train=y_train,X_test=X_test,y_test=y_test):\n",
    "    early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True) # set patience to 10 to accelerate the training\n",
    "    if hparams[HP_WHETHER_DROPOUT] == True:\n",
    "        model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Dropout(hparams[HP_DROPOUT]),\n",
    "            tf.keras.layers.Dense(hparams[HP_NUM_UNITS], activation=hparams[HP_ACTIVATION])]*hparams[HP_HIDDEN_LAYER_NUMBER]+[\n",
    "            tf.keras.layers.Dense(1,activation='sigmoid')])\n",
    "    else:\n",
    "        model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Dense(hparams[HP_NUM_UNITS], activation=hparams[HP_ACTIVATION])]*hparams[HP_HIDDEN_LAYER_NUMBER]+[\n",
    "            tf.keras.layers.Dense(1,activation='sigmoid')])\n",
    "    if hparams[HP_OPTIMIZER] == 'sgd':\n",
    "        # Note that exploding gradients can be a big problem when running regressions, especially under SGD\n",
    "        # Hence, we use \"gradient clipping\" with parameter alpha, which means that the gradients are manually kept between -1 and 1\n",
    "        # This is of course another hyperparameter that we might tune!\n",
    "        optimizer = tf.keras.optimizers.SGD(\n",
    "            learning_rate=hparams[HP_LEARNING_RATE], clipvalue=1)\n",
    "    elif hparams[HP_OPTIMIZER] == 'adam':\n",
    "        optimizer = tf.keras.optimizers.Adam(\n",
    "            learning_rate=hparams[HP_LEARNING_RATE])\n",
    "\n",
    "    # random_seed = 192\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='binary_crossentropy')\n",
    "\n",
    "    model.fit(X_train, y_train, epochs=EPOCHS, validation_data=(X_val,y_val) ,callbacks=[early_stopping_cb],)\n",
    "    loss = model.evaluate(X_test, y_test)\n",
    "    x_test_predict = model.predict(X_test)\n",
    "    # calculate the roc\n",
    "    roc_score = roc_auc_score(y_test, x_test_predict)\n",
    "    # calculate the accuracy suppose the threshold is 0.5\n",
    "    x_test_predict_binary = np.where(x_test_predict>0.5,1,0)\n",
    "    accuracy = accuracy_score(y_test, x_test_predict_binary)\n",
    "    # calculate the sensitivity\n",
    "    sensitivity = recall_score(y_test, x_test_predict_binary)\n",
    "    return loss, accuracy,roc_score,sensitivity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(run_dir, hparams):\n",
    "    with tf.summary.create_file_writer(run_dir).as_default():\n",
    "        hp.hparams(hparams)\n",
    "        \n",
    "        loss, accuracy,roc_score,sensitivity = train_model(hparams) #TODO whether I did it right\n",
    "        tf.summary.scalar('ACCUARY', accuracy, step=1)\n",
    "        tf.summary.scalar('LOSS', loss, step=1)\n",
    "        tf.summary.scalar('ROC', roc_score, step=1)\n",
    "        tf.summary.scalar('SENSITIVITY', sensitivity, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting trial: run-0\n",
      "{'learning_rate': 0.046246040114833964, 'optimizer': 'sgd', 'whether_dropout': False, 'dropout': 0.19513086599790694, 'num_units': 27, 'activation': 'sigmoid', 'hidden_layer_number': 1}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 906us/step - loss: 0.0259 - val_loss: 0.2518\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 964us/step - loss: 0.0054 - val_loss: 0.2828\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 929us/step - loss: 0.0031 - val_loss: 0.3023\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0022 - val_loss: 0.3165\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 1000us/step - loss: 0.0017 - val_loss: 0.3276\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 610us/step - loss: 0.0013 - val_loss: 0.3368\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 669us/step - loss: 0.0011 - val_loss: 0.3446\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 638us/step - loss: 9.7137e-04 - val_loss: 0.3514\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 647us/step - loss: 8.5147e-04 - val_loss: 0.3574\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 646us/step - loss: 7.5742e-04 - val_loss: 0.3628\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 660us/step - loss: 6.8170e-04 - val_loss: 0.3677\n",
      "36/36 [==============================] - 0s 514us/step - loss: 0.2516\n",
      "--- Starting trial: run-1\n",
      "{'learning_rate': 0.009338762119833664, 'optimizer': 'adam', 'whether_dropout': True, 'dropout': 0.17779183940431265, 'num_units': 68, 'activation': 'relu', 'hidden_layer_number': 1}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0073 - val_loss: 0.8565\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 4.3095e-06 - val_loss: 1.0182\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 943us/step - loss: 1.8436e-06 - val_loss: 1.1315\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 786us/step - loss: 7.0032e-07 - val_loss: 1.2082\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 762us/step - loss: 2.7492e-07 - val_loss: 1.2618\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 754us/step - loss: 3.3486e-07 - val_loss: 1.3214\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 763us/step - loss: 1.7667e-07 - val_loss: 1.3638\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 770us/step - loss: 2.3943e-07 - val_loss: 1.4185\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 791us/step - loss: 1.3581e-07 - val_loss: 1.4592\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 763us/step - loss: 7.5769e-08 - val_loss: 1.4861\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 812us/step - loss: 3.4333e-08 - val_loss: 1.5122\n",
      "36/36 [==============================] - 0s 457us/step - loss: 0.8838\n",
      "--- Starting trial: run-2\n",
      "{'learning_rate': 0.0016688817084995259, 'optimizer': 'adam', 'whether_dropout': False, 'dropout': 0.17817417002387081, 'num_units': 68, 'activation': 'relu', 'hidden_layer_number': 2}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0240 - val_loss: 0.4865\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 975us/step - loss: 7.1883e-05 - val_loss: 0.5766\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 2.2060e-05 - val_loss: 0.6275\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 811us/step - loss: 1.0703e-05 - val_loss: 0.6638\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 2ms/step - loss: 6.2569e-06 - val_loss: 0.6925\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 4.0653e-06 - val_loss: 0.7165\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 760us/step - loss: 2.8177e-06 - val_loss: 0.7373\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 817us/step - loss: 2.0430e-06 - val_loss: 0.7557\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 821us/step - loss: 1.5294e-06 - val_loss: 0.7727\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 834us/step - loss: 1.1735e-06 - val_loss: 0.7884\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 771us/step - loss: 9.1781e-07 - val_loss: 0.8030\n",
      "36/36 [==============================] - 0s 521us/step - loss: 0.4955\n",
      "--- Starting trial: run-3\n",
      "{'learning_rate': 0.0032061571873792443, 'optimizer': 'sgd', 'whether_dropout': False, 'dropout': 0.2080091798066182, 'num_units': 27, 'activation': 'sigmoid', 'hidden_layer_number': 3}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 1s 1ms/step - loss: 0.3419 - val_loss: 0.2438\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 983us/step - loss: 0.1044 - val_loss: 0.2046\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0595 - val_loss: 0.2007\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0411 - val_loss: 0.2037\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 672us/step - loss: 0.0313 - val_loss: 0.2083\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 653us/step - loss: 0.0251 - val_loss: 0.2133\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 694us/step - loss: 0.0210 - val_loss: 0.2181\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 679us/step - loss: 0.0180 - val_loss: 0.2227\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 839us/step - loss: 0.0157 - val_loss: 0.2271\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 714us/step - loss: 0.0139 - val_loss: 0.2312\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 696us/step - loss: 0.0125 - val_loss: 0.2350\n",
      "Epoch 12/100\n",
      "285/285 [==============================] - 0s 677us/step - loss: 0.0113 - val_loss: 0.2386\n",
      "Epoch 13/100\n",
      "285/285 [==============================] - 0s 665us/step - loss: 0.0104 - val_loss: 0.2420\n",
      "36/36 [==============================] - 0s 463us/step - loss: 0.2011\n",
      "--- Starting trial: run-4\n",
      "{'learning_rate': 0.0016040138170844327, 'optimizer': 'adam', 'whether_dropout': False, 'dropout': 0.18704802951071484, 'num_units': 68, 'activation': 'sigmoid', 'hidden_layer_number': 2}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0569 - val_loss: 0.2832\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0025 - val_loss: 0.3357\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.3687\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 861us/step - loss: 5.9319e-04 - val_loss: 0.3932\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 782us/step - loss: 3.8048e-04 - val_loss: 0.4129\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 756us/step - loss: 2.6407e-04 - val_loss: 0.4296\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 764us/step - loss: 1.9287e-04 - val_loss: 0.4442\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 753us/step - loss: 1.4598e-04 - val_loss: 0.4573\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 776us/step - loss: 1.1337e-04 - val_loss: 0.4694\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 785us/step - loss: 8.9802e-05 - val_loss: 0.4805\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 740us/step - loss: 7.2242e-05 - val_loss: 0.4910\n",
      "36/36 [==============================] - 0s 547us/step - loss: 0.2850\n",
      "--- Starting trial: run-5\n",
      "{'learning_rate': 0.0012768695953084344, 'optimizer': 'adam', 'whether_dropout': False, 'dropout': 0.25738174783047685, 'num_units': 45, 'activation': 'relu', 'hidden_layer_number': 3}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 957us/step - loss: 0.0449 - val_loss: 0.3806\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 5.0945e-04 - val_loss: 0.4554\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 1.7622e-04 - val_loss: 0.5004\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 842us/step - loss: 8.8933e-05 - val_loss: 0.5332\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 779us/step - loss: 5.2974e-05 - val_loss: 0.5596\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 809us/step - loss: 3.4783e-05 - val_loss: 0.5817\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 744us/step - loss: 2.4272e-05 - val_loss: 0.6010\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 746us/step - loss: 1.7676e-05 - val_loss: 0.6183\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 796us/step - loss: 1.3269e-05 - val_loss: 0.6342\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 788us/step - loss: 1.0199e-05 - val_loss: 0.6489\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 7.9863e-06 - val_loss: 0.6627\n",
      "36/36 [==============================] - 0s 647us/step - loss: 0.3885\n",
      "--- Starting trial: run-6\n",
      "{'learning_rate': 0.04680174222490786, 'optimizer': 'sgd', 'whether_dropout': True, 'dropout': 0.10510422181179008, 'num_units': 27, 'activation': 'sigmoid', 'hidden_layer_number': 3}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 980us/step - loss: 0.0572 - val_loss: 0.2387\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.2705\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0034 - val_loss: 0.2903\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 947us/step - loss: 0.0023 - val_loss: 0.3047\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 667us/step - loss: 0.0018 - val_loss: 0.3159\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 751us/step - loss: 0.0014 - val_loss: 0.3252\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 673us/step - loss: 0.0012 - val_loss: 0.3331\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 712us/step - loss: 0.0010 - val_loss: 0.3399\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 761us/step - loss: 9.1003e-04 - val_loss: 0.3460\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 696us/step - loss: 8.0945e-04 - val_loss: 0.3515\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 754us/step - loss: 7.2671e-04 - val_loss: 0.3564\n",
      "36/36 [==============================] - 0s 529us/step - loss: 0.2393\n",
      "--- Starting trial: run-7\n",
      "{'learning_rate': 0.039957942340065784, 'optimizer': 'adam', 'whether_dropout': False, 'dropout': 0.23416094602976573, 'num_units': 27, 'activation': 'sigmoid', 'hidden_layer_number': 1}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0024 - val_loss: 0.5351\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 941us/step - loss: 1.6211e-05 - val_loss: 0.5599\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 1.0263e-05 - val_loss: 0.5804\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 795us/step - loss: 6.9956e-06 - val_loss: 0.5978\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 759us/step - loss: 5.0365e-06 - val_loss: 0.6129\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 780us/step - loss: 3.7692e-06 - val_loss: 0.6265\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 731us/step - loss: 2.9016e-06 - val_loss: 0.6388\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 748us/step - loss: 2.2825e-06 - val_loss: 0.6503\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 748us/step - loss: 1.8256e-06 - val_loss: 0.6609\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 759us/step - loss: 1.4798e-06 - val_loss: 0.6710\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 776us/step - loss: 1.2124e-06 - val_loss: 0.6806\n",
      "36/36 [==============================] - 0s 498us/step - loss: 0.5363\n",
      "--- Starting trial: run-8\n",
      "{'learning_rate': 0.011657206921105837, 'optimizer': 'sgd', 'whether_dropout': True, 'dropout': 0.13977440768730592, 'num_units': 45, 'activation': 'sigmoid', 'hidden_layer_number': 2}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 877us/step - loss: 0.1066 - val_loss: 0.2083\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 754us/step - loss: 0.0162 - val_loss: 0.2324\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 964us/step - loss: 0.0092 - val_loss: 0.2495\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0065 - val_loss: 0.2624\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 732us/step - loss: 0.0050 - val_loss: 0.2727\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 676us/step - loss: 0.0040 - val_loss: 0.2814\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 673us/step - loss: 0.0034 - val_loss: 0.2887\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 678us/step - loss: 0.0029 - val_loss: 0.2952\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 669us/step - loss: 0.0026 - val_loss: 0.3009\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 697us/step - loss: 0.0023 - val_loss: 0.3061\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 684us/step - loss: 0.0021 - val_loss: 0.3107\n",
      "36/36 [==============================] - 0s 538us/step - loss: 0.2085\n",
      "--- Starting trial: run-9\n",
      "{'learning_rate': 0.007215049104922526, 'optimizer': 'adam', 'whether_dropout': False, 'dropout': 0.21478267338801094, 'num_units': 34, 'activation': 'sigmoid', 'hidden_layer_number': 1}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 986us/step - loss: 0.0049 - val_loss: 0.4186\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 896us/step - loss: 1.4678e-04 - val_loss: 0.4676\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 6.5864e-05 - val_loss: 0.4986\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 997us/step - loss: 3.8176e-05 - val_loss: 0.5217\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 906us/step - loss: 2.5020e-05 - val_loss: 0.5405\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 856us/step - loss: 1.7635e-05 - val_loss: 0.5564\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 2s 8ms/step - loss: 1.3033e-05 - val_loss: 0.5703\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 9.9593e-06 - val_loss: 0.5829\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 775us/step - loss: 7.7968e-06 - val_loss: 0.5944\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 832us/step - loss: 6.2186e-06 - val_loss: 0.6052\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 788us/step - loss: 5.0324e-06 - val_loss: 0.6153\n",
      "36/36 [==============================] - 0s 518us/step - loss: 0.4211\n",
      "--- Starting trial: run-10\n",
      "{'learning_rate': 0.0076861184004607805, 'optimizer': 'adam', 'whether_dropout': False, 'dropout': 0.15250871724241155, 'num_units': 27, 'activation': 'relu', 'hidden_layer_number': 1}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 1s 1ms/step - loss: 0.0105 - val_loss: 0.5416\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 3.4734e-05 - val_loss: 0.6092\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 1s 3ms/step - loss: 1.3049e-05 - val_loss: 0.6525\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 2ms/step - loss: 6.7376e-06 - val_loss: 0.6846\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 933us/step - loss: 4.0498e-06 - val_loss: 0.7106\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 920us/step - loss: 2.6752e-06 - val_loss: 0.7325\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 1.8734e-06 - val_loss: 0.7516\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 1.3678e-06 - val_loss: 0.7687\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 925us/step - loss: 1.0289e-06 - val_loss: 0.7844\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 2ms/step - loss: 7.9198e-07 - val_loss: 0.7990\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 6.2091e-07 - val_loss: 0.8126\n",
      "36/36 [==============================] - 0s 522us/step - loss: 0.5602\n",
      "--- Starting trial: run-11\n",
      "{'learning_rate': 0.015778626373926546, 'optimizer': 'adam', 'whether_dropout': True, 'dropout': 0.13251832085378143, 'num_units': 45, 'activation': 'relu', 'hidden_layer_number': 1}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 1s 1ms/step - loss: 0.0060 - val_loss: 0.8767\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 2.4400e-06 - val_loss: 0.8898\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 967us/step - loss: 4.3358e-06 - val_loss: 0.9128\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 852us/step - loss: 2.0146e-06 - val_loss: 0.9317\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 2ms/step - loss: 1.4961e-06 - val_loss: 0.9522\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 9.9588e-07 - val_loss: 0.9689\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 963us/step - loss: 8.7426e-07 - val_loss: 0.9851\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 818us/step - loss: 6.0235e-07 - val_loss: 0.9994\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 952us/step - loss: 9.2597e-07 - val_loss: 1.0213\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 816us/step - loss: 6.8432e-07 - val_loss: 1.0389\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 850us/step - loss: 1.0411e-06 - val_loss: 1.0694\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.9075\n",
      "--- Starting trial: run-12\n",
      "{'learning_rate': 0.13404047187717852, 'optimizer': 'adam', 'whether_dropout': True, 'dropout': 0.2125005999838529, 'num_units': 27, 'activation': 'relu', 'hidden_layer_number': 3}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 1s 1ms/step - loss: 0.0026 - val_loss: 6.3842\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 2.8998e-21 - val_loss: 6.3842\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 964us/step - loss: 1.7216e-17 - val_loss: 6.3842\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 830us/step - loss: 1.3814e-17 - val_loss: 6.3842\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 840us/step - loss: 8.1529e-22 - val_loss: 6.3842\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 943us/step - loss: 3.6382e-11 - val_loss: 6.3842\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 2.2675e-15 - val_loss: 6.3842\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 1.4859e-17 - val_loss: 6.3842\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 981us/step - loss: 1.9481e-17 - val_loss: 6.3842\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 852us/step - loss: 1.3944e-15 - val_loss: 6.3842\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 884us/step - loss: 8.1990e-20 - val_loss: 6.3842\n",
      "36/36 [==============================] - 0s 558us/step - loss: 6.6021\n",
      "--- Starting trial: run-13\n",
      "{'learning_rate': 0.012729872255485535, 'optimizer': 'sgd', 'whether_dropout': False, 'dropout': 0.21767336944333632, 'num_units': 27, 'activation': 'relu', 'hidden_layer_number': 1}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 906us/step - loss: 0.0927 - val_loss: 0.2135\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.2483\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 0.0070 - val_loss: 0.2723\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 2s 6ms/step - loss: 0.0046 - val_loss: 0.2902\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 1s 3ms/step - loss: 0.0034 - val_loss: 0.3042\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 2ms/step - loss: 0.0027 - val_loss: 0.3158\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 0.0022 - val_loss: 0.3257\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0018 - val_loss: 0.3343\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0016 - val_loss: 0.3419\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 0.3487\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 872us/step - loss: 0.0012 - val_loss: 0.3549\n",
      "36/36 [==============================] - 0s 603us/step - loss: 0.2143\n",
      "--- Starting trial: run-14\n",
      "{'learning_rate': 0.005087886370691307, 'optimizer': 'adam', 'whether_dropout': True, 'dropout': 0.2662144286773921, 'num_units': 27, 'activation': 'sigmoid', 'hidden_layer_number': 1}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 1s 3ms/step - loss: 0.0474 - val_loss: 0.3007\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0017 - val_loss: 0.3525\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 985us/step - loss: 7.1408e-04 - val_loss: 0.3851\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 921us/step - loss: 4.0225e-04 - val_loss: 0.4094\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 2.5653e-04 - val_loss: 0.4289\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 1.7925e-04 - val_loss: 0.4456\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 1.3047e-04 - val_loss: 0.4602\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 834us/step - loss: 9.7996e-05 - val_loss: 0.4731\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 921us/step - loss: 7.6998e-05 - val_loss: 0.4852\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 885us/step - loss: 6.1153e-05 - val_loss: 0.4964\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 978us/step - loss: 4.8421e-05 - val_loss: 0.5068\n",
      "36/36 [==============================] - 0s 835us/step - loss: 0.3018\n",
      "--- Starting trial: run-15\n",
      "{'learning_rate': 0.04412413278912642, 'optimizer': 'adam', 'whether_dropout': True, 'dropout': 0.25732133280969405, 'num_units': 45, 'activation': 'relu', 'hidden_layer_number': 3}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 1s 1ms/step - loss: 0.0035 - val_loss: 2.5866\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 2.6331e-10 - val_loss: 2.5866\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 2.7450e-08 - val_loss: 2.6732\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 2ms/step - loss: 1.1768e-08 - val_loss: 2.6926\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 1.4907e-10 - val_loss: 2.6934\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 850us/step - loss: 8.3730e-08 - val_loss: 2.8035\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 1.5517e-10 - val_loss: 2.8340\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 1.4355e-10 - val_loss: 2.8354\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 2.0199e-10 - val_loss: 2.8375\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 9.3551e-11 - val_loss: 2.8390\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 2ms/step - loss: 2.6093e-11 - val_loss: 2.8398\n",
      "36/36 [==============================] - 0s 565us/step - loss: 2.6857\n",
      "--- Starting trial: run-16\n",
      "{'learning_rate': 0.006401393446344375, 'optimizer': 'sgd', 'whether_dropout': True, 'dropout': 0.2653618134842588, 'num_units': 34, 'activation': 'relu', 'hidden_layer_number': 3}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 0.2906 - val_loss: 0.2001\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 0.0529 - val_loss: 0.2064\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 2ms/step - loss: 0.0259 - val_loss: 0.2263\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0167 - val_loss: 0.2440\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0121 - val_loss: 0.2590\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 847us/step - loss: 0.0096 - val_loss: 0.2717\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0077 - val_loss: 0.2829\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 0.2924\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 942us/step - loss: 0.0056 - val_loss: 0.3011\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 826us/step - loss: 0.0050 - val_loss: 0.3091\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 791us/step - loss: 0.0044 - val_loss: 0.3164\n",
      "36/36 [==============================] - 0s 659us/step - loss: 0.2029\n",
      "--- Starting trial: run-17\n",
      "{'learning_rate': 0.43079155277762265, 'optimizer': 'adam', 'whether_dropout': True, 'dropout': 0.29205922974293674, 'num_units': 34, 'activation': 'relu', 'hidden_layer_number': 1}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 1s 1ms/step - loss: 0.0024 - val_loss: 46.9959\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 973us/step - loss: 0.0000e+00 - val_loss: 46.9959\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - val_loss: 46.9959\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - val_loss: 46.9959\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 897us/step - loss: 0.0000e+00 - val_loss: 46.9959\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - val_loss: 46.9959\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - val_loss: 46.9959\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 988us/step - loss: 0.0000e+00 - val_loss: 46.9959\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 837us/step - loss: 0.0000e+00 - val_loss: 46.9959\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 818us/step - loss: 0.0000e+00 - val_loss: 46.9959\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 923us/step - loss: 0.0000e+00 - val_loss: 46.9959\n",
      "36/36 [==============================] - 0s 637us/step - loss: 48.2728\n",
      "--- Starting trial: run-18\n",
      "{'learning_rate': 0.7727825461704738, 'optimizer': 'adam', 'whether_dropout': True, 'dropout': 0.26474349287822896, 'num_units': 45, 'activation': 'relu', 'hidden_layer_number': 1}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 1s 1ms/step - loss: 0.0021 - val_loss: 218.4705\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - val_loss: 218.4705\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - val_loss: 218.4705\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - val_loss: 218.4705\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 953us/step - loss: 0.0000e+00 - val_loss: 218.4705\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - val_loss: 218.4705\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - val_loss: 218.4705\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - val_loss: 218.4705\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - val_loss: 218.4705\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - val_loss: 218.4705\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 950us/step - loss: 0.0000e+00 - val_loss: 218.4705\n",
      "36/36 [==============================] - 0s 552us/step - loss: 224.2949\n",
      "--- Starting trial: run-19\n",
      "{'learning_rate': 0.0013204465754007057, 'optimizer': 'sgd', 'whether_dropout': True, 'dropout': 0.18518643854447675, 'num_units': 45, 'activation': 'sigmoid', 'hidden_layer_number': 1}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 1s 1ms/step - loss: 0.5182 - val_loss: 0.3095\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.1695 - val_loss: 0.2222\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 0.0955 - val_loss: 0.2024\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 894us/step - loss: 0.0657 - val_loss: 0.1977\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 876us/step - loss: 0.0498 - val_loss: 0.1978\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 798us/step - loss: 0.0400 - val_loss: 0.1999\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 835us/step - loss: 0.0333 - val_loss: 0.2027\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 768us/step - loss: 0.0285 - val_loss: 0.2058\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 748us/step - loss: 0.0250 - val_loss: 0.2090\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 764us/step - loss: 0.0222 - val_loss: 0.2122\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 738us/step - loss: 0.0199 - val_loss: 0.2152\n",
      "Epoch 12/100\n",
      "285/285 [==============================] - 0s 719us/step - loss: 0.0181 - val_loss: 0.2182\n",
      "Epoch 13/100\n",
      "285/285 [==============================] - 0s 724us/step - loss: 0.0165 - val_loss: 0.2210\n",
      "Epoch 14/100\n",
      "285/285 [==============================] - 0s 747us/step - loss: 0.0153 - val_loss: 0.2237\n",
      "36/36 [==============================] - 0s 533us/step - loss: 0.1977\n",
      "--- Starting trial: run-20\n",
      "{'learning_rate': 0.012370826717418631, 'optimizer': 'sgd', 'whether_dropout': False, 'dropout': 0.1723547470640915, 'num_units': 34, 'activation': 'relu', 'hidden_layer_number': 2}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 961us/step - loss: 0.1289 - val_loss: 0.2106\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0169 - val_loss: 0.2442\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 934us/step - loss: 0.0083 - val_loss: 0.2685\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 737us/step - loss: 0.0053 - val_loss: 0.2867\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 792us/step - loss: 0.0039 - val_loss: 0.3011\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 775us/step - loss: 0.0030 - val_loss: 0.3130\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 718us/step - loss: 0.0024 - val_loss: 0.3231\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 747us/step - loss: 0.0021 - val_loss: 0.3319\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 793us/step - loss: 0.0018 - val_loss: 0.3396\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 836us/step - loss: 0.0015 - val_loss: 0.3466\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 784us/step - loss: 0.0014 - val_loss: 0.3529\n",
      "36/36 [==============================] - 0s 736us/step - loss: 0.2155\n",
      "--- Starting trial: run-21\n",
      "{'learning_rate': 0.0326532734967011, 'optimizer': 'adam', 'whether_dropout': True, 'dropout': 0.12034544785231074, 'num_units': 45, 'activation': 'relu', 'hidden_layer_number': 3}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 1s 1ms/step - loss: 0.0033 - val_loss: 1.7885\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 8.3384e-10 - val_loss: 1.7885\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 7.0454e-08 - val_loss: 1.7898\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 4.6248e-09 - val_loss: 1.7900\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 4.0959e-09 - val_loss: 1.7909\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 990us/step - loss: 5.1281e-10 - val_loss: 1.7910\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 954us/step - loss: 6.1767e-10 - val_loss: 1.7911\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 8.7624e-10 - val_loss: 1.7912\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 1.9700e-09 - val_loss: 1.7914\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 8.6095e-10 - val_loss: 1.7916\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 951us/step - loss: 1.7546e-09 - val_loss: 1.7919\n",
      "36/36 [==============================] - 0s 966us/step - loss: 1.8550\n",
      "--- Starting trial: run-22\n",
      "{'learning_rate': 0.9130204827588444, 'optimizer': 'sgd', 'whether_dropout': True, 'dropout': 0.2516074757333651, 'num_units': 27, 'activation': 'relu', 'hidden_layer_number': 1}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 1s 1ms/step - loss: 0.0036 - val_loss: 0.5060\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 1.4901e-04 - val_loss: 0.5603\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 8.3743e-05 - val_loss: 0.5931\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 843us/step - loss: 6.1004e-05 - val_loss: 0.6168\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 761us/step - loss: 4.2611e-05 - val_loss: 0.6344\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 752us/step - loss: 4.5759e-05 - val_loss: 0.6513\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 699us/step - loss: 2.9049e-05 - val_loss: 0.6634\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 906us/step - loss: 2.8418e-05 - val_loss: 0.6743\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 2.3908e-05 - val_loss: 0.6843\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 2.1152e-05 - val_loss: 0.6931\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 738us/step - loss: 1.7597e-05 - val_loss: 0.7007\n",
      "36/36 [==============================] - 0s 697us/step - loss: 0.5110\n",
      "--- Starting trial: run-23\n",
      "{'learning_rate': 0.04013482433208903, 'optimizer': 'sgd', 'whether_dropout': True, 'dropout': 0.2677326635392208, 'num_units': 68, 'activation': 'relu', 'hidden_layer_number': 1}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 1s 1ms/step - loss: 0.0472 - val_loss: 0.2799\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0046 - val_loss: 0.3298\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0025 - val_loss: 0.3603\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 813us/step - loss: 0.0017 - val_loss: 0.3826\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 790us/step - loss: 0.0013 - val_loss: 0.3997\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 703us/step - loss: 0.0011 - val_loss: 0.4139\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 857us/step - loss: 8.6041e-04 - val_loss: 0.4258\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 853us/step - loss: 7.3360e-04 - val_loss: 0.4360\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 711us/step - loss: 6.6057e-04 - val_loss: 0.4454\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 693us/step - loss: 6.0051e-04 - val_loss: 0.4539\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 746us/step - loss: 4.9991e-04 - val_loss: 0.4613\n",
      "36/36 [==============================] - 0s 606us/step - loss: 0.2870\n",
      "--- Starting trial: run-24\n",
      "{'learning_rate': 0.5464866921144468, 'optimizer': 'sgd', 'whether_dropout': True, 'dropout': 0.215889988005536, 'num_units': 27, 'activation': 'sigmoid', 'hidden_layer_number': 2}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.3653\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 4.2720e-04 - val_loss: 0.4011\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 2ms/step - loss: 2.4382e-04 - val_loss: 0.4223\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 980us/step - loss: 1.6992e-04 - val_loss: 0.4374\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 947us/step - loss: 1.3016e-04 - val_loss: 0.4491\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 850us/step - loss: 1.0547e-04 - val_loss: 0.4587\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 734us/step - loss: 8.8656e-05 - val_loss: 0.4669\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 959us/step - loss: 7.5244e-05 - val_loss: 0.4738\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 768us/step - loss: 6.6730e-05 - val_loss: 0.4801\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 887us/step - loss: 5.9434e-05 - val_loss: 0.4856\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 740us/step - loss: 5.3257e-05 - val_loss: 0.4907\n",
      "36/36 [==============================] - 0s 634us/step - loss: 0.3654\n",
      "--- Starting trial: run-25\n",
      "{'learning_rate': 0.0021171765371396606, 'optimizer': 'adam', 'whether_dropout': False, 'dropout': 0.2784706332588353, 'num_units': 27, 'activation': 'relu', 'hidden_layer_number': 3}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 1s 1ms/step - loss: 0.0364 - val_loss: 0.3851\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 2ms/step - loss: 5.8355e-04 - val_loss: 0.4520\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 2ms/step - loss: 2.2324e-04 - val_loss: 0.4935\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 1.1846e-04 - val_loss: 0.5241\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 963us/step - loss: 7.2893e-05 - val_loss: 0.5490\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 850us/step - loss: 4.9016e-05 - val_loss: 0.5700\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 867us/step - loss: 3.4840e-05 - val_loss: 0.5884\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 879us/step - loss: 2.5760e-05 - val_loss: 0.6049\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 922us/step - loss: 1.9586e-05 - val_loss: 0.6200\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 821us/step - loss: 1.5218e-05 - val_loss: 0.6342\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 830us/step - loss: 1.2028e-05 - val_loss: 0.6474\n",
      "36/36 [==============================] - 0s 596us/step - loss: 0.3985\n",
      "--- Starting trial: run-26\n",
      "{'learning_rate': 0.01833584556602331, 'optimizer': 'sgd', 'whether_dropout': False, 'dropout': 0.22874141721301827, 'num_units': 34, 'activation': 'relu', 'hidden_layer_number': 1}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 969us/step - loss: 0.0989 - val_loss: 0.2349\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0099 - val_loss: 0.2759\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 0.3020\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 878us/step - loss: 0.0032 - val_loss: 0.3210\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 863us/step - loss: 0.0023 - val_loss: 0.3358\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 752us/step - loss: 0.0018 - val_loss: 0.3479\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 761us/step - loss: 0.0015 - val_loss: 0.3581\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 802us/step - loss: 0.0013 - val_loss: 0.3670\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 748us/step - loss: 0.0011 - val_loss: 0.3748\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 711us/step - loss: 9.5175e-04 - val_loss: 0.3818\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 767us/step - loss: 8.4583e-04 - val_loss: 0.3882\n",
      "36/36 [==============================] - 0s 523us/step - loss: 0.2324\n",
      "--- Starting trial: run-27\n",
      "{'learning_rate': 0.0018125914726106263, 'optimizer': 'adam', 'whether_dropout': False, 'dropout': 0.2734795698016351, 'num_units': 27, 'activation': 'sigmoid', 'hidden_layer_number': 1}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 1s 1ms/step - loss: 0.0288 - val_loss: 0.2856\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0022 - val_loss: 0.3360\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 9.2742e-04 - val_loss: 0.3678\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 5.2751e-04 - val_loss: 0.3913\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 907us/step - loss: 3.4179e-04 - val_loss: 0.4104\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 920us/step - loss: 2.3893e-04 - val_loss: 0.4266\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 1.7547e-04 - val_loss: 0.4408\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 1.3341e-04 - val_loss: 0.4536\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 981us/step - loss: 1.0401e-04 - val_loss: 0.4653\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 8.2677e-05 - val_loss: 0.4761\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 919us/step - loss: 6.6715e-05 - val_loss: 0.4864\n",
      "36/36 [==============================] - 0s 647us/step - loss: 0.2880\n",
      "--- Starting trial: run-28\n",
      "{'learning_rate': 0.0010259636178788646, 'optimizer': 'sgd', 'whether_dropout': False, 'dropout': 0.17836389572313482, 'num_units': 45, 'activation': 'sigmoid', 'hidden_layer_number': 1}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 0.3637 - val_loss: 0.2977\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 2ms/step - loss: 0.1756 - val_loss: 0.2301\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.1116 - val_loss: 0.2078\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 813us/step - loss: 0.0808 - val_loss: 0.1995\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0630 - val_loss: 0.1968\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 958us/step - loss: 0.0515 - val_loss: 0.1966\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 797us/step - loss: 0.0434 - val_loss: 0.1977\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 826us/step - loss: 0.0375 - val_loss: 0.1995\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 833us/step - loss: 0.0330 - val_loss: 0.2015\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 786us/step - loss: 0.0294 - val_loss: 0.2038\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0265 - val_loss: 0.2061\n",
      "Epoch 12/100\n",
      "285/285 [==============================] - 0s 860us/step - loss: 0.0241 - val_loss: 0.2084\n",
      "Epoch 13/100\n",
      "285/285 [==============================] - 0s 774us/step - loss: 0.0221 - val_loss: 0.2107\n",
      "Epoch 14/100\n",
      "285/285 [==============================] - 0s 691us/step - loss: 0.0204 - val_loss: 0.2130\n",
      "Epoch 15/100\n",
      "285/285 [==============================] - 0s 2ms/step - loss: 0.0190 - val_loss: 0.2152\n",
      "Epoch 16/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0177 - val_loss: 0.2173\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.1969\n",
      "--- Starting trial: run-29\n",
      "{'learning_rate': 0.17330762001542252, 'optimizer': 'adam', 'whether_dropout': False, 'dropout': 0.23207567283139838, 'num_units': 45, 'activation': 'relu', 'hidden_layer_number': 3}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 3s 7ms/step - loss: 0.0022 - val_loss: 16.5869\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - val_loss: 16.5869\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - val_loss: 16.5869\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 964us/step - loss: 0.0000e+00 - val_loss: 16.5869\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 892us/step - loss: 0.0000e+00 - val_loss: 16.5869\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 865us/step - loss: 0.0000e+00 - val_loss: 16.5869\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 882us/step - loss: 0.0000e+00 - val_loss: 16.5869\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 839us/step - loss: 0.0000e+00 - val_loss: 16.5869\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 818us/step - loss: 0.0000e+00 - val_loss: 16.5869\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 928us/step - loss: 0.0000e+00 - val_loss: 16.5869\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - val_loss: 16.5869\n",
      "36/36 [==============================] - 0s 557us/step - loss: 17.0123\n",
      "--- Starting trial: run-30\n",
      "{'learning_rate': 0.0020967095038594437, 'optimizer': 'adam', 'whether_dropout': True, 'dropout': 0.2937650041460256, 'num_units': 34, 'activation': 'sigmoid', 'hidden_layer_number': 3}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 1s 1ms/step - loss: 0.1294 - val_loss: 0.2306\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.2770\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0034 - val_loss: 0.3081\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 791us/step - loss: 0.0019 - val_loss: 0.3318\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 833us/step - loss: 0.0012 - val_loss: 0.3509\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 2ms/step - loss: 8.3872e-04 - val_loss: 0.3674\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 6.0994e-04 - val_loss: 0.3819\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 904us/step - loss: 4.5804e-04 - val_loss: 0.3949\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 955us/step - loss: 3.5801e-04 - val_loss: 0.4071\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 991us/step - loss: 2.8377e-04 - val_loss: 0.4185\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 2.2403e-04 - val_loss: 0.4291\n",
      "36/36 [==============================] - 0s 607us/step - loss: 0.2326\n",
      "--- Starting trial: run-31\n",
      "{'learning_rate': 0.0020054497020999635, 'optimizer': 'adam', 'whether_dropout': True, 'dropout': 0.2621898040756854, 'num_units': 34, 'activation': 'sigmoid', 'hidden_layer_number': 2}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 1s 1ms/step - loss: 0.0475 - val_loss: 0.2780\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 0.0027 - val_loss: 0.3305\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 943us/step - loss: 0.0011 - val_loss: 0.3637\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 877us/step - loss: 6.4233e-04 - val_loss: 0.3884\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 906us/step - loss: 4.0905e-04 - val_loss: 0.4082\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 863us/step - loss: 2.8569e-04 - val_loss: 0.4250\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 2.0885e-04 - val_loss: 0.4397\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 907us/step - loss: 1.5639e-04 - val_loss: 0.4527\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 919us/step - loss: 1.2350e-04 - val_loss: 0.4649\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 829us/step - loss: 9.8366e-05 - val_loss: 0.4762\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 837us/step - loss: 7.7618e-05 - val_loss: 0.4867\n",
      "36/36 [==============================] - 0s 540us/step - loss: 0.2799\n",
      "--- Starting trial: run-32\n",
      "{'learning_rate': 0.014778342455800238, 'optimizer': 'adam', 'whether_dropout': False, 'dropout': 0.19632287170878127, 'num_units': 34, 'activation': 'sigmoid', 'hidden_layer_number': 3}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 1s 1ms/step - loss: 0.0090 - val_loss: 0.4131\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 1.7641e-04 - val_loss: 0.4551\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 8.5895e-05 - val_loss: 0.4839\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 914us/step - loss: 5.1226e-05 - val_loss: 0.5060\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 866us/step - loss: 3.4042e-05 - val_loss: 0.5241\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 829us/step - loss: 2.4183e-05 - val_loss: 0.5396\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 1.7960e-05 - val_loss: 0.5533\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 987us/step - loss: 1.3768e-05 - val_loss: 0.5657\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 938us/step - loss: 1.0803e-05 - val_loss: 0.5771\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 823us/step - loss: 8.6305e-06 - val_loss: 0.5878\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 866us/step - loss: 6.9924e-06 - val_loss: 0.5978\n",
      "36/36 [==============================] - 0s 484us/step - loss: 0.4154\n",
      "--- Starting trial: run-33\n",
      "{'learning_rate': 0.0026559844016543726, 'optimizer': 'sgd', 'whether_dropout': False, 'dropout': 0.23731544655933437, 'num_units': 27, 'activation': 'relu', 'hidden_layer_number': 1}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 984us/step - loss: 0.3745 - val_loss: 0.2841\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 2ms/step - loss: 0.1340 - val_loss: 0.2198\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0675 - val_loss: 0.2126\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 776us/step - loss: 0.0419 - val_loss: 0.2179\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 715us/step - loss: 0.0293 - val_loss: 0.2259\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 695us/step - loss: 0.0220 - val_loss: 0.2343\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 694us/step - loss: 0.0175 - val_loss: 0.2423\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 666us/step - loss: 0.0143 - val_loss: 0.2497\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0121 - val_loss: 0.2566\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 846us/step - loss: 0.0104 - val_loss: 0.2629\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 794us/step - loss: 0.0091 - val_loss: 0.2687\n",
      "Epoch 12/100\n",
      "285/285 [==============================] - 0s 649us/step - loss: 0.0080 - val_loss: 0.2742\n",
      "Epoch 13/100\n",
      "285/285 [==============================] - 0s 684us/step - loss: 0.0072 - val_loss: 0.2792\n",
      "36/36 [==============================] - 0s 545us/step - loss: 0.2176\n",
      "--- Starting trial: run-34\n",
      "{'learning_rate': 0.40129916519149766, 'optimizer': 'adam', 'whether_dropout': False, 'dropout': 0.2454304034000479, 'num_units': 68, 'activation': 'sigmoid', 'hidden_layer_number': 1}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 1s 1ms/step - loss: 0.0011 - val_loss: 5.5134\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - val_loss: 5.5134\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - val_loss: 5.5134\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 861us/step - loss: 0.0000e+00 - val_loss: 5.5134\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 844us/step - loss: 0.0000e+00 - val_loss: 5.5134\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - val_loss: 5.5134\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - val_loss: 5.5134\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - val_loss: 5.5134\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 917us/step - loss: 0.0000e+00 - val_loss: 5.5134\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 900us/step - loss: 0.0000e+00 - val_loss: 5.5134\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 892us/step - loss: 0.0000e+00 - val_loss: 5.5134\n",
      "36/36 [==============================] - 0s 646us/step - loss: 5.5134\n",
      "--- Starting trial: run-35\n",
      "{'learning_rate': 0.0074077570838147234, 'optimizer': 'sgd', 'whether_dropout': True, 'dropout': 0.21330922623585152, 'num_units': 27, 'activation': 'relu', 'hidden_layer_number': 2}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 1s 1ms/step - loss: 0.2514 - val_loss: 0.2016\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.2084\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 745us/step - loss: 0.0231 - val_loss: 0.2295\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 795us/step - loss: 0.0145 - val_loss: 0.2481\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 669us/step - loss: 0.0103 - val_loss: 0.2635\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 671us/step - loss: 0.0081 - val_loss: 0.2766\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.2879\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 917us/step - loss: 0.0052 - val_loss: 0.2975\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 778us/step - loss: 0.0046 - val_loss: 0.3063\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 700us/step - loss: 0.0042 - val_loss: 0.3144\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 758us/step - loss: 0.0035 - val_loss: 0.3215\n",
      "36/36 [==============================] - 0s 518us/step - loss: 0.2021\n",
      "--- Starting trial: run-36\n",
      "{'learning_rate': 0.02943839581826807, 'optimizer': 'sgd', 'whether_dropout': True, 'dropout': 0.16631886422802453, 'num_units': 27, 'activation': 'relu', 'hidden_layer_number': 3}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 855us/step - loss: 0.0519 - val_loss: 0.2723\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.3183\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0032 - val_loss: 0.3473\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 854us/step - loss: 0.0022 - val_loss: 0.3682\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 678us/step - loss: 0.0017 - val_loss: 0.3846\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 671us/step - loss: 0.0013 - val_loss: 0.3981\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 706us/step - loss: 0.0010 - val_loss: 0.4092\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 649us/step - loss: 9.1190e-04 - val_loss: 0.4188\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 8.2383e-04 - val_loss: 0.4278\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 868us/step - loss: 7.1900e-04 - val_loss: 0.4357\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 654us/step - loss: 6.6738e-04 - val_loss: 0.4430\n",
      "36/36 [==============================] - 0s 737us/step - loss: 0.2734\n",
      "--- Starting trial: run-37\n",
      "{'learning_rate': 0.0010322553883650217, 'optimizer': 'sgd', 'whether_dropout': False, 'dropout': 0.14397411241183553, 'num_units': 68, 'activation': 'relu', 'hidden_layer_number': 1}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 850us/step - loss: 0.5879 - val_loss: 0.4658\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 985us/step - loss: 0.3441 - val_loss: 0.3249\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 921us/step - loss: 0.2190 - val_loss: 0.2568\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.1499 - val_loss: 0.2235\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 875us/step - loss: 0.1091 - val_loss: 0.2072\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 742us/step - loss: 0.0835 - val_loss: 0.1997\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 673us/step - loss: 0.0664 - val_loss: 0.1969\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 663us/step - loss: 0.0545 - val_loss: 0.1967\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 683us/step - loss: 0.0457 - val_loss: 0.1979\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 948us/step - loss: 0.0392 - val_loss: 0.2000\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 924us/step - loss: 0.0340 - val_loss: 0.2025\n",
      "Epoch 12/100\n",
      "285/285 [==============================] - 0s 754us/step - loss: 0.0300 - val_loss: 0.2054\n",
      "Epoch 13/100\n",
      "285/285 [==============================] - 0s 905us/step - loss: 0.0267 - val_loss: 0.2083\n",
      "Epoch 14/100\n",
      "285/285 [==============================] - 0s 668us/step - loss: 0.0240 - val_loss: 0.2114\n",
      "Epoch 15/100\n",
      "285/285 [==============================] - 0s 708us/step - loss: 0.0218 - val_loss: 0.2144\n",
      "Epoch 16/100\n",
      "285/285 [==============================] - 0s 992us/step - loss: 0.0199 - val_loss: 0.2174\n",
      "Epoch 17/100\n",
      "285/285 [==============================] - 0s 980us/step - loss: 0.0182 - val_loss: 0.2203\n",
      "Epoch 18/100\n",
      "285/285 [==============================] - 0s 662us/step - loss: 0.0168 - val_loss: 0.2232\n",
      "36/36 [==============================] - 0s 556us/step - loss: 0.1972\n",
      "--- Starting trial: run-38\n",
      "{'learning_rate': 0.004887314761730563, 'optimizer': 'sgd', 'whether_dropout': False, 'dropout': 0.29742885262797153, 'num_units': 27, 'activation': 'sigmoid', 'hidden_layer_number': 1}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0891 - val_loss: 0.1969\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 976us/step - loss: 0.0434 - val_loss: 0.2004\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0284 - val_loss: 0.2080\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0210 - val_loss: 0.2157\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 961us/step - loss: 0.0166 - val_loss: 0.2228\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 762us/step - loss: 0.0137 - val_loss: 0.2292\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 721us/step - loss: 0.0117 - val_loss: 0.2350\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 679us/step - loss: 0.0101 - val_loss: 0.2402\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 671us/step - loss: 0.0089 - val_loss: 0.2451\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 683us/step - loss: 0.0080 - val_loss: 0.2495\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 731us/step - loss: 0.0072 - val_loss: 0.2536\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1979\n",
      "--- Starting trial: run-39\n",
      "{'learning_rate': 0.04521645884500582, 'optimizer': 'sgd', 'whether_dropout': False, 'dropout': 0.2548327208781046, 'num_units': 27, 'activation': 'sigmoid', 'hidden_layer_number': 2}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 1s 1ms/step - loss: 0.0518 - val_loss: 0.2416\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.2739\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 949us/step - loss: 0.0034 - val_loss: 0.2940\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 720us/step - loss: 0.0024 - val_loss: 0.3086\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 686us/step - loss: 0.0018 - val_loss: 0.3200\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0015 - val_loss: 0.3294\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 870us/step - loss: 0.0012 - val_loss: 0.3373\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 803us/step - loss: 0.0011 - val_loss: 0.3443\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 693us/step - loss: 9.2007e-04 - val_loss: 0.3504\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 770us/step - loss: 8.1762e-04 - val_loss: 0.3559\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 666us/step - loss: 7.3525e-04 - val_loss: 0.3609\n",
      "36/36 [==============================] - 0s 472us/step - loss: 0.2413\n",
      "--- Starting trial: run-40\n",
      "{'learning_rate': 0.004753482673245415, 'optimizer': 'sgd', 'whether_dropout': False, 'dropout': 0.28583333724547044, 'num_units': 34, 'activation': 'sigmoid', 'hidden_layer_number': 2}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 1s 1ms/step - loss: 0.1295 - val_loss: 0.1993\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0460 - val_loss: 0.2012\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 844us/step - loss: 0.0279 - val_loss: 0.2097\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 762us/step - loss: 0.0199 - val_loss: 0.2182\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 702us/step - loss: 0.0154 - val_loss: 0.2259\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 688us/step - loss: 0.0126 - val_loss: 0.2327\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 995us/step - loss: 0.0106 - val_loss: 0.2388\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 953us/step - loss: 0.0092 - val_loss: 0.2443\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 899us/step - loss: 0.0081 - val_loss: 0.2493\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 790us/step - loss: 0.0072 - val_loss: 0.2539\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 751us/step - loss: 0.0065 - val_loss: 0.2581\n",
      "36/36 [==============================] - 0s 559us/step - loss: 0.1987\n",
      "--- Starting trial: run-41\n",
      "{'learning_rate': 0.001227413574151663, 'optimizer': 'adam', 'whether_dropout': False, 'dropout': 0.1785114322075035, 'num_units': 34, 'activation': 'sigmoid', 'hidden_layer_number': 3}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 0.1189 - val_loss: 0.2272\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 0.0098 - val_loss: 0.2695\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 958us/step - loss: 0.0042 - val_loss: 0.2989\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0024 - val_loss: 0.3214\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 973us/step - loss: 0.0015 - val_loss: 0.3398\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.3555\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 7.9478e-04 - val_loss: 0.3693\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 6.0525e-04 - val_loss: 0.3818\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 925us/step - loss: 4.7253e-04 - val_loss: 0.3933\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 868us/step - loss: 3.7600e-04 - val_loss: 0.4040\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 849us/step - loss: 3.0367e-04 - val_loss: 0.4140\n",
      "36/36 [==============================] - 0s 555us/step - loss: 0.2296\n",
      "--- Starting trial: run-42\n",
      "{'learning_rate': 0.006879123083100537, 'optimizer': 'sgd', 'whether_dropout': False, 'dropout': 0.1901689474881616, 'num_units': 34, 'activation': 'sigmoid', 'hidden_layer_number': 2}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 1s 1ms/step - loss: 0.0843 - val_loss: 0.1965\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0292 - val_loss: 0.2090\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 859us/step - loss: 0.0177 - val_loss: 0.2213\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 752us/step - loss: 0.0127 - val_loss: 0.2318\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 727us/step - loss: 0.0099 - val_loss: 0.2406\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 708us/step - loss: 0.0081 - val_loss: 0.2483\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 701us/step - loss: 0.0068 - val_loss: 0.2549\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.2609\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 993us/step - loss: 0.0052 - val_loss: 0.2662\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 900us/step - loss: 0.0046 - val_loss: 0.2710\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 926us/step - loss: 0.0042 - val_loss: 0.2754\n",
      "36/36 [==============================] - 0s 544us/step - loss: 0.1960\n",
      "--- Starting trial: run-43\n",
      "{'learning_rate': 0.053583301488607474, 'optimizer': 'sgd', 'whether_dropout': True, 'dropout': 0.15998963845996567, 'num_units': 45, 'activation': 'sigmoid', 'hidden_layer_number': 3}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 925us/step - loss: 0.0267 - val_loss: 0.2725\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 964us/step - loss: 0.0032 - val_loss: 0.3054\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 0.0019 - val_loss: 0.3252\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.3395\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 741us/step - loss: 0.0010 - val_loss: 0.3506\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 722us/step - loss: 8.2180e-04 - val_loss: 0.3597\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 732us/step - loss: 6.8981e-04 - val_loss: 0.3674\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 699us/step - loss: 5.9426e-04 - val_loss: 0.3742\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 5.2387e-04 - val_loss: 0.3801\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 955us/step - loss: 4.6819e-04 - val_loss: 0.3854\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 892us/step - loss: 4.2098e-04 - val_loss: 0.3903\n",
      "36/36 [==============================] - 0s 524us/step - loss: 0.2713\n",
      "--- Starting trial: run-44\n",
      "{'learning_rate': 0.0059562472212459, 'optimizer': 'adam', 'whether_dropout': False, 'dropout': 0.27931088490293604, 'num_units': 45, 'activation': 'relu', 'hidden_layer_number': 3}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.5570\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 3.3154e-05 - val_loss: 0.6303\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 2ms/step - loss: 1.1395e-05 - val_loss: 0.6790\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 5.5178e-06 - val_loss: 0.7152\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 895us/step - loss: 3.1749e-06 - val_loss: 0.7444\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 909us/step - loss: 2.0325e-06 - val_loss: 0.7689\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 825us/step - loss: 1.3892e-06 - val_loss: 0.7902\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 9.9511e-07 - val_loss: 0.8092\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 887us/step - loss: 7.3676e-07 - val_loss: 0.8266\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 826us/step - loss: 5.5984e-07 - val_loss: 0.8428\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 734us/step - loss: 4.3380e-07 - val_loss: 0.8578\n",
      "36/36 [==============================] - 0s 474us/step - loss: 0.5685\n",
      "--- Starting trial: run-45\n",
      "{'learning_rate': 0.0034827201210574244, 'optimizer': 'sgd', 'whether_dropout': True, 'dropout': 0.14581041250231272, 'num_units': 68, 'activation': 'sigmoid', 'hidden_layer_number': 2}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 956us/step - loss: 0.2735 - val_loss: 0.1987\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 757us/step - loss: 0.0430 - val_loss: 0.2032\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0238 - val_loss: 0.2145\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0165 - val_loss: 0.2248\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 709us/step - loss: 0.0126 - val_loss: 0.2335\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 766us/step - loss: 0.0102 - val_loss: 0.2411\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 664us/step - loss: 0.0085 - val_loss: 0.2478\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 661us/step - loss: 0.0073 - val_loss: 0.2537\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 683us/step - loss: 0.0064 - val_loss: 0.2590\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0057 - val_loss: 0.2638\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 777us/step - loss: 0.0052 - val_loss: 0.2681\n",
      "36/36 [==============================] - 0s 453us/step - loss: 0.1984\n",
      "--- Starting trial: run-46\n",
      "{'learning_rate': 0.32718316057324676, 'optimizer': 'sgd', 'whether_dropout': True, 'dropout': 0.27571126043482896, 'num_units': 27, 'activation': 'sigmoid', 'hidden_layer_number': 3}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 911us/step - loss: 0.0106 - val_loss: 0.3470\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 774us/step - loss: 7.1917e-04 - val_loss: 0.3829\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 4.1426e-04 - val_loss: 0.4042\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 838us/step - loss: 2.9022e-04 - val_loss: 0.4193\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 669us/step - loss: 2.2321e-04 - val_loss: 0.4311\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 1.8096e-04 - val_loss: 0.4408\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 749us/step - loss: 1.5239e-04 - val_loss: 0.4489\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 725us/step - loss: 1.2986e-04 - val_loss: 0.4560\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 657us/step - loss: 1.1553e-04 - val_loss: 0.4622\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 706us/step - loss: 1.0251e-04 - val_loss: 0.4678\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 674us/step - loss: 9.2138e-05 - val_loss: 0.4729\n",
      "36/36 [==============================] - 0s 525us/step - loss: 0.3463\n",
      "--- Starting trial: run-47\n",
      "{'learning_rate': 0.3738515995308471, 'optimizer': 'adam', 'whether_dropout': False, 'dropout': 0.12925919706247435, 'num_units': 34, 'activation': 'relu', 'hidden_layer_number': 1}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 1s 1ms/step - loss: 0.0025 - val_loss: 43.5501\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - val_loss: 43.5501\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 963us/step - loss: 0.0000e+00 - val_loss: 43.5501\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 821us/step - loss: 0.0000e+00 - val_loss: 43.5501\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - val_loss: 43.5501\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 936us/step - loss: 0.0000e+00 - val_loss: 43.5501\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 941us/step - loss: 0.0000e+00 - val_loss: 43.5501\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 729us/step - loss: 0.0000e+00 - val_loss: 43.5501\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 777us/step - loss: 0.0000e+00 - val_loss: 43.5501\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 718us/step - loss: 0.0000e+00 - val_loss: 43.5501\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 739us/step - loss: 0.0000e+00 - val_loss: 43.5501\n",
      "36/36 [==============================] - 0s 498us/step - loss: 44.7113\n",
      "--- Starting trial: run-48\n",
      "{'learning_rate': 0.041476567352464674, 'optimizer': 'adam', 'whether_dropout': False, 'dropout': 0.13566984684872613, 'num_units': 27, 'activation': 'sigmoid', 'hidden_layer_number': 3}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 1s 1ms/step - loss: 0.0032 - val_loss: 0.5287\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 1.9783e-05 - val_loss: 0.5482\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 817us/step - loss: 1.3530e-05 - val_loss: 0.5669\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 776us/step - loss: 9.5004e-06 - val_loss: 0.5837\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 737us/step - loss: 6.9011e-06 - val_loss: 0.5988\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 726us/step - loss: 5.1675e-06 - val_loss: 0.6126\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 3.9666e-06 - val_loss: 0.6251\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 946us/step - loss: 3.1061e-06 - val_loss: 0.6368\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 825us/step - loss: 2.4709e-06 - val_loss: 0.6478\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 836us/step - loss: 1.9910e-06 - val_loss: 0.6582\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 754us/step - loss: 1.6212e-06 - val_loss: 0.6682\n",
      "36/36 [==============================] - 0s 455us/step - loss: 0.5297\n",
      "--- Starting trial: run-49\n",
      "{'learning_rate': 0.0023690253620430547, 'optimizer': 'adam', 'whether_dropout': True, 'dropout': 0.2556890655621875, 'num_units': 45, 'activation': 'relu', 'hidden_layer_number': 1}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 1s 1ms/step - loss: 0.0271 - val_loss: 0.4959\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 3.0237e-04 - val_loss: 0.5941\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 913us/step - loss: 1.1174e-04 - val_loss: 0.6550\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 853us/step - loss: 6.7683e-05 - val_loss: 0.7043\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 759us/step - loss: 3.0882e-05 - val_loss: 0.7384\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 817us/step - loss: 4.2680e-05 - val_loss: 0.7781\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 2.0470e-05 - val_loss: 0.8073\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 845us/step - loss: 1.7955e-05 - val_loss: 0.8345\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 794us/step - loss: 1.2851e-05 - val_loss: 0.8611\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 750us/step - loss: 9.9244e-06 - val_loss: 0.8859\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 743us/step - loss: 5.8610e-06 - val_loss: 0.9059\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5060\n",
      "--- Starting trial: run-50\n",
      "{'learning_rate': 0.0011460408317515913, 'optimizer': 'sgd', 'whether_dropout': False, 'dropout': 0.10610581134582647, 'num_units': 68, 'activation': 'sigmoid', 'hidden_layer_number': 2}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 0.2574 - val_loss: 0.2325\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.1075 - val_loss: 0.1976\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 859us/step - loss: 0.0665 - val_loss: 0.1910\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 762us/step - loss: 0.0478 - val_loss: 0.1915\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 666us/step - loss: 0.0372 - val_loss: 0.1942\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0304 - val_loss: 0.1976\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 795us/step - loss: 0.0257 - val_loss: 0.2013\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 701us/step - loss: 0.0222 - val_loss: 0.2049\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 725us/step - loss: 0.0196 - val_loss: 0.2085\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 658us/step - loss: 0.0175 - val_loss: 0.2119\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 655us/step - loss: 0.0158 - val_loss: 0.2151\n",
      "Epoch 12/100\n",
      "285/285 [==============================] - 0s 658us/step - loss: 0.0144 - val_loss: 0.2182\n",
      "Epoch 13/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0132 - val_loss: 0.2211\n",
      "36/36 [==============================] - 0s 799us/step - loss: 0.1903\n",
      "--- Starting trial: run-51\n",
      "{'learning_rate': 0.005640470366715252, 'optimizer': 'adam', 'whether_dropout': False, 'dropout': 0.20704163855792007, 'num_units': 68, 'activation': 'relu', 'hidden_layer_number': 2}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 981us/step - loss: 0.0114 - val_loss: 0.5949\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 957us/step - loss: 2.0134e-05 - val_loss: 0.6516\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 8.5910e-06 - val_loss: 0.6918\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 877us/step - loss: 4.6549e-06 - val_loss: 0.7227\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 2.8668e-06 - val_loss: 0.7483\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 1.9176e-06 - val_loss: 0.7702\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 853us/step - loss: 1.3530e-06 - val_loss: 0.7895\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 759us/step - loss: 9.9227e-07 - val_loss: 0.8068\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 749us/step - loss: 7.4842e-07 - val_loss: 0.8228\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 751us/step - loss: 5.7711e-07 - val_loss: 0.8377\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 4.5290e-07 - val_loss: 0.8516\n",
      "36/36 [==============================] - 0s 580us/step - loss: 0.6156\n",
      "--- Starting trial: run-52\n",
      "{'learning_rate': 0.0014084280682562303, 'optimizer': 'sgd', 'whether_dropout': True, 'dropout': 0.26346107084138815, 'num_units': 68, 'activation': 'sigmoid', 'hidden_layer_number': 2}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 921us/step - loss: 0.3644 - val_loss: 0.2421\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 725us/step - loss: 0.1052 - val_loss: 0.2009\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 759us/step - loss: 0.0599 - val_loss: 0.1965\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 861us/step - loss: 0.0416 - val_loss: 0.1990\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 706us/step - loss: 0.0317 - val_loss: 0.2033\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 737us/step - loss: 0.0256 - val_loss: 0.2079\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0215 - val_loss: 0.2124\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 862us/step - loss: 0.0185 - val_loss: 0.2168\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 700us/step - loss: 0.0162 - val_loss: 0.2209\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 682us/step - loss: 0.0144 - val_loss: 0.2247\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 699us/step - loss: 0.0130 - val_loss: 0.2283\n",
      "Epoch 12/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0118 - val_loss: 0.2317\n",
      "Epoch 13/100\n",
      "285/285 [==============================] - 0s 841us/step - loss: 0.0108 - val_loss: 0.2349\n",
      "36/36 [==============================] - 0s 477us/step - loss: 0.1968\n",
      "--- Starting trial: run-53\n",
      "{'learning_rate': 0.03591056932499208, 'optimizer': 'sgd', 'whether_dropout': False, 'dropout': 0.20720456350210534, 'num_units': 27, 'activation': 'sigmoid', 'hidden_layer_number': 3}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 860us/step - loss: 0.0487 - val_loss: 0.2360\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 710us/step - loss: 0.0077 - val_loss: 0.2659\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 967us/step - loss: 0.0044 - val_loss: 0.2849\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 839us/step - loss: 0.0030 - val_loss: 0.2989\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 810us/step - loss: 0.0023 - val_loss: 0.3099\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0019 - val_loss: 0.3190\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 687us/step - loss: 0.0016 - val_loss: 0.3267\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 705us/step - loss: 0.0013 - val_loss: 0.3334\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 643us/step - loss: 0.0012 - val_loss: 0.3394\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 647us/step - loss: 0.0010 - val_loss: 0.3447\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 9.4413e-04 - val_loss: 0.3495\n",
      "36/36 [==============================] - 0s 654us/step - loss: 0.2362\n",
      "--- Starting trial: run-54\n",
      "{'learning_rate': 0.8885970049897385, 'optimizer': 'adam', 'whether_dropout': False, 'dropout': 0.1470967990083472, 'num_units': 45, 'activation': 'relu', 'hidden_layer_number': 1}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 974us/step - loss: 0.0024 - val_loss: 267.3339\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 868us/step - loss: 0.0000e+00 - val_loss: 267.3339\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - val_loss: 267.3339\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 782us/step - loss: 0.0000e+00 - val_loss: 267.3339\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 772us/step - loss: 0.0000e+00 - val_loss: 267.3339\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 805us/step - loss: 0.0000e+00 - val_loss: 267.3339\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - val_loss: 267.3339\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 916us/step - loss: 0.0000e+00 - val_loss: 267.3339\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 869us/step - loss: 0.0000e+00 - val_loss: 267.3339\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 776us/step - loss: 0.0000e+00 - val_loss: 267.3339\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 740us/step - loss: 0.0000e+00 - val_loss: 267.3339\n",
      "36/36 [==============================] - 0s 436us/step - loss: 274.0829\n",
      "--- Starting trial: run-55\n",
      "{'learning_rate': 0.01307594364717629, 'optimizer': 'adam', 'whether_dropout': False, 'dropout': 0.14569640261958822, 'num_units': 27, 'activation': 'relu', 'hidden_layer_number': 1}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 1s 1ms/step - loss: 0.0066 - val_loss: 1.0251\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 9.9839e-09 - val_loss: 1.1197\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 882us/step - loss: 3.0910e-09 - val_loss: 1.1666\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 793us/step - loss: 1.6046e-09 - val_loss: 1.1989\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 831us/step - loss: 1.0046e-09 - val_loss: 1.2235\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 6.9816e-10 - val_loss: 1.2434\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 815us/step - loss: 5.1645e-10 - val_loss: 1.2602\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 824us/step - loss: 3.9947e-10 - val_loss: 1.2744\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 736us/step - loss: 3.1946e-10 - val_loss: 1.2875\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 724us/step - loss: 2.6213e-10 - val_loss: 1.2990\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 721us/step - loss: 2.1944e-10 - val_loss: 1.3092\n",
      "36/36 [==============================] - 0s 505us/step - loss: 1.0527\n",
      "--- Starting trial: run-56\n",
      "{'learning_rate': 0.003881418829014591, 'optimizer': 'adam', 'whether_dropout': True, 'dropout': 0.21757880370042743, 'num_units': 68, 'activation': 'sigmoid', 'hidden_layer_number': 1}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 1s 1ms/step - loss: 0.0409 - val_loss: 0.3313\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 971us/step - loss: 0.0010 - val_loss: 0.3838\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 916us/step - loss: 4.3767e-04 - val_loss: 0.4170\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 867us/step - loss: 2.4881e-04 - val_loss: 0.4416\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 916us/step - loss: 1.5867e-04 - val_loss: 0.4613\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 1.1195e-04 - val_loss: 0.4781\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 8.1568e-05 - val_loss: 0.4928\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 967us/step - loss: 6.0910e-05 - val_loss: 0.5057\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 794us/step - loss: 4.8311e-05 - val_loss: 0.5178\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 796us/step - loss: 3.8825e-05 - val_loss: 0.5292\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 769us/step - loss: 3.0488e-05 - val_loss: 0.5396\n",
      "36/36 [==============================] - 0s 492us/step - loss: 0.3339\n",
      "--- Starting trial: run-57\n",
      "{'learning_rate': 0.18787297907329922, 'optimizer': 'sgd', 'whether_dropout': True, 'dropout': 0.16930227581068585, 'num_units': 27, 'activation': 'sigmoid', 'hidden_layer_number': 2}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 0.0127 - val_loss: 0.3108\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.3455\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 849us/step - loss: 7.2596e-04 - val_loss: 0.3662\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 679us/step - loss: 5.0649e-04 - val_loss: 0.3809\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 690us/step - loss: 3.8791e-04 - val_loss: 0.3924\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 3.1412e-04 - val_loss: 0.4018\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 818us/step - loss: 2.6315e-04 - val_loss: 0.4098\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 677us/step - loss: 2.2486e-04 - val_loss: 0.4166\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 737us/step - loss: 1.9854e-04 - val_loss: 0.4227\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 665us/step - loss: 1.7722e-04 - val_loss: 0.4282\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 678us/step - loss: 1.5957e-04 - val_loss: 0.4331\n",
      "36/36 [==============================] - 0s 493us/step - loss: 0.3113\n",
      "--- Starting trial: run-58\n",
      "{'learning_rate': 0.016025876160704416, 'optimizer': 'adam', 'whether_dropout': False, 'dropout': 0.15331821583726363, 'num_units': 68, 'activation': 'sigmoid', 'hidden_layer_number': 1}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0055 - val_loss: 0.5178\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 3.0858e-05 - val_loss: 0.5397\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 887us/step - loss: 2.0459e-05 - val_loss: 0.5598\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 754us/step - loss: 1.4115e-05 - val_loss: 0.5774\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 744us/step - loss: 1.0148e-05 - val_loss: 0.5931\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 733us/step - loss: 7.5521e-06 - val_loss: 0.6072\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 748us/step - loss: 5.7748e-06 - val_loss: 0.6200\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 720us/step - loss: 4.5124e-06 - val_loss: 0.6319\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 741us/step - loss: 3.5862e-06 - val_loss: 0.6429\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 728us/step - loss: 2.8903e-06 - val_loss: 0.6534\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 995us/step - loss: 2.3563e-06 - val_loss: 0.6632\n",
      "36/36 [==============================] - 0s 795us/step - loss: 0.5212\n",
      "--- Starting trial: run-59\n",
      "{'learning_rate': 0.5361004430734125, 'optimizer': 'sgd', 'whether_dropout': False, 'dropout': 0.18311034933477405, 'num_units': 68, 'activation': 'sigmoid', 'hidden_layer_number': 1}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 878us/step - loss: 0.0030 - val_loss: 0.3987\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 731us/step - loss: 2.1746e-04 - val_loss: 0.4328\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 906us/step - loss: 1.2703e-04 - val_loss: 0.4529\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 8.9831e-05 - val_loss: 0.4673\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 6.9451e-05 - val_loss: 0.4785\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 890us/step - loss: 5.6578e-05 - val_loss: 0.4876\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 664us/step - loss: 4.7711e-05 - val_loss: 0.4954\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 741us/step - loss: 4.1229e-05 - val_loss: 0.5021\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 648us/step - loss: 3.6286e-05 - val_loss: 0.5080\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 781us/step - loss: 3.2393e-05 - val_loss: 0.5134\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 689us/step - loss: 2.9249e-05 - val_loss: 0.5182\n",
      "36/36 [==============================] - 0s 477us/step - loss: 0.3995\n",
      "--- Starting trial: run-60\n",
      "{'learning_rate': 0.01179306286162873, 'optimizer': 'sgd', 'whether_dropout': True, 'dropout': 0.24670036805150974, 'num_units': 68, 'activation': 'sigmoid', 'hidden_layer_number': 3}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0842 - val_loss: 0.2175\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 862us/step - loss: 0.0115 - val_loss: 0.2444\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 896us/step - loss: 0.0066 - val_loss: 0.2622\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 713us/step - loss: 0.0046 - val_loss: 0.2754\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 663us/step - loss: 0.0036 - val_loss: 0.2858\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 668us/step - loss: 0.0029 - val_loss: 0.2945\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0024 - val_loss: 0.3019\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 812us/step - loss: 0.0021 - val_loss: 0.3083\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 707us/step - loss: 0.0019 - val_loss: 0.3140\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 675us/step - loss: 0.0017 - val_loss: 0.3191\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 738us/step - loss: 0.0015 - val_loss: 0.3238\n",
      "36/36 [==============================] - 0s 604us/step - loss: 0.2183\n",
      "--- Starting trial: run-61\n",
      "{'learning_rate': 0.46234633568697847, 'optimizer': 'sgd', 'whether_dropout': True, 'dropout': 0.24836375626988502, 'num_units': 45, 'activation': 'sigmoid', 'hidden_layer_number': 3}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0044 - val_loss: 0.3760\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 3.5562e-04 - val_loss: 0.4110\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 2.0603e-04 - val_loss: 0.4316\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 737us/step - loss: 1.4519e-04 - val_loss: 0.4464\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 661us/step - loss: 1.1149e-04 - val_loss: 0.4578\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 707us/step - loss: 9.0958e-05 - val_loss: 0.4672\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 7.6492e-05 - val_loss: 0.4751\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 687us/step - loss: 6.5636e-05 - val_loss: 0.4820\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 857us/step - loss: 5.8117e-05 - val_loss: 0.4881\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 651us/step - loss: 5.1866e-05 - val_loss: 0.4935\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 662us/step - loss: 4.6596e-05 - val_loss: 0.4984\n",
      "36/36 [==============================] - 0s 461us/step - loss: 0.3756\n",
      "--- Starting trial: run-62\n",
      "{'learning_rate': 0.2983776581050556, 'optimizer': 'sgd', 'whether_dropout': False, 'dropout': 0.1686253423878689, 'num_units': 45, 'activation': 'sigmoid', 'hidden_layer_number': 2}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 990us/step - loss: 0.0074 - val_loss: 0.3444\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 779us/step - loss: 5.7463e-04 - val_loss: 0.3789\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 859us/step - loss: 3.3068e-04 - val_loss: 0.3993\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 725us/step - loss: 2.3205e-04 - val_loss: 0.4138\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 633us/step - loss: 1.7848e-04 - val_loss: 0.4251\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 651us/step - loss: 1.4484e-04 - val_loss: 0.4343\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 642us/step - loss: 1.2176e-04 - val_loss: 0.4421\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 662us/step - loss: 1.0495e-04 - val_loss: 0.4489\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 897us/step - loss: 9.2177e-05 - val_loss: 0.4549\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 908us/step - loss: 8.2137e-05 - val_loss: 0.4603\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 680us/step - loss: 7.4042e-05 - val_loss: 0.4651\n",
      "36/36 [==============================] - 0s 581us/step - loss: 0.3453\n",
      "--- Starting trial: run-63\n",
      "{'learning_rate': 0.014683861394107538, 'optimizer': 'adam', 'whether_dropout': False, 'dropout': 0.27220540984475594, 'num_units': 34, 'activation': 'sigmoid', 'hidden_layer_number': 3}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 943us/step - loss: 0.0097 - val_loss: 0.4147\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 768us/step - loss: 1.6499e-04 - val_loss: 0.4603\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 996us/step - loss: 7.6983e-05 - val_loss: 0.4901\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 4.5383e-05 - val_loss: 0.5124\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 992us/step - loss: 3.0062e-05 - val_loss: 0.5305\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 747us/step - loss: 2.1343e-05 - val_loss: 0.5460\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 759us/step - loss: 1.5859e-05 - val_loss: 0.5596\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 749us/step - loss: 1.2168e-05 - val_loss: 0.5719\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 734us/step - loss: 9.5566e-06 - val_loss: 0.5833\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 7.6422e-06 - val_loss: 0.5938\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 880us/step - loss: 6.1977e-06 - val_loss: 0.6038\n",
      "36/36 [==============================] - 0s 555us/step - loss: 0.4163\n",
      "--- Starting trial: run-64\n",
      "{'learning_rate': 0.0033633045220215745, 'optimizer': 'adam', 'whether_dropout': False, 'dropout': 0.10025593610066585, 'num_units': 27, 'activation': 'relu', 'hidden_layer_number': 3}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 908us/step - loss: 0.0348 - val_loss: 0.4521\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 872us/step - loss: 1.5253e-04 - val_loss: 0.5315\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 5.1493e-05 - val_loss: 0.5792\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 2.5622e-05 - val_loss: 0.6137\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 848us/step - loss: 1.5135e-05 - val_loss: 0.6414\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 868us/step - loss: 9.8775e-06 - val_loss: 0.6646\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 732us/step - loss: 6.8603e-06 - val_loss: 0.6848\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 768us/step - loss: 4.9781e-06 - val_loss: 0.7028\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 782us/step - loss: 3.7265e-06 - val_loss: 0.7193\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 2.8572e-06 - val_loss: 0.7346\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 885us/step - loss: 2.2329e-06 - val_loss: 0.7488\n",
      "36/36 [==============================] - 0s 454us/step - loss: 0.4682\n",
      "--- Starting trial: run-65\n",
      "{'learning_rate': 0.7670500523028955, 'optimizer': 'sgd', 'whether_dropout': True, 'dropout': 0.16894879153667164, 'num_units': 68, 'activation': 'relu', 'hidden_layer_number': 2}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 856us/step - loss: 0.0044 - val_loss: 0.4878\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 680us/step - loss: 1.6107e-04 - val_loss: 0.5385\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 788us/step - loss: 9.8821e-05 - val_loss: 0.5705\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 2ms/step - loss: 6.3474e-05 - val_loss: 0.5925\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 764us/step - loss: 5.2367e-05 - val_loss: 0.6106\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 727us/step - loss: 4.4622e-05 - val_loss: 0.6255\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 666us/step - loss: 3.1586e-05 - val_loss: 0.6368\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 663us/step - loss: 3.0119e-05 - val_loss: 0.6473\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 680us/step - loss: 2.6851e-05 - val_loss: 0.6569\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 2.3472e-05 - val_loss: 0.6655\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 817us/step - loss: 2.0863e-05 - val_loss: 0.6731\n",
      "36/36 [==============================] - 0s 486us/step - loss: 0.4910\n",
      "--- Starting trial: run-66\n",
      "{'learning_rate': 0.4364395732233059, 'optimizer': 'sgd', 'whether_dropout': True, 'dropout': 0.11682802873389726, 'num_units': 34, 'activation': 'sigmoid', 'hidden_layer_number': 3}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 837us/step - loss: 0.0075 - val_loss: 0.3607\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 684us/step - loss: 4.6379e-04 - val_loss: 0.3958\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 781us/step - loss: 2.6694e-04 - val_loss: 0.4165\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 2ms/step - loss: 1.8729e-04 - val_loss: 0.4314\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 786us/step - loss: 1.4371e-04 - val_loss: 0.4429\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 704us/step - loss: 1.1648e-04 - val_loss: 0.4523\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 666us/step - loss: 9.7503e-05 - val_loss: 0.4603\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 638us/step - loss: 8.3701e-05 - val_loss: 0.4671\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 682us/step - loss: 7.4108e-05 - val_loss: 0.4732\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 6.5883e-05 - val_loss: 0.4787\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 930us/step - loss: 5.9347e-05 - val_loss: 0.4837\n",
      "36/36 [==============================] - 0s 507us/step - loss: 0.3625\n",
      "--- Starting trial: run-67\n",
      "{'learning_rate': 0.6038924850817771, 'optimizer': 'adam', 'whether_dropout': False, 'dropout': 0.16358850148665416, 'num_units': 34, 'activation': 'relu', 'hidden_layer_number': 3}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 920us/step - loss: 0.0032 - val_loss: 97.0880\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 934us/step - loss: 0.0000e+00 - val_loss: 97.0880\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - val_loss: 97.0880\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - val_loss: 97.0880\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 843us/step - loss: 0.0000e+00 - val_loss: 97.0880\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 815us/step - loss: 0.0000e+00 - val_loss: 97.0880\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 749us/step - loss: 0.0000e+00 - val_loss: 97.0880\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 766us/step - loss: 0.0000e+00 - val_loss: 97.0880\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - val_loss: 97.0880\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 954us/step - loss: 0.0000e+00 - val_loss: 97.0880\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 842us/step - loss: 0.0000e+00 - val_loss: 97.0880\n",
      "36/36 [==============================] - 0s 474us/step - loss: 99.2733\n",
      "--- Starting trial: run-68\n",
      "{'learning_rate': 0.016534939586837074, 'optimizer': 'sgd', 'whether_dropout': False, 'dropout': 0.16527664803227288, 'num_units': 45, 'activation': 'relu', 'hidden_layer_number': 3}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 807us/step - loss: 0.1560 - val_loss: 0.2263\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 763us/step - loss: 0.0133 - val_loss: 0.2670\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.2938\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 832us/step - loss: 0.0040 - val_loss: 0.3132\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 706us/step - loss: 0.0028 - val_loss: 0.3284\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 641us/step - loss: 0.0022 - val_loss: 0.3407\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 646us/step - loss: 0.0018 - val_loss: 0.3511\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 654us/step - loss: 0.0015 - val_loss: 0.3601\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 664us/step - loss: 0.0013 - val_loss: 0.3681\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.3752\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 789us/step - loss: 9.9205e-04 - val_loss: 0.3816\n",
      "36/36 [==============================] - 0s 468us/step - loss: 0.2278\n",
      "--- Starting trial: run-69\n",
      "{'learning_rate': 0.005931613570349265, 'optimizer': 'adam', 'whether_dropout': False, 'dropout': 0.28256127399023256, 'num_units': 45, 'activation': 'relu', 'hidden_layer_number': 3}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 944us/step - loss: 0.0189 - val_loss: 0.5050\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 792us/step - loss: 7.3879e-05 - val_loss: 0.5677\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 923us/step - loss: 3.0140e-05 - val_loss: 0.6082\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 1.6341e-05 - val_loss: 0.6385\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 1.0157e-05 - val_loss: 0.6633\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 879us/step - loss: 6.8568e-06 - val_loss: 0.6846\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 856us/step - loss: 4.7718e-06 - val_loss: 0.7049\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 758us/step - loss: 3.1404e-06 - val_loss: 0.7310\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 752us/step - loss: 1.8201e-06 - val_loss: 0.7644\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 9.8618e-07 - val_loss: 0.8000\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 940us/step - loss: 5.5199e-07 - val_loss: 0.8321\n",
      "36/36 [==============================] - 0s 515us/step - loss: 0.5124\n",
      "--- Starting trial: run-70\n",
      "{'learning_rate': 0.507569289261735, 'optimizer': 'sgd', 'whether_dropout': True, 'dropout': 0.2809967063116481, 'num_units': 27, 'activation': 'relu', 'hidden_layer_number': 3}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 854us/step - loss: 0.0083 - val_loss: 0.4816\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 887us/step - loss: 3.1693e-04 - val_loss: 0.5375\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 931us/step - loss: 1.7356e-04 - val_loss: 0.5703\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 1.2907e-04 - val_loss: 0.5944\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 878us/step - loss: 9.0816e-05 - val_loss: 0.6127\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 812us/step - loss: 8.5603e-05 - val_loss: 0.6287\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 759us/step - loss: 5.9547e-05 - val_loss: 0.6411\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 662us/step - loss: 5.8731e-05 - val_loss: 0.6525\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 808us/step - loss: 5.0308e-05 - val_loss: 0.6627\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 5.2237e-05 - val_loss: 0.6725\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 701us/step - loss: 3.6767e-05 - val_loss: 0.6804\n",
      "36/36 [==============================] - 0s 561us/step - loss: 0.4848\n",
      "--- Starting trial: run-71\n",
      "{'learning_rate': 0.09260898183928852, 'optimizer': 'sgd', 'whether_dropout': True, 'dropout': 0.2695212482955841, 'num_units': 68, 'activation': 'sigmoid', 'hidden_layer_number': 3}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 839us/step - loss: 0.0136 - val_loss: 0.3081\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 720us/step - loss: 0.0013 - val_loss: 0.3418\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 7.7684e-04 - val_loss: 0.3618\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 944us/step - loss: 5.4888e-04 - val_loss: 0.3761\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 753us/step - loss: 4.2406e-04 - val_loss: 0.3872\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 672us/step - loss: 3.4509e-04 - val_loss: 0.3963\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 667us/step - loss: 2.9130e-04 - val_loss: 0.4040\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 658us/step - loss: 2.5056e-04 - val_loss: 0.4107\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 682us/step - loss: 2.2154e-04 - val_loss: 0.4166\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 1.9784e-04 - val_loss: 0.4219\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 717us/step - loss: 1.7820e-04 - val_loss: 0.4267\n",
      "36/36 [==============================] - 0s 601us/step - loss: 0.3085\n",
      "--- Starting trial: run-72\n",
      "{'learning_rate': 0.14909127785426582, 'optimizer': 'sgd', 'whether_dropout': False, 'dropout': 0.268262299338181, 'num_units': 68, 'activation': 'relu', 'hidden_layer_number': 2}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 889us/step - loss: 0.0148 - val_loss: 0.3644\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 722us/step - loss: 7.2043e-04 - val_loss: 0.4092\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 2ms/step - loss: 3.8684e-04 - val_loss: 0.4355\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 938us/step - loss: 2.6146e-04 - val_loss: 0.4541\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 747us/step - loss: 1.9599e-04 - val_loss: 0.4685\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 658us/step - loss: 1.5615e-04 - val_loss: 0.4803\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 685us/step - loss: 1.2938e-04 - val_loss: 0.4903\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 665us/step - loss: 1.1024e-04 - val_loss: 0.4989\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 9.5853e-05 - val_loss: 0.5065\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 786us/step - loss: 8.4684e-05 - val_loss: 0.5134\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 655us/step - loss: 7.5773e-05 - val_loss: 0.5195\n",
      "36/36 [==============================] - 0s 643us/step - loss: 0.3690\n",
      "--- Starting trial: run-73\n",
      "{'learning_rate': 0.008390739361948205, 'optimizer': 'adam', 'whether_dropout': True, 'dropout': 0.2776470335140818, 'num_units': 45, 'activation': 'relu', 'hidden_layer_number': 2}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 966us/step - loss: 0.0112 - val_loss: 0.7272\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 864us/step - loss: 3.4339e-05 - val_loss: 0.8566\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 1.1949e-05 - val_loss: 0.9499\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 8.0320e-06 - val_loss: 1.0360\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 1.9692e-06 - val_loss: 1.0755\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 768us/step - loss: 7.5340e-06 - val_loss: 1.1718\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 1.7252e-06 - val_loss: 1.2146\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 943us/step - loss: 1.8588e-06 - val_loss: 1.2609\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 744us/step - loss: 9.6804e-07 - val_loss: 1.2937\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 757us/step - loss: 1.2874e-06 - val_loss: 1.3421\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 732us/step - loss: 2.5721e-07 - val_loss: 1.3605\n",
      "36/36 [==============================] - 0s 484us/step - loss: 0.7445\n",
      "--- Starting trial: run-74\n",
      "{'learning_rate': 0.002912834185550962, 'optimizer': 'adam', 'whether_dropout': False, 'dropout': 0.21629851931865118, 'num_units': 68, 'activation': 'relu', 'hidden_layer_number': 1}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0181 - val_loss: 0.6033\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 1.7053e-05 - val_loss: 0.6925\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 5.4319e-06 - val_loss: 0.7433\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 2.6808e-06 - val_loss: 0.7794\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 857us/step - loss: 1.5812e-06 - val_loss: 0.8082\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 810us/step - loss: 1.0355e-06 - val_loss: 0.8323\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 733us/step - loss: 7.2193e-07 - val_loss: 0.8531\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 744us/step - loss: 5.2573e-07 - val_loss: 0.8716\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 3.9511e-07 - val_loss: 0.8886\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 915us/step - loss: 3.0412e-07 - val_loss: 0.9044\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 825us/step - loss: 2.3854e-07 - val_loss: 0.9190\n",
      "36/36 [==============================] - 0s 530us/step - loss: 0.6226\n",
      "--- Starting trial: run-75\n",
      "{'learning_rate': 0.04760626394521947, 'optimizer': 'sgd', 'whether_dropout': False, 'dropout': 0.26570884567762854, 'num_units': 27, 'activation': 'relu', 'hidden_layer_number': 1}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 845us/step - loss: 0.0603 - val_loss: 0.2892\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 693us/step - loss: 0.0033 - val_loss: 0.3356\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 0.0017 - val_loss: 0.3628\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 838us/step - loss: 0.0011 - val_loss: 0.3822\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 675us/step - loss: 8.0008e-04 - val_loss: 0.3971\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 617us/step - loss: 6.2991e-04 - val_loss: 0.4092\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 645us/step - loss: 5.1733e-04 - val_loss: 0.4195\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 611us/step - loss: 4.3765e-04 - val_loss: 0.4284\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 624us/step - loss: 3.7827e-04 - val_loss: 0.4362\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 3.3256e-04 - val_loss: 0.4432\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 708us/step - loss: 2.9633e-04 - val_loss: 0.4495\n",
      "36/36 [==============================] - 0s 483us/step - loss: 0.2942\n",
      "--- Starting trial: run-76\n",
      "{'learning_rate': 0.14407034066144414, 'optimizer': 'sgd', 'whether_dropout': False, 'dropout': 0.20828082202840958, 'num_units': 45, 'activation': 'sigmoid', 'hidden_layer_number': 1}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 847us/step - loss: 0.0103 - val_loss: 0.3184\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 867us/step - loss: 0.0012 - val_loss: 0.3530\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 773us/step - loss: 6.9137e-04 - val_loss: 0.3736\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 4.8514e-04 - val_loss: 0.3882\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 820us/step - loss: 3.7317e-04 - val_loss: 0.3996\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 656us/step - loss: 3.0283e-04 - val_loss: 0.4090\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 742us/step - loss: 2.5458e-04 - val_loss: 0.4169\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 641us/step - loss: 2.1944e-04 - val_loss: 0.4237\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 972us/step - loss: 1.9272e-04 - val_loss: 0.4298\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 920us/step - loss: 1.7172e-04 - val_loss: 0.4352\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 688us/step - loss: 1.5479e-04 - val_loss: 0.4401\n",
      "36/36 [==============================] - 0s 520us/step - loss: 0.3168\n",
      "--- Starting trial: run-77\n",
      "{'learning_rate': 0.3030651593027368, 'optimizer': 'adam', 'whether_dropout': False, 'dropout': 0.22270329070470074, 'num_units': 68, 'activation': 'relu', 'hidden_layer_number': 2}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0024 - val_loss: 51.8273\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - val_loss: 51.8273\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - val_loss: 51.8273\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - val_loss: 51.8273\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 819us/step - loss: 0.0000e+00 - val_loss: 51.8273\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 743us/step - loss: 0.0000e+00 - val_loss: 51.8273\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 749us/step - loss: 0.0000e+00 - val_loss: 51.8273\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - val_loss: 51.8273\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 962us/step - loss: 0.0000e+00 - val_loss: 51.8273\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 760us/step - loss: 0.0000e+00 - val_loss: 51.8273\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 748us/step - loss: 0.0000e+00 - val_loss: 51.8273\n",
      "36/36 [==============================] - 0s 490us/step - loss: 53.2739\n",
      "--- Starting trial: run-78\n",
      "{'learning_rate': 0.007685102570948405, 'optimizer': 'adam', 'whether_dropout': True, 'dropout': 0.1246143690333619, 'num_units': 68, 'activation': 'relu', 'hidden_layer_number': 2}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 942us/step - loss: 0.0099 - val_loss: 0.6959\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 8.4648e-06 - val_loss: 0.8106\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 4.4688e-06 - val_loss: 0.9136\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 990us/step - loss: 1.2868e-06 - val_loss: 0.9714\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 826us/step - loss: 6.3527e-07 - val_loss: 1.0171\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 790us/step - loss: 3.6102e-07 - val_loss: 1.0505\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 762us/step - loss: 2.9937e-07 - val_loss: 1.0828\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 1.4950e-07 - val_loss: 1.1056\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 893us/step - loss: 1.9836e-07 - val_loss: 1.1392\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 845us/step - loss: 1.2317e-07 - val_loss: 1.1632\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 759us/step - loss: 1.2333e-07 - val_loss: 1.1977\n",
      "36/36 [==============================] - 0s 510us/step - loss: 0.7199\n",
      "--- Starting trial: run-79\n",
      "{'learning_rate': 0.2944689809180534, 'optimizer': 'sgd', 'whether_dropout': False, 'dropout': 0.18075936851421584, 'num_units': 68, 'activation': 'relu', 'hidden_layer_number': 3}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 881us/step - loss: 0.0079 - val_loss: 0.3968\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 2ms/step - loss: 3.3673e-04 - val_loss: 0.4415\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 1.8317e-04 - val_loss: 0.4676\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 761us/step - loss: 1.2463e-04 - val_loss: 0.4862\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 654us/step - loss: 9.3798e-05 - val_loss: 0.5005\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 659us/step - loss: 7.4961e-05 - val_loss: 0.5123\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 6.2259e-05 - val_loss: 0.5222\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 821us/step - loss: 5.3143e-05 - val_loss: 0.5308\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 729us/step - loss: 4.6282e-05 - val_loss: 0.5384\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 654us/step - loss: 4.0945e-05 - val_loss: 0.5452\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 690us/step - loss: 3.6679e-05 - val_loss: 0.5514\n",
      "36/36 [==============================] - 0s 481us/step - loss: 0.4065\n",
      "--- Starting trial: run-80\n",
      "{'learning_rate': 0.0011910412533411047, 'optimizer': 'sgd', 'whether_dropout': True, 'dropout': 0.27555823774040034, 'num_units': 68, 'activation': 'relu', 'hidden_layer_number': 1}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 958us/step - loss: 0.4964 - val_loss: 0.3954\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.2568 - val_loss: 0.2784\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.1602 - val_loss: 0.2319\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 871us/step - loss: 0.1118 - val_loss: 0.2122\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 678us/step - loss: 0.0832 - val_loss: 0.2043\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 684us/step - loss: 0.0658 - val_loss: 0.2020\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0540 - val_loss: 0.2025\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 809us/step - loss: 0.0445 - val_loss: 0.2045\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 667us/step - loss: 0.0392 - val_loss: 0.2074\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 748us/step - loss: 0.0341 - val_loss: 0.2107\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 657us/step - loss: 0.0300 - val_loss: 0.2143\n",
      "Epoch 12/100\n",
      "285/285 [==============================] - 0s 720us/step - loss: 0.0269 - val_loss: 0.2179\n",
      "Epoch 13/100\n",
      "285/285 [==============================] - 0s 641us/step - loss: 0.0241 - val_loss: 0.2216\n",
      "Epoch 14/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0225 - val_loss: 0.2252\n",
      "Epoch 15/100\n",
      "285/285 [==============================] - 0s 730us/step - loss: 0.0201 - val_loss: 0.2287\n",
      "Epoch 16/100\n",
      "285/285 [==============================] - 0s 811us/step - loss: 0.0185 - val_loss: 0.2322\n",
      "36/36 [==============================] - 0s 451us/step - loss: 0.2057\n",
      "--- Starting trial: run-81\n",
      "{'learning_rate': 0.028051922267271594, 'optimizer': 'adam', 'whether_dropout': False, 'dropout': 0.28809070711492957, 'num_units': 68, 'activation': 'relu', 'hidden_layer_number': 1}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 933us/step - loss: 0.0033 - val_loss: 1.9869\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 946us/step - loss: 4.8533e-13 - val_loss: 1.9869\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 4.8530e-13 - val_loss: 1.9869\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 870us/step - loss: 4.8527e-13 - val_loss: 1.9869\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 865us/step - loss: 4.8523e-13 - val_loss: 1.9869\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 4.8519e-13 - val_loss: 1.9869\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 943us/step - loss: 4.8514e-13 - val_loss: 1.9869\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 759us/step - loss: 4.8510e-13 - val_loss: 1.9869\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 727us/step - loss: 4.8505e-13 - val_loss: 1.9869\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 748us/step - loss: 4.8500e-13 - val_loss: 1.9869\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 730us/step - loss: 4.8496e-13 - val_loss: 1.9869\n",
      "36/36 [==============================] - 0s 486us/step - loss: 2.0486\n",
      "--- Starting trial: run-82\n",
      "{'learning_rate': 0.18100553966044045, 'optimizer': 'adam', 'whether_dropout': False, 'dropout': 0.17530785174793756, 'num_units': 45, 'activation': 'sigmoid', 'hidden_layer_number': 2}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 1s 1ms/step - loss: 0.0043 - val_loss: 1.3645\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 9.2997e-13 - val_loss: 1.3645\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 9.2997e-13 - val_loss: 1.3645\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 784us/step - loss: 9.2997e-13 - val_loss: 1.3645\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 808us/step - loss: 9.2997e-13 - val_loss: 1.3645\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 9.2997e-13 - val_loss: 1.3645\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 9.2997e-13 - val_loss: 1.3645\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 856us/step - loss: 9.2997e-13 - val_loss: 1.3645\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 794us/step - loss: 9.2997e-13 - val_loss: 1.3645\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 806us/step - loss: 9.2997e-13 - val_loss: 1.3645\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 786us/step - loss: 9.2997e-13 - val_loss: 1.3645\n",
      "36/36 [==============================] - 0s 472us/step - loss: 1.3645\n",
      "--- Starting trial: run-83\n",
      "{'learning_rate': 0.347153006760165, 'optimizer': 'sgd', 'whether_dropout': False, 'dropout': 0.1042067590813378, 'num_units': 68, 'activation': 'relu', 'hidden_layer_number': 3}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 1s 1ms/step - loss: 0.0071 - val_loss: 0.4112\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 794us/step - loss: 2.8127e-04 - val_loss: 0.4561\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 898us/step - loss: 1.5331e-04 - val_loss: 0.4824\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 691us/step - loss: 1.0440e-04 - val_loss: 0.5011\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 806us/step - loss: 7.8616e-05 - val_loss: 0.5155\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 960us/step - loss: 6.2855e-05 - val_loss: 0.5274\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 744us/step - loss: 5.2209e-05 - val_loss: 0.5373\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 728us/step - loss: 4.4578e-05 - val_loss: 0.5460\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 646us/step - loss: 3.8832e-05 - val_loss: 0.5536\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 641us/step - loss: 3.4359e-05 - val_loss: 0.5604\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 651us/step - loss: 3.0784e-05 - val_loss: 0.5666\n",
      "36/36 [==============================] - 0s 475us/step - loss: 0.4098\n",
      "--- Starting trial: run-84\n",
      "{'learning_rate': 0.4534920035992712, 'optimizer': 'adam', 'whether_dropout': True, 'dropout': 0.18872263132529427, 'num_units': 27, 'activation': 'relu', 'hidden_layer_number': 1}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 1s 1ms/step - loss: 0.0028 - val_loss: 44.3442\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - val_loss: 44.3442\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 894us/step - loss: 0.0000e+00 - val_loss: 44.3442\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - val_loss: 44.3442\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 944us/step - loss: 0.0000e+00 - val_loss: 44.3442\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 856us/step - loss: 0.0000e+00 - val_loss: 44.3442\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 737us/step - loss: 0.0000e+00 - val_loss: 44.3442\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 743us/step - loss: 0.0000e+00 - val_loss: 44.3442\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 742us/step - loss: 0.0000e+00 - val_loss: 44.3442\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - val_loss: 44.3442\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 841us/step - loss: 0.0000e+00 - val_loss: 44.3442\n",
      "36/36 [==============================] - 0s 586us/step - loss: 45.5327\n",
      "--- Starting trial: run-85\n",
      "{'learning_rate': 0.1338505435786426, 'optimizer': 'adam', 'whether_dropout': True, 'dropout': 0.12309876213553664, 'num_units': 34, 'activation': 'sigmoid', 'hidden_layer_number': 1}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 0.0056 - val_loss: 0.7093\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 5.4550e-07 - val_loss: 0.7102\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 918us/step - loss: 5.3399e-07 - val_loss: 0.7115\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 852us/step - loss: 5.1863e-07 - val_loss: 0.7132\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 5.0078e-07 - val_loss: 0.7153\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 951us/step - loss: 4.7968e-07 - val_loss: 0.7179\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 787us/step - loss: 4.5608e-07 - val_loss: 0.7211\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 776us/step - loss: 4.3005e-07 - val_loss: 0.7247\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 900us/step - loss: 4.0103e-07 - val_loss: 0.7289\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 851us/step - loss: 3.7062e-07 - val_loss: 0.7338\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 786us/step - loss: 3.3757e-07 - val_loss: 0.7393\n",
      "36/36 [==============================] - 0s 485us/step - loss: 0.7098\n",
      "--- Starting trial: run-86\n",
      "{'learning_rate': 0.9001435035411669, 'optimizer': 'adam', 'whether_dropout': True, 'dropout': 0.12353793604418123, 'num_units': 45, 'activation': 'sigmoid', 'hidden_layer_number': 3}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 1s 3ms/step - loss: 0.0036 - val_loss: 6.0553\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 894us/step - loss: 0.0000e+00 - val_loss: 6.0553\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 784us/step - loss: 0.0000e+00 - val_loss: 6.0553\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 764us/step - loss: 0.0000e+00 - val_loss: 6.0553\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - val_loss: 6.0553\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 887us/step - loss: 0.0000e+00 - val_loss: 6.0553\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 850us/step - loss: 0.0000e+00 - val_loss: 6.0553\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 745us/step - loss: 0.0000e+00 - val_loss: 6.0553\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 747us/step - loss: 0.0000e+00 - val_loss: 6.0553\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 779us/step - loss: 0.0000e+00 - val_loss: 6.0553\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - val_loss: 6.0553\n",
      "36/36 [==============================] - 0s 733us/step - loss: 6.0553\n",
      "--- Starting trial: run-87\n",
      "{'learning_rate': 0.05024844635966394, 'optimizer': 'sgd', 'whether_dropout': False, 'dropout': 0.268254191353848, 'num_units': 27, 'activation': 'relu', 'hidden_layer_number': 3}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 846us/step - loss: 0.0375 - val_loss: 0.2926\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 770us/step - loss: 0.0028 - val_loss: 0.3376\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 748us/step - loss: 0.0014 - val_loss: 0.3643\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 886us/step - loss: 9.4836e-04 - val_loss: 0.3832\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 7.0220e-04 - val_loss: 0.3978\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 996us/step - loss: 5.5450e-04 - val_loss: 0.4098\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 799us/step - loss: 4.5619e-04 - val_loss: 0.4199\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 652us/step - loss: 3.8650e-04 - val_loss: 0.4286\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 648us/step - loss: 3.3450e-04 - val_loss: 0.4363\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 2.9435e-04 - val_loss: 0.4432\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 841us/step - loss: 2.6249e-04 - val_loss: 0.4495\n",
      "36/36 [==============================] - 0s 482us/step - loss: 0.2996\n",
      "--- Starting trial: run-88\n",
      "{'learning_rate': 0.2839303405592472, 'optimizer': 'adam', 'whether_dropout': True, 'dropout': 0.10962731204061316, 'num_units': 27, 'activation': 'relu', 'hidden_layer_number': 3}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 932us/step - loss: 0.0028 - val_loss: 16.5755\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 955us/step - loss: 0.0000e+00 - val_loss: 16.5755\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 979us/step - loss: 0.0000e+00 - val_loss: 16.5755\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 839us/step - loss: 0.0000e+00 - val_loss: 16.5755\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 733us/step - loss: 0.0000e+00 - val_loss: 16.5755\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - val_loss: 16.5755\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 810us/step - loss: 0.0000e+00 - val_loss: 16.5755\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 871us/step - loss: 0.0000e+00 - val_loss: 16.5755\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 768us/step - loss: 0.0000e+00 - val_loss: 16.5755\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - val_loss: 16.5755\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 978us/step - loss: 0.0000e+00 - val_loss: 16.5755\n",
      "36/36 [==============================] - 0s 641us/step - loss: 16.9888\n",
      "--- Starting trial: run-89\n",
      "{'learning_rate': 0.965709800584807, 'optimizer': 'sgd', 'whether_dropout': False, 'dropout': 0.15007645964368518, 'num_units': 27, 'activation': 'relu', 'hidden_layer_number': 2}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 874us/step - loss: 0.0047 - val_loss: 0.4702\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 772us/step - loss: 9.5671e-05 - val_loss: 0.5153\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 973us/step - loss: 5.2741e-05 - val_loss: 0.5417\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 875us/step - loss: 3.6126e-05 - val_loss: 0.5606\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 2.7292e-05 - val_loss: 0.57523e-0\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 798us/step - loss: 2.1877e-05 - val_loss: 0.5871\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 705us/step - loss: 1.8208e-05 - val_loss: 0.5972\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 664us/step - loss: 1.5569e-05 - val_loss: 0.6059\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 691us/step - loss: 1.3577e-05 - val_loss: 0.6136\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 947us/step - loss: 1.2024e-05 - val_loss: 0.6205\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 832us/step - loss: 1.0781e-05 - val_loss: 0.6267\n",
      "36/36 [==============================] - 0s 537us/step - loss: 0.4696\n",
      "--- Starting trial: run-90\n",
      "{'learning_rate': 0.1687448670673701, 'optimizer': 'sgd', 'whether_dropout': False, 'dropout': 0.21640169104283274, 'num_units': 34, 'activation': 'sigmoid', 'hidden_layer_number': 3}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 807us/step - loss: 0.0153 - val_loss: 0.3178\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 733us/step - loss: 0.0013 - val_loss: 0.3531\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 780us/step - loss: 7.4533e-04 - val_loss: 0.3740\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 5.2009e-04 - val_loss: 0.3889\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 3.9846e-04 - val_loss: 0.4005\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 763us/step - loss: 3.2239e-04 - val_loss: 0.4100\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 698us/step - loss: 2.7037e-04 - val_loss: 0.4180\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 667us/step - loss: 2.3260e-04 - val_loss: 0.4250\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 2.0391e-04 - val_loss: 0.4311\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 781us/step - loss: 1.8142e-04 - val_loss: 0.4366\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 641us/step - loss: 1.6332e-04 - val_loss: 0.4416\n",
      "36/36 [==============================] - 0s 550us/step - loss: 0.3172\n",
      "--- Starting trial: run-91\n",
      "{'learning_rate': 0.0011298571621346635, 'optimizer': 'adam', 'whether_dropout': False, 'dropout': 0.20712703304455432, 'num_units': 68, 'activation': 'sigmoid', 'hidden_layer_number': 1}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 945us/step - loss: 0.0421 - val_loss: 0.2780\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 951us/step - loss: 0.0027 - val_loss: 0.3298\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.3627\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 6.2744e-04 - val_loss: 0.3871\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 802us/step - loss: 4.0315e-04 - val_loss: 0.4068\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 755us/step - loss: 2.8004e-04 - val_loss: 0.4236\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 741us/step - loss: 2.0460e-04 - val_loss: 0.4383\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 1.5486e-04 - val_loss: 0.4515\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 942us/step - loss: 1.2024e-04 - val_loss: 0.4636\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 759us/step - loss: 9.5223e-05 - val_loss: 0.4748\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 748us/step - loss: 7.6575e-05 - val_loss: 0.4853\n",
      "36/36 [==============================] - 0s 500us/step - loss: 0.2801\n",
      "--- Starting trial: run-92\n",
      "{'learning_rate': 0.001231660891942008, 'optimizer': 'sgd', 'whether_dropout': False, 'dropout': 0.2975306537237523, 'num_units': 34, 'activation': 'relu', 'hidden_layer_number': 3}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 950us/step - loss: 0.6837 - val_loss: 0.5266\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 987us/step - loss: 0.3970 - val_loss: 0.3606\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.2506 - val_loss: 0.2769\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 895us/step - loss: 0.1678 - val_loss: 0.2347\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 686us/step - loss: 0.1188 - val_loss: 0.2138\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 721us/step - loss: 0.0884 - val_loss: 0.2042\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0686 - val_loss: 0.2005\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 748us/step - loss: 0.0550 - val_loss: 0.2000\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 769us/step - loss: 0.0454 - val_loss: 0.2014\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 652us/step - loss: 0.0382 - val_loss: 0.2038\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 650us/step - loss: 0.0328 - val_loss: 0.2068\n",
      "Epoch 12/100\n",
      "285/285 [==============================] - 0s 644us/step - loss: 0.0286 - val_loss: 0.2100\n",
      "Epoch 13/100\n",
      "285/285 [==============================] - 0s 626us/step - loss: 0.0252 - val_loss: 0.2134\n",
      "Epoch 14/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0224 - val_loss: 0.2168\n",
      "Epoch 15/100\n",
      "285/285 [==============================] - 0s 859us/step - loss: 0.0202 - val_loss: 0.2202\n",
      "Epoch 16/100\n",
      "285/285 [==============================] - 0s 635us/step - loss: 0.0183 - val_loss: 0.2236\n",
      "Epoch 17/100\n",
      "285/285 [==============================] - 0s 696us/step - loss: 0.0167 - val_loss: 0.2269\n",
      "Epoch 18/100\n",
      "285/285 [==============================] - 0s 651us/step - loss: 0.0153 - val_loss: 0.2300\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.1991\n",
      "--- Starting trial: run-93\n",
      "{'learning_rate': 0.2517277803940719, 'optimizer': 'sgd', 'whether_dropout': False, 'dropout': 0.12919621682946045, 'num_units': 45, 'activation': 'sigmoid', 'hidden_layer_number': 3}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 908us/step - loss: 0.0078 - val_loss: 0.3420\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 656us/step - loss: 6.8834e-04 - val_loss: 0.3766\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 693us/step - loss: 3.9584e-04 - val_loss: 0.3970\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 742us/step - loss: 2.7767e-04 - val_loss: 0.4115\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 840us/step - loss: 2.1350e-04 - val_loss: 0.4228\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 1.7322e-04 - val_loss: 0.4321\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 786us/step - loss: 1.4560e-04 - val_loss: 0.4399\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 647us/step - loss: 1.2549e-04 - val_loss: 0.4467\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 750us/step - loss: 1.1020e-04 - val_loss: 0.4527\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 661us/step - loss: 9.8184e-05 - val_loss: 0.4580\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 664us/step - loss: 8.8498e-05 - val_loss: 0.4629\n",
      "36/36 [==============================] - 0s 486us/step - loss: 0.3425\n",
      "--- Starting trial: run-94\n",
      "{'learning_rate': 0.058281200572107235, 'optimizer': 'sgd', 'whether_dropout': False, 'dropout': 0.2893370230969769, 'num_units': 68, 'activation': 'relu', 'hidden_layer_number': 3}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 964us/step - loss: 0.0327 - val_loss: 0.3104\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 814us/step - loss: 0.0021 - val_loss: 0.3541\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 917us/step - loss: 0.0011 - val_loss: 0.3799\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 788us/step - loss: 7.6174e-04 - val_loss: 0.3984\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 678us/step - loss: 5.6855e-04 - val_loss: 0.4127\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 4.5167e-04 - val_loss: 0.4244\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 793us/step - loss: 3.7338e-04 - val_loss: 0.4342\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 700us/step - loss: 3.1758e-04 - val_loss: 0.4428\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 702us/step - loss: 2.7573e-04 - val_loss: 0.4504\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 2.4332e-04 - val_loss: 0.4572\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 829us/step - loss: 2.1749e-04 - val_loss: 0.4633\n",
      "36/36 [==============================] - 0s 488us/step - loss: 0.3112\n",
      "--- Starting trial: run-95\n",
      "{'learning_rate': 0.10721576302211444, 'optimizer': 'sgd', 'whether_dropout': True, 'dropout': 0.18444018033469578, 'num_units': 68, 'activation': 'sigmoid', 'hidden_layer_number': 2}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0167 - val_loss: 0.3103\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.3443\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 861us/step - loss: 7.2281e-04 - val_loss: 0.3646\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 5.0830e-04 - val_loss: 0.3790\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 885us/step - loss: 3.9205e-04 - val_loss: 0.3902\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 768us/step - loss: 3.1905e-04 - val_loss: 0.3994\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 654us/step - loss: 2.6880e-04 - val_loss: 0.4071\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 2.3165e-04 - val_loss: 0.4139\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 2.0408e-04 - val_loss: 0.4198\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 690us/step - loss: 1.8212e-04 - val_loss: 0.4251\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 652us/step - loss: 1.6446e-04 - val_loss: 0.4299\n",
      "36/36 [==============================] - 0s 456us/step - loss: 0.3098\n",
      "--- Starting trial: run-96\n",
      "{'learning_rate': 0.022685877806136494, 'optimizer': 'adam', 'whether_dropout': True, 'dropout': 0.2947696485576423, 'num_units': 27, 'activation': 'relu', 'hidden_layer_number': 2}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 933us/step - loss: 0.0045 - val_loss: 1.0032\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 6.6502e-06 - val_loss: 1.0390\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 3.8533e-06 - val_loss: 1.0699\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 874us/step - loss: 7.5895e-06 - val_loss: 1.1264\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 770us/step - loss: 1.5320e-06 - val_loss: 1.1506\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 7.5363e-06 - val_loss: 1.2126\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 942us/step - loss: 4.0066e-06 - val_loss: 1.2572\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 788us/step - loss: 1.9318e-06 - val_loss: 1.2863\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 856us/step - loss: 1.2274e-06 - val_loss: 1.3096\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 740us/step - loss: 1.9102e-06 - val_loss: 1.3505\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 754us/step - loss: 3.7779e-07 - val_loss: 1.3666\n",
      "36/36 [==============================] - 0s 537us/step - loss: 1.0382\n",
      "--- Starting trial: run-97\n",
      "{'learning_rate': 0.14168758082543087, 'optimizer': 'adam', 'whether_dropout': True, 'dropout': 0.21734101631602087, 'num_units': 68, 'activation': 'sigmoid', 'hidden_layer_number': 2}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 1s 1ms/step - loss: 0.0026 - val_loss: 1.6216\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 969us/step - loss: 5.0296e-15 - val_loss: 1.6216\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 920us/step - loss: 5.0338e-15 - val_loss: 1.6216\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 788us/step - loss: 5.0350e-15 - val_loss: 1.6216\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 762us/step - loss: 5.0309e-15 - val_loss: 1.6216\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 788us/step - loss: 5.0372e-15 - val_loss: 1.6216\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 752us/step - loss: 5.0322e-15 - val_loss: 1.6216\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 795us/step - loss: 5.0326e-15 - val_loss: 1.6216\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 5.0318e-15 - val_loss: 1.6216\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 5.0368e-15 - val_loss: 1.6216\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 890us/step - loss: 5.0303e-15 - val_loss: 1.6216\n",
      "36/36 [==============================] - 0s 475us/step - loss: 1.6216\n",
      "--- Starting trial: run-98\n",
      "{'learning_rate': 0.005986533422459209, 'optimizer': 'sgd', 'whether_dropout': False, 'dropout': 0.2668652330670327, 'num_units': 27, 'activation': 'sigmoid', 'hidden_layer_number': 1}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 1s 1ms/step - loss: 0.4001 - val_loss: 0.2069\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 960us/step - loss: 0.0558 - val_loss: 0.2007\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 828us/step - loss: 0.0299 - val_loss: 0.2099\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 709us/step - loss: 0.0203 - val_loss: 0.2194\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 641us/step - loss: 0.0153 - val_loss: 0.2279\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 855us/step - loss: 0.0123 - val_loss: 0.2353\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0102 - val_loss: 0.2419\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 806us/step - loss: 0.0088 - val_loss: 0.2478\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 741us/step - loss: 0.0077 - val_loss: 0.2532\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 966us/step - loss: 0.0068 - val_loss: 0.2580\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 885us/step - loss: 0.0061 - val_loss: 0.2625\n",
      "Epoch 12/100\n",
      "285/285 [==============================] - 0s 744us/step - loss: 0.0055 - val_loss: 0.2666\n",
      "36/36 [==============================] - 0s 470us/step - loss: 0.2004\n",
      "--- Starting trial: run-99\n",
      "{'learning_rate': 0.0012158497974410272, 'optimizer': 'adam', 'whether_dropout': False, 'dropout': 0.17830298939672734, 'num_units': 68, 'activation': 'relu', 'hidden_layer_number': 1}\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 944us/step - loss: 0.0454 - val_loss: 0.4131\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 933us/step - loss: 1.8040e-04 - val_loss: 0.5645\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 1.9914e-05 - val_loss: 0.6389\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 7.2141e-06 - val_loss: 0.6849\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 3.7084e-06 - val_loss: 0.7190\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 888us/step - loss: 2.2461e-06 - val_loss: 0.7465\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 828us/step - loss: 1.4865e-06 - val_loss: 0.7697\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 751us/step - loss: 1.0432e-06 - val_loss: 0.7900\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 7.6252e-07 - val_loss: 0.8085\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 975us/step - loss: 5.7463e-07 - val_loss: 0.8255\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 762us/step - loss: 4.4295e-07 - val_loss: 0.8411\n",
      "36/36 [==============================] - 0s 491us/step - loss: 0.4262\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(192)\n",
    "\n",
    "# 100 total sessions\n",
    "total_sessions = 100 #FIXME: change this to the number of sessions you want to run, and fix the issue in the metrics\n",
    "\n",
    "for session in range(total_sessions):\n",
    "    \n",
    "    # Create hyperparameters randomly\n",
    "    whether_dropout = HP_WHETHER_DROPOUT.domain.sample_uniform()\n",
    "    dropout_rate = HP_DROPOUT.domain.sample_uniform()\n",
    "    num_units = HP_NUM_UNITS.domain.sample_uniform()\n",
    "    optimizer = HP_OPTIMIZER.domain.sample_uniform()\n",
    "    activation = HP_ACTIVATION.domain.sample_uniform()\n",
    "    hidden_layer_number = HP_HIDDEN_LAYER_NUMBER.domain.sample_uniform()\n",
    "    \n",
    "    \n",
    "    r = -3*np.random.rand()\n",
    "    learning_rate = 10.0**r\n",
    "    \n",
    "    # Create a dictionary of hyperparameters\n",
    "    hparams = { HP_LEARNING_RATE: learning_rate,\n",
    "                HP_OPTIMIZER: optimizer,\n",
    "                HP_WHETHER_DROPOUT: whether_dropout,\n",
    "                HP_DROPOUT: dropout_rate,\n",
    "                HP_NUM_UNITS: num_units,\n",
    "                HP_ACTIVATION: activation,\n",
    "                HP_HIDDEN_LAYER_NUMBER: hidden_layer_number}\n",
    "    \n",
    "    # train the model with the chosen parameters\n",
    "    run_name = \"run-%d\" % session\n",
    "    print('--- Starting trial: %s' % run_name)\n",
    "    print({h.name: hparams[h] for h in hparams})\n",
    "    run('logs100/hparam_tuning/' + run_name, hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-c87406efc8322f72\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-c87406efc8322f72\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6009;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4\n",
    "### Question\n",
    "The file \"SMOTE.ipynb\" explains the process in detail and shows how to change the dataset with an example. You can copy and adjust the code to make it work within your analysis. You can adjust the \"sampling_strategy\" parameters as you see fit, particularly if\n",
    "you want to fine-tune your model in part 5.\n",
    "\n",
    "### Principle\n",
    "In this part, we are going to try both oversampling and undersampling.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the procedure to process the data\n",
    "1. Split the raw data into train and test\n",
    "2. Fit the MinMaxScaler to train data and then apply the model to test data\n",
    "3. Oversample and undersample the train data\n",
    "4. Split the train data into train and validation data\n",
    "5. Show the data distribution before and after oversampling and undersampling\n",
    "\n",
    "The reason to do so is that we want to make sure that we want to make sure the training data and validation data is similar. And when we test our model, we tend to use real test data instead of the simulated test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Split the raw data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=192,test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Fit the MinMaxScaler to train data and then apply the model to test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Oversample and undersample the train data\n",
    "We will successively try to oversample the minority class to 10%, 30%,50% of the size of all datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oversampling\n",
    "# k_neighbors set to 20 to make sure that the result is more general \n",
    "over = imblearn.over_sampling.SMOTE(sampling_strategy=0.1, random_state = 483, k_neighbors=20)  \n",
    "X_over_synth_10, y_over_synth_10 = over.fit_resample(X_train, y_train)\n",
    "over = imblearn.over_sampling.SMOTE(sampling_strategy=0.5, random_state = 483, k_neighbors=20)\n",
    "X_over_synth_30, y_over_synth_30 = over.fit_resample(X_train, y_train)\n",
    "over = imblearn.over_sampling.SMOTE(sampling_strategy=1, random_state = 483, k_neighbors=20)\n",
    "X_over_synth_50, y_over_synth_50 = over.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of 1 in y_over_synth10: 0.09090909090909091\n",
      "Percentage of 1 in y_over_synth30: 0.3333333333333333\n",
      "Percentage of 1 in y_over_synth50: 0.5\n"
     ]
    }
   ],
   "source": [
    "print(\"Percentage of 1 in y_over_synth10:\", Counter(y_over_synth_10)[1]/len(y_over_synth_10))\n",
    "print(\"Percentage of 1 in y_over_synth30:\", Counter(y_over_synth_30)[1]/len(y_over_synth_30))\n",
    "print(\"Percentage of 1 in y_over_synth50:\", Counter(y_over_synth_50)[1]/len(y_over_synth_50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Undersampling\n",
    "We will successively try to undersample the minority class to 10%, 30%,50% of the size of majority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "under = imblearn.under_sampling.RandomUnderSampler(sampling_strategy=0.1, random_state = 483)  \n",
    "X_under_synth_10, y_under_synth_10 = under.fit_resample(X_train, y_train)\n",
    "under = imblearn.under_sampling.RandomUnderSampler(sampling_strategy=0.5, random_state = 483)\n",
    "X_under_synth_30, y_under_synth_30 = under.fit_resample(X_train, y_train)\n",
    "under = imblearn.under_sampling.RandomUnderSampler(sampling_strategy=1, random_state = 483)\n",
    "X_under_synth_50, y_under_synth_50 = under.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of 1 in y_under_synth_10: 0.09090909090909091\n",
      "Percentage of 1 in y_under_synth_30: 0.3333333333333333\n",
      "Percentage of 1 in y_under_synth_50: 0.5\n"
     ]
    }
   ],
   "source": [
    "print(\"Percentage of 1 in y_under_synth_10:\", Counter(y_under_synth_10)[1]/len(y_under_synth_10))\n",
    "print(\"Percentage of 1 in y_under_synth_30:\", Counter(y_under_synth_30)[1]/len(y_under_synth_30))\n",
    "print(\"Percentage of 1 in y_under_synth_50:\", Counter(y_under_synth_50)[1]/len(y_under_synth_50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fbf9b5b8fd0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABrCElEQVR4nO2dd3wU1drHf2e2ZtNDCIGQEHoJKCUCgg0uICKIIqjoLfbey6uCr9crekHFhl7hRa5yLahcVKSJiiBVkNBCCC1ACoSElE3fOnPePzYZdmZ3Z3aTTbJJzvfz8WMmc3bm2XDmmec85ymEUgoGg8FgtH241haAwWAwGMGBKXQGg8FoJzCFzmAwGO0EptAZDAajncAUOoPBYLQTtK114/j4eJqamtpat2e0c/bt21dKKe3cGvdmc5vRnCjN7VZT6KmpqcjIyGit2zPaOYSQPD/GTAbwPgANgGWU0gWy888BuKP+UAtgIIDOlNJypeuyuc1oTpTmNnO5MDokhBANgH8BuA7AIACzCSGD3MdQSt+ilA6llA4F8CKArWrKnMFoTZhCZ3RURgLIoZSeppTaAXwNYLrC+NkAvmoRyRiMRsIUOqOjkgSgwO34bP3vPCCEmABMBvCtr4sRQu4nhGQQQjJKSkqCKiiD4S9MoTM6KsTL73zVwZgGYKeSu4VSupRSmk4pTe/cuVX2YhkMptAZHZazAJLdjrsDKPQx9jYwdwujDaCq0AkhnxBCLhBCsnycJ4SQRYSQHEJIJiFkePDFZDCCzl4AfQkhPQkheriU9hr5IEJINICrAfzQwvIxGAHjT9jicgAfAvjMx/nrAPSt/28UgMX1/w+YoqIiLF++HHV1dZg1axaGDBnSmMswGKpQSp2EkEcB/ARX2OInlNIjhJAH688vqR96E4CfKaW1LSVbVVUVPv30U5SUlGDixIm4+uqrW+rWjDaOqoVOKd0GQClUazqAz6iL3QBiCCFdGyPMhx9+iDNnzqC4uBj/93//h5qamsZchsHwC0rpBkppP0ppb0rp6/W/W+KmzEEpXU4pva0l5frPf/6DY8eOoaSkBKtWrUJ+fn5L3p7RhgmGDz2QaAHFSIDKykr3saiurg6CeAxG26K0tBSCIAAAOI5DeTkLfWf4RzAUut/RAmqRAOPHj4der4fBYEBycjK6dOkSBPEYjLbF5MmTodPpYDQaER4ejgEDBrS2SIw2QjBS/wOJFlDkpptuwtChQ2GxWNC/f39wHAvCYXQ8Lr/8cqSkpKC8vBx9+/aF0WhsbZEYbYRgKPQ1AB4lhHwN12ZoJaX0fGMv1rNnzyCIxGC0bZKSkpCU5NVzyWD4RFWhE0K+AnANgHhCyFkAfwegA8RIgA0ApgDIAVAH4K7mEpbBYDAYvlFV6JTS2SrnKYBHgiYRg8FgMBoFc1IzGAxGO4EpdAajjVNVVYWtW7fi4MGDcC2YGR2VVmtwwWAwmo7FYsG8efNgsVhACMG4ceMwY8aM1haL0UowC53BaMPk5eXBbrfD4XDAbrdj9+7drS0SoxVhCp3BaMMkJCSIWaUajQbJyckqn2C0Z5jLhcFow8TFxeGRRx7Bxo0bERcXh5kzZ7a2SIxWhCl0BqONM2DAAFYegAEgxBT6mTNn8PHHH8NqteLmm2/G2LFjW1skBoPBaDOElA99yZIlKCsrQ21tLb766itJ9UUGg8FgKBNSCt1isUiOrVZrK0nCYDAYbY+QUujTp0+HTqeDXq9HWloaEhISWlskBoPBaDOElA/9T3/6Ey699FLYbDZ069YNhHgrtc5gMBgMb4SUQgeA+Pj41haBwWAw2iQh5XJhMBgMRuNhCp3RYSGETCaEHCeE5BBCXvAx5hpCyEFCyBFCyNaWlpHBCISQc7kwGC0BIUQD4F8AJsLVRnEvIWQNpTTbbUwMgI8ATKaU5hNC2C49I6RhFjqjozISQA6l9DSl1A7gawDTZWNuB/AdpTQfACilF1pYRgYjIJhCZ3RUkgAUuB2frf+dO/0AxBJCfiOE7COE/NXXxQgh9xNCMgghGSUlJc0gLoOhDlPojI6Kt5hYeXcILYARAK4HcC2A/yWE9PN2MUrpUkppOqU0vXPnzsGVlMHwE+ZDZ3RUzgJwrzXbHUChlzGllNJaALWEkG0ALgVwomVEZDACg1nojI7KXgB9CSE9CSF6ALcBWCMb8wOAKwkhWkKICcAoAEdbWE4Gw2+Yhc7okFBKnYSQRwH8BEAD4BNK6RFCyIP155dQSo8SQjYCyAQgAFhGKc1qPambjo234ce8H1FcV4yRXUZiWOdhrS0SI4gwhc7osFBKNwDYIPvdEtnxWwDeakm5mpONeRtxuOwweMpjQ94GxBvjkRzJuhy1F5jLhcFoIaxWq9gurrUothSDp7x4XGYta0VpGMGGWegMRjMjCAKWLl2KQ4cOwWAw4Mknn0RqamqryDIyYSTW560HAGiJFr2je7eKHIzmgSl0BqOZOXbsGLKzsyEIAiwWC1asWIE5c+a0iixDOw9FfFg8yqxl6BXVC5H6yFaRg9E8MIXOYHQwukd0R/eI7q0tBqMZYD50BqOZGTBgANLS0sBxHMLCwnDHHXe0tkiMdgqz0BmMZobjODzwwAOw2WzQ6XTgOGZHMZoHptAZjBbCYDC0tgiMdg4zFRgMBqOd4JdCV2sEQAiJJoSsJYQcqm8EcFfwRWUwGAyGEqoK3a0RwHUABgGYTQgZJBv2CIBsSumlAK4B8HZ9fQwGg8FgtBD+WOj+NAKgACIJIQRABIByAM6gSspgMBgMRfxR6P40AvgQwEC4yo8eBvAEpdQjx5k1AWAwGIzmwx+F7k8jgGsBHATQDcBQAB8SQqI8PsSaADAYrU52djY2b96M0tLS1haFEWT8Uej+NAK4C67ei5RSmgPgDIABwRGRwWAEi61bt2Lx4sX49ttvMW/ePJSXl7e2SIwg4o9C96cRQD6APwEAIaQLgP4ATjdGoLKyMhQWFoJS+SKAwWA0lZ07d8Jut8PpdEIQBBw/fry1RWIEEdXEIn8aAQCYB2A5IeQwXC6a5ymlAa/nNm/ejO+++w6EEKSlpeGBBx6Aa5+VwWAEg549e6KwsBAOhwMA0K1bt1aWiBFM/MoUVWsEQCktBDCpqcKsXr1anGhZWVm4cOECunTp0tTLMhiMembOnAm9Xo+CggJcffXV6NGjR2uLxAgiIZX6HxYWBpvNJh4bjcZWlIbBaDtYrVbodDpoNBrFcTqdDjfffHMLScVoaUIq9f/BBx9EXFwcTCYTbrvtNkRHR7e2SAxGSEMpxSeffIKnnnoKTz75JE6cONHaIjFakZCy0Hv27In58+e3thgMRqtisVjwzTffoLi4GJMmTcKwYb4bOZ8+fRp//PEHKKWw2+34+OOP8dZb7aYFKiNAQspCZzBaEj9qFF1DCKkkhBys/+/llpDrs88+wx9//IHTp0/jk08+QWGhPEr4IvKIsJqampYQkRGihJSFzmC0FG41iibClWuxlxCyhlKaLRu6nVI6tan3u3DhAjIyMhAfH4/LLrtMMXrr3Llz4HlXI2eO43DhwgWf0Sg9evQAx3Fi8+m4uLimispowzALndFR8adGUVCoqKjA66+/jrVr1+Lzzz/HDz/8oDj+qquugl6vh16vh06nQ58+fXyOTUlJwfXXXw+dToe4uDg8/PDDwRaf0YYIOQvd4XCA53kW4cJobrzVKBrlZdzlhJBDcGVHP0spPRLojc6cOQMAEAQBdrsd+/btw4033uhz/IQJE5CcnIzS0lIMGTIEERERitefOnUqpk5t8iKC0Q4IKYW+f/9+/Pvf/walFOPHj8fMmTNbWyRG+8WfGkX7AfSglNYQQqYAWA2gr9eLEXI/gPsBl9XsTvfu3cX8CkIIUlNTVYXr378/+vfvrzqOwXAnpFwun3/+OZxOJ3iex2+//caKBzGaE9UaRZTSKkppTf3PGwDoCCHx3i6mVHjOYrFIfOa1tbXB+QZtnN27d+Ppp5/GCy+8gFOnTrW2OO2CkFLo7pOeUsrS/hnNiWqNIkJIYn2NfxBCRsL1vJQFeqPy8nIx4YdSirKygC/R7qipqcHnn3+O2tpamM1mLF68uLVFaheElEK/8847xa7okyZNQqdOnVpbJEY7hVLqBNBQo+gogJUNNYoa6hQBmAkgq96HvgjAbbQRVeP69++P8PBwGI1G6PV6XHvttcH6Gm0Wq9UqMdisVmsrStN+IK1V1TA9PZ1mZGR4/F4QBPA8D51O1wpSMdoLhJB9lNL01ri3t7lttVpx4sQJxMXFoXv37q0hVkhBKcWyZcuQmZkJSimmTZvGXnR+ojS3Q2pTFHC5XbTakBOLwWgSv/76K3799VfEx8eLJS46MoQQ3HvvvSgsLIRerwdreBMcQsrlcvToUTz11FN45JFH8NNPP7W2OAxGUMjJycGaNWtQW1uLvLw8fPjhh60tUkhACEFSUhJT5kEkpBT6smXLYLFYwPM81qxZA7PZ3NoiMRhNZufOnZJjpVT+lqC6uhr5+flwOlkf9/ZGSPk2LBaL+LPT6YTFYkFsbKz4O57nsXXrVpSUlGDMmDFITk72dhkGI6SIiYmRHHNc69lRx48fx4cffghCCGJiYjBnzhyWxNeOCCkL3X2D1tukX7lyJb777jts3rwZb731FuuHyGgTXHfddRKl2ZoJcz/88APsdjtsNhsqKipw6NChVpOFEXxCykLv0aMH8vLyIAgCDAaDx8bRkSNHJBl3+fn5HX5ziRH66PV6vPvuu8jNzUV8fDyioqJaTZbIyEhJMa/w8PBWk4URfEJKoT/66KP44YcfUFdXhylTpngsBdPS0rBr1y7Y7XZQSj1SrNsCdrsdW7duhd1ux5VXXtmqDzej5eA4Dr169WptMTB79myYzWYUFxdjzJgxSEtLa22RGEEkpBR6aWkpjhw5AqvVirS0NCQlJUnO33LLLUhMTBR96G3ROv/www9x6tQpUEqxfft2vPbaayxMswNgs9lw6tQpxMXFITExsdXkaPCbM9onIaVJFi9ejIqKCgDAihUrkJaWJmlDp9FoMG7cuFaSLjicPHlSXO42pD2zsK32jdVqxbx581BTUwOe5/GXv/wFo0Z5K+zoorKyEsuWLUNpaSkmTpyI8ePHK16/trYWmZmZiI6OxsCBA1nJjA5MSG2Kuke5EEIalQ5ssVhQWFgo+tpDjZSUFGg0GhBCYDAYPCIgGO2P48ePo7q6GlarFQ6HAxs2bFAc/5///Ac5OTkoLy/H999/j9zcXJ9jG14WK1aswJIlS7Bu3bogS89oS4SUhX711Vfj559/BgB07doVCQkJAX2+oKAACxcuBKUUkZGRmDNnTsht+jz++OP48ccfYbPZcO2117ISBx2A6OhoMYKL4zjVGkVlZWXiKo7jOFRWVvocm5ubC4vFArvdDgDYvn07pk2bFiTJGW2NkLLQ//jjD/Hnc+fOobq6OqDPr1u3DlarFTabDZWVlZLrhQrh4eGYOXMm7rjjDsTHe63EymhnpKamYtSoUdBqtYiMjMStt96qOH7KlCnQ6XQwGo2IjIxUrIseHx8vKn+NRuOzVR2jYxBSFrq7JeJ0OmE2mwOKAjGZTGJIFiGEJUwwQoLCwkLs2bMHTqcTtbW1WLNmDe677z6f40eNGoUePXrAbDajd+/e0Ov1PsfGx8fj6quvxpYtWxAWFsaawnRwQspCd9/M4Tgu4OiPGTNmIDk5GTqdDkOGDMHIkSODLSKDETDFxcVi02en06noEwdcCXbnzp1Dfn4+qqqqVK/922+/wel0oqamBitWrAiW2Iw2SEhZ6P369cOxY8cAAEajMWAfeoPfnMEIJTiOExU6ANUaKmvXrsUvv/wCnufx448/4h//+Ick2sudiooKaDQaOBwOv5pnCIKArVu3orCwEKNHj0bv3r0D/0KMkCWkLPSioiLxZ7vdjrq6ulaUhsEIDmfPnpUcq7Wg27t3L+x2O3ieB6UUp0+f9jm2V69eiImJgcFg8Kt5xtq1a/Hdd99h27ZteO+991q9UBgjuISUhe4tbFFumdTU1KCqqgqJiYmtWuSIwfCX7t27gxAiRrr4srYb6N27N8rKysDzPHieV9zo1Ol0mDt3Lk6cOIGoqCjV7OnDhw+LETE8zyM3N5dtpLYjQkqh33jjjfjuu+9ACMGgQYM8XC6ZmZlYsmQJKKVITEzE3LlzA/azZ2Zm4vDhwxgwYABGjBgRTPEZDK8MGTIERqNRNFjUrOgePXpgz5494DgOBoNBNTBAr9dj8ODBfsniXgCP53mx1ymjfeCXiUsImUwIOU4IySGEvOBjzDWEkIOEkCOEkK2NEWbkyJG49NJL0bt3b0ydOtUj4+3TTz8Fz/MQBAGFhYXYu3ev5HxVVRXmzZuHhx9+GEuWLJH4LQEgKysLH3/8MbZt24bly5d7fJ7BaA42bdokWX1+8803iuO3bNkCQRAgCAKcTieOHz8eNFncDSCdTieGPDLaB6oKnRCiAfAvANcBGARgNiFkkGxMDICPANxAKU0DMKsxwnzwwQc4cOAAjh49ioULF0oeAgDiUrEBecLF999/j/Pnz4PneRw5csQjDv3EiRPiNex2O7KzsxsjJoMREGfOnJEcq22KdunSRbScBUEIarP0iRMnQq/Xw2g0wmg0+m3ZM9oG/vgrRgLIoZSeBgBCyNcApgNw14a3A/iOUpoPAJTSC40R5ty5c6JVTSmF2WxGWFiYeH7EiBHYs2cPAFfkgLweRkO3o4bPy0sH9OvXD7/88gsEQQDHcRgwYEBjxGS0EwghkwG8D0ADYBmldIGPcZcB2A3gVkrpqkDvM3HiROzfv188VvNZ/+1vf8Pnn3+OCxcuYNKkSaqNXA4ePIj169cjNjYWf/7znxVdNOnp6ejatSuKi4vRr18/REREKF47Ozsbq1evRmRkJO644442WRAv2AiCINZk6t+/f0jt5fmj0JMAFLgdnwUgryzUD4COEPIbgEgA71NKP5NfiBByP4D7AXjdvElISMC5c+cAuP5o8kzKO++8E7GxsTh//jwmT54s6WYEANdffz2ysrLgdDphMpk8FH55ebkk8Yg1yOi4uK08J8I1p/cSQtZQSrO9jHsDQKOb3Pbq1QsPPfQQ1qxZg27duuGvf/2r4viIiAg89NBDfl27pKQEy5Ytg8PhwNmzZ7Fs2TI8/fTTip9JSkryqGTqjaqqKixevBh2ux2EECxevBhz5871S672zPLly3Hw4EEAQP/+/fHII4+0rkBu+KPQvZVuo7JjLYARAP4EIAzA74SQ3ZTSE5IPUboUwFIASE9Pl18DJSUlkuPy8nJJqdFdu3bh119/BcdxOHv2LF5++WVJNui+ffvEolxVVVXIz8+XWOHl5eXicpfneZSWlqp8dUY7xp+VJwA8BuBbAJc15WZDhw7F0KFD/R7P8zysVqtqLaLy8nIxDl0QBBQXFzdFTAkVFRXiPhal1OP57Ig4HA788ccf4ubykSNHUFtbGzI1o/xZK5wF4L7m6w5AHrx6FsBGSmktpbQUwDYAlwYqjPuOu8PhgMlkkpxft24dHA4HbDYbzGazmITUwK5du8SfKaXYtm2b5Pwll1wiOR46bKiHDIWFhdiwYQP2798viQhgtDu8rTwlZishJAnATQCWNPVmx44dw/vvv4+VK1eqVgI9c+YMnn76aTz33HP417/+pbhxmZqaivDwcDEO/ZprrmmqqCLdunVDXFwcDAYDDAYDrrzyyqBdu62i1WolbmCdTgeDwdCKEknxx0LfC6AvIaQngHMAboPLZ+7ODwA+JIRoAejhcsm8G6gwNptNclxTUyPxB7onGgmC4LEpGhUVJfmdvM74r3t/da03KAACbNqzCUMGDxHPX7hwAQsWLIDdbodOp0NZWRkmTpwY6NdgtA38WXm+B+B5SimvVmNcyZ1YWFiIxd8vRviQcJyrPIdzS87hqcee8nmtFStWiPs/x44dw7FjxzBo0CCvYw0GA/73f/8XR44cQXR0NPr27asoZyBotVq8+OKLyMrKQnh4uGKRsI4CIQRPPfUUvvjiCwiCgNmzZ4dUgxpVSSilTkLIo3D5EDUAPqGUHiGEPFh/fgml9CghZCOATAACXBtMWYEKI7dEKioqJBtI8phZ+TKnS5cuKCgokBy7Y6XWiwodgA3SF8jJkydBKQWlFHa7Hfv27WMKvf3iz8ozHcDX9co8HsAUQoiTUrpafjEld+LW/VsRfVU0OB0HXScdinXKbhH3KqN2u13Vog8LC0N6errimMZiMBhYvoaMlJSUkC0x4terhVK6AcAG2e+WyI7fAvBWU4Rxb14LwGNHXf4mlCt494mv1Wo9olxuvPZGHD98HI5SB7TRWsy4fobkvLtlpdPpgmrtMEIO1ZUnpbRnw8+EkOUA1nlT5mpEd40G6iNwiYZAH+e7eiLgGY6bn5+PSy8N2IPJ6ICEzloBLiXa4HbRarUe4UByS0Xu4548eTKOHTsGQgj0er2H1RLFRcHkNKFWVwuD04A4rfSFkZycjIceegg7duxAcnIyJk2aFKyvxggx/Fl5Bute3U3dQWspKE9BQUEKlN038pWqWsGt/Px8bN68GXFxcZg8ebJiud1AoZSitLRUrM3OCG1CSqF36tRJUixIXvNCnliUn5+P4cOHi8e9evXCa6+9hpKSEiQlJXnUQ9+2bRuqq6ohCAJ4J49ffvkFs2fPlowZNGiQT38lo33hz8rT7fd3NvY+J3NPgkQREA0BeMCqU26t2LlzZ0lEidJmZGVlJRYuXAibzQatVouioiLcf//9jRVVAqUUS5cuxeHDh0EpxV/+8heMHj06KNdmNA+hExEP16ZkAxzHeYQVymNnhw0b5nGNqKgo9O7d22tzC71eL1r9DXUyGIzmxtjZKO7bEA2BIVF53rmvTDmOU6w6WlhYKIYWOp1O5OTkNF1gt2tnZWXB4XDA6XRi5cqVQbs2o3kIKYXuHqbocDg8EofcXSBxcXFeM+jKysqQkZHh9SEYN24cevXqBY7jkJycjMmTJwdRegbDOxEkAkRHxA13WJTHu7tYBEGQGDpykpOTwXGc6GaUh+Y2Bb1eL3FrMgMo9Akpl4u7EuY4DhUVFRIl/8UXX4g/l5eXY/v27bj66qvF3/3xxx/497//LX7+lVdekUS66PV6PPPMM835FRgMD2g4BSoAwrksaS5K2Y6S13qR14JxJyIiAnPnzsXvv/+O2NhYjBkzpsnyNtC5c2fccMMNWLNmDcLCwvxy5djtdlRVVSEuLi6kUuLVcDqdqKioQExMTEiFIQZKSEnuvhnkrbSnfKLLGwX897//lVxr9erVeOCBByRjGmq8GI1Gj2qODEZzQLVUjHqnlIJoleedTqeTBACo1TiPj4/HtGnT/JbHbDajrKwMKSkpqhuokyZN8js44Ny5c1i4cCEcDgfi4+PxwgsvtIm+vmazGfPnz4fFYkFYWBjmzJmDmJiY1harUYTUK1S+uy+PanGvI20wGDBu3DjJeXm5XPnna2pq8Oyzz+LJJ5/EU089BbPZHAyxGQxFzp48C9RPTUII7NV2xfFXX301dPE6GFON0Bg1GDt2rOL4vXv34pVXXsH777+PiooKxbHZ2dl4+eWX8cEHH+Af//iHR0XTprBmzRrU1dXB4XCgtLTUo9ppqLJ582ZUV1fDbrejuroamzdvbm2RGk1IKXQ57i3pAOCGG27A3Llz8eCDD+LNN9+UpOACQNeuXSXH8jjyzz//HDU1NQBclRk//vjjZpCawZAS7YyGs84p+tCr91crjj9ccRhxU+IQfWU0Ot3YCdknfZd5vnDhAv7zn//g/PnzOHbsGJYtW6Z47bVr18Jut8NqtaK6uhqHDh1q1HfyhnvQASEEOp1OcXxdXR22bNmCXbt2eRhjLYlerxdX6xzHBTXss6UJaYUu92U5HA4cOHAAGRkZHn0aAZdlo9frodVqodfrMWTIEMn5hkqODTS2kFFDr0cGwx9OVZ2CNlIrKo2okcodiIRUAZyOA6fnQHQEp8pP+RxrNpvF66ptoAJATEyMxLet1g0pEGbMmIEuXbqAEIKBAwdi5MiRPsfyPI/58+fj22+/xVdffYWlS5cGTY5AmTBhAnr06AFCCFJSUjBhwoRWk6WphJQPXY7c//bll18iIyMDDocDmZmZePnllyX1WkaMGIFffvkFRUVFGDZsmEfd6V69eknie9XqTHvjm2++wZYtW2A0GvHYY481qmt6Q912tVrUjPZBlaZK/JkQAk24cts3Z4UTmgiNK26dALTOt/EQHx8vyc9QU9CzZs3CmTNnUFVVhbS0NAwcONDPb6FObGwsXnnlFb/GlpaWoqKiQnSLHj58OGhyBEpYWBief/75Vrt/MAlpC10eJpWTkyNOAEKIh8X9xhtvID8/H3a7HXv27MG6desk56dOnQqDwQCtVgudToebb77Z455OpxMFBQWia8adgoIC7NixA5RSWCwWLF++PODvtHPnTjz77LP4n//5H6xaFXCvBEYbxFhx0TChlMJZodyxyHnACWu+FY4yByp3VmJQsu9Et9OnT0uOz58/r3jtX375BTU1NeB5HllZWZLaR944cuQIXn/9dSxatCio/QPco0k4jpOUyWY0npBS6PKoFrlP3L0Yl81m82iAkZeXJzn+7bffJMcmk0ns0ygIgkdxL6vVildffRVvvfUW5syZg5MnT0rO8zwviYxpjN/v66+/htPpBM/z2LJli+omFqPtk9gjEZR3WdmEENWnzsgZUbG5AqWrS8HnK7v35KGBapFbp06dUjSK3KmsrMSSJUuQn5+P7OxsfPTRR8qCB4DBYMCzzz6LYcOGYdSoUXjiiSeCdu2OTEgpdLmC3Lhxo+RYPvny8/MVrycvFfDuu++Kk5nnebz1lrSW2MGDB2E2m2Gz2WCz2fDDDz9Izvfo0QOXXHIJNBoN9Ho97rjjDvUvJUP+ALalWF1G40jpmiLGoFNKwQnK/+buPUQdDgcSEhJ8jh04cCBMJhMIIeA4DldccYXitUePHg2t1uXPp5SiX79+PsdWVlZKGlz40xCG53nU1NT4tceUlJSEBx98EHfeeadHmQ85NTU1eO211/DQQw/hvffeU61A2VEJaR+6XIHL/xGPHj0qSaTQarWSWHV5+Vy5G0UestXwYAAuRSu34AkhuPfee1FTUwO9Xt+o3fC7774by5YtA8/zuPHGG4O6KcUITZyCK8KF1AejNyh3X8gNlVOnTvnsQ2oymXD33Xfjhx9+QGxsLG688UbFazfM+YaIG6WG1d26dUNUVBTKyspACMHll1+ueO3i4mK89dZbqKurQ/fu3fHss88GLWJk3bp1KCwshCAIyMnJwY4dOzzClhkhZqHLSUtLUzxfVVUlOb777rvFnwkhHn0Zp06dKjmW1zofMmQIRo8eDYPBgO7du3sU7mogIiLC50StqqrCDz/8gPXr13uN8b300kuxaNEifPjhh6zWegfBXHMxEoUQAkHruwMRoJ5P4U5FRQWWLl2KgoICZGdn49NPP1W89qFDh0QlznEcTp3yHUFjs9lQVVUFQRBAKfUaWebO6tWrRf/8+fPngxqHbrPZxL+LIAgeq2+Gi5C20M+cOaPYUkve4WjEiBG45557kJmZifHjx3vUU5f7xOWFjAghuP3223H77fKGTP7REIpVUVEBjuOQmZmJF1980WMcIYRlqXYg8ovzAbdkT86obEdptVrJ3JbXNHLn/PnzotvO6XQqlgkAgN69eyM/Px+UUjgcDqSmpvocW1JSIgmJVHNxBurPD4TrrrsOmZmZsNvtiIyMVE226qiEtEJX85PJJ8yPP/6I1atXA3Blzz333HPo06ePeF6eGSpvJNBUqqqqUF3tKs8rCAJyc3MhCEKb85NTSlFVVQWj0cgKMgUBBw3M3ytf2eXm5nqtLAq4ygJoNBrxP1/jGnCf8xqNBpWVlT7dOd26dYPBYIDD4YBGo1Et/HXTTTfh1KlTqKioQGpqqmIceqAkJCRgwYIFqKioQFxcnEcARajicDiwZMkSHDt2DCkpKXjsscc8eiUHk5BW6GppyXIf+aZNmyTHP//8s0ShDx48GCdOnBCPvcXg/vzzz9i2bRuSkpLwt7/9LaA/flRUFCIiIsTNpKSkpDanzAVBwOLFi5GdnQ2O4/Dwww8HNVa5I1J7tBZcEic+bbWZtYCCgRkbGyupuDhgwACfY8PDwyU+9JtuuklRlrKyMsmGpZJRo9frMXfuXOzZswfh4eGqtdDj4+Mxf/58OJ1O1SzRxqDT6Tz6BIc6O3bswPHjx+F0OpGXl4f169dj1qxZzXa/kNY2o0aNUjyvNmnkylRezEteYvfYsWNYu3YtSkpKcPjwYXzzzTcBSOuyeF544QWMHz8ekyZNwlNP+W4EHKrk5OSIE9But+Orr75qbZHaPJYaC5xmp6tjEU9hv6Ds/5UbMkqhrZWVlfjoo4+Qn5+PQ4cOqWZcurtvHA6HJKLGG9HR0Zg0aRLGjh3rl1XsT8p/R8JqtYo1qnieD2rtHG+EtEKXK1y5gpbHocszP3v16iU5llvb8kxU98QJnue9plGfPHkSH3zwAb744guvNddjYmIwa9Ys3Hjjjc26tGoudDqdxIJry6VEQwVDNwO0MVpwWg6cllNN/Zdv+LlnN8vJyMiQbKIeOXJE8druc1yv1ytem9F0xo4di6ioKBgMBoSHh0sKDDYHIa3Q5Ra1XKF76ymq0+mg1+u9dkL//fffJcf79u2THA8ZMkTcsOQ4DuPHj5ecN5vNWLRoEbKysrBr1652WdwrNTUVY8aMASEEERERuPPOO1tbpDaPUWe8WD5XoBAcylEuI0aMEH9Wiy0PNHtz4MCBkg5HjSldwfCfqKgozJs3D//zP/+D+fPne7iJg01Im1/yKJaoqChxAhNCPDJJIyMjodFo4HQ6ERkZ6WGBy/2F8hdGfn6+eE9KKXbv3o3LLrtMPO++68/zvGradFuEEILZs2fj1ltvbXP+/1DFUeyA5ZgF4QPDwdfyqNxeCdzge3xMTIyY+MNxnKKrI9BIknPnzomGkEajwYULF5pdyXRkrFYr3nnnHeTn56Nz58549tlnVZOomkJIP7HyOhU33HDxKYiOjvaIU1+7di2sViucTicqKyuxZ88eyXl5VpzcRSMvFZCdLS1bmpSUJIm88RUd0B5gyjx4dOvWDdV/VKPoP0UoWVUCvkq5ZMRvv/0mKl2n04mDBw/6HBuocnD34XIc1+w+3Y7O9u3bxZdoaWkpNmzYoP6hJhDST63cwnYvtlVRUYHjx49Lzrv7A51OJ6qrpXWn5deT11OX+8TlLp3z589LfMryeu2MtgUhZDIh5DghJIcQ8oKX89MJIZmEkIOEkAxCiHJevQ8SExMR1i8M8TfHI3ZirGocujxcVykSRT6n1Sz26dOnQ6/Xw2AwIC4uTjUU0W63Y//+/Th+/DgrGd0I5E175MfBJqRdLvIvL/cX5uTkSKx0eSbb77//LrHq5Ra/PFEiLS1NkmwkT/2PjIwUJzUhhKXtt2EIIRoA/wIwEcBZAHsJIWsope7Lsl8BrKGUUkLIJQBWAvAdQ+iDElsJokZHgdNx0EZqEX2lslXNcRx0yTpoI7Sw5lkVyyzLlb+a0u3Xr5+Y/Na1a1dFd47T6cT8+fPFUMdx48ZhxowZitc/evQoCgoKMHjw4GZZwba1vI4rr7wSv//+O0pKShAZGYnrrruuWe8X0gpdHsUiR25hqyFP15dP5qioKHAcJ75I5JmmXbp0wS233IJ169YhKioK9913X0D3Z4QUIwHkUEpPAwAh5GsA0wGICp1S6l78JxxAo0zUWqFWrN9CNATaGOXHzjDYgIhLIkA4gohhEcgryPM5Vv6M+FM7JSIiwq9a/IWFhSgrKxP3lbZt26ao0Ddt2iT29f3uu+/w0ksvoXv37qr38Yeqqiq88847OH/+PPr06YMnnniiTXQWMplMePnll1FXVweTydTsL6OQftXJ41nlFru8eJd8vFwhyzNF5cW64uLiJPfw5p9MTExE9+7dkZKSwhpUtG2SALjvap+t/50EQshNhJBjANYDuFt+3m3c/fVumQx5KKC53Cw+aZRS1deCqbcJnI4TG1yUOHyHFso3NNXiygMhJiZGfB4IIaoG1k8//ST+TCmVHDeVdevWiR3G8vLysGPHjqBdu7nhOA4REREtsrIIaYXuni3nDXlxLrnCl/vE5cfyIkgVFRUSq12u8M1mMz744AMcOXIEu3fvVu3fyAhpvDmbPVQtpfR7SukAADcCmOfrYpTSpZTSdEppujybUdBdnJeEEBCDsp+bL+NBnVSUclSa7wQ7eUMLf0rcnjt3DgcOHPCI8pITFRWFhx9+GCkpKRg0aBAefvhhxfHyvItguiSdTqfoTlKrEtmRCWmFLg9blCNP/JFbzCkpKQiE2NhYUaFrNBqPOtQlJSXiW5bnedXqc4yQ5iwA9zCn7gAKfQ2mlG4D0JsQomymeqF3Sm/Jq0JU1j6o2FmB2uxaWPOsMP9iRtX5Kt9jZVmkaoouIyMDCxYswPLly/H3v//dI3BAzt69e1FQUIDjx497NJCRc99990Gn04EQgri4OMn+VVOZMmUKIiMjodPp0KlTJ1acywch7UOX7+DLkcehy31q8sJS4eHhEqtE7qIZOHAgRowYgYyMDMTGxmLmzJmS8ykpKTAYDGLnIvcY9QZ4nseRI0eg1WolSRyMkGMvgL6EkJ4AzgG4DYCkzCYhpA+AU/WbosMB6AEoLxu9UFNUA8Rd3LBUa0EnOARU772oaA8dOoRp06Z5HTt48GBoojQw9TOBr+URUa7sBty0aZOYiUopRVZWls8656dPn8auXbtcMjud+PjjjxW7FnXv3h3vvfceampqxP2oYBEfH48FCxaguro66NduT4S0QldrzyZ3mch9l/I0aHlEgNyayc/Px969e+F0OlFWVoaff/5ZotSNRiNeeuklHDhwAJGRkR6V7SileP/995GbmwsAGDZsGO666y7F78BoHSilTkLIowB+AqAB8Aml9Agh5MH680sA3Azgr4QQBwALgFtpI2L3SiwlgAPg9C4lpIlQr4nCGTlwJg5Os3I25+HjhxF/QzyInoA6KaxnrIrXTUhIQEFBgejCUPKLy903/rRc1Gq1iImJUR3XGDQaTbNdu73g12tOLV7XbdxlhBCeEDLT15hAUNt0VHN5yCek3OKXW+hZWVmikud53muB/oiICPTs2ROpqake1ndlZSVOnToltrDbs2dPs8edyrFYLHjyySfxwAMP4Mknn2SJIwpQSjdQSvtRSntTSl+v/92SemUOSukblNI0SulQSunllNJG7cRpLJqLqf9OCkepcjndibdPROdbO6PT1E6Inx6P6TdN9zn2VMkpgLh885yOgyFJudzxjBkzEBUVBa1Wi0svvRR9+/b1OZYpz7aHqkJ3i9e9DsAgALMJIR5tyOvHvQGXxRMU1DZ4lAr/e2PQIKnYcstHHjUj3zTieR5vv/02Fi5ciJdfftmjNozJZJJsqjbH0rC6uhpvvPEGnnzySXz55ZceL4w333xTVOIWi8Wjbyqj5bGUWFCxuQK2szbUHa9D1U7fPnEAOOw47CrkpeOgidRgf/5+n2OT45JBdERsKcfXKVvRa9asQWVlpZiBqtSxKNj9AloSh8OB3bt3Y+/evY1q5t5W8UfbiPG6lFI7gIZ4XTmPAfgWgGeJwkaitsETaJ1u+a67PCzRapUuV+UTITc3FwUFBbDZbHA4HGIzjQb0ej2eeOIJpKamok+fPnjyyScDks8f/vvf/yI3NxcWiwV79uzxSAuXP4Rt+aFsL3AcB9tZG8ybzajaU6W6KWqvtYMKF6NcNv24yefYyIRIUCcVi8ppTMrunGPHjonz2uFwKHY4aqtlcCmlePvtt/Hll1/i888/V/T7tzf88aF7i9eVxFERQpIA3ARgPADPncKL4+4HcD/gXwSKWjH7LVu2KBb0l7tE5D55+bFc+cndpSaTSWIRe3MJ9e7d22vbOX+pqqrCZ599hvLyckyZMsWjYmRDR6QG+eSriOuuuw6rVq0Sj6dMmdJoWRjBISIyAvxQHsYUI6iDonyjcoXEyu2ViJ0UC024BrVHahFTFeNz7LnT54D601Sg4GuUrVH5HPdWIroBeZBBa27wU0qxfft2HD9+HMOHD5dUpJRTXV0t7hMArr00nufbTJejpuCPQvcnXvc9AM9TSnmlf3RK6VIASwEgPT1ddXPpbKGyj1wtrFHu7pBbs/JaMGr7XV27dsWNN96I9evXIyoqCvfcc4/HmMOHD2PFihXQ6XS48847PWqyq7Fs2TKcPHkSgiBg+fLlSE5OliSPTJ06FadOnQIhBOHh4R4Te+LEiejWrRt+//13XH755aqNthnNT42hBoYkAwjnikGPGqMcn62J0kAT7lI+hm4GdNP5TqGPM8ShckclIodFgq/lUbGtAvAeEAPAc9WplOsxYMAAdOnSRVT6kyZNUpS7Odm2bRtWrVoFu92OzMxMhIWFebhQGwgPD4fBYIDT6QQhBNHR0R0mKsYfhe5PvG46gK/rlXk8gCmEECeldHVThHM6mpY8IN/UkTcOkCtweaKSNyZMmIAJEyZ4PWe1WrFkyRLRMvjggw/wzjvvSCwbSimOHj0Ku92OwYMHezSQuHDhgmiBazQalJeXSxR679698frrr6O8vBzdunXzuixOS0tjijyEMIYbwWsvKlLOoKxcoi5z1X0BAG2MFgV5vss0X3bZZVi5ciWsp1zuQrVSuHq9XmIIKY3nOA5///vfcfr0aZhMJiQleSTSthjHjx8Xn1+73Y4zZ874VOgajQbPPvssVq1aBY1Gg1tuuaXDhA/7o9BV43UppT0bfiaELAewrqnKHABo40pniKhlmsrxJ/uMUoqKigoYjUaPWjINpXsbqKurA6VUMpm++OIL7N27F4CrHO9zzz0nsR4mTJiAH374QbTAvVn4kZGRiIyMDOi7MVqP8IRwVOGiscCZlBW64BBABeqq/0IALfH9mDbEiTfQkB7vi379+uHw4cMAXIpPqV9pwxilSJiWYvjw4Th8+DDsdjt0Op3q/lm3bt3w+OOPt5B0oYOqQvczXrdZCLRbelNRCzEUBAFLlixBVlYWCCG4//77cemllwZ0j507d4org7y8PJSXl0tigSdMmIDevXvDbDZj0KBBHslRgGslUVZWhqSkpDZRoKijY3VIN9vVrMXK7ZWImxQHTbgGdcfqMLaP76xItVwNORMmTMCRI0cgCAKioqJ8WrmhRnp6OsLCwnDmzBkMHDgwYFdmR8GvxCJK6QYAG2S/86rIKaV3NkkaNyOZhAV3mdTQBcYXiYmJYlKQN86cOYPMzEzxGsuXL8e7774rnvfmslEq9+lro6Znz57o2bOnl0+4SgYvWrQIhBCYTCa89NJLHmV+GaGFo1ZmmKgsPPkqHiWrLibJlRp9h+/KC9CpsXHjRtFwqa2tRWZmJoYPHx7QNVoL5kpUJ7R2CmQeD94a3PhRtU1PuRtDbknl5eVJrqFW7Msb7tfUarUBx8iuX78eNpsNVqsVNTU12L/fd4yyL8rKyrBjxw7FkDVG8HAYZAo9wKdOqYhWoE2e3cfb7Xa/9o0YbYeQTv2nda3bIUX+ApD7zOUK31vpUrkFPn78eGzbtg2EEPTq1SvgcqeRkZGSmu2BlvAtLS3FvHnzxM//7W9/8wiNZAQXR5ED2t6uR41SCsESWPaw0n5JoJnA8rBFf/riCoIgxrmrkZ2djYKCAgwZMqRdt2gMVUJaobc0amGQ8sQk+QT3VrmO53lJJMvMmTORnp4Ou92OPn36BLz7fv311yMzMxMWiwUJCQkB+/CzsrLA87xY12bbtm1MoTcz3AUOllMWhPUKg2ATUPZjGTDO93iNRiNZucmL0LkjT4ZTQ26kqK0Qf/jhB2zcuBF6vR4PP/ww+vfv73Ps77//jhUrVoDneaxbtw4vvvgiU+otTGi5XFoZeYs7OWpZlwkJCRLlbTKZPMISAZdVZbFYGlXn5ccffxTDty5cuCBGLPhL165dxZeITqfzaJQNuLrNPProo3jxxRc9yiEwAsdoNKJyayWKPi3ChRUXwFcqK1G5klWal4FGoLi/HAghigq6uLgYv/zyCwRBgNVqxSeffKJ47T179sBut4PneQiCgKNHjwYkG6PpMIXuhpqC7dGjh8SilpcO0Gg0kg1QbxEon3/+OZYsWYJPPvkEb7/9dsBKvaKiQnzgKaUBp/b3798ft956K3r16oUrrrgCN954o+R8bm4utmzZAofDgfLycixfvjyg6zM86dmzJ4iOwNDDAG2nwBfFSj70Pn36SI7Vop5uuOEGcQ6Hh4d7VAx1R/5iUbPme/fuLd6f47iA+xEwmg5zubih5o80GAySJavc+s7Pz5ckL1VUVMDpdErG/f7776ISP3v2LMrKylRLHLgzZcoUnDp1ChzHwWg0NipC4YorrsAVV3hvYG+z2SQvrUCX9AxPTp45ic4zOoPoXXHlVbsD24iUZzS7k5OTA87IwdjTCKFOgDVP+d9r3S/rEHd9HLTRWtQdr8OxY8cwdOhQr2MTEhKg0+lE95zaamDKlCnQaDQ4ffo0Ro8eHRLx6x0NptDdUPNny+ury6tB+qP8YmNjUV5eDkopOI7z2PAqKirC4sWLUVlZiUmTJnnUYunXrx/mzZuHkpISJCcne5QEttvtWLp0KU6cOIF+/frh/vvv97DasrKysGfPHvTo0QPjx4+XrCr69OmDnj17ilX4brnlFtXvxFDGGe2EXq8X66GHDwkszFSpqmj/tP6IN8aD6AhAgfBTyteu7F4JY7wRRENgGmTCxn0bfSr0wsJCiVWu5kLRaDS49tprUVtbyxLfWonQVugtXOxt1KhR2LJli3gsj1CRLyHlST/ynoqA50viiSeewIoVK2C1WjFr1iwPhbxs2TIUFRUBcIUoDhkyxMPPHRMT47NW9aZNm5CdnQ2e55GdnY3Nmzdj8uTJ4vkzZ85gyZIlcDgcOHjwIKxWK6ZOnSr5zk8++SRKSkoQHh7OYtyDQKQ2EnauvkuQQMFXBRaqqlSHJNecC6Ih4LT1pQJ6KD/SGpPG1Xy6Hhv1HQgQHR0taRKtFpFVVFSEt956C1arFd26dcOzzz7rNTGugfPnz2P9+vUwGAyYPn16UHuQdlRCW6G3bKKoR9q03L8tV/Dy46SkJMkSNTIy0mNMly5d8NRTT/mUoUGZA65SBOfPn/e6cemLc+fOiVaVt76n7olTdrsdx48flyh0wPXwyvupMhqPrc6lNEl9nTvBHti+iVKyW3xYPBqqClCeQjArX9t+xA5tnBaggGAVMKyLbx96ZGQkunXrJvYSVapwCACrV69GbW0tKKUoKirCH3/8gSuvvNK7HHY73nzzTdTV1YHjOOTl5eGll15SvD5DHbYp6oZc+cpDvHJyciTH8s0qh8MhaXMnTzzyB/diW4QQj9h3wJUYdPToUa8+f7lfX37sHtWg0+naTJZgW4YP44F6PUs4An18YOUavEVKNaBxaFC9uRrWAivqTtTBtkc59DY1IhUlq0pQ/lM5Sr4rwaB+vlP/CwsLxSgnSil+/vlnxWvLnx+llYXZbBbrHgmCgMJCn/25GQHAFLobahEnamGN7tY14LKQ/Sn45c64ceOg0+mg1WoRERHhEcVw9OhRvPLKK1iyZAlefvllj9h399Z4hBD06NFDcj4iIgJ6vR5arRaUUsUYZ0ZwqDxfKekq5KzxY04QuPzigGLdkpSUFDiKHTD/bEbVrir069VP8bJVVVUQ6gQ4LjigJVrFOW23210laHUE4DyrlcqZOHGiqMQNBoNifkN8fLzYCk+v1zdLSr/dbleVub0RUi4XLpxD9NhocHoO1RnVsBe17D+GWgigWukAb/7mQOswX3PNNcjIyEB1dTWmTJniYaFv3LhRnKQ8z+PAgQO46qqrxPM1NTWS8fJVxIEDB8QHteF6ahX3GE2Di+RAnVQsiavWJFqXoEPcdXEgGgJ7kR0lB32n9589e1ayKlTLS3AfK4/A8pBDp0PU5VEwDTABAlCzvcbnWADYvHmz+IzYbDYcOHAAo0eP9jpWo9Fgzpw52L17NwwGg89xjeX777/Hxo0bAQA333xzq9Zyb0lCykKPmxQHQ5IB+i56xE6KdYV5tSDyrDb5hubJkycVP+9PQ/iqqiosWrQICxcu9NrkesGCBSguLkZdXR2++eYbD/9pXFycuLTlOM5jc9Q925UQ4pH9GhMTI75kNBpNwMWd2hNqzc8JIXcQQjLr/9tFCAksLbcBHiBa11ySl1P2RuyEWHBaDoQQ6BP1sHf2bdjI56RatrO8Q5FS5Io+Tg9TP5OrMYeWIPqKaJ9jAVeUl3s3LX9kOXjwIA4dOhTUVok1NTWiMgeAb7/9NqjN2ouKirBo0SK89957IZd4F1IKXRulddWArketP2KwkStPuYIOtLgXx3EeFvrLL7+MI0eO4OTJk3jttdc8Qh3lS2D5Azdr1iwMHDgQMTExGDduHIYMGSI5P378eERGRsJgMCAiIgLjx4+XnL/kkktwzTXXICYmBgMHDsTMmTMVv1N7xc/m52cAXE0pvQTAPNR32wqUhK4JYh9Rf0o9NLhaxONw359xL73s7/XdUbLQS0ukYblq7sNp06YhLCwMer0ecXFxGDlypM+xVqsV7777Lk6cOIHDhw/j/fffD0huJbztLQWrUXRDv9Ls7GwcPXoUCxcuDKkm1CHlcqk7UYewvmEABfhqHs7KpnUsChSljDxAuUgS4JpI7iV6BUHwKJ/rPtkopcjNzZW4PBITE3H+/HnxWF6rxWQy4bHHHvMpQ1xcHP75z3+ivLwccXFxHh2NCCGYMWMGZsyYofhdOgBi83MAIIQ0ND/PbhhAKXXvHrEbrm5dAeO44ABJuzgvbOeULVfLKQtM/epDYAWgq9P3Pofc4lYzOuTnlZLp4gxxqM2uRfjgcFCeomZnDXC172snJydjwYIFKDWXomtCV8UenlVVVaIslFKPnI6m0KlTJ0RFRYmVJDt37hy0htdOpxPV1dUS15LFYgm4SF5zEVIKver3KtjybSB6Amu+Nej10NVQe9OqLSEbNr2UMBgM4nUIIR6x7S+88AI+/fRTlJaW4oYbbvBa3Ki2thZmsxmJiYleLSydTqfaioyh3vxcxj0AfvR1UqkBehVXhSguSnzZG1J8x2YDQNWOKtjP26GN0sJyyoKYbjE+x3pz2ylhNBolhovSPLlw4QKq91ajen+1K0pHxaNotpnxydFPUOOoQYo5BX8e8GfoOO+KND4+HgkJCWI5X1/JTY2B4zi8+uqr2Lp1KzQajWSPqanodDqkpaWJrq6UlJSQytUIKYUOSK2XQMvnGnsZ4ax2wlnhhDHZCIc5sEB2tR3xbt26eYQuuuPPBujUqVPx7bffAnDF9cqTkYxGIx566CGfnz9z5ozYVCMqKgpz5871GtrIUMWf5ueugYSMg0uhe6+XAOUG6IaEiwqcEAJNmLorsaFHKACE9/WtMALdAxk2bBh27doFQRCg1WoVOxaJSW/1do7a/N5UsAnVDlfU1bnaczhcdhjDO3sPi+U4Ds899xx+/vlnhIeHY9w4hfKTjSAsLEySUBdMHn74YRw8eBCCIGDYsGEh1a80pHzoTUUbp4WzzAk4AVuBDfqEwOJ91TZO1Gqu+BMi1aDMASAjI8Nrg4ItW7bg66+/9toTde3atbDZbLDZbKisrMS+ffs8xhQXF2PPnj2q/SU7OP40Pwch5BIAywBMp5QG1qS2njDNxReuP6s4uYJQKnIld8kpuTkA4NZbb8XYsWPRs2dP/OUvf1EMiezXrx969+4t1kK/+eabFa9dVV0FKri+m8PhUHTnUEqxbNkybNq0CatXr8a6desUrx1KaDQajBgxApdddpniHkRrEFrSNJHaQ7ViAgd1UFjzAyss5d44whtqHX68RQxYrVavJQEaKC0tlbwoFi1aJNaM+e233/DGG29IqjqaTCZRTm+JR7m5uXj77bfF5f0zzzyD1NRURbk7KKrNzwkhKQC+A/AXSumJxt6I68pBwMUUevi7108AUM9QVHfk0SFqL4va2lpkZ2ejoqICR48exahRo3xamIQQPPfccyguLkZYWJhHdVE51XurIfQTwBk4OM1OWGwWwMe7qLS0FMeOHRPDKH/66SfccMMNitdnqNOuLHTqkEWlWAJz2ahZ6GobK946kSspc8BzyZydLe7JgVLq0dV91qxZSE5Ohl6vx4gRIzzKn+7evRt2ux02mw12ux179uxRvH9HhVLqBNDQ/PwogJUNzc8bGqADeBlAJwAfEUIOEkIyGnMvvly2N6MyLTWxGiTcnoDEuxIRfVU0zuT6NiTkCl1tDi9cuBBlZWXgeR67d+/Gjh07FMcTQpCYmKiqzAEg3hSPsv+WoXhFMao2ViEu2rc7SP5chJIfui3Triz05mbQoEGKCrJLly5IT09HRobrub/22ms9xsgbVcuXyPLz8poq0dHRmDNnjk8ZunbtCr1eD7vdDr1eH7KZoJRSCIKg6iJoZhkUm59TSu8FcG9T71ORUYGopCig3gNYtacKUMijiR4bDc7oikM3phphq/K9GR9oT1F5NMmOHTt81lsJlBkzZqC8vBwFBQW47LLLFGuth4eH45577sHKlSthMBhw9913B0WGjg5T6AEgr4zobZNo8uTJqKurg06n87q7Ll8Sy68ht7Dy8/NViyK5c+WVV6K8vBxZWVkYPHiwz7rnrUlOTg4+/PBDWK1W/OlPf8KsWbNaW6RmxVJtgS5PB1NvEwS7AGuBsiuQcG79OymQ2DXR99gmbsj5kwznLyaTCY8//rjf44cMGQKO46DX6wMqQMfwDVPobsh7OcqRx5rKN0QcDgfeeecd1NXVgRCCs2fP4p///KfiPUtKShQjFQK1YDmOw0033YSbbropoM+1JMuXLxc3zLZt24bRo0e36wfa0NMAU18TCCHgjBzip8Yrjq/8vRJx19an/hfbUZnnO4syKSkpIFliYmJQUVEhHo8apRSp6fLf7927F+Hh4UhPTw+4lIUvBEHA22+/LYZdXn755bj99ttVPsVQI6R96CSiZcOB1JID5Jue8qiWmpoaMfOTUoqysjIPi1v+EpA/kGrnBUHA1q1b8dlnnyl2sgllAm1t1tbRxUkraHIG5cfOccGB4i+LceHrCzD/bIa53Oxz7CWXXCI5Tkz0bc0DwDPPPCP6qwcOHKgYLmi32/Hqq69i5cqVWL58OT777DPFawdCWVkZcnNzxQJa27dvD9q1OzKhpdBlxii1Bm856A9qLej279+veg21Tannn39erDT34IMPerxE5OnV8kzA1atXY8WKFdi5cyfeffddxVrZocodd9wBnU4HjUaDoUOHelSEbG84TzkBejFk0XJKeZ4BAARXvXIAHhU13SkqKpJYzUpjgYv1VjQajdjQ2Re5ubmorKyEIAjgeT6oG+wNeyjux4ymE1ouF/ncatnM/yZbit7qn8tT/1NSUvD666/7fc2CggLJ8c6dO8WfKaXYunVrmwtLHDx4MN555x3Y7faQSZluTnS8DiXflSByRCQcpQ7UZtYCf/Y9nugJYifFQhOhQfXBakSV++7kY7fbJYpRLRdi5cqVouGSm5uLQ4cO+SxzKzcu/FG6xcXFKCoqQu/evRX/beUr0VBKzmnLhJZCb2XUrGu1jupJSUkICwsTH5jOnTt7bSS9fPly2Gw23HbbbR7FteSYzdLldkREhCQuWa0tWKii1+tV/57tBQd1oNO0TuD0HIw9jKC8smKMnx4PTaQGhBDEjImBZp/vfRS50lRq+QZAUh2Q53kUFBT4VOg9e/aEVqsVFXvPnj0Vr52dnY3FixeD4zhoNBr87//+r89+qA2GjnuLO0bTCS2XS4ijlmZdVVUlcdt4Cyn74IMPcO7cOZSWlmLJkiWqXY3ktTbuuusucaM0KioKEyZM8Fd8Ce3dbx1KRA6KBKd3hSESjiByhHKRtwZl3oCzm++lqtPphDZKi4jhETANMIEXlP9d7Vo7Os/sjMQ7XTHuJaW+wx7lLkilBCfA1c/WbrfDarWK9dB9YTQaJStXtXyNmpoavP7663jooYfw/vvvS+q6My7CFLobakvKhuptvnCPHmhAvmx1v4bT6VStAy1/iRw+fFh8ECwWi6Qyoz84nU4sWrQIjzzyCF588cWgVrljeMejHC6nbI1Sh7Q8QBzv25Aw15rR6YZOiLg0ApEjI6Efrrzqib482vXC0Lhi3EmCb1lqa2slUVZqCj0hIUFckXIcp7h6jIiIwF//+leEh4cjLi5OsX4R4GqYfu7cOQiCgJMnT6omRAEug6qjzW/mcgkAtSQObz5DtTAvtbBE+UvmxIkTEuskLy9PdSnsTkZGBk6ePAlKKcxmM1atWoUHH3xQ/YOMRmOvtcOIizkMDfVOfFG6ptTlotFxsJyxoLejt8+xxwuPAzH1sescgaG7sstFa3TrOUCB2M7eXSKAy4WYkpKC/Px8CIKAKVOmKF77pptuQk1NDXJzczF69GiPCBw5o0aNUg2bbMBqtYqrSkEQVPcKvv76a+zYsQOUUkyePBnTpk3z6z5tHb8s9Bbr7BLiqGVdRkRESBS4wWDwUOhyn7raUlNuYaSnp0Ov14sFkwJtHyePLGCulxZArr9VmufwlTwufHEBRZ8WofK3Spw+fdrnWKPTCJD6CBonVW3bWL23GoJdgOAQwFfxqDvj2+XHcRyuuuoqGI1GdO7cWXW/x2Aw4N5778Vrr72GqVOnBtUvPnnyZISHh0Ov1yM6Ohpjx471Oba2thbbtm2Dw+GA0+nEhg0bOsw8V7XQ3Tq7TISrQt1eQsgaSmm227CGzi5mQsh1cJUR9e/V24ZQs7YtFotEYdpsNo8oF3eLW6fTwWq1KkYDyH2FV199NWJiYnDu3DlccsklHnHHFosFH3zwAU6fPo1evXrh8ccfl2S4pqenY+vWrTh79iwMBkNIJyC1F5xVLreb2NBBxUKXo6SMxowYg+2Lt8M00AS+locuXwfM9n0tXa0OF766AC6MA1/D4+oZvjtWmM1mfPrppxAEAZWVlVi0aJFqolxz0aVLFyxYsAAVFRXo1KmT4spWp9NJXiZarbbDbLr643Jpsc4uHhjVh7Qkam/5oqIir59xV+jDhw/H3r17Abh8jmpRKvKeoYCrZKq8bGoDmzZtQl5eHiilyMvLw6ZNmzB16lTxvF6vxwsvvIDq6mqEh4e3ai2VjoI+zeXXblAqnDGwrSulwlgpKSkYO2Qstm7dCoPBgMefVk69Dw8PR2VlJfhqHoQQRWOioKAAXCSHiMEREKwCyg+V+xzbEuj1eo/aRr7G3XXXXfjyyy/BcRzuvvvuoGW4hjr+KPSgdXZR6urilcCq3zY7aj50b1aA/Hfu9cvPnTuHuro6SaU5o9Eo6TMaSB0XwFV9r2Ej1temKyEEUVG+Y5sZwYVzNk2ZqJXPbajIabfbsWHDBjz88MM+x7uv+NRqs1fWVaLTtE4gOgIqUOji1du4mc1mFBcXo0ePHq3aeCU9Pd1nOGZ7xp+Z1pjOLs97O08pXUopTaeUpqs1i/BbuiCiuoFpULZmvTWkkEe5yGPd3cvlAtICYDqdjoVntQNo3sXHhVIKoS6wDvSDBw/2ec69pjilFFlZWYrXqqyshC5eh7DeYeCMnGKNf5vGBhDXhiun5VQbxmRlZWHOnDl477338Pzzz6tGcDkcDuzbtw+HDx9u15mipaWl2L17NwoLPfqnBB1/LPRAO7tc19jOLh4ENu+bTExMDMrLfS8rNZyyQu/e3dPTpJY8I48zDw8PF8MfHQ6HR9iiw+HAv//9b+Tn5+Oqq67yaLMl32RV23RlND8WmwVaXguidW1kC47AJrZSwpt8fqkZJbGDY4HBcJlkAtAFvnuKDu8/HFsPbAXlXZa8UKws95dffinKarPZsGbNGvzlL3/xOlYQBLz55ptiV6309HT89a9/Vbx+W6SwsBALFiwA4HrhPvroo+jfv3+z3c8fG1js7EII0cPV2WWN+4BgdXZpbeRZmXIMWuWQMH8sdPcHzpsP0z3RyGAweLxg/vWvf+HAgQMoKyvD999/71FfQ27pNIflk52djVdeeQXz589vEaujrWMrt4FoiOji4GsDi7hQMjLk/nW1TNHE0YngdBw4PQeNToP4Ab4rP1abq1G1oQo1B2tQ/Uc1anYqx6HL55rSi6i0tBRFRUViO8Xdu3crXrutsm/fPvE72u12v+Lnm4KqQm/Jzi4BE+RNUzXlFx+vXPbUH5/hjBkzoNPpoNPpMHr0aA8LfPjw4eKuPMdxHnsN8gqL8o5GDZ8DXC+Pxuzu5+fn47PPPsP69es9XD4WiwWLFy/G+fPnkZubiw8++CDg6wcDs9mMrKws1WSvUEAfowd1UDHUVBuuvDDmOA6aCA10CTqAU+5lK//+NpvvZhgAkBSZBA1xrTS1Wi3iw3zP6ZiYGNgqbag5WIO6o3UwGZVXeyNHjpQcX3217wiaqKgoSZBBe11JJiYmiqsovV4fcLnjQPErsailOrt4oCZdC2+aDho0yGtT5ga8RSPI484vu+wy5OTkiM0d5HTp0kUMdYyIiPBYUsutHnkj6AkTJmDfvn2oqKhATEyM13soYTabsXDhQthsNuh0Oly4cAF33XWXeL6mpkay6vCWHdvc5OfnY+HCheLLas6cOR6uq1DCWeEUd6Kok8J+QTlWPLJPJMIuDwMVXNZ8ciffteIbQvQajBG1psWpllTsOr4L2jgtHLkOxA/2rdBra2vBcZyoeNXKVMit7F9//RX33HOP17Hya7kHArQn0tPTUVJSggMHDqBfv36YOHFis94vtDNFW2+T3Cs5OTmK5+WlbgHPsMV3330XxcXFoJRi4cKFeOuttyRKe+3ataLSLisrQ05ODgYNGuTznvJVRVRUFObNm4eamhqPRCd/KCwsFBWlw+HwWBHodLpWL3v622+/iZYoIQS7d+/G9OnTW1wOfyF1BOafzTClmeCscKLmYI1itUXdYJ3L317/FsgqysJIjPQ6tkePHhKlq5Zo9sXyLyRW/datWz32YRpwz84E1Cs5yl8mSvtH8thwtX69bRVCCKZMmaKaZRssQjs4U7m0c4sjt4bleFNu8t8VFRWJv7NarR5+e/eCSIIgeNS3li+/x48fLzl2Op349NNPMW/ePCxfvtzDh69GQ+cgQgj0er1H+rY8c7U1FHp8fLyoAHQ6nWrRtNaGEAJ7kR1Vu1z+aI8y0TKEOuFi8hEB8k7m+RxbUVEhUbpq9fHl8+nECd9bXlqtVpKnoJazcP/994tjIiMjceutt/ocGxUVhZtvvhlarRZGoxH33Xef4rUZ/hHaFnqIoVZe15vyVFN4ak015MyZMwfz589HeXk5hg4dikmTJknOb968GQcOHIDD4cD+/fuRnJwsWeYJgoDly5dj//796NKlCx5//HGJqygqKgpz5szB7t27ERcX55FiLc9MbY2EjYkTJ6K4uBgnTpzAkCFDFNPAlSCETAbwPlytVZZRShfIzg8A8CmA4QDmUkoXNuY+Or0OpmtMMHQ1gAoU5RuVE3QqtlcgdnwsNJEa1GbVQl/s29JtSFJrQG1j392aB+CzvC3gquXStWtXceWpVtkzNTUVH330kUd2tC/Gjx+PcePGdZgszpaAKfQAUNtw8pb1qWbVyC2msLAw8XeEEERGSkutnjx5EmazGVqtFkePHkVFRYXkoayoqBA3Mh0Oh8cDvn//flHhFxYW4r///S/uvVe6/dGlSxefLoyGBtitGR+v0+kkfv3G4GdJi3IAjwO4sUk36wToE/QgGgKiIYi+3HfmJwAItQLK1l6MmOpzaR+fYwP1PZtMJsmcU9ro12g0mD59OlauXImIiAhceeWVft0jkJc8U+bBJbRdLiGGWpRLYxS6PPnC3aKnlEoSjQDgl19+gcPhgNVqhcViQWZmpuS8vJ2b/NhdAQiCoLrRJSc2NhZhYWGuaA2tNqBKjyGGWNKCUmoH0FDSQoRSeoFSuhdAk95eVKAXN0UpVa3lIp8zSnsoan5ttWsrbaJWVVVh6dKlKCkpwZkzZ/DRRx8pXruurg7vvfcenn32WXzzzTftOlkoVGEKPQDUyhV4szbUJrW8NkVtba3kWL4p6f4CEATBIy1cXplP7lMdMWIEYmJiYDAYYDQaccMNNyjKJ0en0+HFF1/EhAkTMHnyZDz+uHLtkBDGW0mLRseUEULuJ4RkEEIy5CUi7OftsJ6xupJzrAIqdyhnUMprBmVk+I4CDnQzUf4CUHqhl5aWSlZiajkH3333HU6cOIHq6mrs2LFDtQdvZWUl1qxZg59++ingFxPDO6HtcmnpKBcO0uxU2etOzT/pLY3a4XAoJnvIfdIRERGSJbE8akGu8OUypaSkQK/Xw263Q6/Xe7yEwsLC8Morr6C4uFi0tgMlLi4OM2fODPhzIYbfJS38gVK6FK4qo0hPT5dch+M4VG6vdCnyRtzBW8JaA/369cPWrVvFYzUXhvy82r6Qe0ikGmazWXwZ8TyvmCPgcDjwz3/+E1VVVeA4DkeOHMHTTz/t130YvgkpC13bxe39YgDQwi9tTYTMPSJ7Ns6ePav4eW8TX+0Bk/tA3ZfADeV13ZE/gHK//pgxYzBt2jT069cP06ZNw+jRoz3uuXnzZixduhRff/11R7aM/CppEQzEF3ojXxdKG5dyl4ma/3ro0KHiz4QQDBs2zOfYhIQEcQVACFFdobpXBuV5XjH6qLy8HHV1dRAEAU6nUzUkmOEfIWWhO4vdokSU9x+bBY5w4N1jymT6Xa0ui7cKhmoPmFwhx8fHo6KiQnw5yMvnJiYmSlYCvXr1kpwnhGDSpEke0S8NZGdnY82aNbDb7SgpKUFYWBhuu+02RRnbKWJJCwDn4CppcXtz3MjhcCD80nBEDI4AX8uj/KfAytDK91HcOXz4sORYrcRzWloafv/9d1BKERYWprgvFBERgSeffBLr169HREQEZs2apXht95WERqNRbP8WFxcHg8EAh8MBjuM89noYjSOkFHpro7Vr4XDf/5IZr2rLU2+uFbmFHhcXJ9bm0Ol0HnHl99xzDz799FOUl5djypQpHl2S/vznP2PhwoVwOBzo0qULxowZo/a1JJSUlIgvC6fTGXBP0vYCpdRJCGkoaaEB8ElDSYv680sIIYkAMgBEARAIIU8CGEQpDajegCnFBN0IV0YnMRDEXaceNx/WJwyaCA0spy2K+Q+B5hn8+OOP4jy2Wq04fPgwLr/8cp/je/fu7fc+yWWXXYZTp07B6XRCo9EoJjnpdDq88MIL+OWXX2A0Gn0mNzECgyl0N9TCEtUUujeLhOd5SWTBM888g6+//ho2mw0zZszwsL5iY2MVfYndu3fHW2+9herqasTExAQcB37JJZdg9erV0Gg0EATBIzGpI+FHSYsiBKFZC4296GshhEAbpfzYRaZHwjTIBKIhCB8SjthM3y6XGTNmSFLuu3Xrpnhtd7+2IAiq+0KBMHbsWERFRaGgoABDhgxRrVsSHx+P2bMV2is1kfLychBCFF1W7Q2m0AMgOTlZMRPPHws9Pj4ejz76aJPkaEp2ZGxsLP7xj3/g5MmTSExMbPZiQQzAUmSBfpDLXUcphWBTNgyMPYzgdK4XNQUF18n3S7shhLRh1aU2L+Li4sRIKY1GoxqKGyhDhgxR7T3aEqxatQpbtmwBAFx//fUtlnrf2oTUpmhro+YjVwvb8vZ5uULPycnBiy++iGeeecaj9G1LERUVhREjRjBl3kLodDpQp0vhEkJA7cq7o7YiGwRnvdInQMGRAp9jv/76a8lmvFqDi5kzZ8JgMECv1yMxMVGySdpeqKurw+bNm+F0OuF0OrF27VrWJLojohbxodR/EfCexi+PfFm8eLEYO/7ZZ59h8ODBkhZ0jPaHUC2AaC9a0c4aZb931e9V4Gt4aKO1qDtWhxga43NsoJmWcXFxMJlMqKysRLdu3dplUSyNRtNhm0QzC90NNR+5Gt6Wr/LMPHkYotxvLwgC9uzZg59++kmxsQGj7UDDqaQeukd4rBwBqD1Ui8ptlXBccCjWQ5fXsVFbZS5atAhmsxmCIGDv3r3YuXOn398j2JSWluKrr77C999/H3BNIyUMBgP+9re/wWg0wmQy4b777mNNohmeyOuuyPHH2tHr9WJkAs/zHqGOq1atwvbt28HzPH766Se8+uqrqisDRmhjK7chgrj+DSlP4TQHFpmiVK9FnryjlgQkL/GcnZ2NK664IiB5goHD4cBrr70mKvLs7GzMnTs3aNcfOXKkR8ONjkDHeG35iZpCVuq+DnhmcQKeD5h7qjWlFMeOHZOc379/P+x2O3ieB8/zyM/P97jm2bNnsXfvXtUmvIzQgK/gYTlpgeAUwFt5VO0NrMuSkvWq0+kk1qdagwu5BS8vPdFSnD9/XvK9vM3zUCU/Px/z58/H66+/7lFqo7VpWwpd7gYLsvRqFQSbI7FIXkujZ8+eoptGEASP0gAHDx7EG2+8gc8//xyvvPJKUMPOGM1DQp8EhPUNA6floDFqED1KudqiHKUNvR49ekj8w2oNLv70pz+J4zUajWIMOuAyYjZv3ow9e/Y02SXpjrzeTVuBUor33nsPubm5yM/Px/vvvx9wLkBz0qZdLpoYFV9kkFHbNPU2SXmeV7Sa+vbtKzkODw8XH2Bv1RY3b94syqHT6ZCZmanYu5HR+lAjBaEuJUo0BJrowOZtIC4XNUU5depUxMfH4/z580hPT1ds3We32/Haa6+huroaHMfh6NGjuPPOOwOS3RdtNTbc6XRKjDCHwwGbzaa6Mmop2paFLnMP8hUtG4qkFuPbmL6I8lWBe9PnhiYV7nTt2lWcPISQVlsyM/yn6kwVqJ1CsAsQHAJqMz1dc0oorfKKi4slFrxa5i/P8ygqKsK5c+dU+8EWFhbCYrHA6XTCbrfjwIEDqrJWV1fjzJkzqsZPamqqZO4OHz5c9dqhgE6nQ3p6OgwGAwwGA9LS0kIqSi00XiuNJXgrQL8YOHCgh8/bHW9NotXCpeTLafmyVv5gzJgxAzabDfn5+RgzZgwGDhyoJjajlXFanSj5rgT6rnrwNTyc5YEt0ZWs2aNHj0qO1eKtV61ahR07dsDhcODEiRN47rnnfBbd6ty5s7gHpNFoxPaEvjh9+jTee+89EEIQFhaGl156yeeGPsdxeOWVV5CdnQ2DweCxUg1l7r77bhw/fhyUUlUXV6AUFxfjiy++gN1ux8yZMwP+u7RthR5k1DrxqFnD3ix0tagDs9nsUa9FLpM7BoMBw4YNQ0JCgldlLggCVq1ahSNHjiAtLQ0zZ87sMCFboQrP8zANMSF8cDj4ah7mzYHte8i7Vrlz6tQpmAaYEDEsAkKdoHrtkydPinOc53mcPXvWp0IPDw/H008/jR9//BGRkZG46aabFK+9YcMGMQyX53lkZGTgmmuu8Tleo9GERFZpoHAc12yG1Pvvv4/y8nJQSvHBBx/gzTffVCzOJocpdDfUNn1OnjypeN5bll5dXZ3XzdIG5PXI5T0f5f+YW7duxapVq+B0OvHjjz9i7ty5ko3T3377Ddu3b4fdbkd5eTk6d+6McePGKcrNaF50nXWIGBoBTseBM3CIuTJGcbw+To/oidHQmDSoO1aH1IRUn2MTeiXA0dMBTsuBM3KIGad8bXd4nld92WdnZ+Pw4cMwGo0YPXo0+vTx3Q4vMjJSUoYglFwRrYkgCKitrUV4eLjq39tsNot/v4YGNoEodGa6uaG2XFVT+N4SQNT+MdQaTMh30DMyMmC32yEIAiilHh2NSkpKRDdNQ4ncxtBwj8bC83yr9h0NJaI7R4v7P4Qj4EzKj138uHhoTBoQjiCsbxgSBvheGRqjjKLrkXAEXJjytd0jtdTCdEtKSrBhwwbwPI/a2losW7ZMcbz7BqvT6WT7O3AZdP/4xz/wwgsvYM6cOarJgmPGjBH988nJyQHXbGIKPQDUwhbT0tI8fid/aNzf0BzHeZyXv1TkE6Bv376iHN6aDlx++eXQ6/UwGo3Q6/WqYWlyKKVYuHAhHnvsMTz88MOqtUG8sXv3bjz22GN44okn8PPPPwf8+fZGTV4N+Foegl0AdVLU7FPOZ3BwDhDuYlRM9vFsn2OrC6rhrHRCcAgQnAJq9itfe9q0aTB2MsKUakJkbCQuvfRSn2PtdrtkD0jtBZ2dnS1xMbKmFcD27dtRUlICp9OJiooKbNiwQXH8n//8Zzz44IO4++678cwzzwTsLmUulwBQ2+X39vaVhy0OGjRIVJKxsbEeb2CtViuxyuVWztSpU6HX65GXl4fLL7/co0lzSkoK/v73vyM/Px89evTw2rjabrfj7NmziI+P93AH/fHHH6JriVKKxYsX41//+pfi93ZHEAR8/vnn4ovp+++/x9ixY4O+/M7MzEROTg4GDRoU9I2pYGOpscCy2gJdvA5CnQC+JrDorHOF53ye03JalK0tg66zDoJFAF+tfO08ax5ipsa4GlXzQI2txucqsVu3bhg6dKgYaXXrrbcqXttd4VNKWZNouIy2hpciIUS1aTwhRLEpuBpMobuh1j9RLVPUn7BF9ygZs9mMiooKSRRDeHi4JANUrvA5jlNtBhAfH++zLGptbS1ee+01sf3XE088IfGLnjp1SjK+MUkT7quMYCajNLB//358+umnsNvt2Lx5Mx599NGQV+r6rnpEDI2As9KJqh3KmaJ8LQ9NhMvlQnkKjeBbCRgMBoACjgv+ubf+KPsDJJqAgIA6KLYe24qZo733hyWE4J577sGMGTOg1+tVX8ryJDe16qQdgSuvvBIZGRnIy8tDfHw8rr/++ma9X9t2uQS5gJqaRaH2dvWWii93ociVnfye8jTvYBfo2rdvH6qrq2G1WmG327F+/XrJeXnUgZqbSQ35Jm8wyMzMFPcJHA6HR+heqBHWJQxx18ZB30UPUz8TOs/0XWwLACq3V7rcKHYBdUfqoK3ybXcF+iILE8JA+YtzLiFS3c8dGxvr1wpLHo3TVpOHgonRaMSLL76IDz/8EPPmzVMMkAgGbVuhBzlRVG0DUymrzl/kClzul3R/aRBCvDbNaAoRERGS1G957DzHcRK/XSA77IBLZvfPaDSaoH8Hucze4v9DichRLkUnVluMUp64fDWP0u9KUfx5Mar3VStuXspdamqb7BO6TYDtnA3OKifs2XaM7uvZRLyxzJo1CzqdDjqdDhEREbjqqquCdu22TktlkrZtl0uQSyiouRfUrBRvSRT+WPXuL4pRo0Zhx44d4HkeRqPRowl0Uxk2bBiOHz+OvXv3olu3bpg5U7rcjouLE9vTcRynGCPvDUIIHnnkEXzyySfgeR6333570BV6UVGR5Fip52YooLFoQN3TnAN0LcsbhbsjX8Gpuf1+3fgrzDku14her8fBgweDVpWwX79+ePXVV1FcXIzU1FTVlwsj+IS2Qm/ZUi0ICwtTLJHbt29fZGZm+jzv7cFT26WW+8hvvfVWpKSkoKKiAqNGjQp66VxCCGbPnu2zl2PXrl3Rv39/ZGVlgeO4RrXu6tu3L+bPn99UUX0i790a6grdts8GbRctOL1rLlRsrwAUDGONRiNxUyl1liookHYzUnMbuiv8hqqewSQuLq7R7RHbEg1/NzWDraXxy+VCCJlMCDlOCMkhhLzg5TwhhCyqP59JCAlOYYYW7holb5gstzDUKhv640OXI0/t5zgOY8eOxfXXX9+ofo+CIGD16tV47bXXsHr16oA3JXNzc3HixAkArhXLqlWrApahrdCS8/rCFxdQ+UclSn8ohTVH2YqWu1iUVoZq6fhKcBzHIlEawa5du/DYY4/hsccew2+//dba4khQVeiEEA2AfwG4DsAgALMJIfK4musA9K3/734Ai4MsZ4sgL2wkV7aDBw+WHMvrtHhbYqrVcgm2dbl9+3b8+uuvKCgowK+//oodO3YE9HmbzSaRWd5RKRS45JJLJKFgSrHUvmjJeV1jrUHi3YmIHhmN+OnxiPlTjOJ4udvk7NmzPsceOXIkIFncrWdKqdewVoZveJ7Hl19+KfYrWLlyZUg9I/5Y6CMB5FBKT1NK7QC+BjBdNmY6gM+oi90AYgghgTlfQwB59Tm5dWsymSQuFPmuvtxv2KlTJ9XNkEB91GqcP39ekimqVn1PTt++fdGrVy9xc0st9rg1mDJlCtLT0xETE4OxY8c2dvOtxeZ15DXSTVFjj8A2mpXcfIFGIbk3YeE4zqP8LkMd+aomlFY5/vjQkwC4O+rOAhjlx5gkABJtQgi5Hy5Lx2dBoOakS5cuEotYHkKUlpYmuhsAz+gJvV4PrVYrKkyTySQ5z3EcFixYgM2bN0On03ktTGQ0GkULTKPRBN1HPnr0aOzcuVOMqR81Sv5PpQzHcXjiiSdQWlqK8PBwj+8YCuh0Otx7771NvUzQ5jWgPLcTYhNghstd15iHf+jQoT7PXXbZZZJVmD+lJhrmhlarbXJYakdDo9HglltuwcqVKwEA06dPDzgSrDnxx0L35jOQz0p/xoBSupRSmk4pTVdqfNvA//3f/0mO5b7FhQsXSo6nTp0qOZZvzD333HOixcxxHJ5//nnJ+UmTJonlKk0mE5566inJ+aSkJEyYMAEajQZRUVG4++67PWQ2Go2YMmUKJk6c6DXc7IEHHoDJZBKt32Ar9NTUVLz00ku4/fbb8dJLLyE1NTXgaxBC0Llz55BU5kEkaPMaUJ7bj455FIReTFobmzDW2yVE5s6dK7qUkpOTFascDhgwAFdeeaUYLiqfs3Jmz56Nzp07g+M4DB06tE1WO2xtrrnmGrz77rt45513cO2117a2OBKImsVACLkcwCuU0mvrj18EAErpfLcx/wfgN0rpV/XHxwFcQyn1ud5PT0+nGRkZTf8GDIYXCCH7KKXpCuebZV4DbG4zmhelue2Phb4XQF9CSE9CiB7AbQDWyMasAfDX+qiA0QAq1SY9g9HKsHnNaHeo+tAppU5CyKMAfoIrMvwTSukRQsiD9eeXANgAYAqAHAB1AO5qPpEZjKbD5jWjPeJXYhGldANck9v9d0vcfqYAHgmuaAxG88LmNaO90bZruTAYDAZDhCl0BoPBaCcwhc5gMBjtBKbQGQwGo52gGofebDcmpARAno/T8QBKfZxraUJFllCRAwgdWZTk6EEpVc9eawba0NyWw2RrHC0tm8+53WoKXQlCSIZSUkhLEiqyhIocQOjIEipyBEIoy8xkaxyhJBtzuTAYDEY7gSl0BoPBaCeEqkJf2toCuBEqsoSKHEDoyBIqcgRCKMvMZGscISNbSPrQGQwGgxE4oWqhMxgMBiNAmEJnMBiMdkKLK/SmNOZV+2yQ5bij/v6ZhJBdhJBL3c7lEkIOE0IOEkKaXPjaD1muIYRU1t/vICHkZX8/G2Q5nnOTIYsQwhNC4urPBe1vQgj5hBBygRCS5eN8i8yRxtKUOR4i8vmc+60tm9u4y+rn38xQkq3+WT1ICDlCCNnaUrKJUEpb7D+4ypSeAtALgB7AIQCDZGOmAPgRrm4xowHs8fezQZZjDIDY+p+va5Cj/jgXQHwL/k2uAbCuMZ8Nphyy8dMAbG6mv8lVAIYDyPJxvtnnSGvM8RCSz+fcb23Z3MZthqtS5sxQkQ1ADIBsACn1xwktOfcopS1uoTelMa8/nw2aHJTSXZRSc/3hbgDdG3mvJsvSTJ9t6rVmA/iqkfdShFK6DUC5wpCWmCONJdSbqofS3A9YtnoeA/AtgAstJJe/st0O4DtKaT4AUEpbUj4ALe9y8dV0158x/nw2mHK4cw9cFlUDFMDPhJB9xNUcuCn4K8vlhJBDhJAfCSFpAX42mHKAEGICMBmuh6qBYP5N1GiJOdJYmjLHW4Kmzv3mRFU2QkgSgJsALEHL4s/frR+AWELIb/XPwV9bTLp6/GpwEUSa0pjX74a9QZLDNZCQcXBN6ivcfj2WUlpICEkA8Ash5Fi9VdlcsuyHq35DDSFkCoDVAPr6+dlgytHANAA7KaXuVnQw/yZqtMQcaSxBbT7dDDR17jcn/sj2HoDnKaU8Id6GNxv+yKYFMALAnwCEAfidELKbUnqiuYVroKUt9LMAkt2OuwMo9HOMP58NphwghFwCYBmA6ZTSsobfU0oL6/9/AcD3cC3HGouqLJTSKkppTf3PGwDoCCHx/n6PYMnhxm2QuVuC/DdRoyXmSGNpyhxvCZo090NAtnQAXxNCcgHMBPARIeTGEJHtLICNlNJaSmkpgG0AWmxDGUCLb4pqAZwG0BMXNxbSZGOuh3TD6A9/PxtkOVLg6iU5Rvb7cACRbj/vAjC5mf8mibiYBDYSQH7936dF/yb146Lh8m+HN9ffpP46qfC9Kdrsc6Q15ngIyed17oeCbLLxy9Fym6L+/N0GAvi1fqwJQBaAwS35N2xRlwttQmNeX59tRjleBtAJLgsAAJzUVVGtC4Dv63+nBbCCUrqxMXIEIMtMAA8RQpwALABuo64Z1NJ/E8Dlv/yZUlrr9vGg/k0IIV/BFdkTTwg5C+DvAHRucjT7HGksTZnjISSfr7kfCrK1Cv7IRik9SgjZCCATgABgGaXUa+htc8FS/xkMBqOdwDJFGQwGo53AFDqDwWC0E5hCZzAYjHYCU+gMBoPRTmAKncFgMNoJTKEzGAxGO4EpdAaDwWgn/D+sxlB3Uj3W1gAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# set plot xticks\n",
    "x = np.arange(0, len(y_over_synth_10), 1)\n",
    "plt.xticks(x, x)\n",
    "plt.subplot(1,2,1)\n",
    "plt.scatter(X_train[:, 2], X_train[:, 3], c=y_train, s=10, cmap=\"Accent_r\")\n",
    "plt.subplot(1,2,2)\n",
    "plt.scatter(X_under_synth_10[:, 2], X_under_synth_10[:, 3], c=y_under_synth_10, s=10, cmap=\"Accent_r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Split the train data into train and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_over_synth_10_train, X_over_synth_10_val, y_over_synth_10_train, y_over_synth_10_val = train_test_split(\n",
    "    X_over_synth_10, y_over_synth_10, random_state=192, test_size=0.25)\n",
    "X_over_synth_30_train, X_over_synth_30_val, y_over_synth_30_train, y_over_synth_30_val = train_test_split(\n",
    "    X_over_synth_30, y_over_synth_30, random_state=192, test_size=0.25)\n",
    "X_over_synth_50_train, X_over_synth_50_val, y_over_synth_50_train, y_over_synth_50_val = train_test_split(\n",
    "    X_over_synth_50, y_over_synth_50, random_state=192, test_size=0.25)\n",
    "X_under_synth_10_train, X_under_synth_10_val, y_under_synth_10_train, y_under_synth_10_val = train_test_split(\n",
    "    X_under_synth_10, y_under_synth_10, random_state=192, test_size=0.25)\n",
    "X_under_synth_30_train, X_under_synth_30_val, y_under_synth_30_train, y_under_synth_30_val = train_test_split(\n",
    "    X_under_synth_30, y_under_synth_30, random_state=192, test_size=0.25)\n",
    "X_under_synth_50_train, X_under_synth_50_val, y_under_synth_50_train, y_under_synth_50_val = train_test_split(\n",
    "    X_under_synth_50, y_under_synth_50, random_state=192, test_size=0.25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of X_over_synth_10_train is: 7433\n",
      "The length of X_over_synth_10_val is: 2478\n",
      "The length of X_over_synth_30_train is: 10136\n",
      "The length of X_over_synth_30_val is: 3379\n",
      "The length of X_over_synth_50_train is: 13515\n",
      "The length of X_over_synth_50_val is: 4505\n",
      "The length of X_under_synth_10_train is: 709\n",
      "The length of X_under_synth_10_val is: 237\n",
      "The length of X_under_synth_30_train is: 193\n",
      "The length of X_under_synth_30_val is: 65\n",
      "The length of X_under_synth_50_train is: 129\n",
      "The length of X_under_synth_50_val is: 43\n"
     ]
    }
   ],
   "source": [
    "print(\"The length of X_over_synth_10_train is:\", len(X_over_synth_10_train))\n",
    "print(\"The length of X_over_synth_10_val is:\", len(X_over_synth_10_val))\n",
    "print(\"The length of X_over_synth_30_train is:\", len(X_over_synth_30_train))\n",
    "print(\"The length of X_over_synth_30_val is:\", len(X_over_synth_30_val))\n",
    "print(\"The length of X_over_synth_50_train is:\", len(X_over_synth_50_train))\n",
    "print(\"The length of X_over_synth_50_val is:\", len(X_over_synth_50_val))\n",
    "print(\"The length of X_under_synth_10_train is:\", len(X_under_synth_10_train))\n",
    "print(\"The length of X_under_synth_10_val is:\", len(X_under_synth_10_val))\n",
    "print(\"The length of X_under_synth_30_train is:\", len(X_under_synth_30_train))\n",
    "print(\"The length of X_under_synth_30_val is:\", len(X_under_synth_30_val))\n",
    "print(\"The length of X_under_synth_50_train is:\", len(X_under_synth_50_train))\n",
    "print(\"The length of X_under_synth_50_val is:\", len(X_under_synth_50_val))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5\n",
    "### Question\n",
    " Create a new (deep) neural network and train it on your enhanced dataset. Use training and validation sets derived from the enhanced dataset to find a model with high accuracy. Evaluate your final model on a test set consisting only of original data. Again, record the accuracy and AUC. Briefly discuss the changes you would expect in the metrics and the actual changes you observe. Would you say that you are now doing better at identifying fraudulent claims?\n",
    "\n",
    "### Principle\n",
    "To simplify the problem, and save computational time, we will train the synthetic data to a very simple neural network, and then compare the performance of these dinstinct synthetic data.\n",
    "After doing this, we are going to select the best performance dataset and then we can use tunner to train the model for it.\n",
    "\n",
    "The neural network structure is as follows:\n",
    "1. Input layer\n",
    "2. 2 Hiiden layers, in which the number of neurons in each layer is equal to 60 and 'relu' function is used\n",
    "3. No dropout layer\n",
    "4. Output layer, with 'sigmoid' activation function.\n",
    "5. Optimizer: AdamOptimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a controlled model to compare the performance of the different sampling strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainModel:\n",
    "    def __init__(self, X_train, y_train, X_val=None, y_val=None,X_test=None,y_test=None, epochs=100,early_stopping:bool=False,patience:int=10):\n",
    "        tf.keras.backend.clear_session()\n",
    "        tf.random.set_seed(192)\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_val = X_val\n",
    "        self.y_val = y_val\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        self.epochs = epochs\n",
    "        self.early_stopping= early_stopping\n",
    "        self.patience = patience\n",
    "        self.simple_model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Dense(60, activation='relu'),\n",
    "            tf.keras.layers.Dense(60, activation='relu'),\n",
    "            tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "        ])\n",
    "\n",
    "    def compile(self):\n",
    "        self.simple_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    def fit(self): # We fit the model with train and validation data becasue validation data can tell us when to stop training\n",
    "        if self.early_stopping:\n",
    "            early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=self.patience, restore_best_weights=True) # set patience to 10 to accelerate the training\n",
    "            self.log = self.simple_model.fit(self.X_train, self.y_train,validation_data= (self.X_val, self.y_val),callbacks=[early_stopping_cb], epochs=self.epochs)\n",
    "        else:\n",
    "            self.log = self.simple_model.fit(self.X_train, self.y_train,validation_data= (self.X_val, self.y_val),epochs=self.epochs)\n",
    "\n",
    "    def evaluate(self): # evalute it on the test dataset, since we are going to predict the raw data like test one\n",
    "        loss = self.simple_model.evaluate(self.X_test, self.y_test)\n",
    "        x_test_predict = self.simple_model.predict(self.X_test)\n",
    "        # calculate the roc\n",
    "        roc_score = roc_auc_score(self.y_test, x_test_predict)\n",
    "        # calculate the accuracy suppose the threshold is 0.5\n",
    "        x_test_predict_binary = np.where(x_test_predict>0.5,1,0)\n",
    "        accuracy = accuracy_score(self.y_test, x_test_predict_binary)\n",
    "        # calculate the sensitivity\n",
    "        sensitivity = recall_score(self.y_test, x_test_predict_binary)\n",
    "        return {'loss': loss, 'accuracy': accuracy, 'sensitivity': sensitivity, 'roc': roc_score,'modle':self.simple_model}\n",
    "    \n",
    "    def draw_the_loss_curve(self):\n",
    "        # plt.plot(log.history['accuracy'],label = \"training accuracy\",color='green')\n",
    "        plt.plot(self.log.history['loss'],label = \"training loss\",color='darkgreen')\n",
    "        # plt.plot(log.history['val_accuracy'], label = \"validation accuracy\",color='grey')\n",
    "        plt.plot(self.log.history['val_loss'], label = \"validation loss\",color='darkblue')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    def run(self):\n",
    "        self.compile()\n",
    "        self.fit()\n",
    "        # self.draw_the_loss_curve()\n",
    "        return self.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, if we apply the model to the test data (real data), and select ROC as the metrics to select the sampling strategy, we can find that in the oversampling strategy, the ROC rate is higher than undersampling strategy. Since there is a slight difference between about 10%, 30% and 50% oversampling, we will use the 10% oversampling strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-09 10:17:32.369998: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "233/233 [==============================] - 1s 1ms/step - loss: 0.2513 - accuracy: 0.9080 - val_loss: 0.1673 - val_accuracy: 0.9124\n",
      "Epoch 2/100\n",
      "233/233 [==============================] - 0s 1ms/step - loss: 0.1440 - accuracy: 0.9346 - val_loss: 0.1103 - val_accuracy: 0.9572\n",
      "Epoch 3/100\n",
      "233/233 [==============================] - 0s 991us/step - loss: 0.1059 - accuracy: 0.9555 - val_loss: 0.0908 - val_accuracy: 0.9669\n",
      "Epoch 4/100\n",
      "233/233 [==============================] - 0s 973us/step - loss: 0.0817 - accuracy: 0.9684 - val_loss: 0.0703 - val_accuracy: 0.9734\n",
      "Epoch 5/100\n",
      "233/233 [==============================] - 0s 2ms/step - loss: 0.0668 - accuracy: 0.9742 - val_loss: 0.0644 - val_accuracy: 0.9754\n",
      "Epoch 6/100\n",
      "233/233 [==============================] - 0s 1ms/step - loss: 0.0566 - accuracy: 0.9794 - val_loss: 0.0533 - val_accuracy: 0.9806\n",
      "Epoch 7/100\n",
      "233/233 [==============================] - 0s 1ms/step - loss: 0.0501 - accuracy: 0.9817 - val_loss: 0.0455 - val_accuracy: 0.9839\n",
      "Epoch 8/100\n",
      "233/233 [==============================] - 0s 1ms/step - loss: 0.0437 - accuracy: 0.9835 - val_loss: 0.0560 - val_accuracy: 0.9790\n",
      "Epoch 9/100\n",
      "233/233 [==============================] - 0s 1ms/step - loss: 0.0407 - accuracy: 0.9840 - val_loss: 0.0477 - val_accuracy: 0.9831\n",
      "Epoch 10/100\n",
      "233/233 [==============================] - 0s 1ms/step - loss: 0.0347 - accuracy: 0.9863 - val_loss: 0.0537 - val_accuracy: 0.9806\n",
      "Epoch 11/100\n",
      "233/233 [==============================] - 0s 1ms/step - loss: 0.0325 - accuracy: 0.9874 - val_loss: 0.0370 - val_accuracy: 0.9867\n",
      "Epoch 12/100\n",
      "233/233 [==============================] - 0s 1ms/step - loss: 0.0282 - accuracy: 0.9890 - val_loss: 0.0352 - val_accuracy: 0.9855\n",
      "Epoch 13/100\n",
      "233/233 [==============================] - 0s 1ms/step - loss: 0.0268 - accuracy: 0.9907 - val_loss: 0.0432 - val_accuracy: 0.9831\n",
      "Epoch 14/100\n",
      "233/233 [==============================] - 0s 1ms/step - loss: 0.0239 - accuracy: 0.9913 - val_loss: 0.0312 - val_accuracy: 0.9883\n",
      "Epoch 15/100\n",
      "233/233 [==============================] - 0s 1ms/step - loss: 0.0246 - accuracy: 0.9906 - val_loss: 0.0380 - val_accuracy: 0.9851\n",
      "Epoch 16/100\n",
      "233/233 [==============================] - 0s 1ms/step - loss: 0.0251 - accuracy: 0.9895 - val_loss: 0.0358 - val_accuracy: 0.9847\n",
      "Epoch 17/100\n",
      " 60/233 [======>.......................] - ETA: 0s - loss: 0.0207 - accuracy: 0.9911"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [37]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m X_train,y_train,X_val,y_val,name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m([X_over_synth_10_train,X_over_synth_30_train,X_over_synth_50_train,X_under_synth_10_train,X_under_synth_30_train,X_under_synth_50_train], \n\u001b[1;32m      5\u001b[0m                            [y_over_synth_10_train,y_over_synth_30_train,y_over_synth_50_train,y_under_synth_10_train,y_under_synth_30_train,y_under_synth_50_train],\n\u001b[1;32m      6\u001b[0m                            [X_over_synth_10_val,X_over_synth_30_val,X_over_synth_50_val,X_under_synth_10_val,X_under_synth_30_val,X_under_synth_50_val],\n\u001b[1;32m      7\u001b[0m                            [y_over_synth_10_val,y_over_synth_30_val,y_over_synth_50_val,y_under_synth_10_val,y_under_synth_30_val,y_under_synth_50_val],\n\u001b[1;32m      8\u001b[0m                            [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mover_synth_10\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mover_synth_30\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mover_synth_50\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munder_synth_10\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munder_synth_30\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munder_synth_50\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n\u001b[1;32m      9\u001b[0m     tm \u001b[38;5;241m=\u001b[39m TrainModel(X_train,y_train,X_val, y_val, X_test \u001b[38;5;241m=\u001b[39m X_test, y_test \u001b[38;5;241m=\u001b[39my_test,early_stopping\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 10\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mtm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     res_dict[name] \u001b[38;5;241m=\u001b[39m (res)\n",
      "Input \u001b[0;32mIn [36]\u001b[0m, in \u001b[0;36mTrainModel.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompile()\n\u001b[0;32m---> 52\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;66;03m# self.draw_the_loss_curve()\u001b[39;00m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluate()\n",
      "Input \u001b[0;32mIn [36]\u001b[0m, in \u001b[0;36mTrainModel.fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mearly_stopping:\n\u001b[1;32m     25\u001b[0m     early_stopping_cb \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatience, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;66;03m# set patience to 10 to accelerate the training\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimple_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping_cb\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msimple_model\u001b[38;5;241m.\u001b[39mfit(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_train, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_train,validation_data\u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_val, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_val),epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepochs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/adl-mtp/lib/python3.8/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/adl-mtp/lib/python3.8/site-packages/keras/engine/training.py:1216\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1209\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1210\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1211\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1212\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1213\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1214\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1215\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1216\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1217\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1218\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/adl-mtp/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/adl-mtp/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:910\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    907\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    909\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 910\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    912\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    913\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/adl-mtp/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:942\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    939\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    940\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    941\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 942\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    943\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/adl-mtp/lib/python3.8/site-packages/tensorflow/python/eager/function.py:3130\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3127\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   3128\u001b[0m   (graph_function,\n\u001b[1;32m   3129\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3131\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/adl-mtp/lib/python3.8/site-packages/tensorflow/python/eager/function.py:1959\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1955\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1956\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1957\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1958\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1959\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1960\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1961\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1962\u001b[0m     args,\n\u001b[1;32m   1963\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1964\u001b[0m     executing_eagerly)\n\u001b[1;32m   1965\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/adl-mtp/lib/python3.8/site-packages/tensorflow/python/eager/function.py:598\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    597\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 598\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    599\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    600\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    602\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    604\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    605\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    606\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    607\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    610\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    611\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/adl-mtp/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:58\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     57\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 58\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     61\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(192)\n",
    "res_dict = {} # FIXME\n",
    "for X_train,y_train,X_val,y_val,name in zip([X_over_synth_10_train,X_over_synth_30_train,X_over_synth_50_train,X_under_synth_10_train,X_under_synth_30_train,X_under_synth_50_train], \n",
    "                           [y_over_synth_10_train,y_over_synth_30_train,y_over_synth_50_train,y_under_synth_10_train,y_under_synth_30_train,y_under_synth_50_train],\n",
    "                           [X_over_synth_10_val,X_over_synth_30_val,X_over_synth_50_val,X_under_synth_10_val,X_under_synth_30_val,X_under_synth_50_val],\n",
    "                           [y_over_synth_10_val,y_over_synth_30_val,y_over_synth_50_val,y_under_synth_10_val,y_under_synth_30_val,y_under_synth_50_val],\n",
    "                           [\"over_synth_10\",\"over_synth_30\",\"over_synth_50\",\"under_synth_10\",\"under_synth_30\",\"under_synth_50\"]):\n",
    "    tm = TrainModel(X_train,y_train,X_val, y_val, X_test = X_test, y_test =y_test,early_stopping=True)\n",
    "    res = tm.run()\n",
    "    res_dict[name] = (res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key,value in res_dict.items():\n",
    "    print(f\"{key}:{value['roc']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(hp):\n",
    "    number_units = hp.Int('number_units', min_value=20, max_value=80, step=20)\n",
    "    dropout_rate = hp.Float('dropout_rate', min_value = 0.1, max_value=0.3) \n",
    "    # optim_algo = hp.Choice('optimizer', values=['sgd','adam']) \n",
    "    optim_algo = 'adam'\n",
    "    learning_rate = hp.Float('learning_rate', min_value = 0.001, max_value=1, sampling='log') \n",
    "    number_layers = hp.Int('number_layers', min_value=1, max_value=3) # hidden layers\n",
    "    activation = hp.Choice('activation', values=['relu','sigmoid'])\n",
    "    whether_dropout = hp.Choice('whether_dropout', values=[True,False])\n",
    "\n",
    "    if whether_dropout == True:\n",
    "        model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Dropout(dropout_rate),\n",
    "            tf.keras.layers.Dense(number_units, activation=activation)]*number_layers+[ # number_layers is the number of hidden layers\n",
    "            tf.keras.layers.Dense(1,activation='sigmoid')])\n",
    "    else:\n",
    "        model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Dense(number_units, activation=activation)]*number_layers+[ # number_layers is the number of hidden layers\n",
    "            tf.keras.layers.Dense(1,activation='sigmoid')])\n",
    "\n",
    "    if optim_algo== 'sgd':\n",
    "        # Note that exploding gradients can be a big problem when running regressions, especially under SGD\n",
    "        # Hence, we use \"gradient clipping\" with parameter alpha, which means that the gradients are manually kept between -1 and 1\n",
    "        # This is of course another hyperparameter that we might tune!\n",
    "        optimizer = tf.keras.optimizers.SGD(\n",
    "            learning_rate=learning_rate, clipvalue=1)\n",
    "    elif optim_algo == 'adam':\n",
    "        optimizer = tf.keras.optimizers.Adam(\n",
    "            learning_rate=learning_rate)\n",
    "\n",
    "    # random_seed = 192\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rm log file\n",
    "# ! rm -rf ./logs_over_synth_10/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project logs_over_synth_10/kt_tutorial_over_synth_10/oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from logs_over_synth_10/kt_tutorial_over_synth_10/tuner0.json\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "# Run the best model for X_over_synth_10_train\n",
    "tuner = kt.Hyperband(train_model,\n",
    "                     objective='val_loss',\n",
    "                     max_epochs=10,\n",
    "                     factor=3,\n",
    "                     directory='logs_over_synth_10',\n",
    "                     project_name='kt_tutorial_over_synth_10')\n",
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(48)\n",
    "tuner.search(X_over_synth_10_train, y_over_synth_10_train, epochs=10, validation_data =(X_over_synth_10_val,y_over_synth_10_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hps = tuner.get_best_hyperparameters()[0]\n",
    "best_model = tuner.hypermodel.build(best_hps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "233/233 [==============================] - 0s 1ms/step - loss: 0.2074 - val_loss: 0.1455\n",
      "Epoch 2/100\n",
      "233/233 [==============================] - 0s 853us/step - loss: 0.1354 - val_loss: 0.1195\n",
      "Epoch 3/100\n",
      "233/233 [==============================] - 0s 1ms/step - loss: 0.1110 - val_loss: 0.0909\n",
      "Epoch 4/100\n",
      "233/233 [==============================] - 0s 822us/step - loss: 0.0895 - val_loss: 0.0774\n",
      "Epoch 5/100\n",
      "233/233 [==============================] - 0s 870us/step - loss: 0.0754 - val_loss: 0.0675\n",
      "Epoch 6/100\n",
      "233/233 [==============================] - 0s 838us/step - loss: 0.0679 - val_loss: 0.0604\n",
      "Epoch 7/100\n",
      "233/233 [==============================] - 0s 810us/step - loss: 0.0600 - val_loss: 0.0593\n",
      "Epoch 8/100\n",
      "233/233 [==============================] - 0s 859us/step - loss: 0.0579 - val_loss: 0.0603\n",
      "Epoch 9/100\n",
      "233/233 [==============================] - 0s 900us/step - loss: 0.0505 - val_loss: 0.0496\n",
      "Epoch 10/100\n",
      "233/233 [==============================] - 0s 851us/step - loss: 0.0446 - val_loss: 0.0521\n",
      "Epoch 11/100\n",
      "233/233 [==============================] - 0s 863us/step - loss: 0.0402 - val_loss: 0.0520\n",
      "Epoch 12/100\n",
      "233/233 [==============================] - 0s 903us/step - loss: 0.0413 - val_loss: 0.0480\n",
      "Epoch 13/100\n",
      "233/233 [==============================] - 0s 895us/step - loss: 0.0360 - val_loss: 0.0452\n",
      "Epoch 14/100\n",
      "233/233 [==============================] - 0s 892us/step - loss: 0.0356 - val_loss: 0.0473\n",
      "Epoch 15/100\n",
      "233/233 [==============================] - 0s 873us/step - loss: 0.0313 - val_loss: 0.0444\n",
      "Epoch 16/100\n",
      "233/233 [==============================] - 0s 874us/step - loss: 0.0329 - val_loss: 0.0432\n",
      "Epoch 17/100\n",
      "233/233 [==============================] - 0s 849us/step - loss: 0.0289 - val_loss: 0.0499\n",
      "Epoch 18/100\n",
      "233/233 [==============================] - 0s 870us/step - loss: 0.0303 - val_loss: 0.0446\n",
      "Epoch 19/100\n",
      "233/233 [==============================] - 0s 814us/step - loss: 0.0291 - val_loss: 0.0448\n",
      "Epoch 20/100\n",
      "233/233 [==============================] - 0s 791us/step - loss: 0.0305 - val_loss: 0.0404\n",
      "Epoch 21/100\n",
      "233/233 [==============================] - 0s 787us/step - loss: 0.0227 - val_loss: 0.0476\n",
      "Epoch 22/100\n",
      "233/233 [==============================] - 0s 779us/step - loss: 0.0253 - val_loss: 0.0457\n",
      "Epoch 23/100\n",
      "233/233 [==============================] - 0s 842us/step - loss: 0.0222 - val_loss: 0.0431\n",
      "Epoch 24/100\n",
      "233/233 [==============================] - 0s 819us/step - loss: 0.0217 - val_loss: 0.0459\n",
      "Epoch 25/100\n",
      "233/233 [==============================] - 0s 812us/step - loss: 0.0220 - val_loss: 0.0399\n",
      "Epoch 26/100\n",
      "233/233 [==============================] - 0s 1ms/step - loss: 0.0206 - val_loss: 0.0386\n",
      "Epoch 27/100\n",
      "233/233 [==============================] - 0s 1ms/step - loss: 0.0232 - val_loss: 0.0365\n",
      "Epoch 28/100\n",
      "233/233 [==============================] - 0s 1ms/step - loss: 0.0184 - val_loss: 0.0693\n",
      "Epoch 29/100\n",
      "233/233 [==============================] - 0s 840us/step - loss: 0.0200 - val_loss: 0.0345\n",
      "Epoch 30/100\n",
      "233/233 [==============================] - 0s 799us/step - loss: 0.0215 - val_loss: 0.0401\n",
      "Epoch 31/100\n",
      "233/233 [==============================] - 0s 788us/step - loss: 0.0197 - val_loss: 0.0347\n",
      "Epoch 32/100\n",
      "233/233 [==============================] - 0s 787us/step - loss: 0.0174 - val_loss: 0.0369\n",
      "Epoch 33/100\n",
      "233/233 [==============================] - 0s 809us/step - loss: 0.0196 - val_loss: 0.0343\n",
      "Epoch 34/100\n",
      "233/233 [==============================] - 0s 794us/step - loss: 0.0171 - val_loss: 0.0488\n",
      "Epoch 35/100\n",
      "233/233 [==============================] - 0s 853us/step - loss: 0.0179 - val_loss: 0.0386\n",
      "Epoch 36/100\n",
      "233/233 [==============================] - 0s 797us/step - loss: 0.0160 - val_loss: 0.0385\n",
      "Epoch 37/100\n",
      "233/233 [==============================] - 0s 794us/step - loss: 0.0181 - val_loss: 0.0387\n",
      "Epoch 38/100\n",
      "233/233 [==============================] - 0s 805us/step - loss: 0.0200 - val_loss: 0.0417\n",
      "Epoch 39/100\n",
      "233/233 [==============================] - 0s 805us/step - loss: 0.0157 - val_loss: 0.0396\n",
      "Epoch 40/100\n",
      "233/233 [==============================] - 0s 880us/step - loss: 0.0174 - val_loss: 0.0420\n",
      "Epoch 41/100\n",
      "233/233 [==============================] - 0s 880us/step - loss: 0.0169 - val_loss: 0.0387\n",
      "Epoch 42/100\n",
      "233/233 [==============================] - 0s 868us/step - loss: 0.0154 - val_loss: 0.0372\n",
      "Epoch 43/100\n",
      "233/233 [==============================] - 0s 937us/step - loss: 0.0162 - val_loss: 0.0402\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(48)\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True) # set patience to 10 to accelerate the training\n",
    "log = best_model.fit(X_over_synth_10_train, y_over_synth_10_train, epochs=100, validation_data =(X_over_synth_10_val,y_over_synth_10_val),callbacks=[early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_plot(log):\n",
    "    # plt.plot(log.history['accuracy'],label = \"training accuracy\",color='green')\n",
    "    plt.plot(log.history['loss'],label = \"training loss\",color='darkgreen')\n",
    "    # plt.plot(log.history['val_accuracy'], label = \"validation accuracy\",color='grey')\n",
    "    plt.plot(log.history['val_loss'], label = \"validation loss\",color='darkblue')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "create_plot(log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the best model in question 5\n",
    "# best_model.save('./best_model_question_5.h5')\n",
    "\n",
    "# load the best model in question 5\n",
    "best_model=None\n",
    "best_model = tf.keras.models.load_model('./models/best_model_question_5.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model on the test dataset, and we can find that our ROC score is about 0.82 which is good. In the next part, we are going to select the threshold to predcit the fraud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 0s 500us/step - loss: 0.5465\n",
      "loss:0.5464516282081604\n",
      "roc:0.7800475424975203\n"
     ]
    }
   ],
   "source": [
    "loss = best_model.evaluate(X_test, y_test)\n",
    "y_test_predict = best_model.predict(X_test).flatten()\n",
    "# calculate the roc\n",
    "roc_score = roc_auc_score(y_test, y_test_predict)\n",
    "print(f\"loss:{loss}\")\n",
    "print(f\"roc:{roc_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since it is more costly to miss the fraud cases, and less costly to make a false alarm, we are going to suppose that the cost missed fraud is 10 times more than the cost of false alarm (This ratio can be adjusted to the real case).\n",
    "Thus, our cost function is:\n",
    "\n",
    "```Cost = 10*FN + FP```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cost(fn,fp):\n",
    "    return 20*fn+fp\n",
    "\n",
    "cost_lost = {}\n",
    "for i in np.linspace(0,0.1,501):\n",
    "    pred_y = np.where(y_test_predict.flatten()> i, 1, 0)\n",
    "    cm = confusion_matrix(y_test,pred_y)\n",
    "    fn,fp = cm[1][0],cm[0][1]\n",
    "    # cost_lost[\"Threshold: \"+str(i)] = calculate_cost(fn,fp)\n",
    "    cost_lost[i] = calculate_cost(fn,fp)\n",
    "\n",
    "optimal_threshold = min(cost_lost, key=cost_lost.get)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix is :\n",
      "[[2053  196]\n",
      " [  20    6]]\n",
      "Accuracy rate is 0.9050549450549451\n",
      "Sensitivity is 0.23076923076923078\n"
     ]
    }
   ],
   "source": [
    "pred_y = np.where(y_test_predict > optimal_threshold, 1, 0)\n",
    "cm = confusion_matrix(y_test, pred_y)\n",
    "print(f\"Confusion matrix is :\" )\n",
    "print(cm)\n",
    "accuracy_rate = (cm[0,0] + cm[1,1])/np.sum(cm)\n",
    "print(f\"Accuracy rate is {accuracy_rate}\")\n",
    "# calculate the sensitivity \n",
    "sensitivity = cm[1,1]/(cm[1,1] + cm[1,0])\n",
    "print(f\"Sensitivity is {sensitivity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6\n",
    "### Question\n",
    "Our second approach will be to use an autoencoder to learn what \"normal\" (non-fraudulent) data \"looks like.\"\n",
    "\n",
    "1. Prepare dataset for autoencoder\n",
    "\n",
    "   - Using the original data, create a training set that contains only non fraudulent claims\n",
    "   - As well as validation and test sets that contain non fraudulent and fraudulent claims. \n",
    "   - Make sure to spread fraudulent claims evenly across validation and test sets.\n",
    "\n",
    "2. Create an autoencoder using TensorFlow\n",
    "\n",
    "   - Ensure that the middle hidden layer has fewer neurons than your input features. \n",
    "   - Use training and validation sets to find a model that represents its input data well. In particular, you will want to predict your validation set observations. \n",
    "   - For each observation, you can measure the difference between the original observations and the predicted one, using, for example, the mean squared error of all features of the observation. \n",
    "   - Plot the errors for all your validation set observations in a histogram - in a good model, this error should be much higher for fraudulent claims than non-fraudulent ones.\n",
    "\n",
    "3. Assess predictions of autoencoder created\n",
    "\n",
    "   - Use your trained autoencoder to predict the test set and define the corresponding losses(?). \n",
    "   - Create a histogram of your test set claims, clearly marking fraudulent and non- fraudulent claims. \n",
    "   - Discuss how you could use this to decide whether a transaction is fraudulent or not. \n",
    "   - Can you also derive an AUC in this approach - if yes, how does it perform compared to the previous approaches?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of normal_df: 11259\n",
      "The length of fraud_df: 112\n",
      "normal_train_size: 9097\n",
      "fraud_val_test_size: 56\n",
      "normal_val_test_size: 1081\n",
      "\n",
      "len(train_df): 9097\n",
      "len(normal_df) excluding data in train_df: 2162\n",
      "\n",
      "len(val_df): 1081\n",
      "len(test_df): 1081\n",
      "\n",
      "len(test[test.LossDate == False]) = 0\n",
      "\n",
      "len(val_df): 1137\n",
      "len(test_df): 1137\n",
      "\n",
      "Check if len(train_df) + len(val_df) + len(test_df) == len(df_autoencoder): True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_11724/3527323588.py:35: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  val_df = val_df.append(fraud_df.sample(fraud_val_test_size, random_state=0))\n",
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_11724/3527323588.py:36: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  test_df = test_df.append(fraud_df[~fraud_df.isin(val_df)].dropna())\n"
     ]
    }
   ],
   "source": [
    "# get a copy of raw df\n",
    "\n",
    "df_autoencoder = df.copy()\n",
    "# split dataset into non-fraud (normal) and fraud\n",
    "normal_df = df_autoencoder[df_autoencoder.Fraud == 0]\n",
    "fraud_df = df_autoencoder[df_autoencoder.Fraud == 1]\n",
    "print(f'The length of normal_df: {len(normal_df)}')\n",
    "print(f'The length of fraud_df: {len(fraud_df)}')\n",
    "\n",
    "# variables for splitting data into train, val and test sets \n",
    "train_split = 0.8\n",
    "test_split = 1 - train_split\n",
    "normal_train_size = round(len(df_autoencoder) * train_split)\n",
    "fraud_val_test_size = int(len(fraud_df) / 2)\n",
    "normal_val_test_size = int(round(len(df_autoencoder) * test_split / 2) - fraud_val_test_size)\n",
    "print(f'normal_train_size: {normal_train_size}')\n",
    "print(f'fraud_val_test_size: {fraud_val_test_size}')\n",
    "print(f'normal_val_test_size: {normal_val_test_size}\\n')\n",
    "\n",
    "# sample non-fraud data for train set\n",
    "train_df = normal_df.sample(normal_train_size, random_state=0)\n",
    "normal_df = normal_df[~normal_df.isin(train_df)].dropna()\n",
    "print(f'len(train_df): {len(train_df)}')\n",
    "print(f'len(normal_df) excluding data in train_df: {len(normal_df)}\\n')\n",
    "\n",
    "# sample non-fraud data for val and test sets\n",
    "val_df = normal_df.sample(normal_val_test_size, random_state=0)\n",
    "test_df = normal_df[~normal_df.isin(val_df)].dropna()\n",
    "print(f'len(val_df): {len(val_df)}')\n",
    "print(f'len(test_df): {len(test_df)}\\n')\n",
    "\n",
    "# check if all normal data is in the train, val and test sets\n",
    "normal_df = df_autoencoder[df_autoencoder.Fraud == 0]\n",
    "test = pd.concat([train_df, val_df, test_df]).isin(normal_df)\n",
    "print(f'len(test[test.LossDate == False]) = {len(test[test.LossDate == False])}\\n')\n",
    "\n",
    "# sample fraud data for val and test sets\n",
    "val_df = val_df.append(fraud_df.sample(fraud_val_test_size, random_state=0))\n",
    "test_df = test_df.append(fraud_df[~fraud_df.isin(val_df)].dropna())\n",
    "print(f'len(val_df): {len(val_df)}')\n",
    "print(f'len(test_df): {len(test_df)}\\n')\n",
    "\n",
    "print(f'Check if len(train_df) + len(val_df) + len(test_df) == len(df_autoencoder): {len(train_df) + len(val_df) + len(test_df) == len(df_autoencoder)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn the dataframe into numpy arrays\n",
    "y_train = train_df[['Fraud']].to_numpy()\n",
    "y_val = val_df[['Fraud']].to_numpy()\n",
    "y_test = test_df[['Fraud']].to_numpy()\n",
    "\n",
    "X_train = train_df.drop(['Fraud'], axis=1)\n",
    "X_val = val_df.drop(['Fraud'], axis=1)\n",
    "X_test = test_df.drop(['Fraud'], axis=1)\n",
    "\n",
    "train_col_names = list(X_train.columns)+['df_key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check if len(X_train) + len(X_val) + len(X_test) == len(df_autoencoder): True\n",
      "X_train.shape: (9097, 65)\n",
      "X_val.shape: (1137, 65)\n",
      "X_test.shape: (1137, 65)\n"
     ]
    }
   ],
   "source": [
    "# Fit the MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train.loc[:,'df_key'] = 1\n",
    "X_val.loc[:,'df_key'] = 0\n",
    "X_test.loc[:,'df_key'] = 0\n",
    "X_train_val = pd.concat([X_train, X_val])\n",
    "# X_df_key = X_train_val[['df_key']]\n",
    "# X_train_val = X_train_val.drop(['df_key'], axis=1)\n",
    "\n",
    "X_train_val = pd.DataFrame(scaler.fit_transform(X_train_val), columns=train_col_names)\n",
    "X_test = pd.DataFrame(scaler.transform(X_test), columns=train_col_names)\n",
    "X_test = X_test.drop(['df_key'], axis=1)\n",
    "X_train = X_train_val[X_train_val.df_key == 1].drop(['df_key'], axis=1)\n",
    "X_val = X_train_val[X_train_val.df_key == 0].drop(['df_key'], axis=1)\n",
    "\n",
    "print(f'check if len(X_train) + len(X_val) + len(X_test) == len(df_autoencoder): {len(X_train) + len(X_val) + len(X_test) == len(df_autoencoder)}')\n",
    "print(f\"X_train.shape: {X_train.shape}\")\n",
    "print(f\"X_val.shape: {X_val.shape}\")\n",
    "print(f\"X_test.shape: {X_test.shape}\")\n",
    "X_train = X_train.to_numpy()\n",
    "X_val = X_val.to_numpy()\n",
    "X_test = X_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Question 6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_train,X_train_val, y_train_train, y_train_val = train_test_split(X_train, y_train, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncodingModel:\n",
    "    def __init__(self, reg_param, number_units_layers, number_units_bottleneck, dropout_rate, number_layers, whether_dropout, whether_regularizer, X_train_train=X_train_train, X_train_val=X_train_val, X_val=X_val,epochs=100) -> None:\n",
    "        tf.keras.backend.clear_session()\n",
    "        tf.random.set_seed(48)\n",
    "        self.X_train_train = X_train_train\n",
    "        self.X_train_val = X_train_val\n",
    "        self.X_val = X_val\n",
    "        self.reg_param = reg_param\n",
    "        self.number_units_layers = number_units_layers\n",
    "        self.number_units_bottleneck = number_units_bottleneck\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.number_layers = number_layers\n",
    "        self.whether_dropout =  whether_dropout\n",
    "        self.whether_regularizer = whether_regularizer\n",
    "        self.input_dim = self.X_train_train.shape[1]\n",
    "        self.epochs  = epochs\n",
    "        self.build_model()\n",
    "        self.compile_model()\n",
    "\n",
    "    def build_model(self):\n",
    "        \"\"\"\n",
    "        Build the model according to the hyperparameters input\n",
    "        \"\"\"\n",
    "        regularizer = tf.keras.regularizers.l2(\n",
    "            self.reg_param*self.whether_regularizer)\n",
    "        if self.whether_dropout == True:\n",
    "            encoder = tf.keras.models.Sequential([\n",
    "                tf.keras.layers.Dense(self.number_units_layers, activation=\"relu\")]*self.number_layers+[\n",
    "                tf.keras.layers.Dropout(self.dropout_rate), # dropout before the bottleneck layer\n",
    "                tf.keras.layers.Dense(self.number_units_bottleneck,activation='sigmoid', kernel_regularizer=regularizer)])\n",
    "        else:\n",
    "            encoder = tf.keras.models.Sequential([\n",
    "                tf.keras.layers.Dense(self.number_units_layers, activation=\"relu\")]*self.number_layers+[\n",
    "                tf.keras.layers.Dense(self.input_dim,activation='sigmoid')])\n",
    "        decoder = tf.keras.models.Sequential([\n",
    "                tf.keras.layers.Dense(self.number_units_layers, activation=\"relu\")]*self.number_layers+[\n",
    "                tf.keras.layers.Dense(self.input_dim, activation=\"sigmoid\")])\n",
    "        self.autoencoder = tf.keras.models.Sequential([encoder, decoder])\n",
    "\n",
    "        # random_seed = 192\n",
    "    def get_hp(self):\n",
    "        # get all hyperparameters\n",
    "        return {\n",
    "            'reg_param': self.reg_param,\n",
    "            'number_units_layers': self.number_units_layers,\n",
    "            'number_units_bottleneck': self.number_units_bottleneck,\n",
    "            'dropout_rate': self.dropout_rate,\n",
    "            'number_layers': self.number_layers,\n",
    "            'whether_dropout': self.whether_dropout,\n",
    "            'whether_regularizer': self.whether_regularizer\n",
    "        }\n",
    "\n",
    "    def get_model(self):\n",
    "        \"\"\"\n",
    "        get the model from the class\n",
    "        \"\"\"\n",
    "        return self.autoencoder\n",
    "\n",
    "    def compile_model(self):\n",
    "        \"\"\"\n",
    "        compile the model\n",
    "        \"\"\"\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "        self.autoencoder.compile(\n",
    "            optimizer=optimizer, loss='mean_squared_error')\n",
    "\n",
    "    def __train_model(self):\n",
    "        \"\"\"\n",
    "        Train the data only contains non-fraud claims\n",
    "        \"\"\"\n",
    "        early_stopping_cb = tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "        self.log_train_non_fraud = self.autoencoder.fit(x=self.X_train_train, y=self.X_train_train,\n",
    "                                                        epochs=self.epochs,\n",
    "                                                        validation_data=(X_train_val, X_train_val), callbacks=[early_stopping_cb])\n",
    "\n",
    "    def get_train_non_fraud_loss_diff(self):\n",
    "        \"\"\"\n",
    "        calculate the overfit_metric\n",
    "        \"\"\"\n",
    "        self.__train_model()\n",
    "        return self.log_train_non_fraud.history['val_loss'][-1]-self.log_train_non_fraud.history['loss'][-1] \n",
    "        \n",
    "    def get_train_val_loss(self):\n",
    "        \"\"\"\n",
    "        get the val1_loss\n",
    "        \"\"\"\n",
    "        return self.log_train_non_fraud.history['val_loss'][-1]\n",
    "\n",
    "    def __apply_model_fraud(self):\n",
    "        \"\"\"\n",
    "        apply the model on the val2, and get the overall average mse loss\n",
    "        \"\"\"\n",
    "        reconstructions = self.autoencoder.predict(self.X_val)\n",
    "        self.val_loss = np.mean(tf.keras.losses.mse(reconstructions, self.X_val))\n",
    "\n",
    "    def get_val_loss(self):\n",
    "        self.__apply_model_fraud()\n",
    "        return self.val_loss\n",
    "\n",
    "    def run(self):\n",
    "        # the difference of loss in the train_train and train_val, the metric to access the overfitting\n",
    "        overfit_metric = self.get_train_non_fraud_loss_diff()  #TODO change it to overfit_metric\n",
    "        val2_avg_recon_error = self.get_val_loss() #TODO change it to val2_avg_recon_error\n",
    "        val1_loss = self.get_train_val_loss()  #TODO change it to val1_loss\n",
    "        return {\"overfit_metric\": overfit_metric, \"val2_avg_recon_error\": val2_avg_recon_error, \"val1_loss\":val1_loss, \"model\": self.autoencoder, \"log\":self.log_train_non_fraud}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a list of hyperparameters and train the model. After trainnig the model, we will record the hyperparameters and the performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This round is 0\n",
      "Epoch 1/100\n",
      "199/199 [==============================] - 1s 1ms/step - loss: 0.0862 - val_loss: 0.0526\n",
      "Epoch 2/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0438 - val_loss: 0.0382\n",
      "Epoch 3/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0368 - val_loss: 0.0353\n",
      "Epoch 4/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0340 - val_loss: 0.0316\n",
      "Epoch 5/100\n",
      "199/199 [==============================] - 1s 3ms/step - loss: 0.0287 - val_loss: 0.0250\n",
      "Epoch 6/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0226 - val_loss: 0.0205\n",
      "Epoch 7/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0198 - val_loss: 0.0187\n",
      "Epoch 8/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0182 - val_loss: 0.0174\n",
      "Epoch 9/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0171 - val_loss: 0.0163\n",
      "Epoch 10/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0160 - val_loss: 0.0152\n",
      "Epoch 11/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.0139\n",
      "Epoch 12/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0136 - val_loss: 0.0128\n",
      "Epoch 13/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0126 - val_loss: 0.0120\n",
      "Epoch 14/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0118 - val_loss: 0.0114\n",
      "Epoch 15/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0112 - val_loss: 0.0108\n",
      "Epoch 16/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.0103\n",
      "Epoch 17/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0098\n",
      "Epoch 18/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.0093\n",
      "Epoch 19/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0088\n",
      "Epoch 20/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0084\n",
      "Epoch 21/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.0079\n",
      "Epoch 22/100\n",
      "199/199 [==============================] - 0s 983us/step - loss: 0.0077 - val_loss: 0.0075\n",
      "Epoch 23/100\n",
      "199/199 [==============================] - 0s 953us/step - loss: 0.0073 - val_loss: 0.0072\n",
      "Epoch 24/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0070 - val_loss: 0.0068\n",
      "Epoch 25/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0066 - val_loss: 0.0064\n",
      "Epoch 26/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0062 - val_loss: 0.0061\n",
      "Epoch 27/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0058\n",
      "Epoch 28/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0057 - val_loss: 0.0055\n",
      "Epoch 29/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0054 - val_loss: 0.0053\n",
      "Epoch 30/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0051 - val_loss: 0.0050\n",
      "Epoch 31/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 32/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 33/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 34/100\n",
      "199/199 [==============================] - 0s 964us/step - loss: 0.0045 - val_loss: 0.0044\n",
      "Epoch 35/100\n",
      "199/199 [==============================] - 0s 956us/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 36/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0042\n",
      "Epoch 37/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0042\n",
      "Epoch 38/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0040 - val_loss: 0.0041\n",
      "Epoch 39/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 40/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 41/100\n",
      "199/199 [==============================] - 0s 978us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 42/100\n",
      "199/199 [==============================] - 0s 958us/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 43/100\n",
      "199/199 [==============================] - 0s 971us/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 44/100\n",
      "199/199 [==============================] - 0s 973us/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 45/100\n",
      "199/199 [==============================] - 0s 948us/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 46/100\n",
      "199/199 [==============================] - 0s 965us/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 47/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 48/100\n",
      "199/199 [==============================] - 0s 972us/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 49/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 50/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0032 - val_loss: 0.0034\n",
      "Epoch 51/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 52/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0031 - val_loss: 0.0033\n",
      "Epoch 53/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 54/100\n",
      "199/199 [==============================] - 0s 950us/step - loss: 0.0030 - val_loss: 0.0032\n",
      "Epoch 55/100\n",
      "199/199 [==============================] - 0s 947us/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 56/100\n",
      "199/199 [==============================] - 0s 945us/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 57/100\n",
      "199/199 [==============================] - 0s 986us/step - loss: 0.0028 - val_loss: 0.0029\n",
      "Epoch 58/100\n",
      "199/199 [==============================] - 0s 995us/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 59/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 60/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 61/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 62/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 63/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 64/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 65/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0024 - val_loss: 0.0026\n",
      "Epoch 66/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0024 - val_loss: 0.0026\n",
      "Epoch 67/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0024 - val_loss: 0.0026\n",
      "Epoch 68/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 69/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 70/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 71/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 72/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 73/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 74/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 75/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 76/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 77/100\n",
      "199/199 [==============================] - 0s 993us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 78/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 79/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 80/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 81/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 82/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 83/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 84/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 85/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 86/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 87/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 88/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 89/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 90/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 91/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 92/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 93/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 94/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 95/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 96/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 97/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 98/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 99/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 100/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0019 - val_loss: 0.0022\n",
      "This round is 1\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_11724/328462441.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  para_dfm = para_dfm.append({\"reg_param\": reg_param, \"number_units_layers\": numbers_units_layers, \"number_units_bottleneck\": numbers_units_bottleneck, \"dropout_rate\": dropout_rate, \"number_layers\": numbers_layers, \"whether_dropout\": whether_dropout, \"whether_regularizer\": whether_regularizer, \"overfit_metric\": overfit_metric, \"val2_avg_recon_error\": val2_avg_recon_error,'val1_loss':val1_loss}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 1s 2ms/step - loss: 1.8685 - val_loss: 0.5400\n",
      "Epoch 2/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.2335 - val_loss: 0.0891\n",
      "Epoch 3/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0656 - val_loss: 0.0563\n",
      "Epoch 4/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0554 - val_loss: 0.0550\n",
      "Epoch 5/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0551 - val_loss: 0.0551\n",
      "Epoch 6/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0551 - val_loss: 0.0550\n",
      "Epoch 7/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0551 - val_loss: 0.0550\n",
      "Epoch 8/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0551 - val_loss: 0.0551\n",
      "Epoch 9/100\n",
      "199/199 [==============================] - 0s 999us/step - loss: 0.0551 - val_loss: 0.0550\n",
      "Epoch 10/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0551 - val_loss: 0.0550\n",
      "Epoch 11/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0551 - val_loss: 0.0550\n",
      "Epoch 12/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0550 - val_loss: 0.0550\n",
      "Epoch 13/100\n",
      "199/199 [==============================] - 0s 964us/step - loss: 0.0550 - val_loss: 0.0550\n",
      "Epoch 14/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0549 - val_loss: 0.0548\n",
      "Epoch 15/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0545 - val_loss: 0.0536\n",
      "Epoch 16/100\n",
      "199/199 [==============================] - 0s 984us/step - loss: 0.0485 - val_loss: 0.0434\n",
      "Epoch 17/100\n",
      "199/199 [==============================] - 0s 978us/step - loss: 0.0420 - val_loss: 0.0407\n",
      "Epoch 18/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0403 - val_loss: 0.0396\n",
      "Epoch 19/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0395 - val_loss: 0.0389\n",
      "Epoch 20/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0389 - val_loss: 0.0384\n",
      "Epoch 21/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0384 - val_loss: 0.0381\n",
      "Epoch 22/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0381 - val_loss: 0.0377\n",
      "Epoch 23/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0378 - val_loss: 0.0374\n",
      "Epoch 24/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0375 - val_loss: 0.0371\n",
      "Epoch 25/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0373 - val_loss: 0.0369\n",
      "Epoch 26/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0371 - val_loss: 0.0368\n",
      "Epoch 27/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0370 - val_loss: 0.0367\n",
      "Epoch 28/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0368 - val_loss: 0.0366\n",
      "Epoch 29/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0368 - val_loss: 0.0365\n",
      "Epoch 30/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0367 - val_loss: 0.0364\n",
      "Epoch 31/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0366 - val_loss: 0.0364\n",
      "Epoch 32/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0366 - val_loss: 0.0363\n",
      "Epoch 33/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0365 - val_loss: 0.0363\n",
      "Epoch 34/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0365 - val_loss: 0.0363\n",
      "Epoch 35/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0365 - val_loss: 0.0362\n",
      "Epoch 36/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0365 - val_loss: 0.0362\n",
      "Epoch 37/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0364 - val_loss: 0.0361\n",
      "Epoch 38/100\n",
      "199/199 [==============================] - 0s 983us/step - loss: 0.0363 - val_loss: 0.0363\n",
      "Epoch 39/100\n",
      "199/199 [==============================] - 0s 987us/step - loss: 0.0363 - val_loss: 0.0361\n",
      "Epoch 40/100\n",
      "199/199 [==============================] - 0s 988us/step - loss: 0.0363 - val_loss: 0.0362\n",
      "Epoch 41/100\n",
      "199/199 [==============================] - 0s 982us/step - loss: 0.0363 - val_loss: 0.0364\n",
      "Epoch 42/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0362 - val_loss: 0.0361\n",
      "Epoch 43/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0362 - val_loss: 0.0360\n",
      "Epoch 44/100\n",
      "199/199 [==============================] - 0s 965us/step - loss: 0.0362 - val_loss: 0.0362\n",
      "Epoch 45/100\n",
      "199/199 [==============================] - 0s 967us/step - loss: 0.0362 - val_loss: 0.0360\n",
      "Epoch 46/100\n",
      "199/199 [==============================] - 0s 975us/step - loss: 0.0361 - val_loss: 0.0360\n",
      "Epoch 47/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0362 - val_loss: 0.0360\n",
      "Epoch 48/100\n",
      "199/199 [==============================] - 0s 993us/step - loss: 0.0362 - val_loss: 0.0359\n",
      "Epoch 49/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0361 - val_loss: 0.0359\n",
      "Epoch 50/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0361 - val_loss: 0.0360\n",
      "Epoch 51/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0361 - val_loss: 0.0359\n",
      "Epoch 52/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0360 - val_loss: 0.0358\n",
      "Epoch 53/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0361 - val_loss: 0.0359\n",
      "Epoch 54/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0361 - val_loss: 0.0364\n",
      "Epoch 55/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0360 - val_loss: 0.0361\n",
      "Epoch 56/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0360 - val_loss: 0.0360\n",
      "Epoch 57/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0360 - val_loss: 0.0357\n",
      "Epoch 58/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0359 - val_loss: 0.0357\n",
      "Epoch 59/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0358 - val_loss: 0.0358\n",
      "Epoch 60/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0358 - val_loss: 0.0357\n",
      "Epoch 61/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0357 - val_loss: 0.0355\n",
      "Epoch 62/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0356 - val_loss: 0.0354\n",
      "Epoch 63/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0356 - val_loss: 0.0354\n",
      "Epoch 64/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0356 - val_loss: 0.0353\n",
      "Epoch 65/100\n",
      "199/199 [==============================] - 0s 970us/step - loss: 0.0354 - val_loss: 0.0355\n",
      "Epoch 66/100\n",
      "199/199 [==============================] - 0s 984us/step - loss: 0.0353 - val_loss: 0.0350\n",
      "Epoch 67/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0353 - val_loss: 0.0350\n",
      "Epoch 68/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0351 - val_loss: 0.0348\n",
      "Epoch 69/100\n",
      "199/199 [==============================] - 0s 993us/step - loss: 0.0350 - val_loss: 0.0348\n",
      "Epoch 70/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0349 - val_loss: 0.0349\n",
      "Epoch 71/100\n",
      "199/199 [==============================] - 0s 972us/step - loss: 0.0349 - val_loss: 0.0347\n",
      "Epoch 72/100\n",
      "199/199 [==============================] - 0s 976us/step - loss: 0.0348 - val_loss: 0.0346\n",
      "Epoch 73/100\n",
      "199/199 [==============================] - 0s 978us/step - loss: 0.0348 - val_loss: 0.0345\n",
      "Epoch 74/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0348 - val_loss: 0.0346\n",
      "Epoch 75/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0346 - val_loss: 0.0344\n",
      "Epoch 76/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0346 - val_loss: 0.0342\n",
      "Epoch 77/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0344 - val_loss: 0.0344\n",
      "Epoch 78/100\n",
      "199/199 [==============================] - 0s 965us/step - loss: 0.0343 - val_loss: 0.0340\n",
      "Epoch 79/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0341 - val_loss: 0.0340\n",
      "Epoch 80/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0341 - val_loss: 0.0337\n",
      "Epoch 81/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0338 - val_loss: 0.0334\n",
      "Epoch 82/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0336 - val_loss: 0.0332\n",
      "Epoch 83/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0334 - val_loss: 0.0329\n",
      "Epoch 84/100\n",
      "199/199 [==============================] - 0s 979us/step - loss: 0.0331 - val_loss: 0.0328\n",
      "Epoch 85/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0328 - val_loss: 0.0324\n",
      "Epoch 86/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0325 - val_loss: 0.0324\n",
      "Epoch 87/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0325 - val_loss: 0.0320\n",
      "Epoch 88/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0323 - val_loss: 0.0318\n",
      "Epoch 89/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0320 - val_loss: 0.0318\n",
      "Epoch 90/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0319 - val_loss: 0.0316\n",
      "Epoch 91/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0317 - val_loss: 0.0315\n",
      "Epoch 92/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0315 - val_loss: 0.0311\n",
      "Epoch 93/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0314 - val_loss: 0.0310\n",
      "Epoch 94/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0311 - val_loss: 0.0313\n",
      "Epoch 95/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0309 - val_loss: 0.0308\n",
      "Epoch 96/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0308 - val_loss: 0.0304\n",
      "Epoch 97/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0307 - val_loss: 0.0303\n",
      "Epoch 98/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0306 - val_loss: 0.0305\n",
      "Epoch 99/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0305 - val_loss: 0.0301\n",
      "Epoch 100/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0303 - val_loss: 0.0300\n",
      "This round is 2\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_11724/328462441.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  para_dfm = para_dfm.append({\"reg_param\": reg_param, \"number_units_layers\": numbers_units_layers, \"number_units_bottleneck\": numbers_units_bottleneck, \"dropout_rate\": dropout_rate, \"number_layers\": numbers_layers, \"whether_dropout\": whether_dropout, \"whether_regularizer\": whether_regularizer, \"overfit_metric\": overfit_metric, \"val2_avg_recon_error\": val2_avg_recon_error,'val1_loss':val1_loss}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0722 - val_loss: 0.0392\n",
      "Epoch 2/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0343 - val_loss: 0.0297\n",
      "Epoch 3/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0254 - val_loss: 0.0215\n",
      "Epoch 4/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0192 - val_loss: 0.0170\n",
      "Epoch 5/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0160 - val_loss: 0.0147\n",
      "Epoch 6/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0134 - val_loss: 0.0121\n",
      "Epoch 7/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0112 - val_loss: 0.0106\n",
      "Epoch 8/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0097\n",
      "Epoch 9/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0090\n",
      "Epoch 10/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0083\n",
      "Epoch 11/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0077 - val_loss: 0.0076\n",
      "Epoch 12/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0071 - val_loss: 0.0070\n",
      "Epoch 13/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0065 - val_loss: 0.0065\n",
      "Epoch 14/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0059\n",
      "Epoch 15/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0053 - val_loss: 0.0053\n",
      "Epoch 16/100\n",
      "199/199 [==============================] - 0s 992us/step - loss: 0.0048 - val_loss: 0.0049\n",
      "Epoch 17/100\n",
      "199/199 [==============================] - 0s 976us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 18/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0043\n",
      "Epoch 19/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0038 - val_loss: 0.0040\n",
      "Epoch 20/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0036 - val_loss: 0.0038\n",
      "Epoch 21/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 22/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0032 - val_loss: 0.0035\n",
      "Epoch 23/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0030 - val_loss: 0.0034\n",
      "Epoch 24/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 25/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0027 - val_loss: 0.0030\n",
      "Epoch 26/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 27/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 28/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 29/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 30/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 31/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 32/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 33/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 34/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 35/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0016 - val_loss: 0.0020\n",
      "Epoch 36/100\n",
      "199/199 [==============================] - 0s 973us/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 37/100\n",
      "199/199 [==============================] - 0s 971us/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 38/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 39/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 40/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 41/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 42/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 43/100\n",
      "199/199 [==============================] - 0s 989us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 44/100\n",
      "199/199 [==============================] - 0s 956us/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 45/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 46/100\n",
      "199/199 [==============================] - 0s 974us/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 47/100\n",
      "199/199 [==============================] - 0s 955us/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 48/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0010 - val_loss: 0.0015\n",
      "Epoch 49/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 50/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 9.8345e-04 - val_loss: 0.0014\n",
      "Epoch 51/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 9.5979e-04 - val_loss: 0.0014\n",
      "Epoch 52/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 9.4052e-04 - val_loss: 0.0014\n",
      "Epoch 53/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 9.0564e-04 - val_loss: 0.0013\n",
      "Epoch 54/100\n",
      "199/199 [==============================] - 0s 970us/step - loss: 8.9345e-04 - val_loss: 0.0013\n",
      "Epoch 55/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 8.7414e-04 - val_loss: 0.0013\n",
      "Epoch 56/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 8.5209e-04 - val_loss: 0.0014\n",
      "Epoch 57/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 8.5114e-04 - val_loss: 0.0013\n",
      "Epoch 58/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 8.2498e-04 - val_loss: 0.0013\n",
      "Epoch 59/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 8.1013e-04 - val_loss: 0.0013\n",
      "Epoch 60/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 7.8808e-04 - val_loss: 0.0012\n",
      "Epoch 61/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 7.5356e-04 - val_loss: 0.0012\n",
      "Epoch 62/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 7.3910e-04 - val_loss: 0.0012\n",
      "Epoch 63/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 7.4055e-04 - val_loss: 0.0012\n",
      "Epoch 64/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 7.4314e-04 - val_loss: 0.0012\n",
      "Epoch 65/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 7.1169e-04 - val_loss: 0.0012\n",
      "Epoch 66/100\n",
      "199/199 [==============================] - 0s 968us/step - loss: 6.9866e-04 - val_loss: 0.0011\n",
      "Epoch 67/100\n",
      "199/199 [==============================] - 0s 967us/step - loss: 6.9709e-04 - val_loss: 0.0012\n",
      "Epoch 68/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 6.8267e-04 - val_loss: 0.0011\n",
      "Epoch 69/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 6.7122e-04 - val_loss: 0.0011\n",
      "Epoch 70/100\n",
      "199/199 [==============================] - 0s 987us/step - loss: 6.6351e-04 - val_loss: 0.0011\n",
      "Epoch 71/100\n",
      "199/199 [==============================] - 0s 967us/step - loss: 6.4976e-04 - val_loss: 0.0011\n",
      "Epoch 72/100\n",
      "199/199 [==============================] - 0s 977us/step - loss: 6.5449e-04 - val_loss: 0.0011\n",
      "Epoch 73/100\n",
      "199/199 [==============================] - 0s 977us/step - loss: 6.4035e-04 - val_loss: 0.0011\n",
      "Epoch 74/100\n",
      "199/199 [==============================] - 0s 973us/step - loss: 6.1783e-04 - val_loss: 0.0011\n",
      "Epoch 75/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 6.1088e-04 - val_loss: 0.0011\n",
      "Epoch 76/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 6.0932e-04 - val_loss: 0.0011\n",
      "Epoch 77/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 6.0507e-04 - val_loss: 0.0010\n",
      "Epoch 78/100\n",
      "199/199 [==============================] - 0s 911us/step - loss: 6.0850e-04 - val_loss: 0.0010\n",
      "Epoch 79/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 5.9022e-04 - val_loss: 0.0010\n",
      "Epoch 80/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 5.9669e-04 - val_loss: 0.0010\n",
      "Epoch 81/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 5.7744e-04 - val_loss: 0.0011\n",
      "Epoch 82/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 5.8314e-04 - val_loss: 9.6517e-04\n",
      "Epoch 83/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 5.2855e-04 - val_loss: 9.5948e-04\n",
      "Epoch 84/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 5.1145e-04 - val_loss: 8.9598e-04\n",
      "Epoch 85/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 4.8697e-04 - val_loss: 9.2599e-04\n",
      "Epoch 86/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 4.9030e-04 - val_loss: 8.8692e-04\n",
      "Epoch 87/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 4.8365e-04 - val_loss: 9.1055e-04\n",
      "Epoch 88/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 4.8359e-04 - val_loss: 8.6867e-04\n",
      "Epoch 89/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 4.7130e-04 - val_loss: 8.7091e-04\n",
      "Epoch 90/100\n",
      "199/199 [==============================] - 0s 989us/step - loss: 4.6476e-04 - val_loss: 8.3907e-04\n",
      "Epoch 91/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 4.6633e-04 - val_loss: 8.3280e-04\n",
      "Epoch 92/100\n",
      "199/199 [==============================] - 0s 976us/step - loss: 4.5545e-04 - val_loss: 8.2693e-04\n",
      "Epoch 93/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 4.5118e-04 - val_loss: 8.3215e-04\n",
      "Epoch 94/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 4.5217e-04 - val_loss: 8.4790e-04\n",
      "Epoch 95/100\n",
      "199/199 [==============================] - 0s 974us/step - loss: 4.4242e-04 - val_loss: 8.3485e-04\n",
      "Epoch 96/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 4.3648e-04 - val_loss: 8.1630e-04\n",
      "Epoch 97/100\n",
      "199/199 [==============================] - 0s 979us/step - loss: 4.3922e-04 - val_loss: 8.5393e-04\n",
      "Epoch 98/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 4.4509e-04 - val_loss: 8.3731e-04\n",
      "Epoch 99/100\n",
      "199/199 [==============================] - 0s 981us/step - loss: 4.2508e-04 - val_loss: 7.9263e-04\n",
      "Epoch 100/100\n",
      "199/199 [==============================] - 0s 959us/step - loss: 4.0602e-04 - val_loss: 7.6968e-04\n",
      "This round is 3\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_11724/328462441.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  para_dfm = para_dfm.append({\"reg_param\": reg_param, \"number_units_layers\": numbers_units_layers, \"number_units_bottleneck\": numbers_units_bottleneck, \"dropout_rate\": dropout_rate, \"number_layers\": numbers_layers, \"whether_dropout\": whether_dropout, \"whether_regularizer\": whether_regularizer, \"overfit_metric\": overfit_metric, \"val2_avg_recon_error\": val2_avg_recon_error,'val1_loss':val1_loss}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 0s 1ms/step - loss: 0.1109 - val_loss: 0.0551\n",
      "Epoch 2/100\n",
      "199/199 [==============================] - 0s 984us/step - loss: 0.0493 - val_loss: 0.0416\n",
      "Epoch 3/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0391 - val_loss: 0.0373\n",
      "Epoch 4/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0364 - val_loss: 0.0352\n",
      "Epoch 5/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0338 - val_loss: 0.0318\n",
      "Epoch 6/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0298 - val_loss: 0.0275\n",
      "Epoch 7/100\n",
      "199/199 [==============================] - 0s 996us/step - loss: 0.0268 - val_loss: 0.0257\n",
      "Epoch 8/100\n",
      "199/199 [==============================] - 0s 983us/step - loss: 0.0252 - val_loss: 0.0242\n",
      "Epoch 9/100\n",
      "199/199 [==============================] - 0s 934us/step - loss: 0.0236 - val_loss: 0.0222\n",
      "Epoch 10/100\n",
      "199/199 [==============================] - 0s 960us/step - loss: 0.0217 - val_loss: 0.0206\n",
      "Epoch 11/100\n",
      "199/199 [==============================] - 0s 974us/step - loss: 0.0196 - val_loss: 0.0181\n",
      "Epoch 12/100\n",
      "199/199 [==============================] - 0s 959us/step - loss: 0.0179 - val_loss: 0.0170\n",
      "Epoch 13/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0168 - val_loss: 0.0160\n",
      "Epoch 14/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0158 - val_loss: 0.0151\n",
      "Epoch 15/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0149 - val_loss: 0.0143\n",
      "Epoch 16/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0142 - val_loss: 0.0136\n",
      "Epoch 17/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0135 - val_loss: 0.0130\n",
      "Epoch 18/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0129 - val_loss: 0.0125\n",
      "Epoch 19/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0125 - val_loss: 0.0121\n",
      "Epoch 20/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0121 - val_loss: 0.0117\n",
      "Epoch 21/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0117 - val_loss: 0.0114\n",
      "Epoch 22/100\n",
      "199/199 [==============================] - 0s 939us/step - loss: 0.0113 - val_loss: 0.0111\n",
      "Epoch 23/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0110 - val_loss: 0.0108\n",
      "Epoch 24/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0108 - val_loss: 0.0105\n",
      "Epoch 25/100\n",
      "199/199 [==============================] - 0s 929us/step - loss: 0.0105 - val_loss: 0.0103\n",
      "Epoch 26/100\n",
      "199/199 [==============================] - 0s 913us/step - loss: 0.0103 - val_loss: 0.0101\n",
      "Epoch 27/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0101 - val_loss: 0.0099\n",
      "Epoch 28/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0098 - val_loss: 0.0096\n",
      "Epoch 29/100\n",
      "199/199 [==============================] - 0s 971us/step - loss: 0.0096 - val_loss: 0.0094\n",
      "Epoch 30/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0092\n",
      "Epoch 31/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0090\n",
      "Epoch 32/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0088\n",
      "Epoch 33/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0087\n",
      "Epoch 34/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0086\n",
      "Epoch 35/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0084\n",
      "Epoch 36/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0082\n",
      "Epoch 37/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0081\n",
      "Epoch 38/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0080 - val_loss: 0.0080\n",
      "Epoch 39/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0078 - val_loss: 0.0078\n",
      "Epoch 40/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0077 - val_loss: 0.0077\n",
      "Epoch 41/100\n",
      "199/199 [==============================] - 0s 959us/step - loss: 0.0075 - val_loss: 0.0075\n",
      "Epoch 42/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0074 - val_loss: 0.0074\n",
      "Epoch 43/100\n",
      "199/199 [==============================] - 0s 932us/step - loss: 0.0073 - val_loss: 0.0073\n",
      "Epoch 44/100\n",
      "199/199 [==============================] - 0s 916us/step - loss: 0.0072 - val_loss: 0.0072\n",
      "Epoch 45/100\n",
      "199/199 [==============================] - 0s 911us/step - loss: 0.0070 - val_loss: 0.0071\n",
      "Epoch 46/100\n",
      "199/199 [==============================] - 0s 915us/step - loss: 0.0069 - val_loss: 0.0070\n",
      "Epoch 47/100\n",
      "199/199 [==============================] - 0s 910us/step - loss: 0.0068 - val_loss: 0.0069\n",
      "Epoch 48/100\n",
      "199/199 [==============================] - 0s 914us/step - loss: 0.0067 - val_loss: 0.0068\n",
      "Epoch 49/100\n",
      "199/199 [==============================] - 0s 905us/step - loss: 0.0067 - val_loss: 0.0067\n",
      "Epoch 50/100\n",
      "199/199 [==============================] - 0s 898us/step - loss: 0.0066 - val_loss: 0.0066\n",
      "Epoch 51/100\n",
      "199/199 [==============================] - 0s 933us/step - loss: 0.0065 - val_loss: 0.0065\n",
      "Epoch 52/100\n",
      "199/199 [==============================] - 0s 909us/step - loss: 0.0064 - val_loss: 0.0065\n",
      "Epoch 53/100\n",
      "199/199 [==============================] - 0s 913us/step - loss: 0.0064 - val_loss: 0.0064\n",
      "Epoch 54/100\n",
      "199/199 [==============================] - 0s 914us/step - loss: 0.0063 - val_loss: 0.0063\n",
      "Epoch 55/100\n",
      "199/199 [==============================] - 0s 918us/step - loss: 0.0062 - val_loss: 0.0062\n",
      "Epoch 56/100\n",
      "199/199 [==============================] - 0s 899us/step - loss: 0.0061 - val_loss: 0.0062\n",
      "Epoch 57/100\n",
      "199/199 [==============================] - 0s 950us/step - loss: 0.0060 - val_loss: 0.0061\n",
      "Epoch 58/100\n",
      "199/199 [==============================] - 0s 895us/step - loss: 0.0059 - val_loss: 0.0060\n",
      "Epoch 59/100\n",
      "199/199 [==============================] - 0s 906us/step - loss: 0.0059 - val_loss: 0.0059\n",
      "Epoch 60/100\n",
      "199/199 [==============================] - 0s 915us/step - loss: 0.0059 - val_loss: 0.0059\n",
      "Epoch 61/100\n",
      "199/199 [==============================] - 0s 948us/step - loss: 0.0058 - val_loss: 0.0058\n",
      "Epoch 62/100\n",
      "199/199 [==============================] - 0s 971us/step - loss: 0.0057 - val_loss: 0.0057\n",
      "Epoch 63/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0056 - val_loss: 0.0057\n",
      "Epoch 64/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0056 - val_loss: 0.0056\n",
      "Epoch 65/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0055 - val_loss: 0.0055\n",
      "Epoch 66/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0054 - val_loss: 0.0055\n",
      "Epoch 67/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0054 - val_loss: 0.0055\n",
      "Epoch 68/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0053 - val_loss: 0.0054\n",
      "Epoch 69/100\n",
      "199/199 [==============================] - 0s 982us/step - loss: 0.0053 - val_loss: 0.0054\n",
      "Epoch 70/100\n",
      "199/199 [==============================] - 0s 974us/step - loss: 0.0053 - val_loss: 0.0053\n",
      "Epoch 71/100\n",
      "199/199 [==============================] - 0s 951us/step - loss: 0.0052 - val_loss: 0.0053\n",
      "Epoch 72/100\n",
      "199/199 [==============================] - 0s 952us/step - loss: 0.0051 - val_loss: 0.0052\n",
      "Epoch 73/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0051 - val_loss: 0.0052\n",
      "Epoch 74/100\n",
      "199/199 [==============================] - 0s 982us/step - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 75/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 76/100\n",
      "199/199 [==============================] - 0s 923us/step - loss: 0.0050 - val_loss: 0.0051\n",
      "Epoch 77/100\n",
      "199/199 [==============================] - 0s 935us/step - loss: 0.0049 - val_loss: 0.0050\n",
      "Epoch 78/100\n",
      "199/199 [==============================] - 0s 908us/step - loss: 0.0049 - val_loss: 0.0050\n",
      "Epoch 79/100\n",
      "199/199 [==============================] - 0s 940us/step - loss: 0.0049 - val_loss: 0.0050\n",
      "Epoch 80/100\n",
      "199/199 [==============================] - 0s 944us/step - loss: 0.0048 - val_loss: 0.0049\n",
      "Epoch 81/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 0.0049\n",
      "Epoch 82/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 83/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 84/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 85/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 86/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 87/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 88/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0045 - val_loss: 0.0047\n",
      "Epoch 89/100\n",
      "199/199 [==============================] - 0s 978us/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 90/100\n",
      "199/199 [==============================] - 0s 990us/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 91/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 92/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 93/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 94/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 95/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 96/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0043 - val_loss: 0.0045\n",
      "Epoch 97/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 98/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 99/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 100/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "This round is 4\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_11724/328462441.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  para_dfm = para_dfm.append({\"reg_param\": reg_param, \"number_units_layers\": numbers_units_layers, \"number_units_bottleneck\": numbers_units_bottleneck, \"dropout_rate\": dropout_rate, \"number_layers\": numbers_layers, \"whether_dropout\": whether_dropout, \"whether_regularizer\": whether_regularizer, \"overfit_metric\": overfit_metric, \"val2_avg_recon_error\": val2_avg_recon_error,'val1_loss':val1_loss}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 1s 1ms/step - loss: 0.0914 - val_loss: 0.0545\n",
      "Epoch 2/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0489 - val_loss: 0.0401\n",
      "Epoch 3/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0363 - val_loss: 0.0325\n",
      "Epoch 4/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0311 - val_loss: 0.0294\n",
      "Epoch 5/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0281 - val_loss: 0.0261\n",
      "Epoch 6/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0244 - val_loss: 0.0217\n",
      "Epoch 7/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0200 - val_loss: 0.0177\n",
      "Epoch 8/100\n",
      "199/199 [==============================] - 0s 978us/step - loss: 0.0172 - val_loss: 0.0159\n",
      "Epoch 9/100\n",
      "199/199 [==============================] - 0s 974us/step - loss: 0.0158 - val_loss: 0.0147\n",
      "Epoch 10/100\n",
      "199/199 [==============================] - 0s 971us/step - loss: 0.0147 - val_loss: 0.0138\n",
      "Epoch 11/100\n",
      "199/199 [==============================] - 0s 968us/step - loss: 0.0137 - val_loss: 0.0129\n",
      "Epoch 12/100\n",
      "199/199 [==============================] - 0s 971us/step - loss: 0.0127 - val_loss: 0.0120\n",
      "Epoch 13/100\n",
      "199/199 [==============================] - 0s 969us/step - loss: 0.0119 - val_loss: 0.0113\n",
      "Epoch 14/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0111 - val_loss: 0.0107\n",
      "Epoch 15/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.0102\n",
      "Epoch 16/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.0097\n",
      "Epoch 17/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.0093\n",
      "Epoch 18/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0090\n",
      "Epoch 19/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0086\n",
      "Epoch 20/100\n",
      "199/199 [==============================] - 0s 988us/step - loss: 0.0086 - val_loss: 0.0083\n",
      "Epoch 21/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0080\n",
      "Epoch 22/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0079 - val_loss: 0.0077\n",
      "Epoch 23/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0076 - val_loss: 0.0074\n",
      "Epoch 24/100\n",
      "199/199 [==============================] - 0s 974us/step - loss: 0.0073 - val_loss: 0.0071\n",
      "Epoch 25/100\n",
      "199/199 [==============================] - 0s 978us/step - loss: 0.0070 - val_loss: 0.0069\n",
      "Epoch 26/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 0.0067\n",
      "Epoch 27/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0066 - val_loss: 0.0065\n",
      "Epoch 28/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0062\n",
      "Epoch 29/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0061\n",
      "Epoch 30/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0058\n",
      "Epoch 31/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0057\n",
      "Epoch 32/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0055 - val_loss: 0.0055\n",
      "Epoch 33/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0053 - val_loss: 0.0053\n",
      "Epoch 34/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0052 - val_loss: 0.0052\n",
      "Epoch 35/100\n",
      "199/199 [==============================] - 0s 943us/step - loss: 0.0051 - val_loss: 0.0050\n",
      "Epoch 36/100\n",
      "199/199 [==============================] - 0s 986us/step - loss: 0.0050 - val_loss: 0.0049\n",
      "Epoch 37/100\n",
      "199/199 [==============================] - 0s 896us/step - loss: 0.0048 - val_loss: 0.0048\n",
      "Epoch 38/100\n",
      "199/199 [==============================] - 0s 905us/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 39/100\n",
      "199/199 [==============================] - 0s 896us/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 40/100\n",
      "199/199 [==============================] - 0s 959us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 41/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 42/100\n",
      "199/199 [==============================] - 0s 997us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 43/100\n",
      "199/199 [==============================] - 0s 959us/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 44/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0042\n",
      "Epoch 45/100\n",
      "199/199 [==============================] - 0s 974us/step - loss: 0.0042 - val_loss: 0.0042\n",
      "Epoch 46/100\n",
      "199/199 [==============================] - 0s 913us/step - loss: 0.0040 - val_loss: 0.0041\n",
      "Epoch 47/100\n",
      "199/199 [==============================] - 0s 911us/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 48/100\n",
      "199/199 [==============================] - 0s 924us/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 49/100\n",
      "199/199 [==============================] - 0s 904us/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 50/100\n",
      "199/199 [==============================] - 0s 888us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 51/100\n",
      "199/199 [==============================] - 0s 891us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 52/100\n",
      "199/199 [==============================] - 0s 935us/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 53/100\n",
      "199/199 [==============================] - 0s 939us/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 54/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 55/100\n",
      "199/199 [==============================] - 0s 917us/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 56/100\n",
      "199/199 [==============================] - 0s 968us/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 57/100\n",
      "199/199 [==============================] - 0s 902us/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 58/100\n",
      "199/199 [==============================] - 0s 897us/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 59/100\n",
      "199/199 [==============================] - 0s 898us/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 60/100\n",
      "199/199 [==============================] - 0s 898us/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 61/100\n",
      "199/199 [==============================] - 0s 999us/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 62/100\n",
      "199/199 [==============================] - 0s 935us/step - loss: 0.0032 - val_loss: 0.0032\n",
      "Epoch 63/100\n",
      "199/199 [==============================] - 0s 912us/step - loss: 0.0032 - val_loss: 0.0032\n",
      "Epoch 64/100\n",
      "199/199 [==============================] - 0s 909us/step - loss: 0.0032 - val_loss: 0.0032\n",
      "Epoch 65/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 66/100\n",
      "199/199 [==============================] - 0s 921us/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 67/100\n",
      "199/199 [==============================] - 0s 939us/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 68/100\n",
      "199/199 [==============================] - 0s 901us/step - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 69/100\n",
      "199/199 [==============================] - 0s 999us/step - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 70/100\n",
      "199/199 [==============================] - 0s 940us/step - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 71/100\n",
      "199/199 [==============================] - 0s 908us/step - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 72/100\n",
      "199/199 [==============================] - 0s 967us/step - loss: 0.0028 - val_loss: 0.0029\n",
      "Epoch 73/100\n",
      "199/199 [==============================] - 0s 999us/step - loss: 0.0028 - val_loss: 0.0029\n",
      "Epoch 74/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 75/100\n",
      "199/199 [==============================] - 0s 924us/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 76/100\n",
      "199/199 [==============================] - 0s 955us/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 77/100\n",
      "199/199 [==============================] - 0s 974us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 78/100\n",
      "199/199 [==============================] - 0s 930us/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 79/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 80/100\n",
      "199/199 [==============================] - 0s 956us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 81/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 82/100\n",
      "199/199 [==============================] - 0s 923us/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 83/100\n",
      "199/199 [==============================] - 0s 943us/step - loss: 0.0024 - val_loss: 0.0026\n",
      "Epoch 84/100\n",
      "199/199 [==============================] - 0s 937us/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 85/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 86/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 87/100\n",
      "199/199 [==============================] - 0s 939us/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 88/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 89/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 90/100\n",
      "199/199 [==============================] - 0s 982us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 91/100\n",
      "199/199 [==============================] - 0s 934us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 92/100\n",
      "199/199 [==============================] - 0s 924us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 93/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 94/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 95/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 96/100\n",
      "199/199 [==============================] - 0s 927us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 97/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 98/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 99/100\n",
      "199/199 [==============================] - 0s 930us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 100/100\n",
      "199/199 [==============================] - 0s 939us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "This round is 5\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_11724/328462441.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  para_dfm = para_dfm.append({\"reg_param\": reg_param, \"number_units_layers\": numbers_units_layers, \"number_units_bottleneck\": numbers_units_bottleneck, \"dropout_rate\": dropout_rate, \"number_layers\": numbers_layers, \"whether_dropout\": whether_dropout, \"whether_regularizer\": whether_regularizer, \"overfit_metric\": overfit_metric, \"val2_avg_recon_error\": val2_avg_recon_error,'val1_loss':val1_loss}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0893 - val_loss: 0.0452\n",
      "Epoch 2/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0376 - val_loss: 0.0323\n",
      "Epoch 3/100\n",
      "199/199 [==============================] - 0s 897us/step - loss: 0.0284 - val_loss: 0.0251\n",
      "Epoch 4/100\n",
      "199/199 [==============================] - 0s 887us/step - loss: 0.0221 - val_loss: 0.0189\n",
      "Epoch 5/100\n",
      "199/199 [==============================] - 0s 901us/step - loss: 0.0171 - val_loss: 0.0153\n",
      "Epoch 6/100\n",
      "199/199 [==============================] - 0s 911us/step - loss: 0.0144 - val_loss: 0.0131\n",
      "Epoch 7/100\n",
      "199/199 [==============================] - 0s 918us/step - loss: 0.0127 - val_loss: 0.0121\n",
      "Epoch 8/100\n",
      "199/199 [==============================] - 0s 970us/step - loss: 0.0118 - val_loss: 0.0114\n",
      "Epoch 9/100\n",
      "199/199 [==============================] - 0s 893us/step - loss: 0.0109 - val_loss: 0.0106\n",
      "Epoch 10/100\n",
      "199/199 [==============================] - 0s 970us/step - loss: 0.0100 - val_loss: 0.0096\n",
      "Epoch 11/100\n",
      "199/199 [==============================] - 0s 963us/step - loss: 0.0090 - val_loss: 0.0088\n",
      "Epoch 12/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0080\n",
      "Epoch 13/100\n",
      "199/199 [==============================] - 0s 953us/step - loss: 0.0073 - val_loss: 0.0073\n",
      "Epoch 14/100\n",
      "199/199 [==============================] - 0s 908us/step - loss: 0.0068 - val_loss: 0.0069\n",
      "Epoch 15/100\n",
      "199/199 [==============================] - 0s 892us/step - loss: 0.0064 - val_loss: 0.0065\n",
      "Epoch 16/100\n",
      "199/199 [==============================] - 0s 919us/step - loss: 0.0060 - val_loss: 0.0061\n",
      "Epoch 17/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0057 - val_loss: 0.0059\n",
      "Epoch 18/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0054 - val_loss: 0.0056\n",
      "Epoch 19/100\n",
      "199/199 [==============================] - 0s 984us/step - loss: 0.0052 - val_loss: 0.0053\n",
      "Epoch 20/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0050 - val_loss: 0.0051\n",
      "Epoch 21/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0047 - val_loss: 0.0049\n",
      "Epoch 22/100\n",
      "199/199 [==============================] - 0s 907us/step - loss: 0.0045 - val_loss: 0.0047\n",
      "Epoch 23/100\n",
      "199/199 [==============================] - 0s 968us/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 24/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0044\n",
      "Epoch 25/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0040 - val_loss: 0.0042\n",
      "Epoch 26/100\n",
      "199/199 [==============================] - 0s 972us/step - loss: 0.0039 - val_loss: 0.0041\n",
      "Epoch 27/100\n",
      "199/199 [==============================] - 0s 956us/step - loss: 0.0038 - val_loss: 0.0040\n",
      "Epoch 28/100\n",
      "199/199 [==============================] - 0s 936us/step - loss: 0.0036 - val_loss: 0.0038\n",
      "Epoch 29/100\n",
      "199/199 [==============================] - 0s 941us/step - loss: 0.0033 - val_loss: 0.0036\n",
      "Epoch 30/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0032 - val_loss: 0.0034\n",
      "Epoch 31/100\n",
      "199/199 [==============================] - 0s 940us/step - loss: 0.0030 - val_loss: 0.0033\n",
      "Epoch 32/100\n",
      "199/199 [==============================] - 0s 986us/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 33/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0027 - val_loss: 0.0030\n",
      "Epoch 34/100\n",
      "199/199 [==============================] - 0s 900us/step - loss: 0.0026 - val_loss: 0.0030\n",
      "Epoch 35/100\n",
      "199/199 [==============================] - 0s 950us/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 36/100\n",
      "199/199 [==============================] - 0s 938us/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 37/100\n",
      "199/199 [==============================] - 0s 973us/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 38/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 39/100\n",
      "199/199 [==============================] - 0s 981us/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 40/100\n",
      "199/199 [==============================] - 0s 968us/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 41/100\n",
      "199/199 [==============================] - 0s 913us/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 42/100\n",
      "199/199 [==============================] - 0s 915us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 43/100\n",
      "199/199 [==============================] - 0s 892us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 44/100\n",
      "199/199 [==============================] - 0s 921us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 45/100\n",
      "199/199 [==============================] - 0s 905us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 46/100\n",
      "199/199 [==============================] - 0s 889us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 47/100\n",
      "199/199 [==============================] - 0s 903us/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 48/100\n",
      "199/199 [==============================] - 0s 895us/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 49/100\n",
      "199/199 [==============================] - 0s 898us/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 50/100\n",
      "199/199 [==============================] - 0s 899us/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 51/100\n",
      "199/199 [==============================] - 0s 899us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 52/100\n",
      "199/199 [==============================] - 0s 895us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 53/100\n",
      "199/199 [==============================] - 0s 896us/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 54/100\n",
      "199/199 [==============================] - 0s 914us/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 55/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 56/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 57/100\n",
      "199/199 [==============================] - 0s 900us/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 58/100\n",
      "199/199 [==============================] - 0s 889us/step - loss: 0.0016 - val_loss: 0.0020\n",
      "Epoch 59/100\n",
      "199/199 [==============================] - 0s 901us/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 60/100\n",
      "199/199 [==============================] - 0s 897us/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 61/100\n",
      "199/199 [==============================] - 0s 897us/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 62/100\n",
      "199/199 [==============================] - 0s 889us/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 63/100\n",
      "199/199 [==============================] - 0s 918us/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 64/100\n",
      "199/199 [==============================] - 0s 896us/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 65/100\n",
      "199/199 [==============================] - 0s 896us/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 66/100\n",
      "199/199 [==============================] - 0s 882us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 67/100\n",
      "199/199 [==============================] - 0s 901us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 68/100\n",
      "199/199 [==============================] - 0s 898us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 69/100\n",
      "199/199 [==============================] - 0s 889us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 70/100\n",
      "199/199 [==============================] - 0s 897us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 71/100\n",
      "199/199 [==============================] - 0s 915us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 72/100\n",
      "199/199 [==============================] - 0s 892us/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 73/100\n",
      "199/199 [==============================] - 0s 895us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 74/100\n",
      "199/199 [==============================] - 0s 896us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 75/100\n",
      "199/199 [==============================] - 0s 917us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 76/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 77/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 78/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 79/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 80/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 81/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 82/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 83/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 84/100\n",
      "199/199 [==============================] - 0s 946us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 85/100\n",
      "199/199 [==============================] - 0s 901us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 86/100\n",
      "199/199 [==============================] - 0s 898us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 87/100\n",
      "199/199 [==============================] - 0s 895us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 88/100\n",
      "199/199 [==============================] - 0s 899us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 89/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 90/100\n",
      "199/199 [==============================] - 0s 900us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 91/100\n",
      "199/199 [==============================] - 0s 891us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 92/100\n",
      "199/199 [==============================] - 0s 885us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 93/100\n",
      "199/199 [==============================] - 0s 894us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 94/100\n",
      "199/199 [==============================] - 0s 905us/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 95/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 96/100\n",
      "199/199 [==============================] - 0s 913us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 97/100\n",
      "199/199 [==============================] - 0s 917us/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 98/100\n",
      "199/199 [==============================] - 0s 888us/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 99/100\n",
      "199/199 [==============================] - 0s 899us/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 100/100\n",
      "199/199 [==============================] - 0s 895us/step - loss: 0.0011 - val_loss: 0.0016\n",
      "This round is 6\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_11724/328462441.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  para_dfm = para_dfm.append({\"reg_param\": reg_param, \"number_units_layers\": numbers_units_layers, \"number_units_bottleneck\": numbers_units_bottleneck, \"dropout_rate\": dropout_rate, \"number_layers\": numbers_layers, \"whether_dropout\": whether_dropout, \"whether_regularizer\": whether_regularizer, \"overfit_metric\": overfit_metric, \"val2_avg_recon_error\": val2_avg_recon_error,'val1_loss':val1_loss}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0722 - val_loss: 0.0392\n",
      "Epoch 2/100\n",
      "199/199 [==============================] - 0s 939us/step - loss: 0.0343 - val_loss: 0.0297\n",
      "Epoch 3/100\n",
      "199/199 [==============================] - 0s 922us/step - loss: 0.0254 - val_loss: 0.0215\n",
      "Epoch 4/100\n",
      "199/199 [==============================] - 0s 929us/step - loss: 0.0192 - val_loss: 0.0170\n",
      "Epoch 5/100\n",
      "199/199 [==============================] - 0s 924us/step - loss: 0.0160 - val_loss: 0.0147\n",
      "Epoch 6/100\n",
      "199/199 [==============================] - 0s 944us/step - loss: 0.0134 - val_loss: 0.0121\n",
      "Epoch 7/100\n",
      "199/199 [==============================] - 0s 923us/step - loss: 0.0112 - val_loss: 0.0106\n",
      "Epoch 8/100\n",
      "199/199 [==============================] - 0s 921us/step - loss: 0.0100 - val_loss: 0.0097\n",
      "Epoch 9/100\n",
      "199/199 [==============================] - 0s 920us/step - loss: 0.0092 - val_loss: 0.0090\n",
      "Epoch 10/100\n",
      "199/199 [==============================] - 0s 916us/step - loss: 0.0085 - val_loss: 0.0083\n",
      "Epoch 11/100\n",
      "199/199 [==============================] - 0s 912us/step - loss: 0.0077 - val_loss: 0.0076\n",
      "Epoch 12/100\n",
      "199/199 [==============================] - 0s 905us/step - loss: 0.0071 - val_loss: 0.0070\n",
      "Epoch 13/100\n",
      "199/199 [==============================] - 0s 921us/step - loss: 0.0065 - val_loss: 0.0065\n",
      "Epoch 14/100\n",
      "199/199 [==============================] - 0s 943us/step - loss: 0.0059 - val_loss: 0.0059\n",
      "Epoch 15/100\n",
      "199/199 [==============================] - 0s 903us/step - loss: 0.0053 - val_loss: 0.0053\n",
      "Epoch 16/100\n",
      "199/199 [==============================] - 0s 914us/step - loss: 0.0048 - val_loss: 0.0049\n",
      "Epoch 17/100\n",
      "199/199 [==============================] - 0s 905us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 18/100\n",
      "199/199 [==============================] - 0s 923us/step - loss: 0.0041 - val_loss: 0.0043\n",
      "Epoch 19/100\n",
      "199/199 [==============================] - 0s 924us/step - loss: 0.0038 - val_loss: 0.0040\n",
      "Epoch 20/100\n",
      "199/199 [==============================] - 0s 932us/step - loss: 0.0036 - val_loss: 0.0038\n",
      "Epoch 21/100\n",
      "199/199 [==============================] - 0s 920us/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 22/100\n",
      "199/199 [==============================] - 0s 926us/step - loss: 0.0032 - val_loss: 0.0035\n",
      "Epoch 23/100\n",
      "199/199 [==============================] - 0s 916us/step - loss: 0.0030 - val_loss: 0.0034\n",
      "Epoch 24/100\n",
      "199/199 [==============================] - 0s 913us/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 25/100\n",
      "199/199 [==============================] - 0s 921us/step - loss: 0.0027 - val_loss: 0.0030\n",
      "Epoch 26/100\n",
      "199/199 [==============================] - 0s 909us/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 27/100\n",
      "199/199 [==============================] - 0s 942us/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 28/100\n",
      "199/199 [==============================] - 0s 913us/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 29/100\n",
      "199/199 [==============================] - 0s 917us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 30/100\n",
      "199/199 [==============================] - 0s 912us/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 31/100\n",
      "199/199 [==============================] - 0s 921us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 32/100\n",
      "199/199 [==============================] - 0s 930us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 33/100\n",
      "199/199 [==============================] - 0s 975us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 34/100\n",
      "199/199 [==============================] - 0s 935us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 35/100\n",
      "199/199 [==============================] - 0s 918us/step - loss: 0.0016 - val_loss: 0.0020\n",
      "Epoch 36/100\n",
      "199/199 [==============================] - 0s 927us/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 37/100\n",
      "199/199 [==============================] - 0s 904us/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 38/100\n",
      "199/199 [==============================] - 0s 932us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 39/100\n",
      "199/199 [==============================] - 0s 926us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 40/100\n",
      "199/199 [==============================] - 0s 909us/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 41/100\n",
      "199/199 [==============================] - 0s 944us/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 42/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 43/100\n",
      "199/199 [==============================] - 0s 922us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 44/100\n",
      "199/199 [==============================] - 0s 917us/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 45/100\n",
      "199/199 [==============================] - 0s 917us/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 46/100\n",
      "199/199 [==============================] - 0s 926us/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 47/100\n",
      "199/199 [==============================] - 0s 920us/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 48/100\n",
      "199/199 [==============================] - 0s 933us/step - loss: 0.0010 - val_loss: 0.0015\n",
      "Epoch 49/100\n",
      "199/199 [==============================] - 0s 922us/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 50/100\n",
      "199/199 [==============================] - 0s 924us/step - loss: 9.8345e-04 - val_loss: 0.0014\n",
      "Epoch 51/100\n",
      "199/199 [==============================] - 0s 985us/step - loss: 9.5979e-04 - val_loss: 0.0014\n",
      "Epoch 52/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 9.4052e-04 - val_loss: 0.0014\n",
      "Epoch 53/100\n",
      "199/199 [==============================] - 0s 926us/step - loss: 9.0564e-04 - val_loss: 0.0013\n",
      "Epoch 54/100\n",
      "199/199 [==============================] - 0s 927us/step - loss: 8.9345e-04 - val_loss: 0.0013\n",
      "Epoch 55/100\n",
      "199/199 [==============================] - 0s 913us/step - loss: 8.7414e-04 - val_loss: 0.0013\n",
      "Epoch 56/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 8.5209e-04 - val_loss: 0.0014\n",
      "Epoch 57/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 8.5114e-04 - val_loss: 0.0013\n",
      "Epoch 58/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 8.2498e-04 - val_loss: 0.0013\n",
      "Epoch 59/100\n",
      "199/199 [==============================] - 0s 945us/step - loss: 8.1013e-04 - val_loss: 0.0013\n",
      "Epoch 60/100\n",
      "199/199 [==============================] - 0s 903us/step - loss: 7.8808e-04 - val_loss: 0.0012\n",
      "Epoch 61/100\n",
      "199/199 [==============================] - 0s 910us/step - loss: 7.5356e-04 - val_loss: 0.0012\n",
      "Epoch 62/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 7.3910e-04 - val_loss: 0.0012\n",
      "Epoch 63/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 7.4055e-04 - val_loss: 0.0012\n",
      "Epoch 64/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 7.4314e-04 - val_loss: 0.0012\n",
      "Epoch 65/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 7.1169e-04 - val_loss: 0.0012\n",
      "Epoch 66/100\n",
      "199/199 [==============================] - 0s 996us/step - loss: 6.9866e-04 - val_loss: 0.0011\n",
      "Epoch 67/100\n",
      "199/199 [==============================] - 0s 939us/step - loss: 6.9709e-04 - val_loss: 0.0012\n",
      "Epoch 68/100\n",
      "199/199 [==============================] - 0s 920us/step - loss: 6.8267e-04 - val_loss: 0.0011\n",
      "Epoch 69/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 6.7122e-04 - val_loss: 0.0011\n",
      "Epoch 70/100\n",
      "199/199 [==============================] - 0s 918us/step - loss: 6.6351e-04 - val_loss: 0.0011\n",
      "Epoch 71/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 6.4976e-04 - val_loss: 0.0011\n",
      "Epoch 72/100\n",
      "199/199 [==============================] - 0s 991us/step - loss: 6.5449e-04 - val_loss: 0.0011\n",
      "Epoch 73/100\n",
      "199/199 [==============================] - 0s 945us/step - loss: 6.4035e-04 - val_loss: 0.0011\n",
      "Epoch 74/100\n",
      "199/199 [==============================] - 0s 957us/step - loss: 6.1783e-04 - val_loss: 0.0011\n",
      "Epoch 75/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 6.1088e-04 - val_loss: 0.0011\n",
      "Epoch 76/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 6.0932e-04 - val_loss: 0.0011\n",
      "Epoch 77/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 6.0507e-04 - val_loss: 0.0010\n",
      "Epoch 78/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 6.0850e-04 - val_loss: 0.0010\n",
      "Epoch 79/100\n",
      "199/199 [==============================] - 0s 933us/step - loss: 5.9022e-04 - val_loss: 0.0010\n",
      "Epoch 80/100\n",
      "199/199 [==============================] - 0s 927us/step - loss: 5.9669e-04 - val_loss: 0.0010\n",
      "Epoch 81/100\n",
      "199/199 [==============================] - 0s 967us/step - loss: 5.7744e-04 - val_loss: 0.0011\n",
      "Epoch 82/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 5.8314e-04 - val_loss: 9.6517e-04\n",
      "Epoch 83/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 5.2855e-04 - val_loss: 9.5948e-04\n",
      "Epoch 84/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 5.1145e-04 - val_loss: 8.9598e-04\n",
      "Epoch 85/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 4.8697e-04 - val_loss: 9.2599e-04\n",
      "Epoch 86/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 4.9030e-04 - val_loss: 8.8692e-04\n",
      "Epoch 87/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 4.8365e-04 - val_loss: 9.1055e-04\n",
      "Epoch 88/100\n",
      "199/199 [==============================] - 0s 975us/step - loss: 4.8359e-04 - val_loss: 8.6867e-04\n",
      "Epoch 89/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 4.7130e-04 - val_loss: 8.7091e-04\n",
      "Epoch 90/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 4.6476e-04 - val_loss: 8.3907e-04\n",
      "Epoch 91/100\n",
      "199/199 [==============================] - 0s 963us/step - loss: 4.6633e-04 - val_loss: 8.3280e-04\n",
      "Epoch 92/100\n",
      "199/199 [==============================] - 0s 999us/step - loss: 4.5545e-04 - val_loss: 8.2693e-04\n",
      "Epoch 93/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 4.5118e-04 - val_loss: 8.3215e-04\n",
      "Epoch 94/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 4.5217e-04 - val_loss: 8.4790e-04\n",
      "Epoch 95/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 4.4242e-04 - val_loss: 8.3485e-04\n",
      "Epoch 96/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 4.3648e-04 - val_loss: 8.1630e-04\n",
      "Epoch 97/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 4.3922e-04 - val_loss: 8.5393e-04\n",
      "Epoch 98/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 4.4509e-04 - val_loss: 8.3731e-04\n",
      "Epoch 99/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 4.2508e-04 - val_loss: 7.9263e-04\n",
      "Epoch 100/100\n",
      "199/199 [==============================] - 0s 990us/step - loss: 4.0602e-04 - val_loss: 7.6968e-04\n",
      "This round is 7\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_11724/328462441.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  para_dfm = para_dfm.append({\"reg_param\": reg_param, \"number_units_layers\": numbers_units_layers, \"number_units_bottleneck\": numbers_units_bottleneck, \"dropout_rate\": dropout_rate, \"number_layers\": numbers_layers, \"whether_dropout\": whether_dropout, \"whether_regularizer\": whether_regularizer, \"overfit_metric\": overfit_metric, \"val2_avg_recon_error\": val2_avg_recon_error,'val1_loss':val1_loss}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 1s 2ms/step - loss: 2.6751 - val_loss: 0.9388\n",
      "Epoch 2/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.4285 - val_loss: 0.1547\n",
      "Epoch 3/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0915 - val_loss: 0.0620\n",
      "Epoch 4/100\n",
      "199/199 [==============================] - 0s 972us/step - loss: 0.0572 - val_loss: 0.0553\n",
      "Epoch 5/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0551 - val_loss: 0.0550\n",
      "Epoch 6/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0551 - val_loss: 0.0550\n",
      "Epoch 7/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0550 - val_loss: 0.0549\n",
      "Epoch 8/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0550 - val_loss: 0.0550\n",
      "Epoch 9/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0549 - val_loss: 0.0549\n",
      "Epoch 10/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0548 - val_loss: 0.0546\n",
      "Epoch 11/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0543 - val_loss: 0.0535\n",
      "Epoch 12/100\n",
      "199/199 [==============================] - 0s 977us/step - loss: 0.0516 - val_loss: 0.0487\n",
      "Epoch 13/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0461 - val_loss: 0.0436\n",
      "Epoch 14/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0426 - val_loss: 0.0414\n",
      "Epoch 15/100\n",
      "199/199 [==============================] - 0s 956us/step - loss: 0.0411 - val_loss: 0.0402\n",
      "Epoch 16/100\n",
      "199/199 [==============================] - 0s 927us/step - loss: 0.0401 - val_loss: 0.0395\n",
      "Epoch 17/100\n",
      "199/199 [==============================] - 0s 914us/step - loss: 0.0395 - val_loss: 0.0389\n",
      "Epoch 18/100\n",
      "199/199 [==============================] - 0s 911us/step - loss: 0.0390 - val_loss: 0.0384\n",
      "Epoch 19/100\n",
      "199/199 [==============================] - 0s 910us/step - loss: 0.0385 - val_loss: 0.0381\n",
      "Epoch 20/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0382 - val_loss: 0.0378\n",
      "Epoch 21/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0379 - val_loss: 0.0377\n",
      "Epoch 22/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0376 - val_loss: 0.0373\n",
      "Epoch 23/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0375 - val_loss: 0.0370\n",
      "Epoch 24/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0373 - val_loss: 0.0369\n",
      "Epoch 25/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0371 - val_loss: 0.0370\n",
      "Epoch 26/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0370 - val_loss: 0.0367\n",
      "Epoch 27/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0369 - val_loss: 0.0366\n",
      "Epoch 28/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0368 - val_loss: 0.0366\n",
      "Epoch 29/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0367 - val_loss: 0.0365\n",
      "Epoch 30/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0367 - val_loss: 0.0365\n",
      "Epoch 31/100\n",
      "199/199 [==============================] - 0s 945us/step - loss: 0.0366 - val_loss: 0.0363\n",
      "Epoch 32/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0366 - val_loss: 0.0365\n",
      "Epoch 33/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0366 - val_loss: 0.0363\n",
      "Epoch 34/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0365 - val_loss: 0.0364\n",
      "Epoch 35/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0365 - val_loss: 0.0365\n",
      "Epoch 36/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0365 - val_loss: 0.0362\n",
      "Epoch 37/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0364 - val_loss: 0.0362\n",
      "Epoch 38/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0364 - val_loss: 0.0364\n",
      "Epoch 39/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0363 - val_loss: 0.0361\n",
      "Epoch 40/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0363 - val_loss: 0.0361\n",
      "Epoch 41/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0363 - val_loss: 0.0361\n",
      "Epoch 42/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0363 - val_loss: 0.0361\n",
      "Epoch 43/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0362 - val_loss: 0.0360\n",
      "Epoch 44/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0363 - val_loss: 0.0360\n",
      "Epoch 45/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0362 - val_loss: 0.0360\n",
      "Epoch 46/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0362 - val_loss: 0.0359\n",
      "Epoch 47/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0362 - val_loss: 0.0367\n",
      "Epoch 48/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0362 - val_loss: 0.0360\n",
      "Epoch 49/100\n",
      "199/199 [==============================] - 0s 973us/step - loss: 0.0362 - val_loss: 0.0359\n",
      "Epoch 50/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0361 - val_loss: 0.0359\n",
      "Epoch 51/100\n",
      "199/199 [==============================] - 0s 991us/step - loss: 0.0362 - val_loss: 0.0360\n",
      "Epoch 52/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0361 - val_loss: 0.0360\n",
      "Epoch 53/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0361 - val_loss: 0.0359\n",
      "Epoch 54/100\n",
      "199/199 [==============================] - 0s 943us/step - loss: 0.0361 - val_loss: 0.0361\n",
      "Epoch 55/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0360 - val_loss: 0.0360\n",
      "Epoch 56/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0361 - val_loss: 0.0358\n",
      "Epoch 57/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0360 - val_loss: 0.0359\n",
      "Epoch 58/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0361 - val_loss: 0.0362\n",
      "Epoch 59/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0360 - val_loss: 0.0359\n",
      "Epoch 60/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0360 - val_loss: 0.0358\n",
      "Epoch 61/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0360 - val_loss: 0.0359\n",
      "Epoch 62/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0361 - val_loss: 0.0359\n",
      "Epoch 63/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0360 - val_loss: 0.0360\n",
      "Epoch 64/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0361 - val_loss: 0.0358\n",
      "Epoch 65/100\n",
      "199/199 [==============================] - 0s 958us/step - loss: 0.0360 - val_loss: 0.0358\n",
      "Epoch 66/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0360 - val_loss: 0.0358\n",
      "Epoch 67/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0361 - val_loss: 0.0358\n",
      "Epoch 68/100\n",
      "199/199 [==============================] - 0s 959us/step - loss: 0.0359 - val_loss: 0.0359\n",
      "Epoch 69/100\n",
      "199/199 [==============================] - 0s 963us/step - loss: 0.0360 - val_loss: 0.0357\n",
      "Epoch 70/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0359 - val_loss: 0.0358\n",
      "Epoch 71/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0360 - val_loss: 0.0357\n",
      "Epoch 72/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0359 - val_loss: 0.0359\n",
      "Epoch 73/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0359 - val_loss: 0.0357\n",
      "Epoch 74/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0359 - val_loss: 0.0358\n",
      "Epoch 75/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0360 - val_loss: 0.0358\n",
      "Epoch 76/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0359 - val_loss: 0.0357\n",
      "Epoch 77/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0360 - val_loss: 0.0360\n",
      "Epoch 78/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0359 - val_loss: 0.0357\n",
      "Epoch 79/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0359 - val_loss: 0.0359\n",
      "Epoch 80/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0359 - val_loss: 0.0361\n",
      "Epoch 81/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0359 - val_loss: 0.0358\n",
      "Epoch 82/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0359 - val_loss: 0.0358\n",
      "Epoch 83/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0359 - val_loss: 0.0358\n",
      "Epoch 84/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0359 - val_loss: 0.0365\n",
      "Epoch 85/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0359 - val_loss: 0.0357\n",
      "Epoch 86/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0359 - val_loss: 0.0360\n",
      "Epoch 87/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0359 - val_loss: 0.0358\n",
      "Epoch 88/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0358 - val_loss: 0.0356\n",
      "Epoch 89/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0358 - val_loss: 0.0356\n",
      "Epoch 90/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0358 - val_loss: 0.0357\n",
      "Epoch 91/100\n",
      "199/199 [==============================] - 0s 984us/step - loss: 0.0359 - val_loss: 0.0357\n",
      "Epoch 92/100\n",
      "199/199 [==============================] - 0s 961us/step - loss: 0.0358 - val_loss: 0.0357\n",
      "Epoch 93/100\n",
      "199/199 [==============================] - 0s 964us/step - loss: 0.0358 - val_loss: 0.0357\n",
      "Epoch 94/100\n",
      "199/199 [==============================] - 0s 975us/step - loss: 0.0359 - val_loss: 0.0357\n",
      "Epoch 95/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0358 - val_loss: 0.0357\n",
      "Epoch 96/100\n",
      "199/199 [==============================] - 0s 957us/step - loss: 0.0358 - val_loss: 0.0357\n",
      "Epoch 97/100\n",
      "199/199 [==============================] - 0s 945us/step - loss: 0.0358 - val_loss: 0.0358\n",
      "Epoch 98/100\n",
      "199/199 [==============================] - 0s 980us/step - loss: 0.0357 - val_loss: 0.0356\n",
      "Epoch 99/100\n",
      "199/199 [==============================] - 0s 962us/step - loss: 0.0358 - val_loss: 0.0356\n",
      "Epoch 100/100\n",
      "199/199 [==============================] - 0s 964us/step - loss: 0.0358 - val_loss: 0.0356\n",
      "This round is 8\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_11724/328462441.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  para_dfm = para_dfm.append({\"reg_param\": reg_param, \"number_units_layers\": numbers_units_layers, \"number_units_bottleneck\": numbers_units_bottleneck, \"dropout_rate\": dropout_rate, \"number_layers\": numbers_layers, \"whether_dropout\": whether_dropout, \"whether_regularizer\": whether_regularizer, \"overfit_metric\": overfit_metric, \"val2_avg_recon_error\": val2_avg_recon_error,'val1_loss':val1_loss}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 1s 3ms/step - loss: 0.0893 - val_loss: 0.0452\n",
      "Epoch 2/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0376 - val_loss: 0.0323\n",
      "Epoch 3/100\n",
      "199/199 [==============================] - 0s 940us/step - loss: 0.0284 - val_loss: 0.0251\n",
      "Epoch 4/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0221 - val_loss: 0.0189\n",
      "Epoch 5/100\n",
      "199/199 [==============================] - 0s 959us/step - loss: 0.0171 - val_loss: 0.0153\n",
      "Epoch 6/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0144 - val_loss: 0.0131\n",
      "Epoch 7/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0127 - val_loss: 0.0121\n",
      "Epoch 8/100\n",
      "199/199 [==============================] - 0s 969us/step - loss: 0.0118 - val_loss: 0.0114\n",
      "Epoch 9/100\n",
      "199/199 [==============================] - 0s 951us/step - loss: 0.0109 - val_loss: 0.0106\n",
      "Epoch 10/100\n",
      "199/199 [==============================] - 0s 956us/step - loss: 0.0100 - val_loss: 0.0096\n",
      "Epoch 11/100\n",
      "199/199 [==============================] - 0s 966us/step - loss: 0.0090 - val_loss: 0.0088\n",
      "Epoch 12/100\n",
      "199/199 [==============================] - 0s 952us/step - loss: 0.0082 - val_loss: 0.0080\n",
      "Epoch 13/100\n",
      "199/199 [==============================] - 0s 959us/step - loss: 0.0073 - val_loss: 0.0073\n",
      "Epoch 14/100\n",
      "199/199 [==============================] - 0s 954us/step - loss: 0.0068 - val_loss: 0.0069\n",
      "Epoch 15/100\n",
      "199/199 [==============================] - 0s 937us/step - loss: 0.0064 - val_loss: 0.0065\n",
      "Epoch 16/100\n",
      "199/199 [==============================] - 0s 995us/step - loss: 0.0060 - val_loss: 0.0061\n",
      "Epoch 17/100\n",
      "199/199 [==============================] - 0s 956us/step - loss: 0.0057 - val_loss: 0.0059\n",
      "Epoch 18/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0054 - val_loss: 0.0056\n",
      "Epoch 19/100\n",
      "199/199 [==============================] - 0s 981us/step - loss: 0.0052 - val_loss: 0.0053\n",
      "Epoch 20/100\n",
      "199/199 [==============================] - 0s 995us/step - loss: 0.0050 - val_loss: 0.0051\n",
      "Epoch 21/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0047 - val_loss: 0.0049\n",
      "Epoch 22/100\n",
      "199/199 [==============================] - 0s 987us/step - loss: 0.0045 - val_loss: 0.0047\n",
      "Epoch 23/100\n",
      "199/199 [==============================] - 0s 993us/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 24/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0044\n",
      "Epoch 25/100\n",
      "199/199 [==============================] - 0s 951us/step - loss: 0.0040 - val_loss: 0.0042\n",
      "Epoch 26/100\n",
      "199/199 [==============================] - 0s 928us/step - loss: 0.0039 - val_loss: 0.0041\n",
      "Epoch 27/100\n",
      "199/199 [==============================] - 0s 913us/step - loss: 0.0038 - val_loss: 0.0040\n",
      "Epoch 28/100\n",
      "199/199 [==============================] - 0s 957us/step - loss: 0.0036 - val_loss: 0.0038\n",
      "Epoch 29/100\n",
      "199/199 [==============================] - 0s 962us/step - loss: 0.0033 - val_loss: 0.0036\n",
      "Epoch 30/100\n",
      "199/199 [==============================] - 0s 920us/step - loss: 0.0032 - val_loss: 0.0034\n",
      "Epoch 31/100\n",
      "199/199 [==============================] - 0s 974us/step - loss: 0.0030 - val_loss: 0.0033\n",
      "Epoch 32/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 33/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0027 - val_loss: 0.0030\n",
      "Epoch 34/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0026 - val_loss: 0.0030\n",
      "Epoch 35/100\n",
      "199/199 [==============================] - 0s 945us/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 36/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 37/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 38/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 39/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 40/100\n",
      "199/199 [==============================] - 0s 965us/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 41/100\n",
      "199/199 [==============================] - 0s 973us/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 42/100\n",
      "199/199 [==============================] - 0s 961us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 43/100\n",
      "199/199 [==============================] - 0s 962us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 44/100\n",
      "199/199 [==============================] - 0s 957us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 45/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 46/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 47/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 48/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 49/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 50/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 51/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 52/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 53/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 54/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 55/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 56/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 57/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 58/100\n",
      "199/199 [==============================] - 0s 986us/step - loss: 0.0016 - val_loss: 0.0020\n",
      "Epoch 59/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 60/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 61/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 62/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 63/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 64/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 65/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 66/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 67/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 68/100\n",
      "199/199 [==============================] - 0s 962us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 69/100\n",
      "199/199 [==============================] - 0s 962us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 70/100\n",
      "199/199 [==============================] - 0s 980us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 71/100\n",
      "199/199 [==============================] - 0s 962us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 72/100\n",
      "199/199 [==============================] - 0s 950us/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 73/100\n",
      "199/199 [==============================] - 0s 959us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 74/100\n",
      "199/199 [==============================] - 0s 963us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 75/100\n",
      "199/199 [==============================] - 0s 963us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 76/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 77/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 78/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 79/100\n",
      "199/199 [==============================] - 0s 977us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 80/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 81/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 82/100\n",
      "199/199 [==============================] - 0s 966us/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 83/100\n",
      "199/199 [==============================] - 0s 942us/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 84/100\n",
      "199/199 [==============================] - 0s 982us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 85/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 86/100\n",
      "199/199 [==============================] - 0s 914us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 87/100\n",
      "199/199 [==============================] - 0s 938us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 88/100\n",
      "199/199 [==============================] - 0s 936us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 89/100\n",
      "199/199 [==============================] - 0s 1000us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 90/100\n",
      "199/199 [==============================] - 0s 943us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 91/100\n",
      "199/199 [==============================] - 0s 978us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 92/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 93/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 94/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 95/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 96/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 97/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 98/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 99/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 100/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0016\n",
      "This round is 9\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_11724/328462441.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  para_dfm = para_dfm.append({\"reg_param\": reg_param, \"number_units_layers\": numbers_units_layers, \"number_units_bottleneck\": numbers_units_bottleneck, \"dropout_rate\": dropout_rate, \"number_layers\": numbers_layers, \"whether_dropout\": whether_dropout, \"whether_regularizer\": whether_regularizer, \"overfit_metric\": overfit_metric, \"val2_avg_recon_error\": val2_avg_recon_error,'val1_loss':val1_loss}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0681 - val_loss: 0.0353\n",
      "Epoch 2/100\n",
      "199/199 [==============================] - 0s 990us/step - loss: 0.0287 - val_loss: 0.0232\n",
      "Epoch 3/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0202 - val_loss: 0.0173\n",
      "Epoch 4/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0156 - val_loss: 0.0140\n",
      "Epoch 5/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0128 - val_loss: 0.0117\n",
      "Epoch 6/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0107 - val_loss: 0.0098\n",
      "Epoch 7/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0083\n",
      "Epoch 8/100\n",
      "199/199 [==============================] - 0s 950us/step - loss: 0.0075 - val_loss: 0.0070\n",
      "Epoch 9/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0065 - val_loss: 0.0061\n",
      "Epoch 10/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0057 - val_loss: 0.0054\n",
      "Epoch 11/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0050 - val_loss: 0.0048\n",
      "Epoch 12/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 13/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 14/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 15/100\n",
      "199/199 [==============================] - 0s 978us/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 16/100\n",
      "199/199 [==============================] - 0s 936us/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 17/100\n",
      "199/199 [==============================] - 0s 944us/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 18/100\n",
      "199/199 [==============================] - 0s 936us/step - loss: 0.0029 - val_loss: 0.0029\n",
      "Epoch 19/100\n",
      "199/199 [==============================] - 0s 962us/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 20/100\n",
      "199/199 [==============================] - 0s 955us/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 21/100\n",
      "199/199 [==============================] - 0s 942us/step - loss: 0.0024 - val_loss: 0.0026\n",
      "Epoch 22/100\n",
      "199/199 [==============================] - 0s 935us/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 23/100\n",
      "199/199 [==============================] - 0s 938us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 24/100\n",
      "199/199 [==============================] - 0s 928us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 25/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 26/100\n",
      "199/199 [==============================] - 0s 945us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 27/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 28/100\n",
      "199/199 [==============================] - 0s 960us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 29/100\n",
      "199/199 [==============================] - 0s 1000us/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 30/100\n",
      "199/199 [==============================] - 0s 945us/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 31/100\n",
      "199/199 [==============================] - 0s 949us/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 32/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 33/100\n",
      "199/199 [==============================] - 0s 948us/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 34/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 35/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 36/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 37/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 9.6937e-04 - val_loss: 0.0013\n",
      "Epoch 38/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 9.2848e-04 - val_loss: 0.0012\n",
      "Epoch 39/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 8.9782e-04 - val_loss: 0.0012\n",
      "Epoch 40/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 8.5736e-04 - val_loss: 0.0012\n",
      "Epoch 41/100\n",
      "199/199 [==============================] - 0s 984us/step - loss: 8.4197e-04 - val_loss: 0.0012\n",
      "Epoch 42/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 7.9896e-04 - val_loss: 0.0011\n",
      "Epoch 43/100\n",
      "199/199 [==============================] - 0s 993us/step - loss: 7.8467e-04 - val_loss: 0.0011\n",
      "Epoch 44/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 7.5294e-04 - val_loss: 0.0010\n",
      "Epoch 45/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 7.2574e-04 - val_loss: 0.0011\n",
      "Epoch 46/100\n",
      "199/199 [==============================] - 0s 917us/step - loss: 7.1091e-04 - val_loss: 9.8733e-04\n",
      "Epoch 47/100\n",
      "199/199 [==============================] - 0s 907us/step - loss: 6.8931e-04 - val_loss: 9.7894e-04\n",
      "Epoch 48/100\n",
      "199/199 [==============================] - 0s 907us/step - loss: 6.5881e-04 - val_loss: 9.4942e-04\n",
      "Epoch 49/100\n",
      "199/199 [==============================] - 0s 915us/step - loss: 6.4111e-04 - val_loss: 9.4567e-04\n",
      "Epoch 50/100\n",
      "199/199 [==============================] - 0s 952us/step - loss: 6.2335e-04 - val_loss: 9.4044e-04\n",
      "Epoch 51/100\n",
      "199/199 [==============================] - 0s 989us/step - loss: 6.0174e-04 - val_loss: 8.9938e-04\n",
      "Epoch 52/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 5.9338e-04 - val_loss: 8.6376e-04\n",
      "Epoch 53/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 5.8352e-04 - val_loss: 8.6857e-04\n",
      "Epoch 54/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 5.6559e-04 - val_loss: 8.7503e-04\n",
      "Epoch 55/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 5.4948e-04 - val_loss: 8.2769e-04\n",
      "Epoch 56/100\n",
      "199/199 [==============================] - 0s 984us/step - loss: 5.3622e-04 - val_loss: 8.3147e-04\n",
      "Epoch 57/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 5.2585e-04 - val_loss: 8.1736e-04\n",
      "Epoch 58/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 5.1719e-04 - val_loss: 8.3037e-04\n",
      "Epoch 59/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 5.0710e-04 - val_loss: 8.1280e-04\n",
      "Epoch 60/100\n",
      "199/199 [==============================] - 0s 988us/step - loss: 4.9847e-04 - val_loss: 7.9776e-04\n",
      "Epoch 61/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 4.9333e-04 - val_loss: 7.8426e-04\n",
      "Epoch 62/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 4.7069e-04 - val_loss: 7.6330e-04\n",
      "Epoch 63/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 4.6444e-04 - val_loss: 7.8520e-04\n",
      "Epoch 64/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 4.4758e-04 - val_loss: 7.8778e-04\n",
      "Epoch 65/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 4.4250e-04 - val_loss: 7.4345e-04\n",
      "Epoch 66/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 4.4001e-04 - val_loss: 7.4719e-04\n",
      "Epoch 67/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 4.4205e-04 - val_loss: 7.4549e-04\n",
      "Epoch 68/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 4.2782e-04 - val_loss: 7.4758e-04\n",
      "Epoch 69/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 4.2014e-04 - val_loss: 7.2171e-04\n",
      "Epoch 70/100\n",
      "199/199 [==============================] - 0s 996us/step - loss: 4.1604e-04 - val_loss: 7.4042e-04\n",
      "Epoch 71/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 4.1620e-04 - val_loss: 7.6575e-04\n",
      "Epoch 72/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 4.0676e-04 - val_loss: 7.2590e-04\n",
      "Epoch 73/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 4.0383e-04 - val_loss: 7.0191e-04\n",
      "Epoch 74/100\n",
      "199/199 [==============================] - 0s 905us/step - loss: 3.9556e-04 - val_loss: 7.2100e-04\n",
      "Epoch 75/100\n",
      "199/199 [==============================] - 0s 927us/step - loss: 3.8633e-04 - val_loss: 7.0440e-04\n",
      "Epoch 76/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 3.8726e-04 - val_loss: 6.8600e-04\n",
      "Epoch 77/100\n",
      "199/199 [==============================] - 0s 912us/step - loss: 3.8280e-04 - val_loss: 7.7306e-04\n",
      "Epoch 78/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 3.8401e-04 - val_loss: 6.8991e-04\n",
      "Epoch 79/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 3.7853e-04 - val_loss: 6.8005e-04\n",
      "Epoch 80/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 3.7757e-04 - val_loss: 6.9625e-04\n",
      "Epoch 81/100\n",
      "199/199 [==============================] - 0s 954us/step - loss: 3.8406e-04 - val_loss: 6.9839e-04\n",
      "Epoch 82/100\n",
      "199/199 [==============================] - 0s 914us/step - loss: 3.8088e-04 - val_loss: 7.1777e-04\n",
      "Epoch 83/100\n",
      "199/199 [==============================] - 0s 920us/step - loss: 3.6933e-04 - val_loss: 6.5651e-04\n",
      "Epoch 84/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 3.5557e-04 - val_loss: 6.6102e-04\n",
      "Epoch 85/100\n",
      "199/199 [==============================] - 0s 957us/step - loss: 3.5064e-04 - val_loss: 6.7791e-04\n",
      "Epoch 86/100\n",
      "199/199 [==============================] - 0s 929us/step - loss: 3.5449e-04 - val_loss: 6.6084e-04\n",
      "Epoch 87/100\n",
      "199/199 [==============================] - 0s 899us/step - loss: 3.4446e-04 - val_loss: 6.7450e-04\n",
      "Epoch 88/100\n",
      "199/199 [==============================] - 0s 925us/step - loss: 3.4312e-04 - val_loss: 6.4984e-04\n",
      "Epoch 89/100\n",
      "199/199 [==============================] - 0s 900us/step - loss: 3.4904e-04 - val_loss: 6.4546e-04\n",
      "Epoch 90/100\n",
      "199/199 [==============================] - 0s 922us/step - loss: 3.4227e-04 - val_loss: 6.4494e-04\n",
      "Epoch 91/100\n",
      "199/199 [==============================] - 0s 929us/step - loss: 3.4639e-04 - val_loss: 6.5438e-04\n",
      "Epoch 92/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 3.3430e-04 - val_loss: 6.2725e-04\n",
      "Epoch 93/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 3.7220e-04 - val_loss: 6.7547e-04\n",
      "Epoch 94/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 3.5138e-04 - val_loss: 6.3631e-04\n",
      "Epoch 95/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 3.2794e-04 - val_loss: 6.2333e-04\n",
      "Epoch 96/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 3.1917e-04 - val_loss: 6.5635e-04\n",
      "Epoch 97/100\n",
      "199/199 [==============================] - 0s 937us/step - loss: 3.1876e-04 - val_loss: 6.0767e-04\n",
      "Epoch 98/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 3.1860e-04 - val_loss: 6.4145e-04\n",
      "Epoch 99/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 3.1985e-04 - val_loss: 6.0976e-04\n",
      "Epoch 100/100\n",
      "199/199 [==============================] - 0s 982us/step - loss: 3.2241e-04 - val_loss: 6.1946e-04\n",
      "This round is 10\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_11724/328462441.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  para_dfm = para_dfm.append({\"reg_param\": reg_param, \"number_units_layers\": numbers_units_layers, \"number_units_bottleneck\": numbers_units_bottleneck, \"dropout_rate\": dropout_rate, \"number_layers\": numbers_layers, \"whether_dropout\": whether_dropout, \"whether_regularizer\": whether_regularizer, \"overfit_metric\": overfit_metric, \"val2_avg_recon_error\": val2_avg_recon_error,'val1_loss':val1_loss}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 0s 1ms/step - loss: 0.9780 - val_loss: 0.2743\n",
      "Epoch 2/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.1319 - val_loss: 0.0682\n",
      "Epoch 3/100\n",
      "199/199 [==============================] - 0s 972us/step - loss: 0.0590 - val_loss: 0.0554\n",
      "Epoch 4/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0552 - val_loss: 0.0550\n",
      "Epoch 5/100\n",
      "199/199 [==============================] - 0s 971us/step - loss: 0.0550 - val_loss: 0.0550\n",
      "Epoch 6/100\n",
      "199/199 [==============================] - 0s 957us/step - loss: 0.0550 - val_loss: 0.0549\n",
      "Epoch 7/100\n",
      "199/199 [==============================] - 0s 959us/step - loss: 0.0549 - val_loss: 0.0548\n",
      "Epoch 8/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0545 - val_loss: 0.0536\n",
      "Epoch 9/100\n",
      "199/199 [==============================] - 0s 958us/step - loss: 0.0498 - val_loss: 0.0444\n",
      "Epoch 10/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0424 - val_loss: 0.0407\n",
      "Epoch 11/100\n",
      "199/199 [==============================] - 0s 918us/step - loss: 0.0403 - val_loss: 0.0395\n",
      "Epoch 12/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0393 - val_loss: 0.0387\n",
      "Epoch 13/100\n",
      "199/199 [==============================] - 0s 947us/step - loss: 0.0387 - val_loss: 0.0382\n",
      "Epoch 14/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0382 - val_loss: 0.0378\n",
      "Epoch 15/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0379 - val_loss: 0.0375\n",
      "Epoch 16/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0376 - val_loss: 0.0372\n",
      "Epoch 17/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0373 - val_loss: 0.0370\n",
      "Epoch 18/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0372 - val_loss: 0.0369\n",
      "Epoch 19/100\n",
      "199/199 [==============================] - 0s 982us/step - loss: 0.0370 - val_loss: 0.0368\n",
      "Epoch 20/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0369 - val_loss: 0.0366\n",
      "Epoch 21/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0368 - val_loss: 0.0366\n",
      "Epoch 22/100\n",
      "199/199 [==============================] - 0s 993us/step - loss: 0.0367 - val_loss: 0.0365\n",
      "Epoch 23/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0366 - val_loss: 0.0364\n",
      "Epoch 24/100\n",
      "199/199 [==============================] - 0s 975us/step - loss: 0.0366 - val_loss: 0.0364\n",
      "Epoch 25/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0365 - val_loss: 0.0363\n",
      "Epoch 26/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0365 - val_loss: 0.0362\n",
      "Epoch 27/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0364 - val_loss: 0.0363\n",
      "Epoch 28/100\n",
      "199/199 [==============================] - 0s 960us/step - loss: 0.0364 - val_loss: 0.0365\n",
      "Epoch 29/100\n",
      "199/199 [==============================] - 0s 959us/step - loss: 0.0364 - val_loss: 0.0361\n",
      "Epoch 30/100\n",
      "199/199 [==============================] - 0s 959us/step - loss: 0.0363 - val_loss: 0.0361\n",
      "Epoch 31/100\n",
      "199/199 [==============================] - 0s 982us/step - loss: 0.0363 - val_loss: 0.0362\n",
      "Epoch 32/100\n",
      "199/199 [==============================] - 0s 968us/step - loss: 0.0363 - val_loss: 0.0363\n",
      "Epoch 33/100\n",
      "199/199 [==============================] - 0s 963us/step - loss: 0.0362 - val_loss: 0.0360\n",
      "Epoch 34/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0362 - val_loss: 0.0360\n",
      "Epoch 35/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0361 - val_loss: 0.0363\n",
      "Epoch 36/100\n",
      "199/199 [==============================] - 0s 966us/step - loss: 0.0361 - val_loss: 0.0359\n",
      "Epoch 37/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0360 - val_loss: 0.0358\n",
      "Epoch 38/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0360 - val_loss: 0.0361\n",
      "Epoch 39/100\n",
      "199/199 [==============================] - 0s 931us/step - loss: 0.0360 - val_loss: 0.0358\n",
      "Epoch 40/100\n",
      "199/199 [==============================] - 0s 976us/step - loss: 0.0359 - val_loss: 0.0357\n",
      "Epoch 41/100\n",
      "199/199 [==============================] - 0s 987us/step - loss: 0.0359 - val_loss: 0.0357\n",
      "Epoch 42/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0359 - val_loss: 0.0357\n",
      "Epoch 43/100\n",
      "199/199 [==============================] - 0s 979us/step - loss: 0.0358 - val_loss: 0.0356\n",
      "Epoch 44/100\n",
      "199/199 [==============================] - 0s 926us/step - loss: 0.0357 - val_loss: 0.0358\n",
      "Epoch 45/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0357 - val_loss: 0.0355\n",
      "Epoch 46/100\n",
      "199/199 [==============================] - 0s 992us/step - loss: 0.0357 - val_loss: 0.0355\n",
      "Epoch 47/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0355 - val_loss: 0.0355\n",
      "Epoch 48/100\n",
      "199/199 [==============================] - 0s 960us/step - loss: 0.0355 - val_loss: 0.0355\n",
      "Epoch 49/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0355 - val_loss: 0.0353\n",
      "Epoch 50/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0354 - val_loss: 0.0352\n",
      "Epoch 51/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0353 - val_loss: 0.0351\n",
      "Epoch 52/100\n",
      "199/199 [==============================] - 1s 3ms/step - loss: 0.0352 - val_loss: 0.0351\n",
      "Epoch 53/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0352 - val_loss: 0.0351\n",
      "Epoch 54/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0352 - val_loss: 0.0351\n",
      "Epoch 55/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0351 - val_loss: 0.0349\n",
      "Epoch 56/100\n",
      "199/199 [==============================] - 0s 979us/step - loss: 0.0350 - val_loss: 0.0349\n",
      "Epoch 57/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0350 - val_loss: 0.0349\n",
      "Epoch 58/100\n",
      "199/199 [==============================] - 0s 997us/step - loss: 0.0349 - val_loss: 0.0349\n",
      "Epoch 59/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0349 - val_loss: 0.0347\n",
      "Epoch 60/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0348 - val_loss: 0.0347\n",
      "Epoch 61/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0348 - val_loss: 0.0347\n",
      "Epoch 62/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0348 - val_loss: 0.0347\n",
      "Epoch 63/100\n",
      "199/199 [==============================] - 0s 968us/step - loss: 0.0347 - val_loss: 0.0345\n",
      "Epoch 64/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0346 - val_loss: 0.0345\n",
      "Epoch 65/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0346 - val_loss: 0.0344\n",
      "Epoch 66/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0346 - val_loss: 0.0344\n",
      "Epoch 67/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0346 - val_loss: 0.0345\n",
      "Epoch 68/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0345 - val_loss: 0.0343\n",
      "Epoch 69/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0344 - val_loss: 0.0344\n",
      "Epoch 70/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0344 - val_loss: 0.0344\n",
      "Epoch 71/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0345 - val_loss: 0.0343\n",
      "Epoch 72/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0343 - val_loss: 0.0342\n",
      "Epoch 73/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0344 - val_loss: 0.0342\n",
      "Epoch 74/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0343 - val_loss: 0.0341\n",
      "Epoch 75/100\n",
      "199/199 [==============================] - 0s 966us/step - loss: 0.0342 - val_loss: 0.0341\n",
      "Epoch 76/100\n",
      "199/199 [==============================] - 0s 954us/step - loss: 0.0342 - val_loss: 0.0340\n",
      "Epoch 77/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0343 - val_loss: 0.0341\n",
      "Epoch 78/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0341 - val_loss: 0.0341\n",
      "Epoch 79/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0341 - val_loss: 0.0341\n",
      "Epoch 80/100\n",
      "199/199 [==============================] - 0s 956us/step - loss: 0.0341 - val_loss: 0.0339\n",
      "Epoch 81/100\n",
      "199/199 [==============================] - 0s 970us/step - loss: 0.0340 - val_loss: 0.0339\n",
      "Epoch 82/100\n",
      "199/199 [==============================] - 0s 949us/step - loss: 0.0340 - val_loss: 0.0339\n",
      "Epoch 83/100\n",
      "199/199 [==============================] - 0s 959us/step - loss: 0.0339 - val_loss: 0.0338\n",
      "Epoch 84/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0339 - val_loss: 0.0349\n",
      "Epoch 85/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0340 - val_loss: 0.0337\n",
      "Epoch 86/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0338 - val_loss: 0.0336\n",
      "Epoch 87/100\n",
      "199/199 [==============================] - 0s 981us/step - loss: 0.0338 - val_loss: 0.0336\n",
      "Epoch 88/100\n",
      "199/199 [==============================] - 0s 962us/step - loss: 0.0336 - val_loss: 0.0336\n",
      "Epoch 89/100\n",
      "199/199 [==============================] - 0s 901us/step - loss: 0.0335 - val_loss: 0.0337\n",
      "Epoch 90/100\n",
      "199/199 [==============================] - 0s 894us/step - loss: 0.0333 - val_loss: 0.0332\n",
      "Epoch 91/100\n",
      "199/199 [==============================] - 0s 912us/step - loss: 0.0330 - val_loss: 0.0329\n",
      "Epoch 92/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0326 - val_loss: 0.0324\n",
      "Epoch 93/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0322 - val_loss: 0.0318\n",
      "Epoch 94/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0319 - val_loss: 0.0316\n",
      "Epoch 95/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0315 - val_loss: 0.0311\n",
      "Epoch 96/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0312 - val_loss: 0.0311\n",
      "Epoch 97/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0310 - val_loss: 0.0307\n",
      "Epoch 98/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0307 - val_loss: 0.0305\n",
      "Epoch 99/100\n",
      "199/199 [==============================] - 0s 956us/step - loss: 0.0304 - val_loss: 0.0301\n",
      "Epoch 100/100\n",
      "199/199 [==============================] - 0s 896us/step - loss: 0.0302 - val_loss: 0.0298\n",
      "This round is 11\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_11724/328462441.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  para_dfm = para_dfm.append({\"reg_param\": reg_param, \"number_units_layers\": numbers_units_layers, \"number_units_bottleneck\": numbers_units_bottleneck, \"dropout_rate\": dropout_rate, \"number_layers\": numbers_layers, \"whether_dropout\": whether_dropout, \"whether_regularizer\": whether_regularizer, \"overfit_metric\": overfit_metric, \"val2_avg_recon_error\": val2_avg_recon_error,'val1_loss':val1_loss}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0893 - val_loss: 0.0452\n",
      "Epoch 2/100\n",
      "199/199 [==============================] - 0s 865us/step - loss: 0.0376 - val_loss: 0.0323\n",
      "Epoch 3/100\n",
      "199/199 [==============================] - 0s 861us/step - loss: 0.0284 - val_loss: 0.0251\n",
      "Epoch 4/100\n",
      "199/199 [==============================] - 0s 870us/step - loss: 0.0221 - val_loss: 0.0189\n",
      "Epoch 5/100\n",
      "199/199 [==============================] - 0s 867us/step - loss: 0.0171 - val_loss: 0.0153\n",
      "Epoch 6/100\n",
      "199/199 [==============================] - 0s 847us/step - loss: 0.0144 - val_loss: 0.0131\n",
      "Epoch 7/100\n",
      "199/199 [==============================] - 0s 865us/step - loss: 0.0127 - val_loss: 0.0121\n",
      "Epoch 8/100\n",
      "199/199 [==============================] - 0s 883us/step - loss: 0.0118 - val_loss: 0.0114\n",
      "Epoch 9/100\n",
      "199/199 [==============================] - 0s 850us/step - loss: 0.0109 - val_loss: 0.0106\n",
      "Epoch 10/100\n",
      "199/199 [==============================] - 0s 882us/step - loss: 0.0100 - val_loss: 0.0096\n",
      "Epoch 11/100\n",
      "199/199 [==============================] - 0s 858us/step - loss: 0.0090 - val_loss: 0.0088\n",
      "Epoch 12/100\n",
      "199/199 [==============================] - 0s 882us/step - loss: 0.0082 - val_loss: 0.0080\n",
      "Epoch 13/100\n",
      "199/199 [==============================] - 0s 991us/step - loss: 0.0073 - val_loss: 0.0073\n",
      "Epoch 14/100\n",
      "199/199 [==============================] - 0s 932us/step - loss: 0.0068 - val_loss: 0.0069\n",
      "Epoch 15/100\n",
      "199/199 [==============================] - 0s 878us/step - loss: 0.0064 - val_loss: 0.0065\n",
      "Epoch 16/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0061\n",
      "Epoch 17/100\n",
      "199/199 [==============================] - 0s 921us/step - loss: 0.0057 - val_loss: 0.0059\n",
      "Epoch 18/100\n",
      "199/199 [==============================] - 0s 910us/step - loss: 0.0054 - val_loss: 0.0056\n",
      "Epoch 19/100\n",
      "199/199 [==============================] - 0s 877us/step - loss: 0.0052 - val_loss: 0.0053\n",
      "Epoch 20/100\n",
      "199/199 [==============================] - 0s 886us/step - loss: 0.0050 - val_loss: 0.0051\n",
      "Epoch 21/100\n",
      "199/199 [==============================] - 0s 887us/step - loss: 0.0047 - val_loss: 0.0049\n",
      "Epoch 22/100\n",
      "199/199 [==============================] - 0s 904us/step - loss: 0.0045 - val_loss: 0.0047\n",
      "Epoch 23/100\n",
      "199/199 [==============================] - 0s 872us/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 24/100\n",
      "199/199 [==============================] - 0s 873us/step - loss: 0.0042 - val_loss: 0.0044\n",
      "Epoch 25/100\n",
      "199/199 [==============================] - 0s 926us/step - loss: 0.0040 - val_loss: 0.0042\n",
      "Epoch 26/100\n",
      "199/199 [==============================] - 0s 961us/step - loss: 0.0039 - val_loss: 0.0041\n",
      "Epoch 27/100\n",
      "199/199 [==============================] - 0s 869us/step - loss: 0.0038 - val_loss: 0.0040\n",
      "Epoch 28/100\n",
      "199/199 [==============================] - 0s 878us/step - loss: 0.0036 - val_loss: 0.0038\n",
      "Epoch 29/100\n",
      "199/199 [==============================] - 0s 865us/step - loss: 0.0033 - val_loss: 0.0036\n",
      "Epoch 30/100\n",
      "199/199 [==============================] - 0s 865us/step - loss: 0.0032 - val_loss: 0.0034\n",
      "Epoch 31/100\n",
      "199/199 [==============================] - 0s 866us/step - loss: 0.0030 - val_loss: 0.0033\n",
      "Epoch 32/100\n",
      "199/199 [==============================] - 0s 971us/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 33/100\n",
      "199/199 [==============================] - 0s 988us/step - loss: 0.0027 - val_loss: 0.0030\n",
      "Epoch 34/100\n",
      "199/199 [==============================] - 0s 959us/step - loss: 0.0026 - val_loss: 0.0030\n",
      "Epoch 35/100\n",
      "199/199 [==============================] - 0s 918us/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 36/100\n",
      "199/199 [==============================] - 0s 872us/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 37/100\n",
      "199/199 [==============================] - 0s 875us/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 38/100\n",
      "199/199 [==============================] - 0s 883us/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 39/100\n",
      "199/199 [==============================] - 0s 875us/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 40/100\n",
      "199/199 [==============================] - 0s 878us/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 41/100\n",
      "199/199 [==============================] - 0s 936us/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 42/100\n",
      "199/199 [==============================] - 0s 929us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 43/100\n",
      "199/199 [==============================] - 0s 916us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 44/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 45/100\n",
      "199/199 [==============================] - 0s 915us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 46/100\n",
      "199/199 [==============================] - 0s 870us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 47/100\n",
      "199/199 [==============================] - 0s 865us/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 48/100\n",
      "199/199 [==============================] - 0s 872us/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 49/100\n",
      "199/199 [==============================] - 0s 941us/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 50/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 51/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 52/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 53/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 54/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 55/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 56/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 57/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 58/100\n",
      "199/199 [==============================] - 0s 926us/step - loss: 0.0016 - val_loss: 0.0020\n",
      "Epoch 59/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 60/100\n",
      "199/199 [==============================] - 0s 882us/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 61/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 62/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 63/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 64/100\n",
      "199/199 [==============================] - 1s 3ms/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 65/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 66/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 67/100\n",
      "199/199 [==============================] - 0s 926us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 68/100\n",
      "199/199 [==============================] - 0s 923us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 69/100\n",
      "199/199 [==============================] - 0s 941us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 70/100\n",
      "199/199 [==============================] - 0s 922us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 71/100\n",
      "199/199 [==============================] - 0s 942us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 72/100\n",
      "199/199 [==============================] - 0s 985us/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 73/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 74/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 75/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 76/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 77/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 78/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 79/100\n",
      "199/199 [==============================] - 0s 941us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 80/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 81/100\n",
      "199/199 [==============================] - 0s 937us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 82/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 83/100\n",
      "199/199 [==============================] - 0s 951us/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 84/100\n",
      "199/199 [==============================] - 0s 967us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 85/100\n",
      "199/199 [==============================] - 0s 938us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 86/100\n",
      "199/199 [==============================] - 0s 978us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 87/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 88/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 89/100\n",
      "199/199 [==============================] - 0s 909us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 90/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 91/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 92/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 93/100\n",
      "199/199 [==============================] - 0s 947us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 94/100\n",
      "199/199 [==============================] - 0s 991us/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 95/100\n",
      "199/199 [==============================] - 0s 994us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 96/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 97/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 98/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 99/100\n",
      "199/199 [==============================] - 0s 981us/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 100/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0016\n",
      "This round is 12\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_11724/328462441.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  para_dfm = para_dfm.append({\"reg_param\": reg_param, \"number_units_layers\": numbers_units_layers, \"number_units_bottleneck\": numbers_units_bottleneck, \"dropout_rate\": dropout_rate, \"number_layers\": numbers_layers, \"whether_dropout\": whether_dropout, \"whether_regularizer\": whether_regularizer, \"overfit_metric\": overfit_metric, \"val2_avg_recon_error\": val2_avg_recon_error,'val1_loss':val1_loss}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0893 - val_loss: 0.0452\n",
      "Epoch 2/100\n",
      "199/199 [==============================] - 0s 862us/step - loss: 0.0376 - val_loss: 0.0323\n",
      "Epoch 3/100\n",
      "199/199 [==============================] - 0s 872us/step - loss: 0.0284 - val_loss: 0.0251\n",
      "Epoch 4/100\n",
      "199/199 [==============================] - 0s 928us/step - loss: 0.0221 - val_loss: 0.0189\n",
      "Epoch 5/100\n",
      "199/199 [==============================] - 0s 872us/step - loss: 0.0171 - val_loss: 0.0153\n",
      "Epoch 6/100\n",
      "199/199 [==============================] - 0s 900us/step - loss: 0.0144 - val_loss: 0.0131\n",
      "Epoch 7/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0127 - val_loss: 0.0121\n",
      "Epoch 8/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0118 - val_loss: 0.0114\n",
      "Epoch 9/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0109 - val_loss: 0.0106\n",
      "Epoch 10/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0100 - val_loss: 0.0096\n",
      "Epoch 11/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0088\n",
      "Epoch 12/100\n",
      "199/199 [==============================] - 0s 926us/step - loss: 0.0082 - val_loss: 0.0080\n",
      "Epoch 13/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0073 - val_loss: 0.0073\n",
      "Epoch 14/100\n",
      "199/199 [==============================] - 0s 910us/step - loss: 0.0068 - val_loss: 0.0069\n",
      "Epoch 15/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0065\n",
      "Epoch 16/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0061\n",
      "Epoch 17/100\n",
      "199/199 [==============================] - 0s 948us/step - loss: 0.0057 - val_loss: 0.0059\n",
      "Epoch 18/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0054 - val_loss: 0.0056\n",
      "Epoch 19/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0052 - val_loss: 0.0053\n",
      "Epoch 20/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0050 - val_loss: 0.0051\n",
      "Epoch 21/100\n",
      "199/199 [==============================] - 0s 956us/step - loss: 0.0047 - val_loss: 0.0049\n",
      "Epoch 22/100\n",
      "199/199 [==============================] - 0s 952us/step - loss: 0.0045 - val_loss: 0.0047\n",
      "Epoch 23/100\n",
      "199/199 [==============================] - 0s 961us/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 24/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0044\n",
      "Epoch 25/100\n",
      "199/199 [==============================] - 0s 957us/step - loss: 0.0040 - val_loss: 0.0042\n",
      "Epoch 26/100\n",
      "199/199 [==============================] - 0s 903us/step - loss: 0.0039 - val_loss: 0.0041\n",
      "Epoch 27/100\n",
      "199/199 [==============================] - 0s 929us/step - loss: 0.0038 - val_loss: 0.0040\n",
      "Epoch 28/100\n",
      "199/199 [==============================] - 0s 945us/step - loss: 0.0036 - val_loss: 0.0038\n",
      "Epoch 29/100\n",
      "199/199 [==============================] - 0s 880us/step - loss: 0.0033 - val_loss: 0.0036\n",
      "Epoch 30/100\n",
      "199/199 [==============================] - 0s 954us/step - loss: 0.0032 - val_loss: 0.0034\n",
      "Epoch 31/100\n",
      "199/199 [==============================] - 0s 891us/step - loss: 0.0030 - val_loss: 0.0033\n",
      "Epoch 32/100\n",
      "199/199 [==============================] - 0s 924us/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 33/100\n",
      "199/199 [==============================] - 0s 993us/step - loss: 0.0027 - val_loss: 0.0030\n",
      "Epoch 34/100\n",
      "199/199 [==============================] - 0s 956us/step - loss: 0.0026 - val_loss: 0.0030\n",
      "Epoch 35/100\n",
      "199/199 [==============================] - 0s 886us/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 36/100\n",
      "199/199 [==============================] - 0s 907us/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 37/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 38/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 39/100\n",
      "199/199 [==============================] - 0s 925us/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 40/100\n",
      "199/199 [==============================] - 0s 887us/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 41/100\n",
      "199/199 [==============================] - 0s 974us/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 42/100\n",
      "199/199 [==============================] - 0s 959us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 43/100\n",
      "199/199 [==============================] - 0s 885us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 44/100\n",
      "199/199 [==============================] - 0s 921us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 45/100\n",
      "199/199 [==============================] - 0s 882us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 46/100\n",
      "199/199 [==============================] - 0s 936us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 47/100\n",
      "199/199 [==============================] - 0s 877us/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 48/100\n",
      "199/199 [==============================] - 0s 883us/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 49/100\n",
      "199/199 [==============================] - 0s 994us/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 50/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 51/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 52/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 53/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 54/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 55/100\n",
      "199/199 [==============================] - 0s 997us/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 56/100\n",
      "199/199 [==============================] - 0s 975us/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 57/100\n",
      "199/199 [==============================] - 0s 889us/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 58/100\n",
      "199/199 [==============================] - 0s 945us/step - loss: 0.0016 - val_loss: 0.0020\n",
      "Epoch 59/100\n",
      "199/199 [==============================] - 0s 908us/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 60/100\n",
      "199/199 [==============================] - 0s 949us/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 61/100\n",
      "199/199 [==============================] - 0s 933us/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 62/100\n",
      "199/199 [==============================] - 0s 869us/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 63/100\n",
      "199/199 [==============================] - 0s 920us/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 64/100\n",
      "199/199 [==============================] - 0s 881us/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 65/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 66/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 67/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 68/100\n",
      "199/199 [==============================] - 0s 987us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 69/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 70/100\n",
      "199/199 [==============================] - 0s 891us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 71/100\n",
      "199/199 [==============================] - 0s 980us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 72/100\n",
      "199/199 [==============================] - 0s 915us/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 73/100\n",
      "199/199 [==============================] - 0s 891us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 74/100\n",
      "199/199 [==============================] - 0s 856us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 75/100\n",
      "199/199 [==============================] - 0s 874us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 76/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 77/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 78/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 79/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 80/100\n",
      "199/199 [==============================] - 0s 896us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 81/100\n",
      "199/199 [==============================] - 0s 875us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 82/100\n",
      "199/199 [==============================] - 0s 878us/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 83/100\n",
      "199/199 [==============================] - 0s 870us/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 84/100\n",
      "199/199 [==============================] - 0s 872us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 85/100\n",
      "199/199 [==============================] - 0s 878us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 86/100\n",
      "199/199 [==============================] - 0s 868us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 87/100\n",
      "199/199 [==============================] - 0s 967us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 88/100\n",
      "199/199 [==============================] - 0s 907us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 89/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 90/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 91/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 92/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 93/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 94/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 95/100\n",
      "199/199 [==============================] - 0s 924us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 96/100\n",
      "199/199 [==============================] - 0s 924us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 97/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 98/100\n",
      "199/199 [==============================] - 0s 949us/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 99/100\n",
      "199/199 [==============================] - 0s 913us/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 100/100\n",
      "199/199 [==============================] - 0s 934us/step - loss: 0.0011 - val_loss: 0.0016\n",
      "This round is 13\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_11724/328462441.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  para_dfm = para_dfm.append({\"reg_param\": reg_param, \"number_units_layers\": numbers_units_layers, \"number_units_bottleneck\": numbers_units_bottleneck, \"dropout_rate\": dropout_rate, \"number_layers\": numbers_layers, \"whether_dropout\": whether_dropout, \"whether_regularizer\": whether_regularizer, \"overfit_metric\": overfit_metric, \"val2_avg_recon_error\": val2_avg_recon_error,'val1_loss':val1_loss}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 0s 1ms/step - loss: 0.1163 - val_loss: 0.0561\n",
      "Epoch 2/100\n",
      "199/199 [==============================] - 0s 924us/step - loss: 0.0554 - val_loss: 0.0552\n",
      "Epoch 3/100\n",
      "199/199 [==============================] - 0s 955us/step - loss: 0.0534 - val_loss: 0.0481\n",
      "Epoch 4/100\n",
      "199/199 [==============================] - 0s 980us/step - loss: 0.0417 - val_loss: 0.0379\n",
      "Epoch 5/100\n",
      "199/199 [==============================] - 0s 981us/step - loss: 0.0371 - val_loss: 0.0360\n",
      "Epoch 6/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0347 - val_loss: 0.0325\n",
      "Epoch 7/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0310 - val_loss: 0.0289\n",
      "Epoch 8/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0281 - val_loss: 0.0266\n",
      "Epoch 9/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0265 - val_loss: 0.0254\n",
      "Epoch 10/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0254 - val_loss: 0.0242\n",
      "Epoch 11/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0242 - val_loss: 0.0230\n",
      "Epoch 12/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0232 - val_loss: 0.0223\n",
      "Epoch 13/100\n",
      "199/199 [==============================] - 0s 961us/step - loss: 0.0225 - val_loss: 0.0217\n",
      "Epoch 14/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0219 - val_loss: 0.0211\n",
      "Epoch 15/100\n",
      "199/199 [==============================] - 0s 938us/step - loss: 0.0213 - val_loss: 0.0205\n",
      "Epoch 16/100\n",
      "199/199 [==============================] - 0s 910us/step - loss: 0.0207 - val_loss: 0.0198\n",
      "Epoch 17/100\n",
      "199/199 [==============================] - 0s 942us/step - loss: 0.0200 - val_loss: 0.0189\n",
      "Epoch 18/100\n",
      "199/199 [==============================] - 0s 934us/step - loss: 0.0185 - val_loss: 0.0172\n",
      "Epoch 19/100\n",
      "199/199 [==============================] - 0s 916us/step - loss: 0.0171 - val_loss: 0.0162\n",
      "Epoch 20/100\n",
      "199/199 [==============================] - 0s 901us/step - loss: 0.0163 - val_loss: 0.0155\n",
      "Epoch 21/100\n",
      "199/199 [==============================] - 0s 961us/step - loss: 0.0156 - val_loss: 0.0148\n",
      "Epoch 22/100\n",
      "199/199 [==============================] - 0s 998us/step - loss: 0.0149 - val_loss: 0.0142\n",
      "Epoch 23/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0144 - val_loss: 0.0137\n",
      "Epoch 24/100\n",
      "199/199 [==============================] - 0s 954us/step - loss: 0.0139 - val_loss: 0.0132\n",
      "Epoch 25/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0134 - val_loss: 0.0127\n",
      "Epoch 26/100\n",
      "199/199 [==============================] - 0s 979us/step - loss: 0.0130 - val_loss: 0.0124\n",
      "Epoch 27/100\n",
      "199/199 [==============================] - 0s 919us/step - loss: 0.0126 - val_loss: 0.0120\n",
      "Epoch 28/100\n",
      "199/199 [==============================] - 0s 932us/step - loss: 0.0122 - val_loss: 0.0116\n",
      "Epoch 29/100\n",
      "199/199 [==============================] - 0s 912us/step - loss: 0.0118 - val_loss: 0.0112\n",
      "Epoch 30/100\n",
      "199/199 [==============================] - 0s 965us/step - loss: 0.0114 - val_loss: 0.0108\n",
      "Epoch 31/100\n",
      "199/199 [==============================] - 0s 981us/step - loss: 0.0110 - val_loss: 0.0105\n",
      "Epoch 32/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0108 - val_loss: 0.0102\n",
      "Epoch 33/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0106 - val_loss: 0.0100\n",
      "Epoch 34/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0103 - val_loss: 0.0097\n",
      "Epoch 35/100\n",
      "199/199 [==============================] - 0s 973us/step - loss: 0.0100 - val_loss: 0.0095\n",
      "Epoch 36/100\n",
      "199/199 [==============================] - 0s 975us/step - loss: 0.0099 - val_loss: 0.0093\n",
      "Epoch 37/100\n",
      "199/199 [==============================] - 0s 971us/step - loss: 0.0096 - val_loss: 0.0091\n",
      "Epoch 38/100\n",
      "199/199 [==============================] - 0s 951us/step - loss: 0.0093 - val_loss: 0.0089\n",
      "Epoch 39/100\n",
      "199/199 [==============================] - 0s 945us/step - loss: 0.0092 - val_loss: 0.0087\n",
      "Epoch 40/100\n",
      "199/199 [==============================] - 0s 910us/step - loss: 0.0089 - val_loss: 0.0085\n",
      "Epoch 41/100\n",
      "199/199 [==============================] - 0s 917us/step - loss: 0.0088 - val_loss: 0.0083\n",
      "Epoch 42/100\n",
      "199/199 [==============================] - 0s 977us/step - loss: 0.0087 - val_loss: 0.0082\n",
      "Epoch 43/100\n",
      "199/199 [==============================] - 0s 950us/step - loss: 0.0085 - val_loss: 0.0080\n",
      "Epoch 44/100\n",
      "199/199 [==============================] - 0s 927us/step - loss: 0.0084 - val_loss: 0.0079\n",
      "Epoch 45/100\n",
      "199/199 [==============================] - 0s 930us/step - loss: 0.0081 - val_loss: 0.0077\n",
      "Epoch 46/100\n",
      "199/199 [==============================] - 0s 996us/step - loss: 0.0081 - val_loss: 0.0076\n",
      "Epoch 47/100\n",
      "199/199 [==============================] - 0s 924us/step - loss: 0.0079 - val_loss: 0.0075\n",
      "Epoch 48/100\n",
      "199/199 [==============================] - 0s 923us/step - loss: 0.0077 - val_loss: 0.0074\n",
      "Epoch 49/100\n",
      "199/199 [==============================] - 0s 912us/step - loss: 0.0077 - val_loss: 0.0073\n",
      "Epoch 50/100\n",
      "199/199 [==============================] - 0s 906us/step - loss: 0.0076 - val_loss: 0.0072\n",
      "Epoch 51/100\n",
      "199/199 [==============================] - 0s 928us/step - loss: 0.0075 - val_loss: 0.0071\n",
      "Epoch 52/100\n",
      "199/199 [==============================] - 0s 980us/step - loss: 0.0075 - val_loss: 0.0070\n",
      "Epoch 53/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0074 - val_loss: 0.0070\n",
      "Epoch 54/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0072 - val_loss: 0.0069\n",
      "Epoch 55/100\n",
      "199/199 [==============================] - 0s 959us/step - loss: 0.0073 - val_loss: 0.0068\n",
      "Epoch 56/100\n",
      "199/199 [==============================] - 0s 936us/step - loss: 0.0072 - val_loss: 0.0067\n",
      "Epoch 57/100\n",
      "199/199 [==============================] - 0s 941us/step - loss: 0.0072 - val_loss: 0.0067\n",
      "Epoch 58/100\n",
      "199/199 [==============================] - 0s 918us/step - loss: 0.0071 - val_loss: 0.0066\n",
      "Epoch 59/100\n",
      "199/199 [==============================] - 0s 931us/step - loss: 0.0070 - val_loss: 0.0066\n",
      "Epoch 60/100\n",
      "199/199 [==============================] - 0s 914us/step - loss: 0.0069 - val_loss: 0.0066\n",
      "Epoch 61/100\n",
      "199/199 [==============================] - 0s 945us/step - loss: 0.0068 - val_loss: 0.0065\n",
      "Epoch 62/100\n",
      "199/199 [==============================] - 0s 959us/step - loss: 0.0068 - val_loss: 0.0064\n",
      "Epoch 63/100\n",
      "199/199 [==============================] - 0s 933us/step - loss: 0.0068 - val_loss: 0.0064\n",
      "Epoch 64/100\n",
      "199/199 [==============================] - 0s 967us/step - loss: 0.0066 - val_loss: 0.0063\n",
      "Epoch 65/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0067 - val_loss: 0.0063\n",
      "Epoch 66/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0066 - val_loss: 0.0063\n",
      "Epoch 67/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0065 - val_loss: 0.0062\n",
      "Epoch 68/100\n",
      "199/199 [==============================] - 0s 962us/step - loss: 0.0066 - val_loss: 0.0062\n",
      "Epoch 69/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0065 - val_loss: 0.0062\n",
      "Epoch 70/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0061\n",
      "Epoch 71/100\n",
      "199/199 [==============================] - 0s 965us/step - loss: 0.0064 - val_loss: 0.0061\n",
      "Epoch 72/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 0.0060\n",
      "Epoch 73/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 0.0060\n",
      "Epoch 74/100\n",
      "199/199 [==============================] - 0s 984us/step - loss: 0.0063 - val_loss: 0.0059\n",
      "Epoch 75/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0062 - val_loss: 0.0059\n",
      "Epoch 76/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0062 - val_loss: 0.0059\n",
      "Epoch 77/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0058\n",
      "Epoch 78/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0062 - val_loss: 0.0058\n",
      "Epoch 79/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0058\n",
      "Epoch 80/100\n",
      "199/199 [==============================] - 0s 955us/step - loss: 0.0061 - val_loss: 0.0058\n",
      "Epoch 81/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0058\n",
      "Epoch 82/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0057\n",
      "Epoch 83/100\n",
      "199/199 [==============================] - 0s 972us/step - loss: 0.0060 - val_loss: 0.0057\n",
      "Epoch 84/100\n",
      "199/199 [==============================] - 0s 974us/step - loss: 0.0060 - val_loss: 0.0057\n",
      "Epoch 85/100\n",
      "199/199 [==============================] - 0s 925us/step - loss: 0.0060 - val_loss: 0.0057\n",
      "Epoch 86/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0056\n",
      "Epoch 87/100\n",
      "199/199 [==============================] - 0s 966us/step - loss: 0.0059 - val_loss: 0.0056\n",
      "Epoch 88/100\n",
      "199/199 [==============================] - 0s 932us/step - loss: 0.0059 - val_loss: 0.0056\n",
      "Epoch 89/100\n",
      "199/199 [==============================] - 0s 910us/step - loss: 0.0059 - val_loss: 0.0056\n",
      "Epoch 90/100\n",
      "199/199 [==============================] - 0s 916us/step - loss: 0.0058 - val_loss: 0.0056\n",
      "Epoch 91/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0055\n",
      "Epoch 92/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0055\n",
      "Epoch 93/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0055\n",
      "Epoch 94/100\n",
      "199/199 [==============================] - 0s 955us/step - loss: 0.0057 - val_loss: 0.0055\n",
      "Epoch 95/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0055\n",
      "Epoch 96/100\n",
      "199/199 [==============================] - 0s 985us/step - loss: 0.0057 - val_loss: 0.0055\n",
      "Epoch 97/100\n",
      "199/199 [==============================] - 0s 970us/step - loss: 0.0057 - val_loss: 0.0054\n",
      "Epoch 98/100\n",
      "199/199 [==============================] - 0s 927us/step - loss: 0.0057 - val_loss: 0.0054\n",
      "Epoch 99/100\n",
      "199/199 [==============================] - 0s 951us/step - loss: 0.0057 - val_loss: 0.0054\n",
      "Epoch 100/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0057 - val_loss: 0.0054\n",
      "This round is 14\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_11724/328462441.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  para_dfm = para_dfm.append({\"reg_param\": reg_param, \"number_units_layers\": numbers_units_layers, \"number_units_bottleneck\": numbers_units_bottleneck, \"dropout_rate\": dropout_rate, \"number_layers\": numbers_layers, \"whether_dropout\": whether_dropout, \"whether_regularizer\": whether_regularizer, \"overfit_metric\": overfit_metric, \"val2_avg_recon_error\": val2_avg_recon_error,'val1_loss':val1_loss}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0893 - val_loss: 0.0452\n",
      "Epoch 2/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0376 - val_loss: 0.0323\n",
      "Epoch 3/100\n",
      "199/199 [==============================] - 0s 998us/step - loss: 0.0284 - val_loss: 0.0251\n",
      "Epoch 4/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0221 - val_loss: 0.0189\n",
      "Epoch 5/100\n",
      "199/199 [==============================] - 0s 937us/step - loss: 0.0171 - val_loss: 0.0153\n",
      "Epoch 6/100\n",
      "199/199 [==============================] - 0s 981us/step - loss: 0.0144 - val_loss: 0.0131\n",
      "Epoch 7/100\n",
      "199/199 [==============================] - 0s 891us/step - loss: 0.0127 - val_loss: 0.0121\n",
      "Epoch 8/100\n",
      "199/199 [==============================] - 0s 886us/step - loss: 0.0118 - val_loss: 0.0114\n",
      "Epoch 9/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0109 - val_loss: 0.0106\n",
      "Epoch 10/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0100 - val_loss: 0.0096\n",
      "Epoch 11/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0088\n",
      "Epoch 12/100\n",
      "199/199 [==============================] - 0s 966us/step - loss: 0.0082 - val_loss: 0.0080\n",
      "Epoch 13/100\n",
      "199/199 [==============================] - 0s 995us/step - loss: 0.0073 - val_loss: 0.0073\n",
      "Epoch 14/100\n",
      "199/199 [==============================] - 0s 943us/step - loss: 0.0068 - val_loss: 0.0069\n",
      "Epoch 15/100\n",
      "199/199 [==============================] - 0s 1000us/step - loss: 0.0064 - val_loss: 0.0065\n",
      "Epoch 16/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0061\n",
      "Epoch 17/100\n",
      "199/199 [==============================] - 0s 985us/step - loss: 0.0057 - val_loss: 0.0059\n",
      "Epoch 18/100\n",
      "199/199 [==============================] - 0s 973us/step - loss: 0.0054 - val_loss: 0.0056\n",
      "Epoch 19/100\n",
      "199/199 [==============================] - 0s 985us/step - loss: 0.0052 - val_loss: 0.0053\n",
      "Epoch 20/100\n",
      "199/199 [==============================] - 0s 961us/step - loss: 0.0050 - val_loss: 0.0051\n",
      "Epoch 21/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0047 - val_loss: 0.0049\n",
      "Epoch 22/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0045 - val_loss: 0.0047\n",
      "Epoch 23/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 24/100\n",
      "199/199 [==============================] - 0s 986us/step - loss: 0.0042 - val_loss: 0.0044\n",
      "Epoch 25/100\n",
      "199/199 [==============================] - 0s 982us/step - loss: 0.0040 - val_loss: 0.0042\n",
      "Epoch 26/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0039 - val_loss: 0.0041\n",
      "Epoch 27/100\n",
      "199/199 [==============================] - 0s 915us/step - loss: 0.0038 - val_loss: 0.0040\n",
      "Epoch 28/100\n",
      "199/199 [==============================] - 0s 929us/step - loss: 0.0036 - val_loss: 0.0038\n",
      "Epoch 29/100\n",
      "199/199 [==============================] - 0s 942us/step - loss: 0.0033 - val_loss: 0.0036\n",
      "Epoch 30/100\n",
      "199/199 [==============================] - 0s 909us/step - loss: 0.0032 - val_loss: 0.0034\n",
      "Epoch 31/100\n",
      "199/199 [==============================] - 0s 915us/step - loss: 0.0030 - val_loss: 0.0033\n",
      "Epoch 32/100\n",
      "199/199 [==============================] - 0s 901us/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 33/100\n",
      "199/199 [==============================] - 0s 913us/step - loss: 0.0027 - val_loss: 0.0030\n",
      "Epoch 34/100\n",
      "199/199 [==============================] - 0s 909us/step - loss: 0.0026 - val_loss: 0.0030\n",
      "Epoch 35/100\n",
      "199/199 [==============================] - 0s 909us/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 36/100\n",
      "199/199 [==============================] - 0s 919us/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 37/100\n",
      "199/199 [==============================] - 0s 940us/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 38/100\n",
      "199/199 [==============================] - 0s 909us/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 39/100\n",
      "199/199 [==============================] - 0s 915us/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 40/100\n",
      "199/199 [==============================] - 0s 915us/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 41/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 42/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 43/100\n",
      "199/199 [==============================] - 0s 926us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 44/100\n",
      "199/199 [==============================] - 0s 950us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 45/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 46/100\n",
      "199/199 [==============================] - 0s 931us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 47/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 48/100\n",
      "199/199 [==============================] - 0s 957us/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 49/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 50/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 51/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 52/100\n",
      "199/199 [==============================] - 0s 955us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 53/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 54/100\n",
      "199/199 [==============================] - 0s 979us/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 55/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 56/100\n",
      "199/199 [==============================] - 0s 985us/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 57/100\n",
      "199/199 [==============================] - 0s 916us/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 58/100\n",
      "199/199 [==============================] - 0s 985us/step - loss: 0.0016 - val_loss: 0.0020\n",
      "Epoch 59/100\n",
      "199/199 [==============================] - 0s 988us/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 60/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 61/100\n",
      "199/199 [==============================] - 0s 981us/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 62/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 63/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 64/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 65/100\n",
      "199/199 [==============================] - 0s 944us/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 66/100\n",
      "199/199 [==============================] - 0s 922us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 67/100\n",
      "199/199 [==============================] - 0s 974us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 68/100\n",
      "199/199 [==============================] - 0s 911us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 69/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 70/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 71/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 72/100\n",
      "199/199 [==============================] - 0s 964us/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 73/100\n",
      "199/199 [==============================] - 0s 923us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 74/100\n",
      "199/199 [==============================] - 0s 917us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 75/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 76/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 77/100\n",
      "199/199 [==============================] - 0s 935us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 78/100\n",
      "199/199 [==============================] - 0s 966us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 79/100\n",
      "199/199 [==============================] - 0s 945us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 80/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 81/100\n",
      "199/199 [==============================] - 0s 957us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 82/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 83/100\n",
      "199/199 [==============================] - 0s 948us/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 84/100\n",
      "199/199 [==============================] - 0s 973us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 85/100\n",
      "199/199 [==============================] - 0s 992us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 86/100\n",
      "199/199 [==============================] - 0s 973us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 87/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 88/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 89/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 90/100\n",
      "199/199 [==============================] - 0s 960us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 91/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 92/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 93/100\n",
      "199/199 [==============================] - 0s 980us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 94/100\n",
      "199/199 [==============================] - 0s 927us/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 95/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 96/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 97/100\n",
      "199/199 [==============================] - 0s 962us/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 98/100\n",
      "199/199 [==============================] - 0s 917us/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 99/100\n",
      "199/199 [==============================] - 0s 906us/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 100/100\n",
      "199/199 [==============================] - 0s 900us/step - loss: 0.0011 - val_loss: 0.0016\n",
      "This round is 15\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_11724/328462441.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  para_dfm = para_dfm.append({\"reg_param\": reg_param, \"number_units_layers\": numbers_units_layers, \"number_units_bottleneck\": numbers_units_bottleneck, \"dropout_rate\": dropout_rate, \"number_layers\": numbers_layers, \"whether_dropout\": whether_dropout, \"whether_regularizer\": whether_regularizer, \"overfit_metric\": overfit_metric, \"val2_avg_recon_error\": val2_avg_recon_error,'val1_loss':val1_loss}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 0s 1ms/step - loss: 2.4870 - val_loss: 0.7088\n",
      "Epoch 2/100\n",
      "199/199 [==============================] - 0s 928us/step - loss: 0.2955 - val_loss: 0.1009\n",
      "Epoch 3/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0692 - val_loss: 0.0567\n",
      "Epoch 4/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0555 - val_loss: 0.0551\n",
      "Epoch 5/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0551 - val_loss: 0.0551\n",
      "Epoch 6/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0551 - val_loss: 0.0550\n",
      "Epoch 7/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0551 - val_loss: 0.0550\n",
      "Epoch 8/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0551 - val_loss: 0.0551\n",
      "Epoch 9/100\n",
      "199/199 [==============================] - 0s 929us/step - loss: 0.0551 - val_loss: 0.0550\n",
      "Epoch 10/100\n",
      "199/199 [==============================] - 0s 949us/step - loss: 0.0551 - val_loss: 0.0550\n",
      "Epoch 11/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0551 - val_loss: 0.0550\n",
      "Epoch 12/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0550 - val_loss: 0.0550\n",
      "Epoch 13/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0551 - val_loss: 0.0551\n",
      "Epoch 14/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0551 - val_loss: 0.0550\n",
      "Epoch 15/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0550 - val_loss: 0.0549\n",
      "Epoch 16/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0550 - val_loss: 0.0549\n",
      "Epoch 17/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0548 - val_loss: 0.0546\n",
      "Epoch 18/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0539 - val_loss: 0.0521\n",
      "Epoch 19/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0479 - val_loss: 0.0439\n",
      "Epoch 20/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0424 - val_loss: 0.0410\n",
      "Epoch 21/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0406 - val_loss: 0.0398\n",
      "Epoch 22/100\n",
      "199/199 [==============================] - 0s 950us/step - loss: 0.0397 - val_loss: 0.0391\n",
      "Epoch 23/100\n",
      "199/199 [==============================] - 0s 921us/step - loss: 0.0391 - val_loss: 0.0386\n",
      "Epoch 24/100\n",
      "199/199 [==============================] - 0s 940us/step - loss: 0.0385 - val_loss: 0.0382\n",
      "Epoch 25/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0381 - val_loss: 0.0376\n",
      "Epoch 26/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0378 - val_loss: 0.0374\n",
      "Epoch 27/100\n",
      "199/199 [==============================] - 0s 916us/step - loss: 0.0375 - val_loss: 0.0371\n",
      "Epoch 28/100\n",
      "199/199 [==============================] - 0s 927us/step - loss: 0.0372 - val_loss: 0.0370\n",
      "Epoch 29/100\n",
      "199/199 [==============================] - 0s 923us/step - loss: 0.0371 - val_loss: 0.0368\n",
      "Epoch 30/100\n",
      "199/199 [==============================] - 0s 945us/step - loss: 0.0370 - val_loss: 0.0366\n",
      "Epoch 31/100\n",
      "199/199 [==============================] - 0s 928us/step - loss: 0.0368 - val_loss: 0.0366\n",
      "Epoch 32/100\n",
      "199/199 [==============================] - 0s 931us/step - loss: 0.0368 - val_loss: 0.0365\n",
      "Epoch 33/100\n",
      "199/199 [==============================] - 0s 936us/step - loss: 0.0367 - val_loss: 0.0364\n",
      "Epoch 34/100\n",
      "199/199 [==============================] - 0s 972us/step - loss: 0.0366 - val_loss: 0.0365\n",
      "Epoch 35/100\n",
      "199/199 [==============================] - 0s 950us/step - loss: 0.0366 - val_loss: 0.0363\n",
      "Epoch 36/100\n",
      "199/199 [==============================] - 0s 951us/step - loss: 0.0366 - val_loss: 0.0363\n",
      "Epoch 37/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0365 - val_loss: 0.0363\n",
      "Epoch 38/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0364 - val_loss: 0.0365\n",
      "Epoch 39/100\n",
      "199/199 [==============================] - 0s 958us/step - loss: 0.0364 - val_loss: 0.0361\n",
      "Epoch 40/100\n",
      "199/199 [==============================] - 0s 939us/step - loss: 0.0364 - val_loss: 0.0362\n",
      "Epoch 41/100\n",
      "199/199 [==============================] - 0s 943us/step - loss: 0.0364 - val_loss: 0.0364\n",
      "Epoch 42/100\n",
      "199/199 [==============================] - 0s 906us/step - loss: 0.0363 - val_loss: 0.0361\n",
      "Epoch 43/100\n",
      "199/199 [==============================] - 0s 948us/step - loss: 0.0363 - val_loss: 0.0360\n",
      "Epoch 44/100\n",
      "199/199 [==============================] - 0s 952us/step - loss: 0.0363 - val_loss: 0.0361\n",
      "Epoch 45/100\n",
      "199/199 [==============================] - 0s 966us/step - loss: 0.0362 - val_loss: 0.0361\n",
      "Epoch 46/100\n",
      "199/199 [==============================] - 0s 933us/step - loss: 0.0362 - val_loss: 0.0361\n",
      "Epoch 47/100\n",
      "199/199 [==============================] - 0s 939us/step - loss: 0.0363 - val_loss: 0.0361\n",
      "Epoch 48/100\n",
      "199/199 [==============================] - 0s 935us/step - loss: 0.0362 - val_loss: 0.0360\n",
      "Epoch 49/100\n",
      "199/199 [==============================] - 0s 959us/step - loss: 0.0361 - val_loss: 0.0359\n",
      "Epoch 50/100\n",
      "199/199 [==============================] - 0s 949us/step - loss: 0.0362 - val_loss: 0.0360\n",
      "Epoch 51/100\n",
      "199/199 [==============================] - 0s 920us/step - loss: 0.0362 - val_loss: 0.0359\n",
      "Epoch 52/100\n",
      "199/199 [==============================] - 0s 934us/step - loss: 0.0361 - val_loss: 0.0359\n",
      "Epoch 53/100\n",
      "199/199 [==============================] - 0s 932us/step - loss: 0.0361 - val_loss: 0.0360\n",
      "Epoch 54/100\n",
      "199/199 [==============================] - 0s 934us/step - loss: 0.0362 - val_loss: 0.0368\n",
      "Epoch 55/100\n",
      "199/199 [==============================] - 0s 958us/step - loss: 0.0361 - val_loss: 0.0361\n",
      "Epoch 56/100\n",
      "199/199 [==============================] - 0s 904us/step - loss: 0.0360 - val_loss: 0.0358\n",
      "Epoch 57/100\n",
      "199/199 [==============================] - 0s 894us/step - loss: 0.0361 - val_loss: 0.0359\n",
      "Epoch 58/100\n",
      "199/199 [==============================] - 0s 889us/step - loss: 0.0361 - val_loss: 0.0359\n",
      "Epoch 59/100\n",
      "199/199 [==============================] - 0s 892us/step - loss: 0.0361 - val_loss: 0.0358\n",
      "Epoch 60/100\n",
      "199/199 [==============================] - 0s 886us/step - loss: 0.0360 - val_loss: 0.0358\n",
      "Epoch 61/100\n",
      "199/199 [==============================] - 0s 887us/step - loss: 0.0360 - val_loss: 0.0358\n",
      "Epoch 62/100\n",
      "199/199 [==============================] - 0s 889us/step - loss: 0.0361 - val_loss: 0.0358\n",
      "Epoch 63/100\n",
      "199/199 [==============================] - 0s 891us/step - loss: 0.0361 - val_loss: 0.0360\n",
      "Epoch 64/100\n",
      "199/199 [==============================] - 0s 889us/step - loss: 0.0360 - val_loss: 0.0358\n",
      "Epoch 65/100\n",
      "199/199 [==============================] - 0s 898us/step - loss: 0.0360 - val_loss: 0.0358\n",
      "Epoch 66/100\n",
      "199/199 [==============================] - 0s 901us/step - loss: 0.0361 - val_loss: 0.0358\n",
      "Epoch 67/100\n",
      "199/199 [==============================] - 0s 889us/step - loss: 0.0360 - val_loss: 0.0359\n",
      "Epoch 68/100\n",
      "199/199 [==============================] - 0s 896us/step - loss: 0.0360 - val_loss: 0.0358\n",
      "Epoch 69/100\n",
      "199/199 [==============================] - 0s 888us/step - loss: 0.0359 - val_loss: 0.0357\n",
      "Epoch 70/100\n",
      "199/199 [==============================] - 0s 905us/step - loss: 0.0360 - val_loss: 0.0358\n",
      "Epoch 71/100\n",
      "199/199 [==============================] - 0s 900us/step - loss: 0.0359 - val_loss: 0.0358\n",
      "Epoch 72/100\n",
      "199/199 [==============================] - 0s 888us/step - loss: 0.0360 - val_loss: 0.0358\n",
      "Epoch 73/100\n",
      "199/199 [==============================] - 0s 893us/step - loss: 0.0360 - val_loss: 0.0358\n",
      "Epoch 74/100\n",
      "199/199 [==============================] - 0s 892us/step - loss: 0.0364 - val_loss: 0.0358\n",
      "Epoch 75/100\n",
      "199/199 [==============================] - 0s 911us/step - loss: 0.0359 - val_loss: 0.0359\n",
      "Epoch 76/100\n",
      "199/199 [==============================] - 0s 899us/step - loss: 0.0360 - val_loss: 0.0358\n",
      "Epoch 77/100\n",
      "199/199 [==============================] - 0s 903us/step - loss: 0.0359 - val_loss: 0.0358\n",
      "Epoch 78/100\n",
      "199/199 [==============================] - 0s 893us/step - loss: 0.0359 - val_loss: 0.0357\n",
      "Epoch 79/100\n",
      "199/199 [==============================] - 0s 899us/step - loss: 0.0359 - val_loss: 0.0357\n",
      "This round is 16\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_11724/328462441.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  para_dfm = para_dfm.append({\"reg_param\": reg_param, \"number_units_layers\": numbers_units_layers, \"number_units_bottleneck\": numbers_units_bottleneck, \"dropout_rate\": dropout_rate, \"number_layers\": numbers_layers, \"whether_dropout\": whether_dropout, \"whether_regularizer\": whether_regularizer, \"overfit_metric\": overfit_metric, \"val2_avg_recon_error\": val2_avg_recon_error,'val1_loss':val1_loss}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0862 - val_loss: 0.0527\n",
      "Epoch 2/100\n",
      "199/199 [==============================] - 0s 907us/step - loss: 0.0438 - val_loss: 0.0383\n",
      "Epoch 3/100\n",
      "199/199 [==============================] - 0s 910us/step - loss: 0.0369 - val_loss: 0.0355\n",
      "Epoch 4/100\n",
      "199/199 [==============================] - 0s 920us/step - loss: 0.0345 - val_loss: 0.0325\n",
      "Epoch 5/100\n",
      "199/199 [==============================] - 0s 925us/step - loss: 0.0297 - val_loss: 0.0263\n",
      "Epoch 6/100\n",
      "199/199 [==============================] - 0s 906us/step - loss: 0.0239 - val_loss: 0.0213\n",
      "Epoch 7/100\n",
      "199/199 [==============================] - 0s 902us/step - loss: 0.0205 - val_loss: 0.0192\n",
      "Epoch 8/100\n",
      "199/199 [==============================] - 0s 927us/step - loss: 0.0189 - val_loss: 0.0179\n",
      "Epoch 9/100\n",
      "199/199 [==============================] - 0s 899us/step - loss: 0.0177 - val_loss: 0.0169\n",
      "Epoch 10/100\n",
      "199/199 [==============================] - 0s 896us/step - loss: 0.0167 - val_loss: 0.0157\n",
      "Epoch 11/100\n",
      "199/199 [==============================] - 0s 895us/step - loss: 0.0153 - val_loss: 0.0142\n",
      "Epoch 12/100\n",
      "199/199 [==============================] - 0s 922us/step - loss: 0.0139 - val_loss: 0.0130\n",
      "Epoch 13/100\n",
      "199/199 [==============================] - 0s 916us/step - loss: 0.0128 - val_loss: 0.0121\n",
      "Epoch 14/100\n",
      "199/199 [==============================] - 0s 909us/step - loss: 0.0119 - val_loss: 0.0114\n",
      "Epoch 15/100\n",
      "199/199 [==============================] - 0s 908us/step - loss: 0.0112 - val_loss: 0.0107\n",
      "Epoch 16/100\n",
      "199/199 [==============================] - 0s 911us/step - loss: 0.0106 - val_loss: 0.0101\n",
      "Epoch 17/100\n",
      "199/199 [==============================] - 0s 917us/step - loss: 0.0100 - val_loss: 0.0095\n",
      "Epoch 18/100\n",
      "199/199 [==============================] - 0s 908us/step - loss: 0.0095 - val_loss: 0.0090\n",
      "Epoch 19/100\n",
      "199/199 [==============================] - 0s 966us/step - loss: 0.0090 - val_loss: 0.0085\n",
      "Epoch 20/100\n",
      "199/199 [==============================] - 0s 952us/step - loss: 0.0084 - val_loss: 0.0081\n",
      "Epoch 21/100\n",
      "199/199 [==============================] - 0s 925us/step - loss: 0.0079 - val_loss: 0.0076\n",
      "Epoch 22/100\n",
      "199/199 [==============================] - 0s 919us/step - loss: 0.0075 - val_loss: 0.0073\n",
      "Epoch 23/100\n",
      "199/199 [==============================] - 0s 908us/step - loss: 0.0072 - val_loss: 0.0070\n",
      "Epoch 24/100\n",
      "199/199 [==============================] - 0s 913us/step - loss: 0.0070 - val_loss: 0.0068\n",
      "Epoch 25/100\n",
      "199/199 [==============================] - 0s 903us/step - loss: 0.0067 - val_loss: 0.0066\n",
      "Epoch 26/100\n",
      "199/199 [==============================] - 0s 909us/step - loss: 0.0065 - val_loss: 0.0063\n",
      "Epoch 27/100\n",
      "199/199 [==============================] - 0s 912us/step - loss: 0.0063 - val_loss: 0.0062\n",
      "Epoch 28/100\n",
      "199/199 [==============================] - 0s 915us/step - loss: 0.0061 - val_loss: 0.0060\n",
      "Epoch 29/100\n",
      "199/199 [==============================] - 0s 924us/step - loss: 0.0059 - val_loss: 0.0059\n",
      "Epoch 30/100\n",
      "199/199 [==============================] - 0s 915us/step - loss: 0.0057 - val_loss: 0.0056\n",
      "Epoch 31/100\n",
      "199/199 [==============================] - 0s 907us/step - loss: 0.0056 - val_loss: 0.0055\n",
      "Epoch 32/100\n",
      "199/199 [==============================] - 0s 912us/step - loss: 0.0055 - val_loss: 0.0054\n",
      "Epoch 33/100\n",
      "199/199 [==============================] - 0s 916us/step - loss: 0.0053 - val_loss: 0.0053\n",
      "Epoch 34/100\n",
      "199/199 [==============================] - 0s 918us/step - loss: 0.0052 - val_loss: 0.0052\n",
      "Epoch 35/100\n",
      "199/199 [==============================] - 0s 921us/step - loss: 0.0051 - val_loss: 0.0050\n",
      "Epoch 36/100\n",
      "199/199 [==============================] - 0s 908us/step - loss: 0.0050 - val_loss: 0.0050\n",
      "Epoch 37/100\n",
      "199/199 [==============================] - 0s 910us/step - loss: 0.0049 - val_loss: 0.0048\n",
      "Epoch 38/100\n",
      "199/199 [==============================] - 0s 907us/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 39/100\n",
      "199/199 [==============================] - 0s 915us/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 40/100\n",
      "199/199 [==============================] - 0s 947us/step - loss: 0.0045 - val_loss: 0.0044\n",
      "Epoch 41/100\n",
      "199/199 [==============================] - 0s 909us/step - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 42/100\n",
      "199/199 [==============================] - 0s 908us/step - loss: 0.0043 - val_loss: 0.0042\n",
      "Epoch 43/100\n",
      "199/199 [==============================] - 0s 909us/step - loss: 0.0041 - val_loss: 0.0041\n",
      "Epoch 44/100\n",
      "199/199 [==============================] - 0s 912us/step - loss: 0.0041 - val_loss: 0.0039\n",
      "Epoch 45/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 46/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0039 - val_loss: 0.0038\n",
      "Epoch 47/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0039 - val_loss: 0.0038\n",
      "Epoch 48/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0038 - val_loss: 0.0037\n",
      "Epoch 49/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0037 - val_loss: 0.0036\n",
      "Epoch 50/100\n",
      "199/199 [==============================] - 0s 932us/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 51/100\n",
      "199/199 [==============================] - 0s 964us/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 52/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 53/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0035 - val_loss: 0.0034\n",
      "Epoch 54/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 55/100\n",
      "199/199 [==============================] - 0s 998us/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 56/100\n",
      "199/199 [==============================] - 0s 924us/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 57/100\n",
      "199/199 [==============================] - 0s 983us/step - loss: 0.0032 - val_loss: 0.0032\n",
      "Epoch 58/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 59/100\n",
      "199/199 [==============================] - 0s 928us/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 60/100\n",
      "199/199 [==============================] - 0s 910us/step - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 61/100\n",
      "199/199 [==============================] - 0s 991us/step - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 62/100\n",
      "199/199 [==============================] - 0s 959us/step - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 63/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0029 - val_loss: 0.0029\n",
      "Epoch 64/100\n",
      "199/199 [==============================] - 0s 965us/step - loss: 0.0028 - val_loss: 0.0029\n",
      "Epoch 65/100\n",
      "199/199 [==============================] - 0s 949us/step - loss: 0.0028 - val_loss: 0.0029\n",
      "Epoch 66/100\n",
      "199/199 [==============================] - 0s 988us/step - loss: 0.0028 - val_loss: 0.0029\n",
      "Epoch 67/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 68/100\n",
      "199/199 [==============================] - 0s 954us/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 69/100\n",
      "199/199 [==============================] - 0s 932us/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 70/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 71/100\n",
      "199/199 [==============================] - 0s 971us/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 72/100\n",
      "199/199 [==============================] - 0s 939us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 73/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 74/100\n",
      "199/199 [==============================] - 0s 929us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 75/100\n",
      "199/199 [==============================] - 0s 917us/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 76/100\n",
      "199/199 [==============================] - 0s 980us/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 77/100\n",
      "199/199 [==============================] - 0s 977us/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 78/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 79/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 80/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0024 - val_loss: 0.0026\n",
      "Epoch 81/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 82/100\n",
      "199/199 [==============================] - 0s 934us/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 83/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 84/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 85/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 86/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 87/100\n",
      "199/199 [==============================] - 0s 972us/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 88/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 89/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 90/100\n",
      "199/199 [==============================] - 0s 926us/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 91/100\n",
      "199/199 [==============================] - 0s 925us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 92/100\n",
      "199/199 [==============================] - 0s 954us/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 93/100\n",
      "199/199 [==============================] - 0s 944us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 94/100\n",
      "199/199 [==============================] - 0s 896us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 95/100\n",
      "199/199 [==============================] - 0s 911us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 96/100\n",
      "199/199 [==============================] - 0s 933us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 97/100\n",
      "199/199 [==============================] - 0s 937us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 98/100\n",
      "199/199 [==============================] - 0s 907us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 99/100\n",
      "199/199 [==============================] - 0s 920us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 100/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0021 - val_loss: 0.0023\n",
      "This round is 17\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_11724/328462441.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  para_dfm = para_dfm.append({\"reg_param\": reg_param, \"number_units_layers\": numbers_units_layers, \"number_units_bottleneck\": numbers_units_bottleneck, \"dropout_rate\": dropout_rate, \"number_layers\": numbers_layers, \"whether_dropout\": whether_dropout, \"whether_regularizer\": whether_regularizer, \"overfit_metric\": overfit_metric, \"val2_avg_recon_error\": val2_avg_recon_error,'val1_loss':val1_loss}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0722 - val_loss: 0.0392\n",
      "Epoch 2/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0343 - val_loss: 0.0297\n",
      "Epoch 3/100\n",
      "199/199 [==============================] - 0s 962us/step - loss: 0.0254 - val_loss: 0.0215\n",
      "Epoch 4/100\n",
      "199/199 [==============================] - 0s 904us/step - loss: 0.0192 - val_loss: 0.0170\n",
      "Epoch 5/100\n",
      "199/199 [==============================] - 0s 919us/step - loss: 0.0160 - val_loss: 0.0147\n",
      "Epoch 6/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0134 - val_loss: 0.0121\n",
      "Epoch 7/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0112 - val_loss: 0.0106\n",
      "Epoch 8/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0100 - val_loss: 0.0097\n",
      "Epoch 9/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0090\n",
      "Epoch 10/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0083\n",
      "Epoch 11/100\n",
      "199/199 [==============================] - 0s 979us/step - loss: 0.0077 - val_loss: 0.0076\n",
      "Epoch 12/100\n",
      "199/199 [==============================] - 0s 898us/step - loss: 0.0071 - val_loss: 0.0070\n",
      "Epoch 13/100\n",
      "199/199 [==============================] - 0s 963us/step - loss: 0.0065 - val_loss: 0.0065\n",
      "Epoch 14/100\n",
      "199/199 [==============================] - 0s 911us/step - loss: 0.0059 - val_loss: 0.0059\n",
      "Epoch 15/100\n",
      "199/199 [==============================] - 0s 893us/step - loss: 0.0053 - val_loss: 0.0053\n",
      "Epoch 16/100\n",
      "199/199 [==============================] - 0s 884us/step - loss: 0.0048 - val_loss: 0.0049\n",
      "Epoch 17/100\n",
      "199/199 [==============================] - 0s 919us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 18/100\n",
      "199/199 [==============================] - 0s 974us/step - loss: 0.0041 - val_loss: 0.0043\n",
      "Epoch 19/100\n",
      "199/199 [==============================] - 0s 888us/step - loss: 0.0038 - val_loss: 0.0040\n",
      "Epoch 20/100\n",
      "199/199 [==============================] - 0s 937us/step - loss: 0.0036 - val_loss: 0.0038\n",
      "Epoch 21/100\n",
      "199/199 [==============================] - 0s 899us/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 22/100\n",
      "199/199 [==============================] - 0s 888us/step - loss: 0.0032 - val_loss: 0.0035\n",
      "Epoch 23/100\n",
      "199/199 [==============================] - 0s 907us/step - loss: 0.0030 - val_loss: 0.0034\n",
      "Epoch 24/100\n",
      "199/199 [==============================] - 0s 928us/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 25/100\n",
      "199/199 [==============================] - 0s 920us/step - loss: 0.0027 - val_loss: 0.0030\n",
      "Epoch 26/100\n",
      "199/199 [==============================] - 0s 890us/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 27/100\n",
      "199/199 [==============================] - 0s 901us/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 28/100\n",
      "199/199 [==============================] - 0s 915us/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 29/100\n",
      "199/199 [==============================] - 0s 892us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 30/100\n",
      "199/199 [==============================] - 0s 888us/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 31/100\n",
      "199/199 [==============================] - 0s 973us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 32/100\n",
      "199/199 [==============================] - 0s 900us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 33/100\n",
      "199/199 [==============================] - 0s 895us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 34/100\n",
      "199/199 [==============================] - 0s 895us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 35/100\n",
      "199/199 [==============================] - 0s 925us/step - loss: 0.0016 - val_loss: 0.0020\n",
      "Epoch 36/100\n",
      "199/199 [==============================] - 0s 929us/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 37/100\n",
      "199/199 [==============================] - 0s 923us/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 38/100\n",
      "199/199 [==============================] - 0s 913us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 39/100\n",
      "199/199 [==============================] - 0s 886us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 40/100\n",
      "199/199 [==============================] - 0s 885us/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 41/100\n",
      "199/199 [==============================] - 0s 889us/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 42/100\n",
      "199/199 [==============================] - 0s 880us/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 43/100\n",
      "199/199 [==============================] - 0s 889us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 44/100\n",
      "199/199 [==============================] - 0s 878us/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 45/100\n",
      "199/199 [==============================] - 0s 886us/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 46/100\n",
      "199/199 [==============================] - 0s 884us/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 47/100\n",
      "199/199 [==============================] - 0s 936us/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 48/100\n",
      "199/199 [==============================] - 0s 960us/step - loss: 0.0010 - val_loss: 0.0015\n",
      "Epoch 49/100\n",
      "199/199 [==============================] - 0s 960us/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 50/100\n",
      "199/199 [==============================] - 0s 939us/step - loss: 9.8345e-04 - val_loss: 0.0014\n",
      "Epoch 51/100\n",
      "199/199 [==============================] - 0s 924us/step - loss: 9.5979e-04 - val_loss: 0.0014\n",
      "Epoch 52/100\n",
      "199/199 [==============================] - 0s 897us/step - loss: 9.4052e-04 - val_loss: 0.0014\n",
      "Epoch 53/100\n",
      "199/199 [==============================] - 0s 915us/step - loss: 9.0564e-04 - val_loss: 0.0013\n",
      "Epoch 54/100\n",
      "199/199 [==============================] - 0s 907us/step - loss: 8.9345e-04 - val_loss: 0.0013\n",
      "Epoch 55/100\n",
      "199/199 [==============================] - 0s 954us/step - loss: 8.7414e-04 - val_loss: 0.0013\n",
      "Epoch 56/100\n",
      "199/199 [==============================] - 0s 914us/step - loss: 8.5209e-04 - val_loss: 0.0014\n",
      "Epoch 57/100\n",
      "199/199 [==============================] - 0s 951us/step - loss: 8.5114e-04 - val_loss: 0.0013\n",
      "Epoch 58/100\n",
      "199/199 [==============================] - 0s 907us/step - loss: 8.2498e-04 - val_loss: 0.0013\n",
      "Epoch 59/100\n",
      "199/199 [==============================] - 0s 915us/step - loss: 8.1013e-04 - val_loss: 0.0013\n",
      "Epoch 60/100\n",
      "199/199 [==============================] - 0s 913us/step - loss: 7.8808e-04 - val_loss: 0.0012\n",
      "Epoch 61/100\n",
      "199/199 [==============================] - 0s 966us/step - loss: 7.5356e-04 - val_loss: 0.0012\n",
      "Epoch 62/100\n",
      "199/199 [==============================] - 0s 930us/step - loss: 7.3910e-04 - val_loss: 0.0012\n",
      "Epoch 63/100\n",
      "199/199 [==============================] - 0s 995us/step - loss: 7.4055e-04 - val_loss: 0.0012\n",
      "Epoch 64/100\n",
      "199/199 [==============================] - 0s 913us/step - loss: 7.4314e-04 - val_loss: 0.0012\n",
      "Epoch 65/100\n",
      "199/199 [==============================] - 0s 878us/step - loss: 7.1169e-04 - val_loss: 0.0012\n",
      "Epoch 66/100\n",
      "199/199 [==============================] - 0s 884us/step - loss: 6.9866e-04 - val_loss: 0.0011\n",
      "Epoch 67/100\n",
      "199/199 [==============================] - 0s 939us/step - loss: 6.9709e-04 - val_loss: 0.0012\n",
      "Epoch 68/100\n",
      "199/199 [==============================] - 0s 936us/step - loss: 6.8267e-04 - val_loss: 0.0011\n",
      "Epoch 69/100\n",
      "199/199 [==============================] - 0s 936us/step - loss: 6.7122e-04 - val_loss: 0.0011\n",
      "Epoch 70/100\n",
      "199/199 [==============================] - 0s 909us/step - loss: 6.6351e-04 - val_loss: 0.0011\n",
      "Epoch 71/100\n",
      "199/199 [==============================] - 0s 905us/step - loss: 6.4976e-04 - val_loss: 0.0011\n",
      "Epoch 72/100\n",
      "199/199 [==============================] - 0s 933us/step - loss: 6.5449e-04 - val_loss: 0.0011\n",
      "Epoch 73/100\n",
      "199/199 [==============================] - 0s 923us/step - loss: 6.4035e-04 - val_loss: 0.0011\n",
      "Epoch 74/100\n",
      "199/199 [==============================] - 0s 946us/step - loss: 6.1783e-04 - val_loss: 0.0011\n",
      "Epoch 75/100\n",
      "199/199 [==============================] - 0s 960us/step - loss: 6.1088e-04 - val_loss: 0.0011\n",
      "Epoch 76/100\n",
      "199/199 [==============================] - 0s 962us/step - loss: 6.0932e-04 - val_loss: 0.0011\n",
      "Epoch 77/100\n",
      "199/199 [==============================] - 0s 993us/step - loss: 6.0507e-04 - val_loss: 0.0010\n",
      "Epoch 78/100\n",
      "199/199 [==============================] - 0s 927us/step - loss: 6.0850e-04 - val_loss: 0.0010\n",
      "Epoch 79/100\n",
      "199/199 [==============================] - 0s 932us/step - loss: 5.9022e-04 - val_loss: 0.0010\n",
      "Epoch 80/100\n",
      "199/199 [==============================] - 0s 976us/step - loss: 5.9669e-04 - val_loss: 0.0010\n",
      "Epoch 81/100\n",
      "199/199 [==============================] - 0s 907us/step - loss: 5.7744e-04 - val_loss: 0.0011\n",
      "Epoch 82/100\n",
      "199/199 [==============================] - 0s 960us/step - loss: 5.8314e-04 - val_loss: 9.6517e-04\n",
      "Epoch 83/100\n",
      "199/199 [==============================] - 0s 907us/step - loss: 5.2855e-04 - val_loss: 9.5948e-04\n",
      "Epoch 84/100\n",
      "199/199 [==============================] - 0s 907us/step - loss: 5.1145e-04 - val_loss: 8.9598e-04\n",
      "Epoch 85/100\n",
      "199/199 [==============================] - 0s 911us/step - loss: 4.8697e-04 - val_loss: 9.2599e-04\n",
      "Epoch 86/100\n",
      "199/199 [==============================] - 0s 922us/step - loss: 4.9030e-04 - val_loss: 8.8692e-04\n",
      "Epoch 87/100\n",
      "199/199 [==============================] - 0s 955us/step - loss: 4.8365e-04 - val_loss: 9.1055e-04\n",
      "Epoch 88/100\n",
      "199/199 [==============================] - 0s 936us/step - loss: 4.8359e-04 - val_loss: 8.6867e-04\n",
      "Epoch 89/100\n",
      "199/199 [==============================] - 0s 919us/step - loss: 4.7130e-04 - val_loss: 8.7091e-04\n",
      "Epoch 90/100\n",
      "199/199 [==============================] - 0s 912us/step - loss: 4.6476e-04 - val_loss: 8.3907e-04\n",
      "Epoch 91/100\n",
      "199/199 [==============================] - 0s 929us/step - loss: 4.6633e-04 - val_loss: 8.3280e-04\n",
      "Epoch 92/100\n",
      "199/199 [==============================] - 0s 921us/step - loss: 4.5545e-04 - val_loss: 8.2693e-04\n",
      "Epoch 93/100\n",
      "199/199 [==============================] - 0s 913us/step - loss: 4.5118e-04 - val_loss: 8.3215e-04\n",
      "Epoch 94/100\n",
      "199/199 [==============================] - 0s 942us/step - loss: 4.5217e-04 - val_loss: 8.4790e-04\n",
      "Epoch 95/100\n",
      "199/199 [==============================] - 0s 924us/step - loss: 4.4242e-04 - val_loss: 8.3485e-04\n",
      "Epoch 96/100\n",
      "199/199 [==============================] - 0s 911us/step - loss: 4.3648e-04 - val_loss: 8.1630e-04\n",
      "Epoch 97/100\n",
      "199/199 [==============================] - 0s 918us/step - loss: 4.3922e-04 - val_loss: 8.5393e-04\n",
      "Epoch 98/100\n",
      "199/199 [==============================] - 0s 921us/step - loss: 4.4509e-04 - val_loss: 8.3731e-04\n",
      "Epoch 99/100\n",
      "199/199 [==============================] - 0s 925us/step - loss: 4.2508e-04 - val_loss: 7.9263e-04\n",
      "Epoch 100/100\n",
      "199/199 [==============================] - 0s 951us/step - loss: 4.0602e-04 - val_loss: 7.6968e-04\n",
      "This round is 18\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_11724/328462441.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  para_dfm = para_dfm.append({\"reg_param\": reg_param, \"number_units_layers\": numbers_units_layers, \"number_units_bottleneck\": numbers_units_bottleneck, \"dropout_rate\": dropout_rate, \"number_layers\": numbers_layers, \"whether_dropout\": whether_dropout, \"whether_regularizer\": whether_regularizer, \"overfit_metric\": overfit_metric, \"val2_avg_recon_error\": val2_avg_recon_error,'val1_loss':val1_loss}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 0s 1ms/step - loss: 2.0860 - val_loss: 0.6467\n",
      "Epoch 2/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.2829 - val_loss: 0.1038\n",
      "Epoch 3/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0710 - val_loss: 0.0572\n",
      "Epoch 4/100\n",
      "199/199 [==============================] - 0s 938us/step - loss: 0.0557 - val_loss: 0.0551\n",
      "Epoch 5/100\n",
      "199/199 [==============================] - 0s 927us/step - loss: 0.0551 - val_loss: 0.0550\n",
      "Epoch 6/100\n",
      "199/199 [==============================] - 0s 959us/step - loss: 0.0551 - val_loss: 0.0550\n",
      "Epoch 7/100\n",
      "199/199 [==============================] - 0s 906us/step - loss: 0.0550 - val_loss: 0.0550\n",
      "Epoch 8/100\n",
      "199/199 [==============================] - 0s 899us/step - loss: 0.0550 - val_loss: 0.0551\n",
      "Epoch 9/100\n",
      "199/199 [==============================] - 0s 906us/step - loss: 0.0550 - val_loss: 0.0550\n",
      "Epoch 10/100\n",
      "199/199 [==============================] - 0s 899us/step - loss: 0.0550 - val_loss: 0.0549\n",
      "Epoch 11/100\n",
      "199/199 [==============================] - 0s 888us/step - loss: 0.0549 - val_loss: 0.0547\n",
      "Epoch 12/100\n",
      "199/199 [==============================] - 0s 880us/step - loss: 0.0544 - val_loss: 0.0535\n",
      "Epoch 13/100\n",
      "199/199 [==============================] - 0s 874us/step - loss: 0.0494 - val_loss: 0.0439\n",
      "Epoch 14/100\n",
      "199/199 [==============================] - 0s 908us/step - loss: 0.0422 - val_loss: 0.0406\n",
      "Epoch 15/100\n",
      "199/199 [==============================] - 0s 940us/step - loss: 0.0402 - val_loss: 0.0396\n",
      "Epoch 16/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0393 - val_loss: 0.0387\n",
      "Epoch 17/100\n",
      "199/199 [==============================] - 0s 921us/step - loss: 0.0387 - val_loss: 0.0382\n",
      "Epoch 18/100\n",
      "199/199 [==============================] - 0s 955us/step - loss: 0.0383 - val_loss: 0.0378\n",
      "Epoch 19/100\n",
      "199/199 [==============================] - 0s 951us/step - loss: 0.0378 - val_loss: 0.0375\n",
      "Epoch 20/100\n",
      "199/199 [==============================] - 0s 918us/step - loss: 0.0376 - val_loss: 0.0373\n",
      "Epoch 21/100\n",
      "199/199 [==============================] - 0s 891us/step - loss: 0.0373 - val_loss: 0.0370\n",
      "Epoch 22/100\n",
      "199/199 [==============================] - 0s 918us/step - loss: 0.0371 - val_loss: 0.0368\n",
      "Epoch 23/100\n",
      "199/199 [==============================] - 0s 905us/step - loss: 0.0370 - val_loss: 0.0367\n",
      "Epoch 24/100\n",
      "199/199 [==============================] - 0s 934us/step - loss: 0.0369 - val_loss: 0.0368\n",
      "Epoch 25/100\n",
      "199/199 [==============================] - 0s 884us/step - loss: 0.0368 - val_loss: 0.0365\n",
      "Epoch 26/100\n",
      "199/199 [==============================] - 0s 894us/step - loss: 0.0367 - val_loss: 0.0364\n",
      "Epoch 27/100\n",
      "199/199 [==============================] - 0s 882us/step - loss: 0.0366 - val_loss: 0.0364\n",
      "Epoch 28/100\n",
      "199/199 [==============================] - 0s 887us/step - loss: 0.0366 - val_loss: 0.0363\n",
      "Epoch 29/100\n",
      "199/199 [==============================] - 0s 886us/step - loss: 0.0365 - val_loss: 0.0363\n",
      "Epoch 30/100\n",
      "199/199 [==============================] - 0s 885us/step - loss: 0.0365 - val_loss: 0.0363\n",
      "Epoch 31/100\n",
      "199/199 [==============================] - 0s 885us/step - loss: 0.0364 - val_loss: 0.0361\n",
      "Epoch 32/100\n",
      "199/199 [==============================] - 0s 869us/step - loss: 0.0364 - val_loss: 0.0362\n",
      "Epoch 33/100\n",
      "199/199 [==============================] - 0s 882us/step - loss: 0.0364 - val_loss: 0.0361\n",
      "Epoch 34/100\n",
      "199/199 [==============================] - 0s 937us/step - loss: 0.0363 - val_loss: 0.0363\n",
      "Epoch 35/100\n",
      "199/199 [==============================] - 0s 949us/step - loss: 0.0363 - val_loss: 0.0361\n",
      "Epoch 36/100\n",
      "199/199 [==============================] - 0s 925us/step - loss: 0.0363 - val_loss: 0.0362\n",
      "Epoch 37/100\n",
      "199/199 [==============================] - 0s 893us/step - loss: 0.0362 - val_loss: 0.0359\n",
      "Epoch 38/100\n",
      "199/199 [==============================] - 0s 895us/step - loss: 0.0362 - val_loss: 0.0363\n",
      "Epoch 39/100\n",
      "199/199 [==============================] - 0s 907us/step - loss: 0.0361 - val_loss: 0.0358\n",
      "Epoch 40/100\n",
      "199/199 [==============================] - 0s 884us/step - loss: 0.0360 - val_loss: 0.0358\n",
      "Epoch 41/100\n",
      "199/199 [==============================] - 0s 908us/step - loss: 0.0359 - val_loss: 0.0357\n",
      "Epoch 42/100\n",
      "199/199 [==============================] - 0s 906us/step - loss: 0.0359 - val_loss: 0.0357\n",
      "Epoch 43/100\n",
      "199/199 [==============================] - 0s 882us/step - loss: 0.0358 - val_loss: 0.0356\n",
      "Epoch 44/100\n",
      "199/199 [==============================] - 0s 887us/step - loss: 0.0357 - val_loss: 0.0359\n",
      "Epoch 45/100\n",
      "199/199 [==============================] - 0s 917us/step - loss: 0.0357 - val_loss: 0.0354\n",
      "Epoch 46/100\n",
      "199/199 [==============================] - 0s 907us/step - loss: 0.0356 - val_loss: 0.0354\n",
      "Epoch 47/100\n",
      "199/199 [==============================] - 0s 925us/step - loss: 0.0355 - val_loss: 0.0353\n",
      "Epoch 48/100\n",
      "199/199 [==============================] - 0s 924us/step - loss: 0.0354 - val_loss: 0.0355\n",
      "Epoch 49/100\n",
      "199/199 [==============================] - 0s 937us/step - loss: 0.0354 - val_loss: 0.0353\n",
      "Epoch 50/100\n",
      "199/199 [==============================] - 0s 923us/step - loss: 0.0353 - val_loss: 0.0353\n",
      "Epoch 51/100\n",
      "199/199 [==============================] - 0s 914us/step - loss: 0.0353 - val_loss: 0.0350\n",
      "Epoch 52/100\n",
      "199/199 [==============================] - 0s 940us/step - loss: 0.0352 - val_loss: 0.0350\n",
      "Epoch 53/100\n",
      "199/199 [==============================] - 0s 951us/step - loss: 0.0351 - val_loss: 0.0349\n",
      "Epoch 54/100\n",
      "199/199 [==============================] - 0s 953us/step - loss: 0.0349 - val_loss: 0.0348\n",
      "Epoch 55/100\n",
      "199/199 [==============================] - 0s 903us/step - loss: 0.0349 - val_loss: 0.0349\n",
      "Epoch 56/100\n",
      "199/199 [==============================] - 0s 882us/step - loss: 0.0350 - val_loss: 0.0347\n",
      "Epoch 57/100\n",
      "199/199 [==============================] - 0s 891us/step - loss: 0.0348 - val_loss: 0.0346\n",
      "Epoch 58/100\n",
      "199/199 [==============================] - 0s 915us/step - loss: 0.0348 - val_loss: 0.0346\n",
      "Epoch 59/100\n",
      "199/199 [==============================] - 0s 913us/step - loss: 0.0347 - val_loss: 0.0345\n",
      "Epoch 60/100\n",
      "199/199 [==============================] - 0s 909us/step - loss: 0.0346 - val_loss: 0.0347\n",
      "Epoch 61/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0346 - val_loss: 0.0345\n",
      "Epoch 62/100\n",
      "199/199 [==============================] - 0s 942us/step - loss: 0.0345 - val_loss: 0.0342\n",
      "Epoch 63/100\n",
      "199/199 [==============================] - 0s 906us/step - loss: 0.0345 - val_loss: 0.0344\n",
      "Epoch 64/100\n",
      "199/199 [==============================] - 0s 905us/step - loss: 0.0344 - val_loss: 0.0342\n",
      "Epoch 65/100\n",
      "199/199 [==============================] - 0s 912us/step - loss: 0.0344 - val_loss: 0.0342\n",
      "Epoch 66/100\n",
      "199/199 [==============================] - 0s 910us/step - loss: 0.0343 - val_loss: 0.0340\n",
      "Epoch 67/100\n",
      "199/199 [==============================] - 0s 884us/step - loss: 0.0342 - val_loss: 0.0343\n",
      "Epoch 68/100\n",
      "199/199 [==============================] - 0s 883us/step - loss: 0.0342 - val_loss: 0.0340\n",
      "Epoch 69/100\n",
      "199/199 [==============================] - 0s 906us/step - loss: 0.0341 - val_loss: 0.0340\n",
      "Epoch 70/100\n",
      "199/199 [==============================] - 0s 888us/step - loss: 0.0341 - val_loss: 0.0338\n",
      "Epoch 71/100\n",
      "199/199 [==============================] - 0s 876us/step - loss: 0.0340 - val_loss: 0.0338\n",
      "Epoch 72/100\n",
      "199/199 [==============================] - 0s 865us/step - loss: 0.0339 - val_loss: 0.0339\n",
      "Epoch 73/100\n",
      "199/199 [==============================] - 0s 893us/step - loss: 0.0339 - val_loss: 0.0338\n",
      "Epoch 74/100\n",
      "199/199 [==============================] - 0s 934us/step - loss: 0.0339 - val_loss: 0.0337\n",
      "Epoch 75/100\n",
      "199/199 [==============================] - 0s 928us/step - loss: 0.0337 - val_loss: 0.0337\n",
      "Epoch 76/100\n",
      "199/199 [==============================] - 0s 917us/step - loss: 0.0338 - val_loss: 0.0337\n",
      "Epoch 77/100\n",
      "199/199 [==============================] - 0s 939us/step - loss: 0.0336 - val_loss: 0.0338\n",
      "Epoch 78/100\n",
      "199/199 [==============================] - 0s 921us/step - loss: 0.0336 - val_loss: 0.0339\n",
      "Epoch 79/100\n",
      "199/199 [==============================] - 0s 922us/step - loss: 0.0336 - val_loss: 0.0334\n",
      "Epoch 80/100\n",
      "199/199 [==============================] - 0s 933us/step - loss: 0.0335 - val_loss: 0.0333\n",
      "Epoch 81/100\n",
      "199/199 [==============================] - 0s 934us/step - loss: 0.0335 - val_loss: 0.0333\n",
      "Epoch 82/100\n",
      "199/199 [==============================] - 0s 914us/step - loss: 0.0336 - val_loss: 0.0335\n",
      "Epoch 83/100\n",
      "199/199 [==============================] - 0s 944us/step - loss: 0.0333 - val_loss: 0.0332\n",
      "Epoch 84/100\n",
      "199/199 [==============================] - 0s 915us/step - loss: 0.0334 - val_loss: 0.0331\n",
      "Epoch 85/100\n",
      "199/199 [==============================] - 0s 906us/step - loss: 0.0333 - val_loss: 0.0331\n",
      "Epoch 86/100\n",
      "199/199 [==============================] - 0s 896us/step - loss: 0.0332 - val_loss: 0.0333\n",
      "Epoch 87/100\n",
      "199/199 [==============================] - 0s 895us/step - loss: 0.0332 - val_loss: 0.0332\n",
      "Epoch 88/100\n",
      "199/199 [==============================] - 0s 919us/step - loss: 0.0332 - val_loss: 0.0329\n",
      "Epoch 89/100\n",
      "199/199 [==============================] - 0s 914us/step - loss: 0.0331 - val_loss: 0.0339\n",
      "Epoch 90/100\n",
      "199/199 [==============================] - 0s 902us/step - loss: 0.0331 - val_loss: 0.0332\n",
      "Epoch 91/100\n",
      "199/199 [==============================] - 0s 950us/step - loss: 0.0331 - val_loss: 0.0328\n",
      "Epoch 92/100\n",
      "199/199 [==============================] - 0s 915us/step - loss: 0.0330 - val_loss: 0.0328\n",
      "Epoch 93/100\n",
      "199/199 [==============================] - 0s 908us/step - loss: 0.0329 - val_loss: 0.0327\n",
      "Epoch 94/100\n",
      "199/199 [==============================] - 0s 943us/step - loss: 0.0328 - val_loss: 0.0327\n",
      "Epoch 95/100\n",
      "199/199 [==============================] - 0s 908us/step - loss: 0.0329 - val_loss: 0.0331\n",
      "Epoch 96/100\n",
      "199/199 [==============================] - 0s 899us/step - loss: 0.0329 - val_loss: 0.0328\n",
      "Epoch 97/100\n",
      "199/199 [==============================] - 0s 951us/step - loss: 0.0328 - val_loss: 0.0329\n",
      "Epoch 98/100\n",
      "199/199 [==============================] - 0s 922us/step - loss: 0.0328 - val_loss: 0.0326\n",
      "Epoch 99/100\n",
      "199/199 [==============================] - 0s 914us/step - loss: 0.0328 - val_loss: 0.0326\n",
      "Epoch 100/100\n",
      "199/199 [==============================] - 0s 932us/step - loss: 0.0327 - val_loss: 0.0324\n",
      "This round is 19\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_11724/328462441.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  para_dfm = para_dfm.append({\"reg_param\": reg_param, \"number_units_layers\": numbers_units_layers, \"number_units_bottleneck\": numbers_units_bottleneck, \"dropout_rate\": dropout_rate, \"number_layers\": numbers_layers, \"whether_dropout\": whether_dropout, \"whether_regularizer\": whether_regularizer, \"overfit_metric\": overfit_metric, \"val2_avg_recon_error\": val2_avg_recon_error,'val1_loss':val1_loss}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 0s 1ms/step - loss: 1.3998 - val_loss: 0.3472\n",
      "Epoch 2/100\n",
      "199/199 [==============================] - 0s 954us/step - loss: 0.1506 - val_loss: 0.0682\n",
      "Epoch 3/100\n",
      "199/199 [==============================] - 0s 929us/step - loss: 0.0585 - val_loss: 0.0552\n",
      "Epoch 4/100\n",
      "199/199 [==============================] - 0s 916us/step - loss: 0.0549 - val_loss: 0.0546\n",
      "Epoch 5/100\n",
      "199/199 [==============================] - 0s 951us/step - loss: 0.0539 - val_loss: 0.0522\n",
      "Epoch 6/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0479 - val_loss: 0.0440\n",
      "Epoch 7/100\n",
      "199/199 [==============================] - 0s 949us/step - loss: 0.0424 - val_loss: 0.0411\n",
      "Epoch 8/100\n",
      "199/199 [==============================] - 0s 929us/step - loss: 0.0405 - val_loss: 0.0398\n",
      "Epoch 9/100\n",
      "199/199 [==============================] - 0s 921us/step - loss: 0.0395 - val_loss: 0.0389\n",
      "Epoch 10/100\n",
      "199/199 [==============================] - 0s 896us/step - loss: 0.0388 - val_loss: 0.0383\n",
      "Epoch 11/100\n",
      "199/199 [==============================] - 0s 896us/step - loss: 0.0382 - val_loss: 0.0378\n",
      "Epoch 12/100\n",
      "199/199 [==============================] - 0s 905us/step - loss: 0.0378 - val_loss: 0.0375\n",
      "Epoch 13/100\n",
      "199/199 [==============================] - 0s 913us/step - loss: 0.0375 - val_loss: 0.0372\n",
      "Epoch 14/100\n",
      "199/199 [==============================] - 0s 921us/step - loss: 0.0372 - val_loss: 0.0370\n",
      "Epoch 15/100\n",
      "199/199 [==============================] - 0s 946us/step - loss: 0.0370 - val_loss: 0.0368\n",
      "Epoch 16/100\n",
      "199/199 [==============================] - 0s 946us/step - loss: 0.0369 - val_loss: 0.0367\n",
      "Epoch 17/100\n",
      "199/199 [==============================] - 0s 926us/step - loss: 0.0368 - val_loss: 0.0365\n",
      "Epoch 18/100\n",
      "199/199 [==============================] - 0s 902us/step - loss: 0.0367 - val_loss: 0.0365\n",
      "Epoch 19/100\n",
      "199/199 [==============================] - 0s 893us/step - loss: 0.0366 - val_loss: 0.0364\n",
      "Epoch 20/100\n",
      "199/199 [==============================] - 0s 903us/step - loss: 0.0365 - val_loss: 0.0363\n",
      "Epoch 21/100\n",
      "199/199 [==============================] - 0s 941us/step - loss: 0.0364 - val_loss: 0.0363\n",
      "Epoch 22/100\n",
      "199/199 [==============================] - 0s 986us/step - loss: 0.0364 - val_loss: 0.0363\n",
      "Epoch 23/100\n",
      "199/199 [==============================] - 0s 968us/step - loss: 0.0364 - val_loss: 0.0362\n",
      "Epoch 24/100\n",
      "199/199 [==============================] - 0s 951us/step - loss: 0.0363 - val_loss: 0.0361\n",
      "Epoch 25/100\n",
      "199/199 [==============================] - 0s 942us/step - loss: 0.0363 - val_loss: 0.0362\n",
      "Epoch 26/100\n",
      "199/199 [==============================] - 0s 941us/step - loss: 0.0363 - val_loss: 0.0361\n",
      "Epoch 27/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0362 - val_loss: 0.0360\n",
      "Epoch 28/100\n",
      "199/199 [==============================] - 0s 969us/step - loss: 0.0362 - val_loss: 0.0360\n",
      "Epoch 29/100\n",
      "199/199 [==============================] - 0s 959us/step - loss: 0.0362 - val_loss: 0.0360\n",
      "Epoch 30/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0361 - val_loss: 0.0359\n",
      "Epoch 31/100\n",
      "199/199 [==============================] - 0s 973us/step - loss: 0.0361 - val_loss: 0.0361\n",
      "Epoch 32/100\n",
      "199/199 [==============================] - 0s 959us/step - loss: 0.0361 - val_loss: 0.0359\n",
      "Epoch 33/100\n",
      "199/199 [==============================] - 0s 945us/step - loss: 0.0360 - val_loss: 0.0359\n",
      "Epoch 34/100\n",
      "199/199 [==============================] - 0s 913us/step - loss: 0.0361 - val_loss: 0.0361\n",
      "Epoch 35/100\n",
      "199/199 [==============================] - 0s 935us/step - loss: 0.0361 - val_loss: 0.0361\n",
      "Epoch 36/100\n",
      "199/199 [==============================] - 0s 923us/step - loss: 0.0360 - val_loss: 0.0360\n",
      "Epoch 37/100\n",
      "199/199 [==============================] - 0s 909us/step - loss: 0.0360 - val_loss: 0.0358\n",
      "Epoch 38/100\n",
      "199/199 [==============================] - 0s 904us/step - loss: 0.0361 - val_loss: 0.0370\n",
      "Epoch 39/100\n",
      "199/199 [==============================] - 0s 900us/step - loss: 0.0360 - val_loss: 0.0358\n",
      "Epoch 40/100\n",
      "199/199 [==============================] - 0s 917us/step - loss: 0.0360 - val_loss: 0.0358\n",
      "Epoch 41/100\n",
      "199/199 [==============================] - 0s 903us/step - loss: 0.0359 - val_loss: 0.0358\n",
      "Epoch 42/100\n",
      "199/199 [==============================] - 0s 901us/step - loss: 0.0361 - val_loss: 0.0359\n",
      "Epoch 43/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0359 - val_loss: 0.0358\n",
      "Epoch 44/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0359 - val_loss: 0.0358\n",
      "Epoch 45/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0359 - val_loss: 0.0358\n",
      "Epoch 46/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0359 - val_loss: 0.0358\n",
      "Epoch 47/100\n",
      "199/199 [==============================] - 0s 957us/step - loss: 0.0359 - val_loss: 0.0359\n",
      "Epoch 48/100\n",
      "199/199 [==============================] - 0s 914us/step - loss: 0.0359 - val_loss: 0.0357\n",
      "Epoch 49/100\n",
      "199/199 [==============================] - 0s 961us/step - loss: 0.0359 - val_loss: 0.0357\n",
      "Epoch 50/100\n",
      "199/199 [==============================] - 0s 985us/step - loss: 0.0358 - val_loss: 0.0358\n",
      "Epoch 51/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0359 - val_loss: 0.0358\n",
      "Epoch 52/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0358 - val_loss: 0.0357\n",
      "Epoch 53/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0358 - val_loss: 0.0356\n",
      "Epoch 54/100\n",
      "199/199 [==============================] - 0s 992us/step - loss: 0.0358 - val_loss: 0.0359\n",
      "Epoch 55/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0358 - val_loss: 0.0358\n",
      "Epoch 56/100\n",
      "199/199 [==============================] - 0s 961us/step - loss: 0.0358 - val_loss: 0.0356\n",
      "Epoch 57/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0358 - val_loss: 0.0365\n",
      "Epoch 58/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0359 - val_loss: 0.0358\n",
      "Epoch 59/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0358 - val_loss: 0.0356\n",
      "Epoch 60/100\n",
      "199/199 [==============================] - 0s 946us/step - loss: 0.0358 - val_loss: 0.0358\n",
      "Epoch 61/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0358 - val_loss: 0.0356\n",
      "Epoch 62/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0358 - val_loss: 0.0358\n",
      "Epoch 63/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0357 - val_loss: 0.0359\n",
      "Epoch 64/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0358 - val_loss: 0.0355\n",
      "Epoch 65/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0356 - val_loss: 0.0355\n",
      "Epoch 66/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0357 - val_loss: 0.0355\n",
      "Epoch 67/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0358 - val_loss: 0.0357\n",
      "Epoch 68/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0356 - val_loss: 0.0358\n",
      "Epoch 69/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0355 - val_loss: 0.0354\n",
      "Epoch 70/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0355 - val_loss: 0.0356\n",
      "Epoch 71/100\n",
      "199/199 [==============================] - 0s 935us/step - loss: 0.0355 - val_loss: 0.0354\n",
      "Epoch 72/100\n",
      "199/199 [==============================] - 0s 909us/step - loss: 0.0354 - val_loss: 0.0353\n",
      "Epoch 73/100\n",
      "199/199 [==============================] - 0s 920us/step - loss: 0.0354 - val_loss: 0.0353\n",
      "Epoch 74/100\n",
      "199/199 [==============================] - 0s 908us/step - loss: 0.0353 - val_loss: 0.0353\n",
      "Epoch 75/100\n",
      "199/199 [==============================] - 0s 898us/step - loss: 0.0352 - val_loss: 0.0351\n",
      "Epoch 76/100\n",
      "199/199 [==============================] - 0s 914us/step - loss: 0.0354 - val_loss: 0.0350\n",
      "Epoch 77/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0351 - val_loss: 0.0350\n",
      "Epoch 78/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0350 - val_loss: 0.0349\n",
      "Epoch 79/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0349 - val_loss: 0.0347\n",
      "Epoch 80/100\n",
      "199/199 [==============================] - 0s 936us/step - loss: 0.0349 - val_loss: 0.0346\n",
      "Epoch 81/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0347 - val_loss: 0.0345\n",
      "Epoch 82/100\n",
      "199/199 [==============================] - 0s 964us/step - loss: 0.0346 - val_loss: 0.0346\n",
      "Epoch 83/100\n",
      "199/199 [==============================] - 0s 975us/step - loss: 0.0345 - val_loss: 0.0343\n",
      "Epoch 84/100\n",
      "199/199 [==============================] - 0s 925us/step - loss: 0.0345 - val_loss: 0.0344\n",
      "Epoch 85/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0342 - val_loss: 0.0338\n",
      "Epoch 86/100\n",
      "199/199 [==============================] - 0s 944us/step - loss: 0.0339 - val_loss: 0.0336\n",
      "Epoch 87/100\n",
      "199/199 [==============================] - 0s 915us/step - loss: 0.0338 - val_loss: 0.0334\n",
      "Epoch 88/100\n",
      "199/199 [==============================] - 0s 952us/step - loss: 0.0333 - val_loss: 0.0331\n",
      "Epoch 89/100\n",
      "199/199 [==============================] - 0s 908us/step - loss: 0.0329 - val_loss: 0.0327\n",
      "Epoch 90/100\n",
      "199/199 [==============================] - 0s 917us/step - loss: 0.0324 - val_loss: 0.0323\n",
      "Epoch 91/100\n",
      "199/199 [==============================] - 0s 918us/step - loss: 0.0320 - val_loss: 0.0320\n",
      "Epoch 92/100\n",
      "199/199 [==============================] - 0s 927us/step - loss: 0.0317 - val_loss: 0.0316\n",
      "Epoch 93/100\n",
      "199/199 [==============================] - 0s 933us/step - loss: 0.0315 - val_loss: 0.0312\n",
      "Epoch 94/100\n",
      "199/199 [==============================] - 0s 922us/step - loss: 0.0311 - val_loss: 0.0310\n",
      "Epoch 95/100\n",
      "199/199 [==============================] - 0s 924us/step - loss: 0.0310 - val_loss: 0.0305\n",
      "Epoch 96/100\n",
      "199/199 [==============================] - 0s 924us/step - loss: 0.0306 - val_loss: 0.0307\n",
      "Epoch 97/100\n",
      "199/199 [==============================] - 0s 925us/step - loss: 0.0303 - val_loss: 0.0303\n",
      "Epoch 98/100\n",
      "199/199 [==============================] - 0s 932us/step - loss: 0.0301 - val_loss: 0.0299\n",
      "Epoch 99/100\n",
      "199/199 [==============================] - 0s 897us/step - loss: 0.0298 - val_loss: 0.0295\n",
      "Epoch 100/100\n",
      "199/199 [==============================] - 0s 928us/step - loss: 0.0295 - val_loss: 0.0292\n",
      "This round is 20\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_11724/328462441.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  para_dfm = para_dfm.append({\"reg_param\": reg_param, \"number_units_layers\": numbers_units_layers, \"number_units_bottleneck\": numbers_units_bottleneck, \"dropout_rate\": dropout_rate, \"number_layers\": numbers_layers, \"whether_dropout\": whether_dropout, \"whether_regularizer\": whether_regularizer, \"overfit_metric\": overfit_metric, \"val2_avg_recon_error\": val2_avg_recon_error,'val1_loss':val1_loss}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 0s 1ms/step - loss: 0.8834 - val_loss: 0.2968\n",
      "Epoch 2/100\n",
      "199/199 [==============================] - 0s 907us/step - loss: 0.1511 - val_loss: 0.0778\n",
      "Epoch 3/100\n",
      "199/199 [==============================] - 0s 877us/step - loss: 0.0630 - val_loss: 0.0565\n",
      "Epoch 4/100\n",
      "199/199 [==============================] - 0s 908us/step - loss: 0.0556 - val_loss: 0.0551\n",
      "Epoch 5/100\n",
      "199/199 [==============================] - 0s 895us/step - loss: 0.0551 - val_loss: 0.0551\n",
      "Epoch 6/100\n",
      "199/199 [==============================] - 0s 902us/step - loss: 0.0551 - val_loss: 0.0550\n",
      "Epoch 7/100\n",
      "199/199 [==============================] - 0s 884us/step - loss: 0.0551 - val_loss: 0.0550\n",
      "Epoch 8/100\n",
      "199/199 [==============================] - 0s 874us/step - loss: 0.0551 - val_loss: 0.0551\n",
      "Epoch 9/100\n",
      "199/199 [==============================] - 0s 908us/step - loss: 0.0551 - val_loss: 0.0550\n",
      "Epoch 10/100\n",
      "199/199 [==============================] - 0s 912us/step - loss: 0.0551 - val_loss: 0.0550\n",
      "Epoch 11/100\n",
      "199/199 [==============================] - 0s 896us/step - loss: 0.0551 - val_loss: 0.0550\n",
      "Epoch 12/100\n",
      "199/199 [==============================] - 0s 956us/step - loss: 0.0550 - val_loss: 0.0550\n",
      "Epoch 13/100\n",
      "199/199 [==============================] - 0s 949us/step - loss: 0.0550 - val_loss: 0.0550\n",
      "Epoch 14/100\n",
      "199/199 [==============================] - 0s 945us/step - loss: 0.0550 - val_loss: 0.0550\n",
      "Epoch 15/100\n",
      "199/199 [==============================] - 0s 926us/step - loss: 0.0550 - val_loss: 0.0549\n",
      "Epoch 16/100\n",
      "199/199 [==============================] - 0s 954us/step - loss: 0.0550 - val_loss: 0.0549\n",
      "Epoch 17/100\n",
      "199/199 [==============================] - 0s 903us/step - loss: 0.0549 - val_loss: 0.0548\n",
      "Epoch 18/100\n",
      "199/199 [==============================] - 0s 887us/step - loss: 0.0548 - val_loss: 0.0545\n",
      "Epoch 19/100\n",
      "199/199 [==============================] - 0s 895us/step - loss: 0.0532 - val_loss: 0.0494\n",
      "Epoch 20/100\n",
      "199/199 [==============================] - 0s 887us/step - loss: 0.0445 - val_loss: 0.0414\n",
      "Epoch 21/100\n",
      "199/199 [==============================] - 0s 873us/step - loss: 0.0408 - val_loss: 0.0398\n",
      "Epoch 22/100\n",
      "199/199 [==============================] - 0s 906us/step - loss: 0.0396 - val_loss: 0.0392\n",
      "Epoch 23/100\n",
      "199/199 [==============================] - 0s 879us/step - loss: 0.0389 - val_loss: 0.0384\n",
      "Epoch 24/100\n",
      "199/199 [==============================] - 0s 878us/step - loss: 0.0384 - val_loss: 0.0379\n",
      "Epoch 25/100\n",
      "199/199 [==============================] - 0s 874us/step - loss: 0.0380 - val_loss: 0.0376\n",
      "Epoch 26/100\n",
      "199/199 [==============================] - 0s 880us/step - loss: 0.0377 - val_loss: 0.0373\n",
      "Epoch 27/100\n",
      "199/199 [==============================] - 0s 871us/step - loss: 0.0374 - val_loss: 0.0370\n",
      "Epoch 28/100\n",
      "199/199 [==============================] - 0s 958us/step - loss: 0.0372 - val_loss: 0.0369\n",
      "Epoch 29/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0370 - val_loss: 0.0367\n",
      "Epoch 30/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0369 - val_loss: 0.0366\n",
      "Epoch 31/100\n",
      "199/199 [==============================] - 0s 865us/step - loss: 0.0368 - val_loss: 0.0367\n",
      "Epoch 32/100\n",
      "199/199 [==============================] - 0s 880us/step - loss: 0.0367 - val_loss: 0.0366\n",
      "Epoch 33/100\n",
      "199/199 [==============================] - 0s 945us/step - loss: 0.0366 - val_loss: 0.0364\n",
      "Epoch 34/100\n",
      "199/199 [==============================] - 0s 882us/step - loss: 0.0366 - val_loss: 0.0364\n",
      "Epoch 35/100\n",
      "199/199 [==============================] - 0s 999us/step - loss: 0.0365 - val_loss: 0.0362\n",
      "Epoch 36/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0364 - val_loss: 0.0362\n",
      "Epoch 37/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0364 - val_loss: 0.0362\n",
      "Epoch 38/100\n",
      "199/199 [==============================] - 0s 942us/step - loss: 0.0363 - val_loss: 0.0361\n",
      "Epoch 39/100\n",
      "199/199 [==============================] - 0s 912us/step - loss: 0.0363 - val_loss: 0.0361\n",
      "Epoch 40/100\n",
      "199/199 [==============================] - 0s 984us/step - loss: 0.0363 - val_loss: 0.0362\n",
      "Epoch 41/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0362 - val_loss: 0.0360\n",
      "Epoch 42/100\n",
      "199/199 [==============================] - 0s 966us/step - loss: 0.0362 - val_loss: 0.0361\n",
      "Epoch 43/100\n",
      "199/199 [==============================] - 0s 924us/step - loss: 0.0362 - val_loss: 0.0360\n",
      "Epoch 44/100\n",
      "199/199 [==============================] - 0s 907us/step - loss: 0.0362 - val_loss: 0.0362\n",
      "Epoch 45/100\n",
      "199/199 [==============================] - 0s 983us/step - loss: 0.0361 - val_loss: 0.0359\n",
      "Epoch 46/100\n",
      "199/199 [==============================] - 0s 880us/step - loss: 0.0362 - val_loss: 0.0359\n",
      "Epoch 47/100\n",
      "199/199 [==============================] - 0s 922us/step - loss: 0.0361 - val_loss: 0.0359\n",
      "Epoch 48/100\n",
      "199/199 [==============================] - 0s 887us/step - loss: 0.0361 - val_loss: 0.0360\n",
      "Epoch 49/100\n",
      "199/199 [==============================] - 0s 928us/step - loss: 0.0360 - val_loss: 0.0359\n",
      "Epoch 50/100\n",
      "199/199 [==============================] - 0s 887us/step - loss: 0.0360 - val_loss: 0.0359\n",
      "Epoch 51/100\n",
      "199/199 [==============================] - 0s 894us/step - loss: 0.0361 - val_loss: 0.0359\n",
      "Epoch 52/100\n",
      "199/199 [==============================] - 0s 892us/step - loss: 0.0360 - val_loss: 0.0358\n",
      "Epoch 53/100\n",
      "199/199 [==============================] - 0s 876us/step - loss: 0.0360 - val_loss: 0.0359\n",
      "Epoch 54/100\n",
      "199/199 [==============================] - 0s 890us/step - loss: 0.0360 - val_loss: 0.0359\n",
      "Epoch 55/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0360 - val_loss: 0.0358\n",
      "Epoch 56/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0360 - val_loss: 0.0358\n",
      "Epoch 57/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0359 - val_loss: 0.0357\n",
      "Epoch 58/100\n",
      "199/199 [==============================] - 0s 885us/step - loss: 0.0359 - val_loss: 0.0357\n",
      "Epoch 59/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0359 - val_loss: 0.0358\n",
      "Epoch 60/100\n",
      "199/199 [==============================] - 0s 943us/step - loss: 0.0359 - val_loss: 0.0363\n",
      "Epoch 61/100\n",
      "199/199 [==============================] - 0s 920us/step - loss: 0.0360 - val_loss: 0.0358\n",
      "Epoch 62/100\n",
      "199/199 [==============================] - 0s 894us/step - loss: 0.0359 - val_loss: 0.0357\n",
      "Epoch 63/100\n",
      "199/199 [==============================] - 0s 881us/step - loss: 0.0359 - val_loss: 0.0357\n",
      "Epoch 64/100\n",
      "199/199 [==============================] - 0s 892us/step - loss: 0.0359 - val_loss: 0.0357\n",
      "Epoch 65/100\n",
      "199/199 [==============================] - 0s 900us/step - loss: 0.0358 - val_loss: 0.0357\n",
      "Epoch 66/100\n",
      "199/199 [==============================] - 0s 903us/step - loss: 0.0358 - val_loss: 0.0357\n",
      "Epoch 67/100\n",
      "199/199 [==============================] - 0s 906us/step - loss: 0.0359 - val_loss: 0.0357\n",
      "Epoch 68/100\n",
      "199/199 [==============================] - 0s 880us/step - loss: 0.0358 - val_loss: 0.0357\n",
      "Epoch 69/100\n",
      "199/199 [==============================] - 0s 903us/step - loss: 0.0358 - val_loss: 0.0356\n",
      "Epoch 70/100\n",
      "199/199 [==============================] - 0s 900us/step - loss: 0.0358 - val_loss: 0.0356\n",
      "Epoch 71/100\n",
      "199/199 [==============================] - 0s 882us/step - loss: 0.0358 - val_loss: 0.0357\n",
      "Epoch 72/100\n",
      "199/199 [==============================] - 0s 888us/step - loss: 0.0358 - val_loss: 0.0358\n",
      "Epoch 73/100\n",
      "199/199 [==============================] - 0s 887us/step - loss: 0.0358 - val_loss: 0.0356\n",
      "Epoch 74/100\n",
      "199/199 [==============================] - 0s 902us/step - loss: 0.0358 - val_loss: 0.0356\n",
      "Epoch 75/100\n",
      "199/199 [==============================] - 0s 906us/step - loss: 0.0358 - val_loss: 0.0356\n",
      "Epoch 76/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0358 - val_loss: 0.0355\n",
      "Epoch 77/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0358 - val_loss: 0.0357\n",
      "Epoch 78/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0357 - val_loss: 0.0356\n",
      "Epoch 79/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0357 - val_loss: 0.0356\n",
      "Epoch 80/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0357 - val_loss: 0.0356\n",
      "Epoch 81/100\n",
      "199/199 [==============================] - 0s 906us/step - loss: 0.0357 - val_loss: 0.0357\n",
      "Epoch 82/100\n",
      "199/199 [==============================] - 0s 936us/step - loss: 0.0357 - val_loss: 0.0357\n",
      "Epoch 83/100\n",
      "199/199 [==============================] - 0s 948us/step - loss: 0.0357 - val_loss: 0.0357\n",
      "Epoch 84/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0357 - val_loss: 0.0356\n",
      "Epoch 85/100\n",
      "199/199 [==============================] - 0s 941us/step - loss: 0.0357 - val_loss: 0.0355\n",
      "Epoch 86/100\n",
      "199/199 [==============================] - 0s 940us/step - loss: 0.0356 - val_loss: 0.0355\n",
      "Epoch 87/100\n",
      "199/199 [==============================] - 0s 938us/step - loss: 0.0357 - val_loss: 0.0356\n",
      "Epoch 88/100\n",
      "199/199 [==============================] - 0s 920us/step - loss: 0.0356 - val_loss: 0.0355\n",
      "Epoch 89/100\n",
      "199/199 [==============================] - 0s 943us/step - loss: 0.0356 - val_loss: 0.0357\n",
      "Epoch 90/100\n",
      "199/199 [==============================] - 0s 947us/step - loss: 0.0357 - val_loss: 0.0356\n",
      "Epoch 91/100\n",
      "199/199 [==============================] - 0s 902us/step - loss: 0.0357 - val_loss: 0.0355\n",
      "Epoch 92/100\n",
      "199/199 [==============================] - 0s 902us/step - loss: 0.0356 - val_loss: 0.0355\n",
      "Epoch 93/100\n",
      "199/199 [==============================] - 0s 923us/step - loss: 0.0356 - val_loss: 0.0354\n",
      "Epoch 94/100\n",
      "199/199 [==============================] - 0s 927us/step - loss: 0.0356 - val_loss: 0.0358\n",
      "Epoch 95/100\n",
      "199/199 [==============================] - 0s 884us/step - loss: 0.0356 - val_loss: 0.0354\n",
      "Epoch 96/100\n",
      "199/199 [==============================] - 0s 890us/step - loss: 0.0355 - val_loss: 0.0354\n",
      "Epoch 97/100\n",
      "199/199 [==============================] - 0s 880us/step - loss: 0.0356 - val_loss: 0.0354\n",
      "Epoch 98/100\n",
      "199/199 [==============================] - 0s 891us/step - loss: 0.0356 - val_loss: 0.0356\n",
      "Epoch 99/100\n",
      "199/199 [==============================] - 0s 893us/step - loss: 0.0356 - val_loss: 0.0355\n",
      "Epoch 100/100\n",
      "199/199 [==============================] - 0s 894us/step - loss: 0.0356 - val_loss: 0.0354\n",
      "This round is 21\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_11724/328462441.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  para_dfm = para_dfm.append({\"reg_param\": reg_param, \"number_units_layers\": numbers_units_layers, \"number_units_bottleneck\": numbers_units_bottleneck, \"dropout_rate\": dropout_rate, \"number_layers\": numbers_layers, \"whether_dropout\": whether_dropout, \"whether_regularizer\": whether_regularizer, \"overfit_metric\": overfit_metric, \"val2_avg_recon_error\": val2_avg_recon_error,'val1_loss':val1_loss}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0893 - val_loss: 0.0452\n",
      "Epoch 2/100\n",
      "199/199 [==============================] - 0s 859us/step - loss: 0.0376 - val_loss: 0.0323\n",
      "Epoch 3/100\n",
      "199/199 [==============================] - 0s 854us/step - loss: 0.0284 - val_loss: 0.0251\n",
      "Epoch 4/100\n",
      "199/199 [==============================] - 0s 866us/step - loss: 0.0221 - val_loss: 0.0189\n",
      "Epoch 5/100\n",
      "199/199 [==============================] - 0s 862us/step - loss: 0.0171 - val_loss: 0.0153\n",
      "Epoch 6/100\n",
      "199/199 [==============================] - 0s 862us/step - loss: 0.0144 - val_loss: 0.0131\n",
      "Epoch 7/100\n",
      "199/199 [==============================] - 0s 857us/step - loss: 0.0127 - val_loss: 0.0121\n",
      "Epoch 8/100\n",
      "199/199 [==============================] - 0s 860us/step - loss: 0.0118 - val_loss: 0.0114\n",
      "Epoch 9/100\n",
      "199/199 [==============================] - 0s 863us/step - loss: 0.0109 - val_loss: 0.0106\n",
      "Epoch 10/100\n",
      "199/199 [==============================] - 0s 909us/step - loss: 0.0100 - val_loss: 0.0096\n",
      "Epoch 11/100\n",
      "199/199 [==============================] - 0s 969us/step - loss: 0.0090 - val_loss: 0.0088\n",
      "Epoch 12/100\n",
      "199/199 [==============================] - 0s 880us/step - loss: 0.0082 - val_loss: 0.0080\n",
      "Epoch 13/100\n",
      "199/199 [==============================] - 0s 880us/step - loss: 0.0073 - val_loss: 0.0073\n",
      "Epoch 14/100\n",
      "199/199 [==============================] - 0s 900us/step - loss: 0.0068 - val_loss: 0.0069\n",
      "Epoch 15/100\n",
      "199/199 [==============================] - 0s 872us/step - loss: 0.0064 - val_loss: 0.0065\n",
      "Epoch 16/100\n",
      "199/199 [==============================] - 0s 860us/step - loss: 0.0060 - val_loss: 0.0061\n",
      "Epoch 17/100\n",
      "199/199 [==============================] - 0s 881us/step - loss: 0.0057 - val_loss: 0.0059\n",
      "Epoch 18/100\n",
      "199/199 [==============================] - 0s 908us/step - loss: 0.0054 - val_loss: 0.0056\n",
      "Epoch 19/100\n",
      "199/199 [==============================] - 0s 912us/step - loss: 0.0052 - val_loss: 0.0053\n",
      "Epoch 20/100\n",
      "199/199 [==============================] - 0s 898us/step - loss: 0.0050 - val_loss: 0.0051\n",
      "Epoch 21/100\n",
      "199/199 [==============================] - 0s 920us/step - loss: 0.0047 - val_loss: 0.0049\n",
      "Epoch 22/100\n",
      "199/199 [==============================] - 0s 876us/step - loss: 0.0045 - val_loss: 0.0047\n",
      "Epoch 23/100\n",
      "199/199 [==============================] - 0s 902us/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 24/100\n",
      "199/199 [==============================] - 0s 864us/step - loss: 0.0042 - val_loss: 0.0044\n",
      "Epoch 25/100\n",
      "199/199 [==============================] - 0s 862us/step - loss: 0.0040 - val_loss: 0.0042\n",
      "Epoch 26/100\n",
      "199/199 [==============================] - 0s 871us/step - loss: 0.0039 - val_loss: 0.0041\n",
      "Epoch 27/100\n",
      "199/199 [==============================] - 0s 866us/step - loss: 0.0038 - val_loss: 0.0040\n",
      "Epoch 28/100\n",
      "199/199 [==============================] - 0s 864us/step - loss: 0.0036 - val_loss: 0.0038\n",
      "Epoch 29/100\n",
      "199/199 [==============================] - 0s 903us/step - loss: 0.0033 - val_loss: 0.0036\n",
      "Epoch 30/100\n",
      "199/199 [==============================] - 0s 867us/step - loss: 0.0032 - val_loss: 0.0034\n",
      "Epoch 31/100\n",
      "199/199 [==============================] - 0s 932us/step - loss: 0.0030 - val_loss: 0.0033\n",
      "Epoch 32/100\n",
      "199/199 [==============================] - 0s 894us/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 33/100\n",
      "199/199 [==============================] - 0s 893us/step - loss: 0.0027 - val_loss: 0.0030\n",
      "Epoch 34/100\n",
      "199/199 [==============================] - 0s 887us/step - loss: 0.0026 - val_loss: 0.0030\n",
      "Epoch 35/100\n",
      "199/199 [==============================] - 0s 901us/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 36/100\n",
      "199/199 [==============================] - 0s 922us/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 37/100\n",
      "199/199 [==============================] - 0s 892us/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 38/100\n",
      "199/199 [==============================] - 0s 907us/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 39/100\n",
      "199/199 [==============================] - 0s 966us/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 40/100\n",
      "199/199 [==============================] - 0s 906us/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 41/100\n",
      "199/199 [==============================] - 0s 916us/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 42/100\n",
      "199/199 [==============================] - 0s 898us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 43/100\n",
      "199/199 [==============================] - 0s 906us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 44/100\n",
      "199/199 [==============================] - 0s 892us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 45/100\n",
      "199/199 [==============================] - 0s 906us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 46/100\n",
      "199/199 [==============================] - 0s 884us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 47/100\n",
      "199/199 [==============================] - 0s 916us/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 48/100\n",
      "199/199 [==============================] - 0s 901us/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 49/100\n",
      "199/199 [==============================] - 0s 909us/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 50/100\n",
      "199/199 [==============================] - 0s 876us/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 51/100\n",
      "199/199 [==============================] - 0s 886us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 52/100\n",
      "199/199 [==============================] - 0s 869us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 53/100\n",
      "199/199 [==============================] - 0s 873us/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 54/100\n",
      "199/199 [==============================] - 0s 869us/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 55/100\n",
      "199/199 [==============================] - 0s 866us/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 56/100\n",
      "199/199 [==============================] - 0s 890us/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 57/100\n",
      "199/199 [==============================] - 0s 868us/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 58/100\n",
      "199/199 [==============================] - 0s 875us/step - loss: 0.0016 - val_loss: 0.0020\n",
      "Epoch 59/100\n",
      "199/199 [==============================] - 0s 863us/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 60/100\n",
      "199/199 [==============================] - 0s 862us/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 61/100\n",
      "199/199 [==============================] - 0s 869us/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 62/100\n",
      "199/199 [==============================] - 0s 868us/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 63/100\n",
      "199/199 [==============================] - 0s 868us/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 64/100\n",
      "199/199 [==============================] - 0s 861us/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 65/100\n",
      "199/199 [==============================] - 0s 833us/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 66/100\n",
      "199/199 [==============================] - 0s 872us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 67/100\n",
      "199/199 [==============================] - 0s 869us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 68/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 69/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 70/100\n",
      "199/199 [==============================] - 0s 911us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 71/100\n",
      "199/199 [==============================] - 0s 909us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 72/100\n",
      "199/199 [==============================] - 0s 932us/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 73/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 74/100\n",
      "199/199 [==============================] - 0s 876us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 75/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 76/100\n",
      "199/199 [==============================] - 0s 883us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 77/100\n",
      "199/199 [==============================] - 0s 908us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 78/100\n",
      "199/199 [==============================] - 0s 950us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 79/100\n",
      "199/199 [==============================] - 0s 985us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 80/100\n",
      "199/199 [==============================] - 0s 918us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 81/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 82/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 83/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 84/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 85/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 86/100\n",
      "199/199 [==============================] - 0s 992us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 87/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 88/100\n",
      "199/199 [==============================] - 0s 927us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 89/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 90/100\n",
      "199/199 [==============================] - 0s 942us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 91/100\n",
      "199/199 [==============================] - 0s 915us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 92/100\n",
      "199/199 [==============================] - 0s 922us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 93/100\n",
      "199/199 [==============================] - 0s 965us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 94/100\n",
      "199/199 [==============================] - 0s 919us/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 95/100\n",
      "199/199 [==============================] - 0s 907us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 96/100\n",
      "199/199 [==============================] - 0s 898us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 97/100\n",
      "199/199 [==============================] - 0s 925us/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 98/100\n",
      "199/199 [==============================] - 0s 907us/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 99/100\n",
      "199/199 [==============================] - 0s 951us/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 100/100\n",
      "199/199 [==============================] - 0s 922us/step - loss: 0.0011 - val_loss: 0.0016\n",
      "This round is 22\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_11724/328462441.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  para_dfm = para_dfm.append({\"reg_param\": reg_param, \"number_units_layers\": numbers_units_layers, \"number_units_bottleneck\": numbers_units_bottleneck, \"dropout_rate\": dropout_rate, \"number_layers\": numbers_layers, \"whether_dropout\": whether_dropout, \"whether_regularizer\": whether_regularizer, \"overfit_metric\": overfit_metric, \"val2_avg_recon_error\": val2_avg_recon_error,'val1_loss':val1_loss}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0681 - val_loss: 0.0353\n",
      "Epoch 2/100\n",
      "199/199 [==============================] - 0s 945us/step - loss: 0.0287 - val_loss: 0.0232\n",
      "Epoch 3/100\n",
      "199/199 [==============================] - 0s 944us/step - loss: 0.0202 - val_loss: 0.0173\n",
      "Epoch 4/100\n",
      "199/199 [==============================] - 0s 939us/step - loss: 0.0156 - val_loss: 0.0140\n",
      "Epoch 5/100\n",
      "199/199 [==============================] - 0s 938us/step - loss: 0.0128 - val_loss: 0.0117\n",
      "Epoch 6/100\n",
      "199/199 [==============================] - 0s 943us/step - loss: 0.0107 - val_loss: 0.0098\n",
      "Epoch 7/100\n",
      "199/199 [==============================] - 0s 942us/step - loss: 0.0090 - val_loss: 0.0083\n",
      "Epoch 8/100\n",
      "199/199 [==============================] - 0s 932us/step - loss: 0.0075 - val_loss: 0.0070\n",
      "Epoch 9/100\n",
      "199/199 [==============================] - 0s 935us/step - loss: 0.0065 - val_loss: 0.0061\n",
      "Epoch 10/100\n",
      "199/199 [==============================] - 0s 933us/step - loss: 0.0057 - val_loss: 0.0054\n",
      "Epoch 11/100\n",
      "199/199 [==============================] - 0s 942us/step - loss: 0.0050 - val_loss: 0.0048\n",
      "Epoch 12/100\n",
      "199/199 [==============================] - 0s 929us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 13/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 14/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 15/100\n",
      "199/199 [==============================] - 0s 975us/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 16/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 17/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 18/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0029 - val_loss: 0.0029\n",
      "Epoch 19/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 20/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 21/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0024 - val_loss: 0.0026\n",
      "Epoch 22/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 23/100\n",
      "199/199 [==============================] - 0s 902us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 24/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 25/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 26/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 27/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 28/100\n",
      "199/199 [==============================] - 0s 989us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 29/100\n",
      "199/199 [==============================] - 0s 997us/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 30/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 31/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 32/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 33/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 34/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 35/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 36/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 37/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 9.6937e-04 - val_loss: 0.0013\n",
      "Epoch 38/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 9.2848e-04 - val_loss: 0.0012\n",
      "Epoch 39/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 8.9782e-04 - val_loss: 0.0012\n",
      "Epoch 40/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 8.5736e-04 - val_loss: 0.0012\n",
      "Epoch 41/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 8.4197e-04 - val_loss: 0.0012\n",
      "Epoch 42/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 7.9896e-04 - val_loss: 0.0011\n",
      "Epoch 43/100\n",
      "199/199 [==============================] - 0s 975us/step - loss: 7.8467e-04 - val_loss: 0.0011\n",
      "Epoch 44/100\n",
      "199/199 [==============================] - 0s 949us/step - loss: 7.5294e-04 - val_loss: 0.0010\n",
      "Epoch 45/100\n",
      "199/199 [==============================] - 0s 955us/step - loss: 7.2574e-04 - val_loss: 0.0011\n",
      "Epoch 46/100\n",
      "199/199 [==============================] - 0s 937us/step - loss: 7.1091e-04 - val_loss: 9.8733e-04\n",
      "Epoch 47/100\n",
      "199/199 [==============================] - 0s 945us/step - loss: 6.8931e-04 - val_loss: 9.7894e-04\n",
      "Epoch 48/100\n",
      "199/199 [==============================] - 0s 967us/step - loss: 6.5881e-04 - val_loss: 9.4942e-04\n",
      "Epoch 49/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 6.4111e-04 - val_loss: 9.4567e-04\n",
      "Epoch 50/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 6.2335e-04 - val_loss: 9.4044e-04\n",
      "Epoch 51/100\n",
      "199/199 [==============================] - 0s 965us/step - loss: 6.0174e-04 - val_loss: 8.9938e-04\n",
      "Epoch 52/100\n",
      "199/199 [==============================] - 0s 930us/step - loss: 5.9338e-04 - val_loss: 8.6376e-04\n",
      "Epoch 53/100\n",
      "199/199 [==============================] - 0s 938us/step - loss: 5.8352e-04 - val_loss: 8.6857e-04\n",
      "Epoch 54/100\n",
      "199/199 [==============================] - 0s 948us/step - loss: 5.6559e-04 - val_loss: 8.7503e-04\n",
      "Epoch 55/100\n",
      "199/199 [==============================] - 0s 943us/step - loss: 5.4948e-04 - val_loss: 8.2769e-04\n",
      "Epoch 56/100\n",
      "199/199 [==============================] - 0s 941us/step - loss: 5.3622e-04 - val_loss: 8.3147e-04\n",
      "Epoch 57/100\n",
      "199/199 [==============================] - 0s 976us/step - loss: 5.2585e-04 - val_loss: 8.1736e-04\n",
      "Epoch 58/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 5.1719e-04 - val_loss: 8.3037e-04\n",
      "Epoch 59/100\n",
      "199/199 [==============================] - 0s 972us/step - loss: 5.0710e-04 - val_loss: 8.1280e-04\n",
      "Epoch 60/100\n",
      "199/199 [==============================] - 0s 933us/step - loss: 4.9847e-04 - val_loss: 7.9776e-04\n",
      "Epoch 61/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 4.9333e-04 - val_loss: 7.8426e-04\n",
      "Epoch 62/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 4.7069e-04 - val_loss: 7.6330e-04\n",
      "Epoch 63/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 4.6444e-04 - val_loss: 7.8520e-04\n",
      "Epoch 64/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 4.4758e-04 - val_loss: 7.8778e-04\n",
      "Epoch 65/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 4.4250e-04 - val_loss: 7.4345e-04\n",
      "Epoch 66/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 4.4001e-04 - val_loss: 7.4719e-04\n",
      "Epoch 67/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 4.4205e-04 - val_loss: 7.4549e-04\n",
      "Epoch 68/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 4.2782e-04 - val_loss: 7.4758e-04\n",
      "Epoch 69/100\n",
      "199/199 [==============================] - 0s 936us/step - loss: 4.2014e-04 - val_loss: 7.2171e-04\n",
      "Epoch 70/100\n",
      "199/199 [==============================] - 0s 948us/step - loss: 4.1604e-04 - val_loss: 7.4042e-04\n",
      "Epoch 71/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 4.1620e-04 - val_loss: 7.6575e-04\n",
      "Epoch 72/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 4.0676e-04 - val_loss: 7.2590e-04\n",
      "Epoch 73/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 4.0383e-04 - val_loss: 7.0191e-04\n",
      "Epoch 74/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 3.9556e-04 - val_loss: 7.2100e-04\n",
      "Epoch 75/100\n",
      "199/199 [==============================] - 0s 943us/step - loss: 3.8633e-04 - val_loss: 7.0440e-04\n",
      "Epoch 76/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 3.8726e-04 - val_loss: 6.8600e-04\n",
      "Epoch 77/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 3.8280e-04 - val_loss: 7.7306e-04\n",
      "Epoch 78/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 3.8401e-04 - val_loss: 6.8991e-04\n",
      "Epoch 79/100\n",
      "199/199 [==============================] - 0s 977us/step - loss: 3.7853e-04 - val_loss: 6.8005e-04\n",
      "Epoch 80/100\n",
      "199/199 [==============================] - 0s 950us/step - loss: 3.7757e-04 - val_loss: 6.9625e-04\n",
      "Epoch 81/100\n",
      "199/199 [==============================] - 0s 934us/step - loss: 3.8406e-04 - val_loss: 6.9839e-04\n",
      "Epoch 82/100\n",
      "199/199 [==============================] - 0s 953us/step - loss: 3.8088e-04 - val_loss: 7.1777e-04\n",
      "Epoch 83/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 3.6933e-04 - val_loss: 6.5651e-04\n",
      "Epoch 84/100\n",
      "199/199 [==============================] - 0s 970us/step - loss: 3.5557e-04 - val_loss: 6.6102e-04\n",
      "Epoch 85/100\n",
      "199/199 [==============================] - 0s 985us/step - loss: 3.5064e-04 - val_loss: 6.7791e-04\n",
      "Epoch 86/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 3.5449e-04 - val_loss: 6.6084e-04\n",
      "Epoch 87/100\n",
      "199/199 [==============================] - 0s 992us/step - loss: 3.4446e-04 - val_loss: 6.7450e-04\n",
      "Epoch 88/100\n",
      "199/199 [==============================] - 0s 955us/step - loss: 3.4312e-04 - val_loss: 6.4984e-04\n",
      "Epoch 89/100\n",
      "199/199 [==============================] - 0s 980us/step - loss: 3.4904e-04 - val_loss: 6.4546e-04\n",
      "Epoch 90/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 3.4227e-04 - val_loss: 6.4494e-04\n",
      "Epoch 91/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 3.4639e-04 - val_loss: 6.5438e-04\n",
      "Epoch 92/100\n",
      "199/199 [==============================] - 0s 936us/step - loss: 3.3430e-04 - val_loss: 6.2725e-04\n",
      "Epoch 93/100\n",
      "199/199 [==============================] - 0s 930us/step - loss: 3.7220e-04 - val_loss: 6.7547e-04\n",
      "Epoch 94/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 3.5138e-04 - val_loss: 6.3631e-04\n",
      "Epoch 95/100\n",
      "199/199 [==============================] - 0s 974us/step - loss: 3.2794e-04 - val_loss: 6.2333e-04\n",
      "Epoch 96/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 3.1917e-04 - val_loss: 6.5635e-04\n",
      "Epoch 97/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 3.1876e-04 - val_loss: 6.0767e-04\n",
      "Epoch 98/100\n",
      "199/199 [==============================] - 0s 977us/step - loss: 3.1860e-04 - val_loss: 6.4145e-04\n",
      "Epoch 99/100\n",
      "199/199 [==============================] - 0s 938us/step - loss: 3.1985e-04 - val_loss: 6.0976e-04\n",
      "Epoch 100/100\n",
      "199/199 [==============================] - 0s 937us/step - loss: 3.2241e-04 - val_loss: 6.1946e-04\n",
      "This round is 23\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_11724/328462441.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  para_dfm = para_dfm.append({\"reg_param\": reg_param, \"number_units_layers\": numbers_units_layers, \"number_units_bottleneck\": numbers_units_bottleneck, \"dropout_rate\": dropout_rate, \"number_layers\": numbers_layers, \"whether_dropout\": whether_dropout, \"whether_regularizer\": whether_regularizer, \"overfit_metric\": overfit_metric, \"val2_avg_recon_error\": val2_avg_recon_error,'val1_loss':val1_loss}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 0s 1ms/step - loss: 1.5059 - val_loss: 0.3884\n",
      "Epoch 2/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.1678 - val_loss: 0.0722\n",
      "Epoch 3/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0599 - val_loss: 0.0555\n",
      "Epoch 4/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0552 - val_loss: 0.0550\n",
      "Epoch 5/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0551 - val_loss: 0.0550\n",
      "Epoch 6/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0551 - val_loss: 0.0550\n",
      "Epoch 7/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0550 - val_loss: 0.0550\n",
      "Epoch 8/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0550 - val_loss: 0.0551\n",
      "Epoch 9/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0550 - val_loss: 0.0550\n",
      "Epoch 10/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0550 - val_loss: 0.0548\n",
      "Epoch 11/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0547 - val_loss: 0.0543\n",
      "Epoch 12/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0496 - val_loss: 0.0433\n",
      "Epoch 13/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0415 - val_loss: 0.0402\n",
      "Epoch 14/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0397 - val_loss: 0.0391\n",
      "Epoch 15/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0390 - val_loss: 0.0386\n",
      "Epoch 16/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0384 - val_loss: 0.0380\n",
      "Epoch 17/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0380 - val_loss: 0.0376\n",
      "Epoch 18/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0377 - val_loss: 0.0373\n",
      "Epoch 19/100\n",
      "199/199 [==============================] - 0s 996us/step - loss: 0.0374 - val_loss: 0.0371\n",
      "Epoch 20/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0372 - val_loss: 0.0369\n",
      "Epoch 21/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0370 - val_loss: 0.0369\n",
      "Epoch 22/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0369 - val_loss: 0.0366\n",
      "Epoch 23/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0368 - val_loss: 0.0365\n",
      "Epoch 24/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0367 - val_loss: 0.0365\n",
      "Epoch 25/100\n",
      "199/199 [==============================] - 0s 968us/step - loss: 0.0366 - val_loss: 0.0364\n",
      "Epoch 26/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0366 - val_loss: 0.0364\n",
      "Epoch 27/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0365 - val_loss: 0.0363\n",
      "Epoch 28/100\n",
      "199/199 [==============================] - 1s 3ms/step - loss: 0.0364 - val_loss: 0.0362\n",
      "Epoch 29/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0364 - val_loss: 0.0362\n",
      "Epoch 30/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0364 - val_loss: 0.0362\n",
      "Epoch 31/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0363 - val_loss: 0.0362\n",
      "Epoch 32/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0363 - val_loss: 0.0361\n",
      "Epoch 33/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0363 - val_loss: 0.0361\n",
      "Epoch 34/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0362 - val_loss: 0.0361\n",
      "Epoch 35/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0362 - val_loss: 0.0360\n",
      "Epoch 36/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0362 - val_loss: 0.0360\n",
      "Epoch 37/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0362 - val_loss: 0.0361\n",
      "Epoch 38/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0362 - val_loss: 0.0362\n",
      "Epoch 39/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0361 - val_loss: 0.0360\n",
      "Epoch 40/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0361 - val_loss: 0.0361\n",
      "Epoch 41/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0362 - val_loss: 0.0359\n",
      "Epoch 42/100\n",
      "199/199 [==============================] - 0s 926us/step - loss: 0.0361 - val_loss: 0.0359\n",
      "Epoch 43/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0360 - val_loss: 0.0359\n",
      "Epoch 44/100\n",
      "199/199 [==============================] - 0s 981us/step - loss: 0.0361 - val_loss: 0.0363\n",
      "Epoch 45/100\n",
      "199/199 [==============================] - 0s 903us/step - loss: 0.0361 - val_loss: 0.0359\n",
      "Epoch 46/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0360 - val_loss: 0.0360\n",
      "Epoch 47/100\n",
      "199/199 [==============================] - 0s 928us/step - loss: 0.0361 - val_loss: 0.0358\n",
      "Epoch 48/100\n",
      "199/199 [==============================] - 0s 924us/step - loss: 0.0360 - val_loss: 0.0358\n",
      "Epoch 49/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0359 - val_loss: 0.0358\n",
      "Epoch 50/100\n",
      "199/199 [==============================] - 0s 949us/step - loss: 0.0360 - val_loss: 0.0362\n",
      "Epoch 51/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0360 - val_loss: 0.0358\n",
      "Epoch 52/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0360 - val_loss: 0.0358\n",
      "Epoch 53/100\n",
      "199/199 [==============================] - 0s 983us/step - loss: 0.0359 - val_loss: 0.0357\n",
      "Epoch 54/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0359 - val_loss: 0.0357\n",
      "Epoch 55/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0359 - val_loss: 0.0358\n",
      "Epoch 56/100\n",
      "199/199 [==============================] - 0s 991us/step - loss: 0.0360 - val_loss: 0.0358\n",
      "Epoch 57/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0359 - val_loss: 0.0360\n",
      "Epoch 58/100\n",
      "199/199 [==============================] - 0s 916us/step - loss: 0.0360 - val_loss: 0.0358\n",
      "Epoch 59/100\n",
      "199/199 [==============================] - 0s 975us/step - loss: 0.0358 - val_loss: 0.0358\n",
      "Epoch 60/100\n",
      "199/199 [==============================] - 0s 992us/step - loss: 0.0359 - val_loss: 0.0359\n",
      "Epoch 61/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0358 - val_loss: 0.0357\n",
      "Epoch 62/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0358 - val_loss: 0.0356\n",
      "Epoch 63/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0357 - val_loss: 0.0356\n",
      "Epoch 64/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0358 - val_loss: 0.0355\n",
      "Epoch 65/100\n",
      "199/199 [==============================] - 0s 959us/step - loss: 0.0357 - val_loss: 0.0355\n",
      "Epoch 66/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0357 - val_loss: 0.0358\n",
      "Epoch 67/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0356 - val_loss: 0.0356\n",
      "Epoch 68/100\n",
      "199/199 [==============================] - 0s 951us/step - loss: 0.0355 - val_loss: 0.0354\n",
      "Epoch 69/100\n",
      "199/199 [==============================] - 0s 952us/step - loss: 0.0354 - val_loss: 0.0352\n",
      "Epoch 70/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0353 - val_loss: 0.0352\n",
      "Epoch 71/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0353 - val_loss: 0.0351\n",
      "Epoch 72/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0351 - val_loss: 0.0349\n",
      "Epoch 73/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0349 - val_loss: 0.0347\n",
      "Epoch 74/100\n",
      "199/199 [==============================] - 0s 978us/step - loss: 0.0348 - val_loss: 0.0348\n",
      "Epoch 75/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0345 - val_loss: 0.0343\n",
      "Epoch 76/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0342 - val_loss: 0.0337\n",
      "Epoch 77/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0337 - val_loss: 0.0336\n",
      "Epoch 78/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0332 - val_loss: 0.0329\n",
      "Epoch 79/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0327 - val_loss: 0.0329\n",
      "Epoch 80/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0324 - val_loss: 0.0321\n",
      "Epoch 81/100\n",
      "199/199 [==============================] - 0s 970us/step - loss: 0.0320 - val_loss: 0.0318\n",
      "Epoch 82/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0318 - val_loss: 0.0314\n",
      "Epoch 83/100\n",
      "199/199 [==============================] - 0s 963us/step - loss: 0.0316 - val_loss: 0.0311\n",
      "Epoch 84/100\n",
      "199/199 [==============================] - 0s 949us/step - loss: 0.0311 - val_loss: 0.0312\n",
      "Epoch 85/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0309 - val_loss: 0.0307\n",
      "Epoch 86/100\n",
      "199/199 [==============================] - 0s 932us/step - loss: 0.0307 - val_loss: 0.0307\n",
      "Epoch 87/100\n",
      "199/199 [==============================] - 0s 989us/step - loss: 0.0306 - val_loss: 0.0302\n",
      "Epoch 88/100\n",
      "199/199 [==============================] - 0s 947us/step - loss: 0.0304 - val_loss: 0.0300\n",
      "Epoch 89/100\n",
      "199/199 [==============================] - 0s 906us/step - loss: 0.0302 - val_loss: 0.0298\n",
      "Epoch 90/100\n",
      "199/199 [==============================] - 0s 915us/step - loss: 0.0301 - val_loss: 0.0309\n",
      "Epoch 91/100\n",
      "199/199 [==============================] - 0s 910us/step - loss: 0.0298 - val_loss: 0.0297\n",
      "Epoch 92/100\n",
      "199/199 [==============================] - 0s 921us/step - loss: 0.0296 - val_loss: 0.0293\n",
      "Epoch 93/100\n",
      "199/199 [==============================] - 0s 915us/step - loss: 0.0296 - val_loss: 0.0294\n",
      "Epoch 94/100\n",
      "199/199 [==============================] - 0s 922us/step - loss: 0.0292 - val_loss: 0.0291\n",
      "Epoch 95/100\n",
      "199/199 [==============================] - 0s 928us/step - loss: 0.0291 - val_loss: 0.0289\n",
      "Epoch 96/100\n",
      "199/199 [==============================] - 0s 979us/step - loss: 0.0290 - val_loss: 0.0286\n",
      "Epoch 97/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0288 - val_loss: 0.0286\n",
      "Epoch 98/100\n",
      "199/199 [==============================] - 0s 912us/step - loss: 0.0288 - val_loss: 0.0285\n",
      "Epoch 99/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0284 - val_loss: 0.0283\n",
      "Epoch 100/100\n",
      "199/199 [==============================] - 0s 966us/step - loss: 0.0284 - val_loss: 0.0281\n",
      "This round is 24\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_11724/328462441.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  para_dfm = para_dfm.append({\"reg_param\": reg_param, \"number_units_layers\": numbers_units_layers, \"number_units_bottleneck\": numbers_units_bottleneck, \"dropout_rate\": dropout_rate, \"number_layers\": numbers_layers, \"whether_dropout\": whether_dropout, \"whether_regularizer\": whether_regularizer, \"overfit_metric\": overfit_metric, \"val2_avg_recon_error\": val2_avg_recon_error,'val1_loss':val1_loss}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 1s 1ms/step - loss: 0.1163 - val_loss: 0.0561\n",
      "Epoch 2/100\n",
      "199/199 [==============================] - 0s 947us/step - loss: 0.0554 - val_loss: 0.0552\n",
      "Epoch 3/100\n",
      "199/199 [==============================] - 0s 901us/step - loss: 0.0530 - val_loss: 0.0472\n",
      "Epoch 4/100\n",
      "199/199 [==============================] - 0s 959us/step - loss: 0.0413 - val_loss: 0.0377\n",
      "Epoch 5/100\n",
      "199/199 [==============================] - 0s 900us/step - loss: 0.0368 - val_loss: 0.0355\n",
      "Epoch 6/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0341 - val_loss: 0.0323\n",
      "Epoch 7/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0309 - val_loss: 0.0289\n",
      "Epoch 8/100\n",
      "199/199 [==============================] - 0s 931us/step - loss: 0.0277 - val_loss: 0.0262\n",
      "Epoch 9/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0259 - val_loss: 0.0247\n",
      "Epoch 10/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0246 - val_loss: 0.0236\n",
      "Epoch 11/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0236 - val_loss: 0.0229\n",
      "Epoch 12/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0230 - val_loss: 0.0224\n",
      "Epoch 13/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0225 - val_loss: 0.0219\n",
      "Epoch 14/100\n",
      "199/199 [==============================] - 0s 939us/step - loss: 0.0220 - val_loss: 0.0215\n",
      "Epoch 15/100\n",
      "199/199 [==============================] - 0s 906us/step - loss: 0.0216 - val_loss: 0.0210\n",
      "Epoch 16/100\n",
      "199/199 [==============================] - 0s 919us/step - loss: 0.0211 - val_loss: 0.0205\n",
      "Epoch 17/100\n",
      "199/199 [==============================] - 0s 900us/step - loss: 0.0206 - val_loss: 0.0200\n",
      "Epoch 18/100\n",
      "199/199 [==============================] - 0s 1000us/step - loss: 0.0201 - val_loss: 0.0195\n",
      "Epoch 19/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0195 - val_loss: 0.0187\n",
      "Epoch 20/100\n",
      "199/199 [==============================] - 0s 944us/step - loss: 0.0186 - val_loss: 0.0179\n",
      "Epoch 21/100\n",
      "199/199 [==============================] - 0s 951us/step - loss: 0.0177 - val_loss: 0.0169\n",
      "Epoch 22/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0167 - val_loss: 0.0161\n",
      "Epoch 23/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0160 - val_loss: 0.0156\n",
      "Epoch 24/100\n",
      "199/199 [==============================] - 0s 933us/step - loss: 0.0155 - val_loss: 0.0152\n",
      "Epoch 25/100\n",
      "199/199 [==============================] - 0s 903us/step - loss: 0.0151 - val_loss: 0.0148\n",
      "Epoch 26/100\n",
      "199/199 [==============================] - 0s 880us/step - loss: 0.0148 - val_loss: 0.0145\n",
      "Epoch 27/100\n",
      "199/199 [==============================] - 0s 892us/step - loss: 0.0144 - val_loss: 0.0142\n",
      "Epoch 28/100\n",
      "199/199 [==============================] - 0s 859us/step - loss: 0.0141 - val_loss: 0.0138\n",
      "Epoch 29/100\n",
      "199/199 [==============================] - 0s 916us/step - loss: 0.0138 - val_loss: 0.0135\n",
      "Epoch 30/100\n",
      "199/199 [==============================] - 0s 879us/step - loss: 0.0133 - val_loss: 0.0130\n",
      "Epoch 31/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0129 - val_loss: 0.0126\n",
      "Epoch 32/100\n",
      "199/199 [==============================] - 0s 968us/step - loss: 0.0126 - val_loss: 0.0123\n",
      "Epoch 33/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.0120\n",
      "Epoch 34/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.0117\n",
      "Epoch 35/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0117 - val_loss: 0.0115\n",
      "Epoch 36/100\n",
      "199/199 [==============================] - 0s 972us/step - loss: 0.0114 - val_loss: 0.0112\n",
      "Epoch 37/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0112 - val_loss: 0.0110\n",
      "Epoch 38/100\n",
      "199/199 [==============================] - 0s 928us/step - loss: 0.0109 - val_loss: 0.0107\n",
      "Epoch 39/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0107 - val_loss: 0.0105\n",
      "Epoch 40/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0105 - val_loss: 0.0104\n",
      "Epoch 41/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0104 - val_loss: 0.0102\n",
      "Epoch 42/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0102 - val_loss: 0.0100\n",
      "Epoch 43/100\n",
      "199/199 [==============================] - 0s 974us/step - loss: 0.0099 - val_loss: 0.0098\n",
      "Epoch 44/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.0095\n",
      "Epoch 45/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 46/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0091\n",
      "Epoch 47/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0090\n",
      "Epoch 48/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0089\n",
      "Epoch 49/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0087\n",
      "Epoch 50/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0087\n",
      "Epoch 51/100\n",
      "199/199 [==============================] - 0s 953us/step - loss: 0.0086 - val_loss: 0.0085\n",
      "Epoch 52/100\n",
      "199/199 [==============================] - 0s 939us/step - loss: 0.0085 - val_loss: 0.0084\n",
      "Epoch 53/100\n",
      "199/199 [==============================] - 0s 930us/step - loss: 0.0084 - val_loss: 0.0084\n",
      "Epoch 54/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0083\n",
      "Epoch 55/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0082\n",
      "Epoch 56/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0082\n",
      "Epoch 57/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.0081\n",
      "Epoch 58/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.0080\n",
      "Epoch 59/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0080 - val_loss: 0.0080\n",
      "Epoch 60/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0079 - val_loss: 0.0080\n",
      "Epoch 61/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0079 - val_loss: 0.0080\n",
      "Epoch 62/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0079 - val_loss: 0.0079\n",
      "Epoch 63/100\n",
      "199/199 [==============================] - 0s 970us/step - loss: 0.0078 - val_loss: 0.0078\n",
      "Epoch 64/100\n",
      "199/199 [==============================] - 0s 969us/step - loss: 0.0077 - val_loss: 0.0078\n",
      "Epoch 65/100\n",
      "199/199 [==============================] - 0s 917us/step - loss: 0.0077 - val_loss: 0.0077\n",
      "Epoch 66/100\n",
      "199/199 [==============================] - 0s 916us/step - loss: 0.0076 - val_loss: 0.0077\n",
      "Epoch 67/100\n",
      "199/199 [==============================] - 0s 908us/step - loss: 0.0076 - val_loss: 0.0077\n",
      "Epoch 68/100\n",
      "199/199 [==============================] - 0s 905us/step - loss: 0.0076 - val_loss: 0.0076\n",
      "Epoch 69/100\n",
      "199/199 [==============================] - 0s 958us/step - loss: 0.0075 - val_loss: 0.0076\n",
      "Epoch 70/100\n",
      "199/199 [==============================] - 0s 888us/step - loss: 0.0075 - val_loss: 0.0076\n",
      "Epoch 71/100\n",
      "199/199 [==============================] - 0s 926us/step - loss: 0.0074 - val_loss: 0.0075\n",
      "Epoch 72/100\n",
      "199/199 [==============================] - 0s 891us/step - loss: 0.0073 - val_loss: 0.0074\n",
      "Epoch 73/100\n",
      "199/199 [==============================] - 0s 874us/step - loss: 0.0073 - val_loss: 0.0074\n",
      "Epoch 74/100\n",
      "199/199 [==============================] - 0s 900us/step - loss: 0.0073 - val_loss: 0.0074\n",
      "Epoch 75/100\n",
      "199/199 [==============================] - 0s 983us/step - loss: 0.0072 - val_loss: 0.0074\n",
      "Epoch 76/100\n",
      "199/199 [==============================] - 0s 919us/step - loss: 0.0072 - val_loss: 0.0073\n",
      "Epoch 77/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0071 - val_loss: 0.0072\n",
      "Epoch 78/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0071 - val_loss: 0.0072\n",
      "Epoch 79/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0071 - val_loss: 0.0072\n",
      "Epoch 80/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0070 - val_loss: 0.0072\n",
      "Epoch 81/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0070 - val_loss: 0.0071\n",
      "Epoch 82/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0070 - val_loss: 0.0071\n",
      "Epoch 83/100\n",
      "199/199 [==============================] - 0s 989us/step - loss: 0.0069 - val_loss: 0.0071\n",
      "Epoch 84/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0069 - val_loss: 0.0070\n",
      "Epoch 85/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0070\n",
      "Epoch 86/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 0.0070\n",
      "Epoch 87/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0067 - val_loss: 0.0069\n",
      "Epoch 88/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0067 - val_loss: 0.0069\n",
      "Epoch 89/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0067 - val_loss: 0.0069\n",
      "Epoch 90/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0066 - val_loss: 0.0068\n",
      "Epoch 91/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0066 - val_loss: 0.0068\n",
      "Epoch 92/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0066 - val_loss: 0.0068\n",
      "Epoch 93/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0067\n",
      "Epoch 94/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0067\n",
      "Epoch 95/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0066\n",
      "Epoch 96/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 0.0066\n",
      "Epoch 97/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 0.0065\n",
      "Epoch 98/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0062 - val_loss: 0.0064\n",
      "Epoch 99/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0064\n",
      "Epoch 100/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0063\n",
      "This round is 25\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_11724/328462441.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  para_dfm = para_dfm.append({\"reg_param\": reg_param, \"number_units_layers\": numbers_units_layers, \"number_units_bottleneck\": numbers_units_bottleneck, \"dropout_rate\": dropout_rate, \"number_layers\": numbers_layers, \"whether_dropout\": whether_dropout, \"whether_regularizer\": whether_regularizer, \"overfit_metric\": overfit_metric, \"val2_avg_recon_error\": val2_avg_recon_error,'val1_loss':val1_loss}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 1s 2ms/step - loss: 0.0893 - val_loss: 0.0452\n",
      "Epoch 2/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0376 - val_loss: 0.0323\n",
      "Epoch 3/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0284 - val_loss: 0.0251\n",
      "Epoch 4/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0221 - val_loss: 0.0189\n",
      "Epoch 5/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0171 - val_loss: 0.0153\n",
      "Epoch 6/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0144 - val_loss: 0.0131\n",
      "Epoch 7/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0127 - val_loss: 0.0121\n",
      "Epoch 8/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0118 - val_loss: 0.0114\n",
      "Epoch 9/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0109 - val_loss: 0.0106\n",
      "Epoch 10/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0100 - val_loss: 0.0096\n",
      "Epoch 11/100\n",
      "199/199 [==============================] - 0s 954us/step - loss: 0.0090 - val_loss: 0.0088\n",
      "Epoch 12/100\n",
      "199/199 [==============================] - 0s 947us/step - loss: 0.0082 - val_loss: 0.0080\n",
      "Epoch 13/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0073 - val_loss: 0.0073\n",
      "Epoch 14/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 0.0069\n",
      "Epoch 15/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0065\n",
      "Epoch 16/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0061\n",
      "Epoch 17/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0057 - val_loss: 0.0059\n",
      "Epoch 18/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0054 - val_loss: 0.0056\n",
      "Epoch 19/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0052 - val_loss: 0.0053\n",
      "Epoch 20/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0050 - val_loss: 0.0051\n",
      "Epoch 21/100\n",
      "199/199 [==============================] - 0s 940us/step - loss: 0.0047 - val_loss: 0.0049\n",
      "Epoch 22/100\n",
      "199/199 [==============================] - 0s 964us/step - loss: 0.0045 - val_loss: 0.0047\n",
      "Epoch 23/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 24/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0044\n",
      "Epoch 25/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0040 - val_loss: 0.0042\n",
      "Epoch 26/100\n",
      "199/199 [==============================] - 0s 949us/step - loss: 0.0039 - val_loss: 0.0041\n",
      "Epoch 27/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0038 - val_loss: 0.0040\n",
      "Epoch 28/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0036 - val_loss: 0.0038\n",
      "Epoch 29/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0033 - val_loss: 0.0036\n",
      "Epoch 30/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0032 - val_loss: 0.0034\n",
      "Epoch 31/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0030 - val_loss: 0.0033\n",
      "Epoch 32/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 33/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0027 - val_loss: 0.0030\n",
      "Epoch 34/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0026 - val_loss: 0.0030\n",
      "Epoch 35/100\n",
      "199/199 [==============================] - 0s 936us/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 36/100\n",
      "199/199 [==============================] - 0s 959us/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 37/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 38/100\n",
      "199/199 [==============================] - 0s 929us/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 39/100\n",
      "199/199 [==============================] - 0s 958us/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 40/100\n",
      "199/199 [==============================] - 0s 893us/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 41/100\n",
      "199/199 [==============================] - 0s 909us/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 42/100\n",
      "199/199 [==============================] - 0s 867us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 43/100\n",
      "199/199 [==============================] - 0s 879us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 44/100\n",
      "199/199 [==============================] - 0s 901us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 45/100\n",
      "199/199 [==============================] - 0s 873us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 46/100\n",
      "199/199 [==============================] - 0s 880us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 47/100\n",
      "199/199 [==============================] - 0s 874us/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 48/100\n",
      "199/199 [==============================] - 0s 927us/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 49/100\n",
      "199/199 [==============================] - 0s 932us/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 50/100\n",
      "199/199 [==============================] - 0s 983us/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 51/100\n",
      "199/199 [==============================] - 0s 935us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 52/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 53/100\n",
      "199/199 [==============================] - 0s 972us/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 54/100\n",
      "199/199 [==============================] - 0s 933us/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 55/100\n",
      "199/199 [==============================] - 0s 959us/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 56/100\n",
      "199/199 [==============================] - 0s 929us/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 57/100\n",
      "199/199 [==============================] - 0s 922us/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 58/100\n",
      "199/199 [==============================] - 0s 990us/step - loss: 0.0016 - val_loss: 0.0020\n",
      "Epoch 59/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 60/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 61/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 62/100\n",
      "199/199 [==============================] - 0s 957us/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 63/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 64/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 65/100\n",
      "199/199 [==============================] - 0s 988us/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 66/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 67/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 68/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 69/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 70/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 71/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 72/100\n",
      "199/199 [==============================] - 0s 898us/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 73/100\n",
      "199/199 [==============================] - 0s 979us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 74/100\n",
      "199/199 [==============================] - 0s 884us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 75/100\n",
      "199/199 [==============================] - 0s 877us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 76/100\n",
      "199/199 [==============================] - 0s 870us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 77/100\n",
      "199/199 [==============================] - 0s 872us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 78/100\n",
      "199/199 [==============================] - 0s 876us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 79/100\n",
      "199/199 [==============================] - 0s 936us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 80/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 81/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 82/100\n",
      "199/199 [==============================] - 0s 938us/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 83/100\n",
      "199/199 [==============================] - 0s 962us/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 84/100\n",
      "199/199 [==============================] - 0s 936us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 85/100\n",
      "199/199 [==============================] - 0s 965us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 86/100\n",
      "199/199 [==============================] - 0s 958us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 87/100\n",
      "199/199 [==============================] - 0s 915us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 88/100\n",
      "199/199 [==============================] - 0s 925us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 89/100\n",
      "199/199 [==============================] - 0s 922us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 90/100\n",
      "199/199 [==============================] - 0s 930us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 91/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 92/100\n",
      "199/199 [==============================] - 0s 952us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 93/100\n",
      "199/199 [==============================] - 0s 928us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 94/100\n",
      "199/199 [==============================] - 0s 912us/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 95/100\n",
      "199/199 [==============================] - 0s 928us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 96/100\n",
      "199/199 [==============================] - 0s 904us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 97/100\n",
      "199/199 [==============================] - 0s 934us/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 98/100\n",
      "199/199 [==============================] - 0s 977us/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 99/100\n",
      "199/199 [==============================] - 0s 910us/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 100/100\n",
      "199/199 [==============================] - 0s 917us/step - loss: 0.0011 - val_loss: 0.0016\n",
      "This round is 26\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_11724/328462441.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  para_dfm = para_dfm.append({\"reg_param\": reg_param, \"number_units_layers\": numbers_units_layers, \"number_units_bottleneck\": numbers_units_bottleneck, \"dropout_rate\": dropout_rate, \"number_layers\": numbers_layers, \"whether_dropout\": whether_dropout, \"whether_regularizer\": whether_regularizer, \"overfit_metric\": overfit_metric, \"val2_avg_recon_error\": val2_avg_recon_error,'val1_loss':val1_loss}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0681 - val_loss: 0.0353\n",
      "Epoch 2/100\n",
      "199/199 [==============================] - 0s 913us/step - loss: 0.0287 - val_loss: 0.0232\n",
      "Epoch 3/100\n",
      "199/199 [==============================] - 0s 913us/step - loss: 0.0202 - val_loss: 0.0173\n",
      "Epoch 4/100\n",
      "199/199 [==============================] - 0s 925us/step - loss: 0.0156 - val_loss: 0.0140\n",
      "Epoch 5/100\n",
      "199/199 [==============================] - 0s 912us/step - loss: 0.0128 - val_loss: 0.0117\n",
      "Epoch 6/100\n",
      "199/199 [==============================] - 0s 908us/step - loss: 0.0107 - val_loss: 0.0098\n",
      "Epoch 7/100\n",
      "199/199 [==============================] - 0s 910us/step - loss: 0.0090 - val_loss: 0.0083\n",
      "Epoch 8/100\n",
      "199/199 [==============================] - 0s 905us/step - loss: 0.0075 - val_loss: 0.0070\n",
      "Epoch 9/100\n",
      "199/199 [==============================] - 0s 911us/step - loss: 0.0065 - val_loss: 0.0061\n",
      "Epoch 10/100\n",
      "199/199 [==============================] - 0s 909us/step - loss: 0.0057 - val_loss: 0.0054\n",
      "Epoch 11/100\n",
      "199/199 [==============================] - 0s 945us/step - loss: 0.0050 - val_loss: 0.0048\n",
      "Epoch 12/100\n",
      "199/199 [==============================] - 0s 919us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 13/100\n",
      "199/199 [==============================] - 0s 914us/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 14/100\n",
      "199/199 [==============================] - 0s 930us/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 15/100\n",
      "199/199 [==============================] - 0s 904us/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 16/100\n",
      "199/199 [==============================] - 0s 920us/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 17/100\n",
      "199/199 [==============================] - 0s 945us/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 18/100\n",
      "199/199 [==============================] - 0s 921us/step - loss: 0.0029 - val_loss: 0.0029\n",
      "Epoch 19/100\n",
      "199/199 [==============================] - 0s 893us/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 20/100\n",
      "199/199 [==============================] - 0s 898us/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 21/100\n",
      "199/199 [==============================] - 0s 907us/step - loss: 0.0024 - val_loss: 0.0026\n",
      "Epoch 22/100\n",
      "199/199 [==============================] - 0s 913us/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 23/100\n",
      "199/199 [==============================] - 0s 908us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 24/100\n",
      "199/199 [==============================] - 0s 908us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 25/100\n",
      "199/199 [==============================] - 0s 899us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 26/100\n",
      "199/199 [==============================] - 0s 910us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 27/100\n",
      "199/199 [==============================] - 0s 896us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 28/100\n",
      "199/199 [==============================] - 0s 906us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 29/100\n",
      "199/199 [==============================] - 0s 914us/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 30/100\n",
      "199/199 [==============================] - 0s 907us/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 31/100\n",
      "199/199 [==============================] - 0s 911us/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 32/100\n",
      "199/199 [==============================] - 0s 919us/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 33/100\n",
      "199/199 [==============================] - 0s 906us/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 34/100\n",
      "199/199 [==============================] - 0s 910us/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 35/100\n",
      "199/199 [==============================] - 0s 903us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 36/100\n",
      "199/199 [==============================] - 0s 933us/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 37/100\n",
      "199/199 [==============================] - 0s 904us/step - loss: 9.6937e-04 - val_loss: 0.0013\n",
      "Epoch 38/100\n",
      "199/199 [==============================] - 0s 906us/step - loss: 9.2848e-04 - val_loss: 0.0012\n",
      "Epoch 39/100\n",
      "199/199 [==============================] - 0s 910us/step - loss: 8.9782e-04 - val_loss: 0.0012\n",
      "Epoch 40/100\n",
      "199/199 [==============================] - 0s 902us/step - loss: 8.5736e-04 - val_loss: 0.0012\n",
      "Epoch 41/100\n",
      "199/199 [==============================] - 0s 908us/step - loss: 8.4197e-04 - val_loss: 0.0012\n",
      "Epoch 42/100\n",
      "199/199 [==============================] - 0s 907us/step - loss: 7.9896e-04 - val_loss: 0.0011\n",
      "Epoch 43/100\n",
      "199/199 [==============================] - 0s 942us/step - loss: 7.8467e-04 - val_loss: 0.0011\n",
      "Epoch 44/100\n",
      "199/199 [==============================] - 0s 929us/step - loss: 7.5294e-04 - val_loss: 0.0010\n",
      "Epoch 45/100\n",
      "199/199 [==============================] - 0s 939us/step - loss: 7.2574e-04 - val_loss: 0.0011\n",
      "Epoch 46/100\n",
      "199/199 [==============================] - 0s 917us/step - loss: 7.1091e-04 - val_loss: 9.8733e-04\n",
      "Epoch 47/100\n",
      "199/199 [==============================] - 0s 962us/step - loss: 6.8931e-04 - val_loss: 9.7894e-04\n",
      "Epoch 48/100\n",
      "199/199 [==============================] - 0s 904us/step - loss: 6.5881e-04 - val_loss: 9.4942e-04\n",
      "Epoch 49/100\n",
      "199/199 [==============================] - 0s 908us/step - loss: 6.4111e-04 - val_loss: 9.4567e-04\n",
      "Epoch 50/100\n",
      "199/199 [==============================] - 0s 949us/step - loss: 6.2335e-04 - val_loss: 9.4044e-04\n",
      "Epoch 51/100\n",
      "199/199 [==============================] - 0s 969us/step - loss: 6.0174e-04 - val_loss: 8.9938e-04\n",
      "Epoch 52/100\n",
      "199/199 [==============================] - 0s 901us/step - loss: 5.9338e-04 - val_loss: 8.6376e-04\n",
      "Epoch 53/100\n",
      "199/199 [==============================] - 0s 902us/step - loss: 5.8352e-04 - val_loss: 8.6857e-04\n",
      "Epoch 54/100\n",
      "199/199 [==============================] - 0s 907us/step - loss: 5.6559e-04 - val_loss: 8.7503e-04\n",
      "Epoch 55/100\n",
      "199/199 [==============================] - 0s 904us/step - loss: 5.4948e-04 - val_loss: 8.2769e-04\n",
      "Epoch 56/100\n",
      "199/199 [==============================] - 0s 895us/step - loss: 5.3622e-04 - val_loss: 8.3147e-04\n",
      "Epoch 57/100\n",
      "199/199 [==============================] - 0s 901us/step - loss: 5.2585e-04 - val_loss: 8.1736e-04\n",
      "Epoch 58/100\n",
      "199/199 [==============================] - 0s 902us/step - loss: 5.1719e-04 - val_loss: 8.3037e-04\n",
      "Epoch 59/100\n",
      "199/199 [==============================] - 0s 931us/step - loss: 5.0710e-04 - val_loss: 8.1280e-04\n",
      "Epoch 60/100\n",
      "199/199 [==============================] - 0s 907us/step - loss: 4.9847e-04 - val_loss: 7.9776e-04\n",
      "Epoch 61/100\n",
      "199/199 [==============================] - 0s 904us/step - loss: 4.9333e-04 - val_loss: 7.8426e-04\n",
      "Epoch 62/100\n",
      "199/199 [==============================] - 0s 900us/step - loss: 4.7069e-04 - val_loss: 7.6330e-04\n",
      "Epoch 63/100\n",
      "199/199 [==============================] - 0s 902us/step - loss: 4.6444e-04 - val_loss: 7.8520e-04\n",
      "Epoch 64/100\n",
      "199/199 [==============================] - 0s 900us/step - loss: 4.4758e-04 - val_loss: 7.8778e-04\n",
      "Epoch 65/100\n",
      "199/199 [==============================] - 0s 914us/step - loss: 4.4250e-04 - val_loss: 7.4345e-04\n",
      "Epoch 66/100\n",
      "199/199 [==============================] - 0s 897us/step - loss: 4.4001e-04 - val_loss: 7.4719e-04\n",
      "Epoch 67/100\n",
      "199/199 [==============================] - 0s 912us/step - loss: 4.4205e-04 - val_loss: 7.4549e-04\n",
      "Epoch 68/100\n",
      "199/199 [==============================] - 0s 905us/step - loss: 4.2782e-04 - val_loss: 7.4758e-04\n",
      "Epoch 69/100\n",
      "199/199 [==============================] - 0s 905us/step - loss: 4.2014e-04 - val_loss: 7.2171e-04\n",
      "Epoch 70/100\n",
      "199/199 [==============================] - 0s 894us/step - loss: 4.1604e-04 - val_loss: 7.4042e-04\n",
      "Epoch 71/100\n",
      "199/199 [==============================] - 0s 913us/step - loss: 4.1620e-04 - val_loss: 7.6575e-04\n",
      "Epoch 72/100\n",
      "199/199 [==============================] - 0s 945us/step - loss: 4.0676e-04 - val_loss: 7.2590e-04\n",
      "Epoch 73/100\n",
      "199/199 [==============================] - 0s 913us/step - loss: 4.0383e-04 - val_loss: 7.0191e-04\n",
      "Epoch 74/100\n",
      "199/199 [==============================] - 0s 903us/step - loss: 3.9556e-04 - val_loss: 7.2100e-04\n",
      "Epoch 75/100\n",
      "199/199 [==============================] - 0s 898us/step - loss: 3.8633e-04 - val_loss: 7.0440e-04\n",
      "Epoch 76/100\n",
      "199/199 [==============================] - 0s 913us/step - loss: 3.8726e-04 - val_loss: 6.8600e-04\n",
      "Epoch 77/100\n",
      "199/199 [==============================] - 0s 902us/step - loss: 3.8280e-04 - val_loss: 7.7306e-04\n",
      "Epoch 78/100\n",
      "199/199 [==============================] - 0s 911us/step - loss: 3.8401e-04 - val_loss: 6.8991e-04\n",
      "Epoch 79/100\n",
      "199/199 [==============================] - 0s 893us/step - loss: 3.7853e-04 - val_loss: 6.8005e-04\n",
      "Epoch 80/100\n",
      "199/199 [==============================] - 0s 895us/step - loss: 3.7757e-04 - val_loss: 6.9625e-04\n",
      "Epoch 81/100\n",
      "199/199 [==============================] - 0s 895us/step - loss: 3.8406e-04 - val_loss: 6.9839e-04\n",
      "Epoch 82/100\n",
      "199/199 [==============================] - 0s 907us/step - loss: 3.8088e-04 - val_loss: 7.1777e-04\n",
      "Epoch 83/100\n",
      "199/199 [==============================] - 0s 903us/step - loss: 3.6933e-04 - val_loss: 6.5651e-04\n",
      "Epoch 84/100\n",
      "199/199 [==============================] - 0s 910us/step - loss: 3.5557e-04 - val_loss: 6.6102e-04\n",
      "Epoch 85/100\n",
      "199/199 [==============================] - 0s 907us/step - loss: 3.5064e-04 - val_loss: 6.7791e-04\n",
      "Epoch 86/100\n",
      "199/199 [==============================] - 0s 911us/step - loss: 3.5449e-04 - val_loss: 6.6084e-04\n",
      "Epoch 87/100\n",
      "199/199 [==============================] - 0s 922us/step - loss: 3.4446e-04 - val_loss: 6.7450e-04\n",
      "Epoch 88/100\n",
      "199/199 [==============================] - 0s 902us/step - loss: 3.4312e-04 - val_loss: 6.4984e-04\n",
      "Epoch 89/100\n",
      "199/199 [==============================] - 0s 896us/step - loss: 3.4904e-04 - val_loss: 6.4546e-04\n",
      "Epoch 90/100\n",
      "199/199 [==============================] - 0s 906us/step - loss: 3.4227e-04 - val_loss: 6.4494e-04\n",
      "Epoch 91/100\n",
      "199/199 [==============================] - 0s 908us/step - loss: 3.4639e-04 - val_loss: 6.5438e-04\n",
      "Epoch 92/100\n",
      "199/199 [==============================] - 0s 907us/step - loss: 3.3430e-04 - val_loss: 6.2725e-04\n",
      "Epoch 93/100\n",
      "199/199 [==============================] - 0s 895us/step - loss: 3.7220e-04 - val_loss: 6.7547e-04\n",
      "Epoch 94/100\n",
      "199/199 [==============================] - 0s 903us/step - loss: 3.5138e-04 - val_loss: 6.3631e-04\n",
      "Epoch 95/100\n",
      "199/199 [==============================] - 0s 903us/step - loss: 3.2794e-04 - val_loss: 6.2333e-04\n",
      "Epoch 96/100\n",
      "199/199 [==============================] - 0s 896us/step - loss: 3.1917e-04 - val_loss: 6.5635e-04\n",
      "Epoch 97/100\n",
      "199/199 [==============================] - 0s 907us/step - loss: 3.1876e-04 - val_loss: 6.0767e-04\n",
      "Epoch 98/100\n",
      "199/199 [==============================] - 0s 900us/step - loss: 3.1860e-04 - val_loss: 6.4145e-04\n",
      "Epoch 99/100\n",
      "199/199 [==============================] - 0s 911us/step - loss: 3.1985e-04 - val_loss: 6.0976e-04\n",
      "Epoch 100/100\n",
      "199/199 [==============================] - 0s 897us/step - loss: 3.2241e-04 - val_loss: 6.1946e-04\n",
      "This round is 27\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_11724/328462441.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  para_dfm = para_dfm.append({\"reg_param\": reg_param, \"number_units_layers\": numbers_units_layers, \"number_units_bottleneck\": numbers_units_bottleneck, \"dropout_rate\": dropout_rate, \"number_layers\": numbers_layers, \"whether_dropout\": whether_dropout, \"whether_regularizer\": whether_regularizer, \"overfit_metric\": overfit_metric, \"val2_avg_recon_error\": val2_avg_recon_error,'val1_loss':val1_loss}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 0s 1ms/step - loss: 2.0686 - val_loss: 0.6416\n",
      "Epoch 2/100\n",
      "199/199 [==============================] - 0s 889us/step - loss: 0.2810 - val_loss: 0.1034\n",
      "Epoch 3/100\n",
      "199/199 [==============================] - 0s 878us/step - loss: 0.0708 - val_loss: 0.0572\n",
      "Epoch 4/100\n",
      "199/199 [==============================] - 0s 881us/step - loss: 0.0557 - val_loss: 0.0551\n",
      "Epoch 5/100\n",
      "199/199 [==============================] - 0s 872us/step - loss: 0.0551 - val_loss: 0.0550\n",
      "Epoch 6/100\n",
      "199/199 [==============================] - 0s 878us/step - loss: 0.0551 - val_loss: 0.0550\n",
      "Epoch 7/100\n",
      "199/199 [==============================] - 0s 888us/step - loss: 0.0550 - val_loss: 0.0550\n",
      "Epoch 8/100\n",
      "199/199 [==============================] - 0s 881us/step - loss: 0.0551 - val_loss: 0.0551\n",
      "Epoch 9/100\n",
      "199/199 [==============================] - 0s 873us/step - loss: 0.0550 - val_loss: 0.0550\n",
      "Epoch 10/100\n",
      "199/199 [==============================] - 0s 886us/step - loss: 0.0550 - val_loss: 0.0549\n",
      "Epoch 11/100\n",
      "199/199 [==============================] - 0s 886us/step - loss: 0.0550 - val_loss: 0.0548\n",
      "Epoch 12/100\n",
      "199/199 [==============================] - 0s 890us/step - loss: 0.0547 - val_loss: 0.0543\n",
      "Epoch 13/100\n",
      "199/199 [==============================] - 0s 894us/step - loss: 0.0520 - val_loss: 0.0471\n",
      "Epoch 14/100\n",
      "199/199 [==============================] - 0s 881us/step - loss: 0.0436 - val_loss: 0.0413\n",
      "Epoch 15/100\n",
      "199/199 [==============================] - 0s 886us/step - loss: 0.0407 - val_loss: 0.0398\n",
      "Epoch 16/100\n",
      "199/199 [==============================] - 0s 887us/step - loss: 0.0397 - val_loss: 0.0390\n",
      "Epoch 17/100\n",
      "199/199 [==============================] - 0s 882us/step - loss: 0.0390 - val_loss: 0.0384\n",
      "Epoch 18/100\n",
      "199/199 [==============================] - 0s 883us/step - loss: 0.0385 - val_loss: 0.0380\n",
      "Epoch 19/100\n",
      "199/199 [==============================] - 0s 882us/step - loss: 0.0380 - val_loss: 0.0376\n",
      "Epoch 20/100\n",
      "199/199 [==============================] - 0s 873us/step - loss: 0.0377 - val_loss: 0.0375\n",
      "Epoch 21/100\n",
      "199/199 [==============================] - 0s 897us/step - loss: 0.0375 - val_loss: 0.0372\n",
      "Epoch 22/100\n",
      "199/199 [==============================] - 0s 867us/step - loss: 0.0373 - val_loss: 0.0369\n",
      "Epoch 23/100\n",
      "199/199 [==============================] - 0s 874us/step - loss: 0.0372 - val_loss: 0.0368\n",
      "Epoch 24/100\n",
      "199/199 [==============================] - 0s 855us/step - loss: 0.0370 - val_loss: 0.0367\n",
      "Epoch 25/100\n",
      "199/199 [==============================] - 0s 885us/step - loss: 0.0369 - val_loss: 0.0366\n",
      "Epoch 26/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0368 - val_loss: 0.0365\n",
      "Epoch 27/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0367 - val_loss: 0.0364\n",
      "Epoch 28/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0367 - val_loss: 0.0364\n",
      "Epoch 29/100\n",
      "199/199 [==============================] - 0s 989us/step - loss: 0.0366 - val_loss: 0.0363\n",
      "Epoch 30/100\n",
      "199/199 [==============================] - 0s 949us/step - loss: 0.0366 - val_loss: 0.0362\n",
      "Epoch 31/100\n",
      "199/199 [==============================] - 0s 949us/step - loss: 0.0365 - val_loss: 0.0362\n",
      "Epoch 32/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0365 - val_loss: 0.0365\n",
      "Epoch 33/100\n",
      "199/199 [==============================] - 0s 978us/step - loss: 0.0365 - val_loss: 0.0362\n",
      "Epoch 34/100\n",
      "199/199 [==============================] - 0s 878us/step - loss: 0.0364 - val_loss: 0.0369\n",
      "Epoch 35/100\n",
      "199/199 [==============================] - 0s 927us/step - loss: 0.0364 - val_loss: 0.0362\n",
      "Epoch 36/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0364 - val_loss: 0.0364\n",
      "Epoch 37/100\n",
      "199/199 [==============================] - 0s 941us/step - loss: 0.0363 - val_loss: 0.0361\n",
      "Epoch 38/100\n",
      "199/199 [==============================] - 0s 922us/step - loss: 0.0363 - val_loss: 0.0360\n",
      "Epoch 39/100\n",
      "199/199 [==============================] - 0s 915us/step - loss: 0.0363 - val_loss: 0.0360\n",
      "Epoch 40/100\n",
      "199/199 [==============================] - 0s 885us/step - loss: 0.0362 - val_loss: 0.0360\n",
      "Epoch 41/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0362 - val_loss: 0.0360\n",
      "Epoch 42/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0362 - val_loss: 0.0362\n",
      "Epoch 43/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0362 - val_loss: 0.0360\n",
      "Epoch 44/100\n",
      "199/199 [==============================] - 0s 966us/step - loss: 0.0362 - val_loss: 0.0360\n",
      "Epoch 45/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0362 - val_loss: 0.0359\n",
      "Epoch 46/100\n",
      "199/199 [==============================] - 0s 948us/step - loss: 0.0362 - val_loss: 0.0359\n",
      "Epoch 47/100\n",
      "199/199 [==============================] - 0s 930us/step - loss: 0.0361 - val_loss: 0.0359\n",
      "Epoch 48/100\n",
      "199/199 [==============================] - 0s 931us/step - loss: 0.0361 - val_loss: 0.0359\n",
      "Epoch 49/100\n",
      "199/199 [==============================] - 0s 934us/step - loss: 0.0361 - val_loss: 0.0360\n",
      "Epoch 50/100\n",
      "199/199 [==============================] - 0s 923us/step - loss: 0.0361 - val_loss: 0.0361\n",
      "Epoch 51/100\n",
      "199/199 [==============================] - 0s 921us/step - loss: 0.0361 - val_loss: 0.0358\n",
      "Epoch 52/100\n",
      "199/199 [==============================] - 0s 925us/step - loss: 0.0361 - val_loss: 0.0358\n",
      "Epoch 53/100\n",
      "199/199 [==============================] - 0s 924us/step - loss: 0.0361 - val_loss: 0.0359\n",
      "Epoch 54/100\n",
      "199/199 [==============================] - 0s 919us/step - loss: 0.0360 - val_loss: 0.0358\n",
      "Epoch 55/100\n",
      "199/199 [==============================] - 0s 926us/step - loss: 0.0360 - val_loss: 0.0359\n",
      "Epoch 56/100\n",
      "199/199 [==============================] - 0s 923us/step - loss: 0.0360 - val_loss: 0.0358\n",
      "Epoch 57/100\n",
      "199/199 [==============================] - 0s 918us/step - loss: 0.0360 - val_loss: 0.0359\n",
      "Epoch 58/100\n",
      "199/199 [==============================] - 0s 909us/step - loss: 0.0360 - val_loss: 0.0358\n",
      "Epoch 59/100\n",
      "199/199 [==============================] - 0s 997us/step - loss: 0.0360 - val_loss: 0.0358\n",
      "Epoch 60/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0359 - val_loss: 0.0363\n",
      "Epoch 61/100\n",
      "199/199 [==============================] - 0s 991us/step - loss: 0.0360 - val_loss: 0.0357\n",
      "Epoch 62/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0359 - val_loss: 0.0358\n",
      "Epoch 63/100\n",
      "199/199 [==============================] - 0s 995us/step - loss: 0.0359 - val_loss: 0.0359\n",
      "Epoch 64/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0359 - val_loss: 0.0357\n",
      "Epoch 65/100\n",
      "199/199 [==============================] - 0s 989us/step - loss: 0.0359 - val_loss: 0.0363\n",
      "Epoch 66/100\n",
      "199/199 [==============================] - 0s 959us/step - loss: 0.0359 - val_loss: 0.0358\n",
      "Epoch 67/100\n",
      "199/199 [==============================] - 0s 882us/step - loss: 0.0360 - val_loss: 0.0360\n",
      "Epoch 68/100\n",
      "199/199 [==============================] - 0s 903us/step - loss: 0.0358 - val_loss: 0.0357\n",
      "Epoch 69/100\n",
      "199/199 [==============================] - 0s 885us/step - loss: 0.0359 - val_loss: 0.0357\n",
      "Epoch 70/100\n",
      "199/199 [==============================] - 0s 885us/step - loss: 0.0358 - val_loss: 0.0358\n",
      "Epoch 71/100\n",
      "199/199 [==============================] - 0s 884us/step - loss: 0.0360 - val_loss: 0.0358\n",
      "Epoch 72/100\n",
      "199/199 [==============================] - 0s 900us/step - loss: 0.0358 - val_loss: 0.0356\n",
      "Epoch 73/100\n",
      "199/199 [==============================] - 0s 893us/step - loss: 0.0359 - val_loss: 0.0358\n",
      "Epoch 74/100\n",
      "199/199 [==============================] - 0s 957us/step - loss: 0.0360 - val_loss: 0.0357\n",
      "Epoch 75/100\n",
      "199/199 [==============================] - 0s 883us/step - loss: 0.0359 - val_loss: 0.0359\n",
      "Epoch 76/100\n",
      "199/199 [==============================] - 0s 897us/step - loss: 0.0358 - val_loss: 0.0356\n",
      "Epoch 77/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0358 - val_loss: 0.0356\n",
      "Epoch 78/100\n",
      "199/199 [==============================] - 0s 957us/step - loss: 0.0358 - val_loss: 0.0357\n",
      "Epoch 79/100\n",
      "199/199 [==============================] - 0s 891us/step - loss: 0.0358 - val_loss: 0.0356\n",
      "Epoch 80/100\n",
      "199/199 [==============================] - 0s 898us/step - loss: 0.0357 - val_loss: 0.0355\n",
      "Epoch 81/100\n",
      "199/199 [==============================] - 0s 891us/step - loss: 0.0357 - val_loss: 0.0355\n",
      "Epoch 82/100\n",
      "199/199 [==============================] - 0s 994us/step - loss: 0.0356 - val_loss: 0.0356\n",
      "Epoch 83/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0356 - val_loss: 0.0354\n",
      "Epoch 84/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0355 - val_loss: 0.0355\n",
      "Epoch 85/100\n",
      "199/199 [==============================] - 0s 1000us/step - loss: 0.0355 - val_loss: 0.0353\n",
      "Epoch 86/100\n",
      "199/199 [==============================] - 0s 914us/step - loss: 0.0355 - val_loss: 0.0360\n",
      "Epoch 87/100\n",
      "199/199 [==============================] - 0s 892us/step - loss: 0.0355 - val_loss: 0.0352\n",
      "Epoch 88/100\n",
      "199/199 [==============================] - 0s 989us/step - loss: 0.0355 - val_loss: 0.0353\n",
      "Epoch 89/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0354 - val_loss: 0.0351\n",
      "Epoch 90/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0353 - val_loss: 0.0351\n",
      "Epoch 91/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0352 - val_loss: 0.0352\n",
      "Epoch 92/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0351 - val_loss: 0.0350\n",
      "Epoch 93/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0351 - val_loss: 0.0349\n",
      "Epoch 94/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0349 - val_loss: 0.0353\n",
      "Epoch 95/100\n",
      "199/199 [==============================] - 0s 959us/step - loss: 0.0349 - val_loss: 0.0347\n",
      "Epoch 96/100\n",
      "199/199 [==============================] - 0s 914us/step - loss: 0.0349 - val_loss: 0.0347\n",
      "Epoch 97/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0347 - val_loss: 0.0347\n",
      "Epoch 98/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0347 - val_loss: 0.0347\n",
      "Epoch 99/100\n",
      "199/199 [==============================] - 0s 964us/step - loss: 0.0347 - val_loss: 0.0345\n",
      "Epoch 100/100\n",
      "199/199 [==============================] - 0s 968us/step - loss: 0.0346 - val_loss: 0.0343\n",
      "This round is 28\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_11724/328462441.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  para_dfm = para_dfm.append({\"reg_param\": reg_param, \"number_units_layers\": numbers_units_layers, \"number_units_bottleneck\": numbers_units_bottleneck, \"dropout_rate\": dropout_rate, \"number_layers\": numbers_layers, \"whether_dropout\": whether_dropout, \"whether_regularizer\": whether_regularizer, \"overfit_metric\": overfit_metric, \"val2_avg_recon_error\": val2_avg_recon_error,'val1_loss':val1_loss}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 0s 1ms/step - loss: 1.1260 - val_loss: 0.4048\n",
      "Epoch 2/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.2027 - val_loss: 0.0945\n",
      "Epoch 3/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0695 - val_loss: 0.0577\n",
      "Epoch 4/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0559 - val_loss: 0.0551\n",
      "Epoch 5/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0550 - val_loss: 0.0549\n",
      "Epoch 6/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0549 - val_loss: 0.0547\n",
      "Epoch 7/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0545 - val_loss: 0.0540\n",
      "Epoch 8/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0526 - val_loss: 0.0501\n",
      "Epoch 9/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0468 - val_loss: 0.0438\n",
      "Epoch 10/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0426 - val_loss: 0.0412\n",
      "Epoch 11/100\n",
      "199/199 [==============================] - 0s 935us/step - loss: 0.0408 - val_loss: 0.0400\n",
      "Epoch 12/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0398 - val_loss: 0.0392\n",
      "Epoch 13/100\n",
      "199/199 [==============================] - 0s 977us/step - loss: 0.0391 - val_loss: 0.0386\n",
      "Epoch 14/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0385 - val_loss: 0.0381\n",
      "Epoch 15/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0381 - val_loss: 0.0378\n",
      "Epoch 16/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0378 - val_loss: 0.0374\n",
      "Epoch 17/100\n",
      "199/199 [==============================] - 0s 917us/step - loss: 0.0375 - val_loss: 0.0372\n",
      "Epoch 18/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0373 - val_loss: 0.0370\n",
      "Epoch 19/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0371 - val_loss: 0.0368\n",
      "Epoch 20/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0370 - val_loss: 0.0367\n",
      "Epoch 21/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0368 - val_loss: 0.0368\n",
      "Epoch 22/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0367 - val_loss: 0.0365\n",
      "Epoch 23/100\n",
      "199/199 [==============================] - 0s 976us/step - loss: 0.0367 - val_loss: 0.0364\n",
      "Epoch 24/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0366 - val_loss: 0.0364\n",
      "Epoch 25/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0365 - val_loss: 0.0363\n",
      "Epoch 26/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0364 - val_loss: 0.0362\n",
      "Epoch 27/100\n",
      "199/199 [==============================] - 0s 964us/step - loss: 0.0364 - val_loss: 0.0362\n",
      "Epoch 28/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0364 - val_loss: 0.0363\n",
      "Epoch 29/100\n",
      "199/199 [==============================] - 0s 944us/step - loss: 0.0363 - val_loss: 0.0361\n",
      "Epoch 30/100\n",
      "199/199 [==============================] - 0s 914us/step - loss: 0.0363 - val_loss: 0.0362\n",
      "Epoch 31/100\n",
      "199/199 [==============================] - 0s 895us/step - loss: 0.0363 - val_loss: 0.0360\n",
      "Epoch 32/100\n",
      "199/199 [==============================] - 0s 942us/step - loss: 0.0362 - val_loss: 0.0361\n",
      "Epoch 33/100\n",
      "199/199 [==============================] - 0s 937us/step - loss: 0.0362 - val_loss: 0.0361\n",
      "Epoch 34/100\n",
      "199/199 [==============================] - 0s 940us/step - loss: 0.0362 - val_loss: 0.0362\n",
      "Epoch 35/100\n",
      "199/199 [==============================] - 0s 921us/step - loss: 0.0362 - val_loss: 0.0361\n",
      "Epoch 36/100\n",
      "199/199 [==============================] - 0s 961us/step - loss: 0.0361 - val_loss: 0.0359\n",
      "Epoch 37/100\n",
      "199/199 [==============================] - 0s 942us/step - loss: 0.0361 - val_loss: 0.0359\n",
      "Epoch 38/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0361 - val_loss: 0.0366\n",
      "Epoch 39/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0361 - val_loss: 0.0359\n",
      "Epoch 40/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0361 - val_loss: 0.0359\n",
      "Epoch 41/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0360 - val_loss: 0.0358\n",
      "Epoch 42/100\n",
      "199/199 [==============================] - 0s 993us/step - loss: 0.0360 - val_loss: 0.0358\n",
      "Epoch 43/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0360 - val_loss: 0.0358\n",
      "Epoch 44/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0360 - val_loss: 0.0358\n",
      "Epoch 45/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0360 - val_loss: 0.0358\n",
      "Epoch 46/100\n",
      "199/199 [==============================] - 0s 993us/step - loss: 0.0360 - val_loss: 0.0358\n",
      "Epoch 47/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0359 - val_loss: 0.0359\n",
      "Epoch 48/100\n",
      "199/199 [==============================] - 0s 960us/step - loss: 0.0359 - val_loss: 0.0360\n",
      "Epoch 49/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0360 - val_loss: 0.0357\n",
      "Epoch 50/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0359 - val_loss: 0.0358\n",
      "Epoch 51/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0359 - val_loss: 0.0361\n",
      "Epoch 52/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0359 - val_loss: 0.0357\n",
      "Epoch 53/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0359 - val_loss: 0.0358\n",
      "Epoch 54/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0359 - val_loss: 0.0358\n",
      "Epoch 55/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0359 - val_loss: 0.0357\n",
      "Epoch 56/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0358 - val_loss: 0.0357\n",
      "Epoch 57/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0359 - val_loss: 0.0358\n",
      "Epoch 58/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0359 - val_loss: 0.0358\n",
      "Epoch 59/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0359 - val_loss: 0.0357\n",
      "Epoch 60/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0359 - val_loss: 0.0364\n",
      "Epoch 61/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0359 - val_loss: 0.0357\n",
      "Epoch 62/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0358 - val_loss: 0.0358\n",
      "Epoch 63/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0358 - val_loss: 0.0356\n",
      "Epoch 64/100\n",
      "199/199 [==============================] - 0s 961us/step - loss: 0.0358 - val_loss: 0.0356\n",
      "Epoch 65/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0358 - val_loss: 0.0358\n",
      "Epoch 66/100\n",
      "199/199 [==============================] - 0s 951us/step - loss: 0.0358 - val_loss: 0.0356\n",
      "Epoch 67/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0358 - val_loss: 0.0356\n",
      "Epoch 68/100\n",
      "199/199 [==============================] - 0s 935us/step - loss: 0.0357 - val_loss: 0.0357\n",
      "Epoch 69/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0358 - val_loss: 0.0356\n",
      "Epoch 70/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0358 - val_loss: 0.0356\n",
      "Epoch 71/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0358 - val_loss: 0.0358\n",
      "Epoch 72/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0358 - val_loss: 0.0358\n",
      "Epoch 73/100\n",
      "199/199 [==============================] - 0s 999us/step - loss: 0.0357 - val_loss: 0.0356\n",
      "Epoch 74/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0358 - val_loss: 0.0356\n",
      "Epoch 75/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0358 - val_loss: 0.0355\n",
      "Epoch 76/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0357 - val_loss: 0.0356\n",
      "Epoch 77/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0357 - val_loss: 0.0356\n",
      "Epoch 78/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0357 - val_loss: 0.0356\n",
      "Epoch 79/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0357 - val_loss: 0.0357\n",
      "Epoch 80/100\n",
      "199/199 [==============================] - 0s 930us/step - loss: 0.0357 - val_loss: 0.0357\n",
      "Epoch 81/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0358 - val_loss: 0.0355\n",
      "Epoch 82/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0357 - val_loss: 0.0356\n",
      "Epoch 83/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0357 - val_loss: 0.0356\n",
      "Epoch 84/100\n",
      "199/199 [==============================] - 0s 925us/step - loss: 0.0357 - val_loss: 0.0355\n",
      "Epoch 85/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0357 - val_loss: 0.0355\n",
      "Epoch 86/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0357 - val_loss: 0.0357\n",
      "Epoch 87/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0356 - val_loss: 0.0356\n",
      "Epoch 88/100\n",
      "199/199 [==============================] - 0s 958us/step - loss: 0.0356 - val_loss: 0.0355\n",
      "Epoch 89/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0357 - val_loss: 0.0357\n",
      "Epoch 90/100\n",
      "199/199 [==============================] - 0s 948us/step - loss: 0.0357 - val_loss: 0.0356\n",
      "Epoch 91/100\n",
      "199/199 [==============================] - 0s 988us/step - loss: 0.0358 - val_loss: 0.0355\n",
      "Epoch 92/100\n",
      "199/199 [==============================] - 0s 985us/step - loss: 0.0356 - val_loss: 0.0355\n",
      "Epoch 93/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0356 - val_loss: 0.0355\n",
      "Epoch 94/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0356 - val_loss: 0.0356\n",
      "Epoch 95/100\n",
      "199/199 [==============================] - 0s 967us/step - loss: 0.0356 - val_loss: 0.0354\n",
      "Epoch 96/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0356 - val_loss: 0.0355\n",
      "Epoch 97/100\n",
      "199/199 [==============================] - 0s 948us/step - loss: 0.0357 - val_loss: 0.0356\n",
      "Epoch 98/100\n",
      "199/199 [==============================] - 0s 982us/step - loss: 0.0356 - val_loss: 0.0355\n",
      "Epoch 99/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0356 - val_loss: 0.0354\n",
      "Epoch 100/100\n",
      "199/199 [==============================] - 0s 925us/step - loss: 0.0356 - val_loss: 0.0354\n",
      "This round is 29\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_11724/328462441.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  para_dfm = para_dfm.append({\"reg_param\": reg_param, \"number_units_layers\": numbers_units_layers, \"number_units_bottleneck\": numbers_units_bottleneck, \"dropout_rate\": dropout_rate, \"number_layers\": numbers_layers, \"whether_dropout\": whether_dropout, \"whether_regularizer\": whether_regularizer, \"overfit_metric\": overfit_metric, \"val2_avg_recon_error\": val2_avg_recon_error,'val1_loss':val1_loss}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 0s 1ms/step - loss: 1.7126 - val_loss: 0.6071\n",
      "Epoch 2/100\n",
      "199/199 [==============================] - 0s 924us/step - loss: 0.2883 - val_loss: 0.1174\n",
      "Epoch 3/100\n",
      "199/199 [==============================] - 0s 919us/step - loss: 0.0778 - val_loss: 0.0594\n",
      "Epoch 4/100\n",
      "199/199 [==============================] - 0s 913us/step - loss: 0.0564 - val_loss: 0.0552\n",
      "Epoch 5/100\n",
      "199/199 [==============================] - 0s 908us/step - loss: 0.0551 - val_loss: 0.0550\n",
      "Epoch 6/100\n",
      "199/199 [==============================] - 0s 948us/step - loss: 0.0550 - val_loss: 0.0549\n",
      "Epoch 7/100\n",
      "199/199 [==============================] - 0s 936us/step - loss: 0.0549 - val_loss: 0.0548\n",
      "Epoch 8/100\n",
      "199/199 [==============================] - 0s 918us/step - loss: 0.0548 - val_loss: 0.0547\n",
      "Epoch 9/100\n",
      "199/199 [==============================] - 0s 908us/step - loss: 0.0543 - val_loss: 0.0537\n",
      "Epoch 10/100\n",
      "199/199 [==============================] - 0s 908us/step - loss: 0.0518 - val_loss: 0.0487\n",
      "Epoch 11/100\n",
      "199/199 [==============================] - 0s 904us/step - loss: 0.0460 - val_loss: 0.0435\n",
      "Epoch 12/100\n",
      "199/199 [==============================] - 0s 931us/step - loss: 0.0425 - val_loss: 0.0412\n",
      "Epoch 13/100\n",
      "199/199 [==============================] - 0s 917us/step - loss: 0.0410 - val_loss: 0.0401\n",
      "Epoch 14/100\n",
      "199/199 [==============================] - 0s 918us/step - loss: 0.0400 - val_loss: 0.0393\n",
      "Epoch 15/100\n",
      "199/199 [==============================] - 0s 941us/step - loss: 0.0393 - val_loss: 0.0388\n",
      "Epoch 16/100\n",
      "199/199 [==============================] - 0s 900us/step - loss: 0.0388 - val_loss: 0.0383\n",
      "Epoch 17/100\n",
      "199/199 [==============================] - 0s 929us/step - loss: 0.0384 - val_loss: 0.0379\n",
      "Epoch 18/100\n",
      "199/199 [==============================] - 0s 942us/step - loss: 0.0381 - val_loss: 0.0376\n",
      "Epoch 19/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0378 - val_loss: 0.0373\n",
      "Epoch 20/100\n",
      "199/199 [==============================] - 0s 997us/step - loss: 0.0376 - val_loss: 0.0372\n",
      "Epoch 21/100\n",
      "199/199 [==============================] - 0s 946us/step - loss: 0.0374 - val_loss: 0.0370\n",
      "Epoch 22/100\n",
      "199/199 [==============================] - 0s 937us/step - loss: 0.0372 - val_loss: 0.0368\n",
      "Epoch 23/100\n",
      "199/199 [==============================] - 0s 975us/step - loss: 0.0371 - val_loss: 0.0367\n",
      "Epoch 24/100\n",
      "199/199 [==============================] - 0s 971us/step - loss: 0.0370 - val_loss: 0.0366\n",
      "Epoch 25/100\n",
      "199/199 [==============================] - 0s 994us/step - loss: 0.0369 - val_loss: 0.0366\n",
      "Epoch 26/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0367 - val_loss: 0.0364\n",
      "Epoch 27/100\n",
      "199/199 [==============================] - 0s 983us/step - loss: 0.0367 - val_loss: 0.0364\n",
      "Epoch 28/100\n",
      "199/199 [==============================] - 0s 983us/step - loss: 0.0366 - val_loss: 0.0364\n",
      "Epoch 29/100\n",
      "199/199 [==============================] - 0s 914us/step - loss: 0.0366 - val_loss: 0.0363\n",
      "Epoch 30/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0366 - val_loss: 0.0364\n",
      "Epoch 31/100\n",
      "199/199 [==============================] - 0s 2ms/step - loss: 0.0365 - val_loss: 0.0362\n",
      "Epoch 32/100\n",
      "199/199 [==============================] - 0s 972us/step - loss: 0.0365 - val_loss: 0.0362\n",
      "Epoch 33/100\n",
      "199/199 [==============================] - 0s 917us/step - loss: 0.0364 - val_loss: 0.0362\n",
      "Epoch 34/100\n",
      "199/199 [==============================] - 0s 984us/step - loss: 0.0364 - val_loss: 0.0362\n",
      "Epoch 35/100\n",
      "199/199 [==============================] - 0s 987us/step - loss: 0.0363 - val_loss: 0.0364\n",
      "Epoch 36/100\n",
      "199/199 [==============================] - 0s 966us/step - loss: 0.0363 - val_loss: 0.0362\n",
      "Epoch 37/100\n",
      "199/199 [==============================] - 0s 951us/step - loss: 0.0363 - val_loss: 0.0360\n",
      "Epoch 38/100\n",
      "199/199 [==============================] - 0s 971us/step - loss: 0.0363 - val_loss: 0.0365\n",
      "Epoch 39/100\n",
      "199/199 [==============================] - 0s 970us/step - loss: 0.0363 - val_loss: 0.0360\n",
      "Epoch 40/100\n",
      "199/199 [==============================] - 0s 916us/step - loss: 0.0362 - val_loss: 0.0361\n",
      "Epoch 41/100\n",
      "199/199 [==============================] - 0s 911us/step - loss: 0.0363 - val_loss: 0.0360\n",
      "Epoch 42/100\n",
      "199/199 [==============================] - 0s 956us/step - loss: 0.0362 - val_loss: 0.0360\n",
      "Epoch 43/100\n",
      "199/199 [==============================] - 0s 999us/step - loss: 0.0362 - val_loss: 0.0360\n",
      "Epoch 44/100\n",
      "199/199 [==============================] - 0s 910us/step - loss: 0.0362 - val_loss: 0.0359\n",
      "Epoch 45/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0362 - val_loss: 0.0360\n",
      "Epoch 46/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0361 - val_loss: 0.0359\n",
      "Epoch 47/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0361 - val_loss: 0.0360\n",
      "Epoch 48/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0361 - val_loss: 0.0359\n",
      "Epoch 49/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0361 - val_loss: 0.0359\n",
      "Epoch 50/100\n",
      "199/199 [==============================] - 0s 927us/step - loss: 0.0361 - val_loss: 0.0359\n",
      "Epoch 51/100\n",
      "199/199 [==============================] - 0s 937us/step - loss: 0.0362 - val_loss: 0.0360\n",
      "Epoch 52/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0361 - val_loss: 0.0358\n",
      "Epoch 53/100\n",
      "199/199 [==============================] - 0s 995us/step - loss: 0.0360 - val_loss: 0.0359\n",
      "Epoch 54/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0360 - val_loss: 0.0360\n",
      "Epoch 55/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0361 - val_loss: 0.0358\n",
      "Epoch 56/100\n",
      "199/199 [==============================] - 0s 934us/step - loss: 0.0360 - val_loss: 0.0358\n",
      "Epoch 57/100\n",
      "199/199 [==============================] - 0s 933us/step - loss: 0.0360 - val_loss: 0.0358\n",
      "Epoch 58/100\n",
      "199/199 [==============================] - 0s 955us/step - loss: 0.0360 - val_loss: 0.0363\n",
      "Epoch 59/100\n",
      "199/199 [==============================] - 0s 918us/step - loss: 0.0360 - val_loss: 0.0358\n",
      "Epoch 60/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0361 - val_loss: 0.0361\n",
      "Epoch 61/100\n",
      "199/199 [==============================] - 0s 950us/step - loss: 0.0360 - val_loss: 0.0360\n",
      "Epoch 62/100\n",
      "199/199 [==============================] - 0s 914us/step - loss: 0.0360 - val_loss: 0.0359\n",
      "Epoch 63/100\n",
      "199/199 [==============================] - 0s 913us/step - loss: 0.0360 - val_loss: 0.0358\n",
      "Epoch 64/100\n",
      "199/199 [==============================] - 0s 904us/step - loss: 0.0359 - val_loss: 0.0358\n",
      "Epoch 65/100\n",
      "199/199 [==============================] - 0s 907us/step - loss: 0.0359 - val_loss: 0.0357\n",
      "Epoch 66/100\n",
      "199/199 [==============================] - 0s 916us/step - loss: 0.0360 - val_loss: 0.0359\n",
      "Epoch 67/100\n",
      "199/199 [==============================] - 0s 915us/step - loss: 0.0360 - val_loss: 0.0357\n",
      "Epoch 68/100\n",
      "199/199 [==============================] - 0s 930us/step - loss: 0.0359 - val_loss: 0.0358\n",
      "Epoch 69/100\n",
      "199/199 [==============================] - 0s 947us/step - loss: 0.0359 - val_loss: 0.0357\n",
      "Epoch 70/100\n",
      "199/199 [==============================] - 0s 956us/step - loss: 0.0359 - val_loss: 0.0359\n",
      "Epoch 71/100\n",
      "199/199 [==============================] - 0s 962us/step - loss: 0.0359 - val_loss: 0.0357\n",
      "Epoch 72/100\n",
      "199/199 [==============================] - 0s 981us/step - loss: 0.0359 - val_loss: 0.0359\n",
      "Epoch 73/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0359 - val_loss: 0.0357\n",
      "Epoch 74/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0359 - val_loss: 0.0357\n",
      "Epoch 75/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0358 - val_loss: 0.0358\n",
      "Epoch 76/100\n",
      "199/199 [==============================] - 0s 935us/step - loss: 0.0359 - val_loss: 0.0356\n",
      "Epoch 77/100\n",
      "199/199 [==============================] - 0s 947us/step - loss: 0.0359 - val_loss: 0.0358\n",
      "Epoch 78/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0358 - val_loss: 0.0356\n",
      "Epoch 79/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0358 - val_loss: 0.0358\n",
      "Epoch 80/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0358 - val_loss: 0.0357\n",
      "Epoch 81/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0359 - val_loss: 0.0356\n",
      "Epoch 82/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0358 - val_loss: 0.0359\n",
      "Epoch 83/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0358 - val_loss: 0.0358\n",
      "Epoch 84/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0358 - val_loss: 0.0362\n",
      "Epoch 85/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0358 - val_loss: 0.0356\n",
      "Epoch 86/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0358 - val_loss: 0.0356\n",
      "Epoch 87/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0358 - val_loss: 0.0357\n",
      "Epoch 88/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0357 - val_loss: 0.0356\n",
      "Epoch 89/100\n",
      "199/199 [==============================] - 0s 984us/step - loss: 0.0358 - val_loss: 0.0357\n",
      "Epoch 90/100\n",
      "199/199 [==============================] - 0s 934us/step - loss: 0.0358 - val_loss: 0.0357\n",
      "Epoch 91/100\n",
      "199/199 [==============================] - 0s 992us/step - loss: 0.0358 - val_loss: 0.0356\n",
      "Epoch 92/100\n",
      "199/199 [==============================] - 0s 965us/step - loss: 0.0357 - val_loss: 0.0356\n",
      "Epoch 93/100\n",
      "199/199 [==============================] - 0s 963us/step - loss: 0.0358 - val_loss: 0.0357\n",
      "Epoch 94/100\n",
      "199/199 [==============================] - 0s 986us/step - loss: 0.0359 - val_loss: 0.0356\n",
      "Epoch 95/100\n",
      "199/199 [==============================] - 0s 954us/step - loss: 0.0358 - val_loss: 0.0356\n",
      "Epoch 96/100\n",
      "199/199 [==============================] - 0s 926us/step - loss: 0.0357 - val_loss: 0.0356\n",
      "Epoch 97/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0357 - val_loss: 0.0357\n",
      "Epoch 98/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0357 - val_loss: 0.0355\n",
      "Epoch 99/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0357 - val_loss: 0.0355\n",
      "Epoch 100/100\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.0357 - val_loss: 0.0355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_11724/328462441.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  para_dfm = para_dfm.append({\"reg_param\": reg_param, \"number_units_layers\": numbers_units_layers, \"number_units_bottleneck\": numbers_units_bottleneck, \"dropout_rate\": dropout_rate, \"number_layers\": numbers_layers, \"whether_dropout\": whether_dropout, \"whether_regularizer\": whether_regularizer, \"overfit_metric\": overfit_metric, \"val2_avg_recon_error\": val2_avg_recon_error,'val1_loss':val1_loss}, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(48)\n",
    "round = 30\n",
    "model_list = [] # list of to save model\n",
    "class_list = []\n",
    "log_list = []\n",
    "para_dfm = pd.DataFrame(columns=['reg_param', 'number_units_layers', 'number_units_bottleneck', 'dropout_rate', 'number_layers', 'whether_dropout', 'whether_regularizer','overfit_metric', 'val1_loss','val2_avg_recon_error'])\n",
    "for i in range(round):\n",
    "    print(f\"This round is {i}\")\n",
    "    # generate a list of hyperparameters\n",
    "    reg_param = np.random.uniform(low=0.1, high=0.3)\n",
    "    numbers_units_layers = np.random.choice(np.arange(30, 61, 15))\n",
    "    numbers_units_bottleneck = np.random.choice(np.arange(5, 16, 5))\n",
    "    dropout_rate = np.random.uniform(low=0.01, high=0.05)\n",
    "    numbers_layers = np.random.choice(np.arange(1, 4, 1))\n",
    "    whether_dropout = np.random.choice([True, False])\n",
    "    whether_regularizer = np.random.choice([True, False])\n",
    "    autoencoder = AutoEncodingModel(reg_param, numbers_units_layers, numbers_units_bottleneck, dropout_rate, numbers_layers, whether_dropout, whether_regularizer)\n",
    "    \n",
    "    # get the result of the model\n",
    "    res = autoencoder.run()\n",
    "    overfit_metric  = res['overfit_metric']\n",
    "    val2_avg_recon_error = res['val2_avg_recon_error']\n",
    "    model = res['model']\n",
    "    val1_loss = res['val1_loss']\n",
    "\n",
    "    # fill the value into the dataframe\n",
    "    para_dfm = para_dfm.append({\"reg_param\": reg_param, \"number_units_layers\": numbers_units_layers, \"number_units_bottleneck\": numbers_units_bottleneck, \"dropout_rate\": dropout_rate, \"number_layers\": numbers_layers, \"whether_dropout\": whether_dropout, \"whether_regularizer\": whether_regularizer, \"overfit_metric\": overfit_metric, \"val2_avg_recon_error\": val2_avg_recon_error,'val1_loss':val1_loss}, ignore_index=True)\n",
    "    \n",
    "    # add model into model_list\n",
    "    model_list.append(model)\n",
    "\n",
    "    # add initalized class into class_list\n",
    "    class_list.append(autoencoder)\n",
    "\n",
    "    # add log into log_list\n",
    "    log_list.append(res['log'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   reg_param number_units_layers number_units_bottleneck dropout_rate  \\\n",
      "0   0.195836                  60                      15     0.025107   \n",
      "1   0.189372                  45                      15     0.034574   \n",
      "2   0.153161                  45                      10     0.043861   \n",
      "3   0.171582                  30                      15     0.014654   \n",
      "4    0.29831                  45                      15     0.019937   \n",
      "5   0.133741                  30                       5     0.024791   \n",
      "6   0.117615                  45                      10     0.029217   \n",
      "7   0.263344                  30                      15      0.02766   \n",
      "8   0.247725                  30                      10     0.025174   \n",
      "9   0.122018                  60                       5     0.039958   \n",
      "10   0.23989                  60                       5     0.031917   \n",
      "11  0.111435                  30                      10     0.026453   \n",
      "12  0.124437                  30                      10     0.046113   \n",
      "13  0.194221                  30                      10     0.038851   \n",
      "14   0.21105                  30                      10     0.043907   \n",
      "15  0.255449                  45                      15     0.036539   \n",
      "16  0.299427                  60                      15      0.04457   \n",
      "17  0.100055                  45                      10     0.021704   \n",
      "18  0.267967                  45                      10     0.026593   \n",
      "19  0.139381                  60                      15     0.013309   \n",
      "20  0.194863                  45                       5      0.03923   \n",
      "21  0.143941                  30                      10     0.046023   \n",
      "22  0.115309                  60                      15     0.031843   \n",
      "23  0.207384                  60                      10     0.014709   \n",
      "24  0.229799                  30                      10      0.01798   \n",
      "25  0.207906                  30                      15      0.04078   \n",
      "26  0.107454                  60                       5     0.038433   \n",
      "27  0.265663                  45                      10     0.039034   \n",
      "28  0.103882                  30                      15     0.017916   \n",
      "29  0.164288                  30                      15     0.042504   \n",
      "\n",
      "   number_layers whether_dropout whether_regularizer overfit_metric val1_loss  \\\n",
      "0              1            True               False       0.000321   0.00218   \n",
      "1              1            True                True      -0.000283   0.03001   \n",
      "2              1           False                True       0.000364   0.00077   \n",
      "3              1            True               False       0.000048  0.004306   \n",
      "4              3            True               False       0.000128  0.002145   \n",
      "5              3           False                True         0.0005  0.001634   \n",
      "6              3           False               False       0.000364   0.00077   \n",
      "7              3            True                True      -0.000242  0.035554   \n",
      "8              3           False                True         0.0005  0.001634   \n",
      "9              2           False                True       0.000297  0.000619   \n",
      "10             2            True                True      -0.000385  0.029769   \n",
      "11             2           False                True         0.0005  0.001634   \n",
      "12             3           False               False         0.0005  0.001634   \n",
      "13             3            True               False      -0.000281  0.005374   \n",
      "14             2           False                True         0.0005  0.001634   \n",
      "15             1            True                True      -0.000139   0.03574   \n",
      "16             1            True               False       0.000186  0.002324   \n",
      "17             3           False               False       0.000364   0.00077   \n",
      "18             3            True                True      -0.000341  0.032403   \n",
      "19             2            True                True      -0.000372  0.029166   \n",
      "20             3            True                True        -0.0002  0.035385   \n",
      "21             2           False                True         0.0005  0.001634   \n",
      "22             2           False                True       0.000297  0.000619   \n",
      "23             1            True                True      -0.000287  0.028125   \n",
      "24             2            True               False       0.000221  0.006348   \n",
      "25             1           False               False         0.0005  0.001634   \n",
      "26             1           False               False       0.000297  0.000619   \n",
      "27             1            True                True      -0.000304  0.034323   \n",
      "28             3            True                True      -0.000176  0.035385   \n",
      "29             1            True                True       -0.00024  0.035478   \n",
      "\n",
      "   val2_avg_recon_error model_score  \n",
      "0              0.002053    0.001732  \n",
      "1              0.029271    0.029554  \n",
      "2              0.000633    0.000269  \n",
      "3              0.004445    0.004397  \n",
      "4              0.001927    0.001799  \n",
      "5              0.001507    0.001007  \n",
      "6              0.000633    0.000269  \n",
      "7              0.035921    0.036163  \n",
      "8              0.001507    0.001007  \n",
      "9                0.0005    0.000203  \n",
      "10             0.029023    0.029408  \n",
      "11             0.001507    0.001007  \n",
      "12             0.001507    0.001007  \n",
      "13              0.00533    0.005611  \n",
      "14             0.001507    0.001007  \n",
      "15              0.03608    0.036219  \n",
      "16             0.002179    0.001993  \n",
      "17             0.000633    0.000269  \n",
      "18              0.03201    0.032351  \n",
      "19             0.028234    0.028606  \n",
      "20             0.035731    0.035931  \n",
      "21             0.001507    0.001007  \n",
      "22               0.0005    0.000203  \n",
      "23             0.027223     0.02751  \n",
      "24             0.006342    0.006121  \n",
      "25             0.001507    0.001007  \n",
      "26               0.0005    0.000203  \n",
      "27             0.034279    0.034583  \n",
      "28             0.035747    0.035923  \n",
      "29              0.03585    0.036091  \n"
     ]
    }
   ],
   "source": [
    "# calculate the model score according to the val2_avg_recon_error and overfit_metric\n",
    "para_dfm[\"model_score\"] = para_dfm[\"val2_avg_recon_error\"] - para_dfm[\"overfit_metric\"] \n",
    "print(para_dfm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go through all the models we have trained and look into the relationship of the model_score and the performance of model.\n",
    "In the table, we are going to record the model_score, the sensitivity(select the mean of reconstruction_error as threshold), accuracy_rate and AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model_score is: 0.0017324490623488852\n",
      "0.4642857142857143\n",
      "The model_score is: 0.02955409999976271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_11724/3198456538.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_performance_diff_sens = df_performance_diff_sens.append({\"model_score\": row['model_score'], \"sensitivity\": sensitivity,'accuracy_rate':accuracy_rate,'roc':roc}, ignore_index=True)\n",
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_11724/3198456538.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_performance_diff_sens = df_performance_diff_sens.append({\"model_score\": row['model_score'], \"sensitivity\": sensitivity,'accuracy_rate':accuracy_rate,'roc':roc}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7142857142857143\n",
      "The model_score is: 0.00026917694689201075\n",
      "0.44642857142857145\n",
      "The model_score is: 0.004396980136256059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_11724/3198456538.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_performance_diff_sens = df_performance_diff_sens.append({\"model_score\": row['model_score'], \"sensitivity\": sensitivity,'accuracy_rate':accuracy_rate,'roc':roc}, ignore_index=True)\n",
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_11724/3198456538.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_performance_diff_sens = df_performance_diff_sens.append({\"model_score\": row['model_score'], \"sensitivity\": sensitivity,'accuracy_rate':accuracy_rate,'roc':roc}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5357142857142857\n",
      "The model_score is: 0.0017993927538018809\n",
      "0.5535714285714286\n",
      "The model_score is: 0.0010065635818173996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_11724/3198456538.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_performance_diff_sens = df_performance_diff_sens.append({\"model_score\": row['model_score'], \"sensitivity\": sensitivity,'accuracy_rate':accuracy_rate,'roc':roc}, ignore_index=True)\n",
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_11724/3198456538.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_performance_diff_sens = df_performance_diff_sens.append({\"model_score\": row['model_score'], \"sensitivity\": sensitivity,'accuracy_rate':accuracy_rate,'roc':roc}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39285714285714285\n",
      "The model_score is: 0.00026917694689201075\n",
      "0.44642857142857145\n",
      "The model_score is: 0.036162773309437936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_11724/3198456538.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_performance_diff_sens = df_performance_diff_sens.append({\"model_score\": row['model_score'], \"sensitivity\": sensitivity,'accuracy_rate':accuracy_rate,'roc':roc}, ignore_index=True)\n",
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_11724/3198456538.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_performance_diff_sens = df_performance_diff_sens.append({\"model_score\": row['model_score'], \"sensitivity\": sensitivity,'accuracy_rate':accuracy_rate,'roc':roc}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.875\n",
      "The model_score is: 0.0010065635818173996\n",
      "0.39285714285714285\n",
      "The model_score is: 0.00020301059329618464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_11724/3198456538.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_performance_diff_sens = df_performance_diff_sens.append({\"model_score\": row['model_score'], \"sensitivity\": sensitivity,'accuracy_rate':accuracy_rate,'roc':roc}, ignore_index=True)\n",
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_11724/3198456538.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_performance_diff_sens = df_performance_diff_sens.append({\"model_score\": row['model_score'], \"sensitivity\": sensitivity,'accuracy_rate':accuracy_rate,'roc':roc}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4642857142857143\n",
      "The model_score is: 0.029407983100715334\n",
      "0.7321428571428571\n",
      "The model_score is: 0.0010065635818173996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_11724/3198456538.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_performance_diff_sens = df_performance_diff_sens.append({\"model_score\": row['model_score'], \"sensitivity\": sensitivity,'accuracy_rate':accuracy_rate,'roc':roc}, ignore_index=True)\n",
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_11724/3198456538.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_performance_diff_sens = df_performance_diff_sens.append({\"model_score\": row['model_score'], \"sensitivity\": sensitivity,'accuracy_rate':accuracy_rate,'roc':roc}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39285714285714285\n",
      "The model_score is: 0.0010065635818173996\n",
      "0.39285714285714285\n",
      "The model_score is: 0.005610904483660444\n",
      "0.5892857142857143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_11724/3198456538.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_performance_diff_sens = df_performance_diff_sens.append({\"model_score\": row['model_score'], \"sensitivity\": sensitivity,'accuracy_rate':accuracy_rate,'roc':roc}, ignore_index=True)\n",
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_11724/3198456538.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_performance_diff_sens = df_performance_diff_sens.append({\"model_score\": row['model_score'], \"sensitivity\": sensitivity,'accuracy_rate':accuracy_rate,'roc':roc}, ignore_index=True)\n",
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_11724/3198456538.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_performance_diff_sens = df_performance_diff_sens.append({\"model_score\": row['model_score'], \"sensitivity\": sensitivity,'accuracy_rate':accuracy_rate,'roc':roc}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model_score is: 0.0010065635818173996\n",
      "0.39285714285714285\n",
      "The model_score is: 0.03621902804128503\n",
      "0.875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_11724/3198456538.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_performance_diff_sens = df_performance_diff_sens.append({\"model_score\": row['model_score'], \"sensitivity\": sensitivity,'accuracy_rate':accuracy_rate,'roc':roc}, ignore_index=True)\n",
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_11724/3198456538.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_performance_diff_sens = df_performance_diff_sens.append({\"model_score\": row['model_score'], \"sensitivity\": sensitivity,'accuracy_rate':accuracy_rate,'roc':roc}, ignore_index=True)\n",
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_11724/3198456538.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_performance_diff_sens = df_performance_diff_sens.append({\"model_score\": row['model_score'], \"sensitivity\": sensitivity,'accuracy_rate':accuracy_rate,'roc':roc}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model_score is: 0.0019925031825803225\n",
      "0.48214285714285715\n",
      "The model_score is: 0.00026917694689201075\n",
      "0.44642857142857145\n",
      "The model_score is: 0.032350758632074136\n",
      "0.7678571428571429\n",
      "The model_score is: 0.02860636884771137\n",
      "0.7678571428571429\n",
      "The model_score is: 0.035931039090865306\n",
      "0.875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_11724/3198456538.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_performance_diff_sens = df_performance_diff_sens.append({\"model_score\": row['model_score'], \"sensitivity\": sensitivity,'accuracy_rate':accuracy_rate,'roc':roc}, ignore_index=True)\n",
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_11724/3198456538.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_performance_diff_sens = df_performance_diff_sens.append({\"model_score\": row['model_score'], \"sensitivity\": sensitivity,'accuracy_rate':accuracy_rate,'roc':roc}, ignore_index=True)\n",
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_11724/3198456538.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_performance_diff_sens = df_performance_diff_sens.append({\"model_score\": row['model_score'], \"sensitivity\": sensitivity,'accuracy_rate':accuracy_rate,'roc':roc}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model_score is: 0.0010065635818173996\n",
      "0.39285714285714285\n",
      "The model_score is: 0.00020301059329618464\n",
      "0.4642857142857143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_11724/3198456538.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_performance_diff_sens = df_performance_diff_sens.append({\"model_score\": row['model_score'], \"sensitivity\": sensitivity,'accuracy_rate':accuracy_rate,'roc':roc}, ignore_index=True)\n",
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_11724/3198456538.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_performance_diff_sens = df_performance_diff_sens.append({\"model_score\": row['model_score'], \"sensitivity\": sensitivity,'accuracy_rate':accuracy_rate,'roc':roc}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model_score is: 0.027510410438838513\n",
      "0.7857142857142857\n",
      "The model_score is: 0.006121217889033317\n",
      "0.5535714285714286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_11724/3198456538.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_performance_diff_sens = df_performance_diff_sens.append({\"model_score\": row['model_score'], \"sensitivity\": sensitivity,'accuracy_rate':accuracy_rate,'roc':roc}, ignore_index=True)\n",
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_11724/3198456538.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_performance_diff_sens = df_performance_diff_sens.append({\"model_score\": row['model_score'], \"sensitivity\": sensitivity,'accuracy_rate':accuracy_rate,'roc':roc}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model_score is: 0.0010065635818173996\n",
      "0.39285714285714285\n",
      "The model_score is: 0.00020301059329618464\n",
      "0.4642857142857143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_11724/3198456538.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_performance_diff_sens = df_performance_diff_sens.append({\"model_score\": row['model_score'], \"sensitivity\": sensitivity,'accuracy_rate':accuracy_rate,'roc':roc}, ignore_index=True)\n",
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_11724/3198456538.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_performance_diff_sens = df_performance_diff_sens.append({\"model_score\": row['model_score'], \"sensitivity\": sensitivity,'accuracy_rate':accuracy_rate,'roc':roc}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model_score is: 0.034582983664973296\n",
      "0.875\n",
      "The model_score is: 0.03592332742311696\n",
      "0.8928571428571429\n",
      "The model_score is: 0.036090885252058544\n",
      "0.8928571428571429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_11724/3198456538.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_performance_diff_sens = df_performance_diff_sens.append({\"model_score\": row['model_score'], \"sensitivity\": sensitivity,'accuracy_rate':accuracy_rate,'roc':roc}, ignore_index=True)\n",
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_11724/3198456538.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_performance_diff_sens = df_performance_diff_sens.append({\"model_score\": row['model_score'], \"sensitivity\": sensitivity,'accuracy_rate':accuracy_rate,'roc':roc}, ignore_index=True)\n",
      "/var/folders/3d/_kfrpmln4vl2vz6_7j1h6byh0000gn/T/ipykernel_11724/3198456538.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_performance_diff_sens = df_performance_diff_sens.append({\"model_score\": row['model_score'], \"sensitivity\": sensitivity,'accuracy_rate':accuracy_rate,'roc':roc}, ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_score</th>\n",
       "      <th>sensitivity</th>\n",
       "      <th>accuracy_rate</th>\n",
       "      <th>roc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001732</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.722076</td>\n",
       "      <td>0.638265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.029554</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.60774</td>\n",
       "      <td>0.706324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000269</td>\n",
       "      <td>0.446429</td>\n",
       "      <td>0.743184</td>\n",
       "      <td>0.651546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.004397</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.689534</td>\n",
       "      <td>0.647218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001799</td>\n",
       "      <td>0.553571</td>\n",
       "      <td>0.685136</td>\n",
       "      <td>0.635936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.001007</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>0.765172</td>\n",
       "      <td>0.636018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000269</td>\n",
       "      <td>0.446429</td>\n",
       "      <td>0.743184</td>\n",
       "      <td>0.651546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.036163</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.567282</td>\n",
       "      <td>0.761233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.001007</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>0.765172</td>\n",
       "      <td>0.636018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000203</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.74934</td>\n",
       "      <td>0.671782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.029408</td>\n",
       "      <td>0.732143</td>\n",
       "      <td>0.599824</td>\n",
       "      <td>0.699468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.001007</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>0.765172</td>\n",
       "      <td>0.636018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.001007</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>0.765172</td>\n",
       "      <td>0.636018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.005611</td>\n",
       "      <td>0.589286</td>\n",
       "      <td>0.66051</td>\n",
       "      <td>0.698923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.001007</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>0.765172</td>\n",
       "      <td>0.636018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.036219</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.563764</td>\n",
       "      <td>0.757153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.001993</td>\n",
       "      <td>0.482143</td>\n",
       "      <td>0.719437</td>\n",
       "      <td>0.627362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.000269</td>\n",
       "      <td>0.446429</td>\n",
       "      <td>0.743184</td>\n",
       "      <td>0.651546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.032351</td>\n",
       "      <td>0.767857</td>\n",
       "      <td>0.596306</td>\n",
       "      <td>0.742946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.028606</td>\n",
       "      <td>0.767857</td>\n",
       "      <td>0.586631</td>\n",
       "      <td>0.710354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.035931</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.564644</td>\n",
       "      <td>0.762819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.001007</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>0.765172</td>\n",
       "      <td>0.636018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.000203</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.74934</td>\n",
       "      <td>0.671782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.02751</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.580475</td>\n",
       "      <td>0.712535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.006121</td>\n",
       "      <td>0.553571</td>\n",
       "      <td>0.648197</td>\n",
       "      <td>0.686649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.001007</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>0.765172</td>\n",
       "      <td>0.636018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.000203</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.74934</td>\n",
       "      <td>0.671782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.034583</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.565523</td>\n",
       "      <td>0.765165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.035923</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.575198</td>\n",
       "      <td>0.763694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.036091</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.565523</td>\n",
       "      <td>0.76272</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model_score sensitivity accuracy_rate       roc\n",
       "0     0.001732    0.464286      0.722076  0.638265\n",
       "1     0.029554    0.714286       0.60774  0.706324\n",
       "2     0.000269    0.446429      0.743184  0.651546\n",
       "3     0.004397    0.535714      0.689534  0.647218\n",
       "4     0.001799    0.553571      0.685136  0.635936\n",
       "5     0.001007    0.392857      0.765172  0.636018\n",
       "6     0.000269    0.446429      0.743184  0.651546\n",
       "7     0.036163       0.875      0.567282  0.761233\n",
       "8     0.001007    0.392857      0.765172  0.636018\n",
       "9     0.000203    0.464286       0.74934  0.671782\n",
       "10    0.029408    0.732143      0.599824  0.699468\n",
       "11    0.001007    0.392857      0.765172  0.636018\n",
       "12    0.001007    0.392857      0.765172  0.636018\n",
       "13    0.005611    0.589286       0.66051  0.698923\n",
       "14    0.001007    0.392857      0.765172  0.636018\n",
       "15    0.036219       0.875      0.563764  0.757153\n",
       "16    0.001993    0.482143      0.719437  0.627362\n",
       "17    0.000269    0.446429      0.743184  0.651546\n",
       "18    0.032351    0.767857      0.596306  0.742946\n",
       "19    0.028606    0.767857      0.586631  0.710354\n",
       "20    0.035931       0.875      0.564644  0.762819\n",
       "21    0.001007    0.392857      0.765172  0.636018\n",
       "22    0.000203    0.464286       0.74934  0.671782\n",
       "23     0.02751    0.785714      0.580475  0.712535\n",
       "24    0.006121    0.553571      0.648197  0.686649\n",
       "25    0.001007    0.392857      0.765172  0.636018\n",
       "26    0.000203    0.464286       0.74934  0.671782\n",
       "27    0.034583       0.875      0.565523  0.765165\n",
       "28    0.035923    0.892857      0.575198  0.763694\n",
       "29    0.036091    0.892857      0.565523   0.76272"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_performance_diff_sens = pd.DataFrame(columns=['model_score', 'sensitivity','accuracy_rate','roc'])\n",
    "for ind, row in para_dfm.iterrows():\n",
    "    print(f\"The model_score is: {row['model_score']}\")\n",
    "    model_pred = model_list[ind]\n",
    "    X_pred = model_pred.predict(X_val)\n",
    "    mse = np.mean(np.power(X_val.flatten() - X_pred.flatten(), 2))\n",
    "    reconstructions = model_pred.predict(X_val)\n",
    "    val_loss = tf.keras.losses.mae(reconstructions, X_val)\n",
    "    # sns.histplot(x=val_loss,y=y_val.flatten(),hue=y_val.flatten())\n",
    "    # plt.show()\n",
    "    df_tmp = pd.DataFrame({\"val_loss\": val_loss, \"y_val\": y_val.flatten()})\n",
    "    df_tmp_fraud = df_tmp[df_tmp[\"y_val\"] == 1]\n",
    "    df_tmp_non_fraud = df_tmp[df_tmp[\"y_val\"] == 0]\n",
    "    mse = np.mean(np.power(X_val.flatten() - X_pred.flatten(), 2))\n",
    "    error_df = pd.DataFrame({'Reconstruction_error': mse, 'True_class': y_val.flatten()})\n",
    "    df_temp = pd.DataFrame({'Reconstruction_error': val_loss, 'True_class': y_val.flatten()})\n",
    "    roc = roc_auc_score(y_val.flatten(), val_loss)\n",
    "    threshold = np.mean(df_temp[\"Reconstruction_error\"])\n",
    "    pred_y = np.where(val_loss > threshold, 1, 0)\n",
    "    cm = confusion_matrix(y_val.flatten(), pred_y)\n",
    "    accuracy_rate = (cm[0,0] + cm[1,1])/np.sum(cm)\n",
    "    # calculate the sensitivity \n",
    "    sensitivity = cm[1,1]/(cm[1,1] + cm[1,0])\n",
    "    print(sensitivity)\n",
    "    df_performance_diff_sens = df_performance_diff_sens.append({\"model_score\": row['model_score'], \"sensitivity\": sensitivity,'accuracy_rate':accuracy_rate,'roc':roc}, ignore_index=True)\n",
    "df_performance_diff_sens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to explore the distubution of the fraud cases in the test set of each model. Usually, the higher the model score, the fraud cases are more likely to be concentrated at a large number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model_score is: 0.0017324490623488852\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model_score is: 0.02955409999976271\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model_score is: 0.00026917694689201075\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model_score is: 0.004396980136256059\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model_score is: 0.0017993927538018809\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model_score is: 0.0010065635818173996\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model_score is: 0.00026917694689201075\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model_score is: 0.036162773309437936\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model_score is: 0.0010065635818173996\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model_score is: 0.00020301059329618464\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model_score is: 0.029407983100715334\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAANmElEQVR4nO3dXYhc93nH8e9TyW6cpMEyWrmqZXcTEGlDobbZpmpdymLFIJIQ+SKGBJKq4CACDThtQ6q0F51cFHxRglsoBWGnVZs0QSSmFobSCiVLKKSOV4njWJUT5dVRq1qbgOu0F3lpnl7McbIazdvO+7P6fmCZOWfO2fPTas9v//ufObORmUiS6vmZeQeQJI3GApekoixwSSrKApekoixwSSpq5ywPtnv37lxeXp7lISWpvLNnz34nM5c618+0wJeXl1lfX5/lISWpvIj4Vrf1TqFIUlEWuCQVZYFLUlEWuCQVZYFLUlEWuCQVZYFLUlEWuCQVZYFLUlEzvRJTC67V6r8saaE4ApekoixwSSrKApekoixwSSrKApekoixwSSrKApekoixwSSrKApekoixwSSrKApekoixwSSrKApekoixwSSrKApekoixwSSrKApekoixwSSrKApekoixwSSrKApekoixwSSrKApekoixwSSrKApekoixwSSrKApekoixwSSpq6AKPiB0R8YWIeLxZvikiTkfEheZ21/RiSpI6bWUE/gBwftPyMeBMZu4HzjTLkqQZGarAI2If8Cbg4U2rDwMnmvsngHsnmkyS1NewI/CHgPcDP9607ubMvATQ3O6ZbDRJUj8DCzwi3gxczsyzoxwgIo5GxHpErG9sbIzyKSRJXQwzAr8LeEtEfBP4OHB3RHwEeD4i9gI0t5e77ZyZxzNzJTNXlpaWJhRbkjSwwDPzA5m5LzOXgbcBn8rMdwCngCPNZkeAx6aWUpJ0lXFeB/4gcE9EXADuaZYlSTOycysbZ+YasNbc/y5wcPKRJEnD8EpMSSrKApekoixwSSpqS3Pg0hVarf7LGsyvocbgCFySirLAJakoC1ySirLAJakoC1ySirLAJakoC1ySirLAJakoC1ySirLAJakoC1ySirLAJakoC1ySirLAJakoC1ySirLAJakoC1ySirLAJakoC1ySirLAJakoC1ySirLAJakoC1ySirLAJakoC1ySirLAJakoC1ySirLAJakoC1ySirLAJakoC1ySihpY4BHxsoj4XER8MSLORcQHm/U3RcTpiLjQ3O6aflxJ0kuGGYF/H7g7M38VuB04FBEHgGPAmczcD5xpliVJMzKwwLPtf5rF65qPBA4DJ5r1J4B7pxFQktTdUHPgEbEjIp4CLgOnM/MJ4ObMvATQ3O7pse/RiFiPiPWNjY0JxZYkDVXgmfl/mXk7sA94fUT8yrAHyMzjmbmSmStLS0sjxpQkddrSq1Ay8wVgDTgEPB8RewGa28uTDidJ6m2YV6EsRcSNzf0bgDcAzwKngCPNZkeAx6aUUZLUxc4httkLnIiIHbQL/2RmPh4RnwVORsT9wHPAfVPMKUnqMLDAM/Np4I4u678LHJxGKEnSYF6JKUlFDTOFomlrtfovT+NzTuIYkubKEbgkFWWBS1JRFrgkFWWBS1JRFrgkFWWBS1JRFrgkFWWBS1JRFrgkFWWBS1JRFrgkFWWBS1JRFrgkFWWBS1JRFrgkFWWBS1JRFrgkFWWBS1JRFrgkFWWBS1JR/lHjMfT6u8D+vWBJs2CBT4HFLmkWnEKRpKIscEkqygKXpKIscEkqygKXpKIscEkqygKXpKIscEkqygKXpKIscEkqykvpF5iX5EvqZ+AIPCJujYhPR8T5iDgXEQ8062+KiNMRcaG53TX9uJKklwwzhfIj4A8z85eBA8DvRcTrgGPAmczcD5xpliVJMzKwwDPzUmZ+vrn/PeA8cAtwGDjRbHYCuHdKGSVJXWxpDjwiloE7gCeAmzPzErRLPiL29NjnKHAU4Lbbbhsr7FZMcv7YOWdJi2joV6FExCuBTwLvzcwXh90vM49n5kpmriwtLY2SUZLUxVAj8Ii4jnZ5fzQzH21WPx8Re5vR917g8rRCTlK/0bQjbUmVDCzwiAjgEeB8Zn5o00OngCPAg83tY1NJOEMWuKRKhhmB3wW8E/hSRDzVrPtj2sV9MiLuB54D7ptKwmrW1q5cXl2d/OdsrV29zaCfPpP46TTKMba6zzA5R9lnGubxNXeUoU0GFnhm/isQPR4+ONk421vPJ1ZnGULStuGVmNvIFT8g1lZ/un51bcZJJM2C74UiSUU5Ar+GtTaN0q9Y74hdKsERuCQVZYFLUlEWuCQV5Rz4ArhqLro1jxSSqnEELklFWeCSVJQFLklFWeCSVJRPYhbU9QKc1qxTSJo3R+CSVJQFLklFWeCSVJQFLklFWeCSVJQFLklFWeCSVJQFLklFWeCSVJQFLklFWeCSVJTvhXIN6PXHiyXV5ghckoqywCWpKAtckoqywCWpKAtckoqywCWpKAtckoqywCWpKAtckoqywCWpqIEFHhEfjojLEfHMpnU3RcTpiLjQ3O6abkxJUqdhRuB/CxzqWHcMOJOZ+4EzzbIkaYYGvplVZn4mIpY7Vh8GVpv7J4A14I8mGUzz85M3v2p1PNDnTbFaq2vTCSOpp1HnwG/OzEsAze2eXhtGxNGIWI+I9Y2NjREPJ0nqNPUnMTPzeGauZObK0tLStA8nSdeMUd8P/PmI2JuZlyJiL3B5kqG2otVq7qytXfnA6urVG3duM0i3z7Gotvpvm5fmP+yn71G+euXDM86xLXX+2wb9W7s9vp2/PtvIqCPwU8CR5v4R4LHJxJEkDWvgCDwiPkZ7mLQ7Ii4Cfwo8CJyMiPuB54D7phlS145eAz8HhNLVhnkVytt7PHRwwlm0DV1VvP55N2livBJTkoqywCWpKP8qvSai1WtqpMdqSeNzBC5JRVngklSUUygqrbW22vXqH192qGuBI3BJKsoCl6SiLHBJKsoCl6SiLHBJKsoCl6SiLHBJKsoCl6SivJBHJVxxYY5vSSsBFrjUV8836QJaq2szyyF14xSKJBVlgUtSUU6hSPSfKhn5c7U61ncsS+NyBC5JRTkC1zXlJ6PgCYy4Jzlql0bhCFySirLAJakoC1ySiiozB+4z+JJ0JUfgklRUmRG4tBXb4Te2VourXy3T2h7/Nk2GBS4V06vALfZrj1MoklSUBS5JRTmFIs3ZFVd0tuaVQhU5ApekohyBSzPS9UlG309FY7DApW2i1xt1tdB25RSKJBU11gg8Ig4BfwHsAB7OzAcnkkrSxAx8fXi3aZwu+4zyOvOt7jOp17JfK6+VH7nAI2IH8FfAPcBF4MmIOJWZ/z6pcJIWxzzLr0oh98szjazjTKG8HvhqZn49M38AfBw4PJlYkqRBIjNH2zHircChzHxXs/xO4Ncz8z0d2x0FjjaLrwW+PHrcvnYD35nS554WM8+GmWfDzNPzi5m51LlynDnw6LLuqp8GmXkcOD7GcYYLE7GemSvTPs4kmXk2zDwbZp69caZQLgK3blreB/zneHEkScMap8CfBPZHxKsj4nrgbcCpycSSJA0y8hRKZv4oIt4D/DPtlxF+ODPPTSzZ1k19mmYKzDwbZp4NM8/YyE9iSpLmyysxJakoC1ySilr4Ao+IQxHx5Yj4akQc6/J4RMRfNo8/HRF3djy+IyK+EBGPV8gcETdGxCci4tmIOB8Rv1Eg8+9HxLmIeCYiPhYRL1uQzL8UEZ+NiO9HxPu2su+iZY6IWyPi0833xLmIeGDRM296fBHPwX7fG3M5B0eSmQv7QfvJ0a8BrwGuB74IvK5jmzcC/0T7dekHgCc6Hv8D4B+AxytkBk4A72ruXw/cuMiZgVuAbwA3NMsngd9dkMx7gF8D/gx431b2XcDMe4E7m/s/B3xl0TNvenwRz8GemedxDo76segj8GEu1z8M/F22/RtwY0TsBYiIfcCbgIcrZI6IVwG/DTwCkJk/yMwXFjlz89hO4IaI2Am8nNlcDzAwc2ZezswngR9udd9Fy5yZlzLz88397wHnaf/wXNjMsLjnYK/MczwHR7LoBX4L8O1Nyxe5+pu23zYPAe8HfjylfN2Mk/k1wAbwN82vnA9HxCumGXZAnoHbZOZ/AH8OPAdcAv47M/9liln75pnBvuOYyHEjYhm4A3hiMrH6GjfzQyzmOdjLvM7BkSx6gQ9zuX7XbSLizcDlzDw7+Vh9jZyZ9kj2TuCvM/MO4H+BWczPjvN13kV7dPNq4BeAV0TEOyacr5uh3sphCvuOY+zjRsQrgU8C783MFyeSasAhu6wbKvOCn4O9zOscHMmiF/gwl+v32uYu4C0R8U3av0LdHREfmV7UgXmG2eYicDEzXxpZfYL2N9O0jZP5DcA3MnMjM38IPAr85hSzDsoz7X3HMdZxI+I62uX90cx8dMLZehkn8yKfg/32ncc5OJJFL/BhLtc/BfxO8yqJA7R/hb+UmR/IzH2Zudzs96nMnMXIcJzM/wV8OyJe22x3EJjF+6uPnJn21MmBiHh5REST+fyCZJ7GvuMY+bjN1/YR4HxmfmiKGTuNnHnBz8Gu5ngOjmbez6IO+qD96oev0H5W+U+ade8G3t3cD9p/WOJrwJeAlS6fY5UZPQM+bmbgdmAdeBr4R2BXgcwfBJ4FngH+HvjZBcn887RHVC8CLzT3X9Vr30XODPwW7WmAp4Gnmo83LnLmjs+xaOdgv++NuZyDo3x4Kb0kFbXoUyiSpB4scEkqygKXpKIscEkqygKXpKIscEkqygKXpKL+HyXxYdnUUSn8AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model_score is: 0.0010065635818173996\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model_score is: 0.0010065635818173996\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model_score is: 0.005610904483660444\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model_score is: 0.0010065635818173996\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model_score is: 0.03621902804128503\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model_score is: 0.0019925031825803225\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model_score is: 0.00026917694689201075\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAARkElEQVR4nO3dX4xcZ33G8e+DEwIikZIom8jYVh2QqZqg4kQrN1Iq5BLauAHVQWoqcxHlIpVBSiRQkaqESmW5sMQF/1qpQTIQYVogtQQoFoKWEGFR1DZmE5w/TkgxJE0WW/ECRSQ3ae38erEnZHBmd2d3ZnbXr78f6WjOvOc9Z36vd/3M8TtnjlNVSJLa8prVLkCSNHqGuyQ1yHCXpAYZ7pLUIMNdkhp0zmoXAHDJJZfU5s2bV7sMSTqjPPjggz+vqol+29ZEuG/evJnp6enVLkOSzihJ/nu+bU7LSFKDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYtGu5JXpfkUJKHkxxJ8tGufSrJz5Ic7pYbeva5M8nRJE8muX6cA5Akvdog17m/CLyjql5Ici7w/STf6rZ9qqo+3ts5yRXALuBK4I3Ad5K8papOjbJwSdL8Fj1zrzkvdE/P7ZaFbgK/E7inql6sqqeAo8C2oSuVJA1soDn3JOuSHAZOAPdV1QPdptuTPJLk7iQXdW0bgGd7dp/p2k4/5u4k00mmZ2dnlz+CUZuamlsk6Qw2ULhX1amq2gpsBLYleSvwGeDNwFbgOPCJrnv6HaLPMfdW1WRVTU5M9L01giRpmZZ0tUxV/Qo4COyoque60H8J+CyvTL3MAJt6dtsIHBu+VEnSoAa5WmYiyYXd+uuBdwI/SrK+p9t7gMe69QPAriTnJbkc2AIcGmnVkqQFDXK1zHpgX5J1zL0Z7K+qbyT5xyRbmZtyeRp4H0BVHUmyH3gcOAnc5pUykrSyFg33qnoEuKpP+80L7LMH2DNcaZKk5fIbqpLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJatCi4Z7kdUkOJXk4yZEkH+3aL05yX5Ifd48X9exzZ5KjSZ5Mcv04ByBJerVBztxfBN5RVW8DtgI7klwD3AHcX1VbgPu75yS5AtgFXAnsAO5Ksm4MtUuS5rFouNecF7qn53ZLATuBfV37PuDGbn0ncE9VvVhVTwFHgW2jLFqStLCB5tyTrEtyGDgB3FdVDwCXVdVxgO7x0q77BuDZnt1nurbTj7k7yXSS6dnZ2SGGIEk63UDhXlWnqmorsBHYluStC3RPv0P0OebeqpqsqsmJiYmBipUkDWZJV8tU1a+Ag8zNpT+XZD1A93ii6zYDbOrZbSNwbNhCJUmDG+RqmYkkF3brrwfeCfwIOADc0nW7Bbi3Wz8A7EpyXpLLgS3AoRHXLUlawDkD9FkP7OuueHkNsL+qvpHkP4D9SW4FngFuAqiqI0n2A48DJ4HbqurUeMqXJPWzaLhX1SPAVX3afwFcN88+e4A9Q1cnSVoWv6EqSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGjTIde5nrKmppbVLUis8c5ekBhnuktQgw12SGtT0nPt8nIuX1DrP3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1aNFwT7IpyXeTPJHkSJIPdO1TSX6W5HC33NCzz51JjiZ5Msn14xyAJOnVBrm3zEngQ1X1UJILgAeT3Ndt+1RVfby3c5IrgF3AlcAbge8keUtVnRpl4ZKk+S165l5Vx6vqoW79eeAJYMMCu+wE7qmqF6vqKeAosG0UxUqSBrOkOfckm4GrgAe6ptuTPJLk7iQXdW0bgGd7dpuhz5tBkt1JppNMz87OLr1ySdK8Bg73JOcDXwU+WFW/Bj4DvBnYChwHPvFy1z6716saqvZW1WRVTU5MTCy1bknSAgYK9yTnMhfsX6qqrwFU1XNVdaqqXgI+yytTLzPApp7dNwLHRleyJGkxg1wtE+DzwBNV9cme9vU93d4DPNatHwB2JTkvyeXAFuDQ6EqWJC1mkKtlrgVuBh5Ncrhr+zDw3iRbmZtyeRp4H0BVHUmyH3icuSttbvNKGUlaWYuGe1V9n/7z6N9cYJ89wJ4h6pIkDcFvqEpSgwx3SWqQ4S5JDTLcJalBg1wt06aDB19Z3759taqQpLHwzF2SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGLRruSTYl+W6SJ5IcSfKBrv3iJPcl+XH3eFHPPncmOZrkySTXj3MAkqRXG+TM/STwoar6PeAa4LYkVwB3APdX1Rbg/u453bZdwJXADuCuJOvGUbwkqb9Fw72qjlfVQ93688ATwAZgJ7Cv67YPuLFb3wncU1UvVtVTwFFg24jrliQtYElz7kk2A1cBDwCXVdVxmHsDAC7tum0Anu3ZbaZrkyStkIHDPcn5wFeBD1bVrxfq2qet+hxvd5LpJNOzs7ODliFJGsBA4Z7kXOaC/UtV9bWu+bkk67vt64ETXfsMsKln943AsdOPWVV7q2qyqiYnJiaWW78kqY9BrpYJ8Hngiar6ZM+mA8At3fotwL097buSnJfkcmALcGh0JUuSFnPOAH2uBW4GHk1yuGv7MPAxYH+SW4FngJsAqupIkv3A48xdaXNbVZ0adeGLmpqCg9vn1rdvX/GXl6TVtGi4V9X36T+PDnDdPPvsAfYMUZckaQh+Q1WSGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYuGe5K7k5xI8lhP21SSnyU53C039Gy7M8nRJE8muX5chS/JwYOvLMOamppbJGkNG+TM/QvAjj7tn6qqrd3yTYAkVwC7gCu7fe5Ksm5UxUqSBrNouFfV94BfDni8ncA9VfViVT0FHAW2DVGfJGkZhplzvz3JI920zUVd2wbg2Z4+M13bqyTZnWQ6yfTs7OwQZUiSTrfccP8M8GZgK3Ac+ETXnj59q98BqmpvVU1W1eTExMQyy5Ak9bOscK+q56rqVFW9BHyWV6ZeZoBNPV03AseGK1GStFTLCvck63uevgd4+UqaA8CuJOcluRzYAhwarkRJ0lKds1iHJF8BtgOXJJkBPgJsT7KVuSmXp4H3AVTVkST7gceBk8BtVXVqLJVLkua1aLhX1Xv7NH9+gf57gD3DFCVJGo7fUJWkBhnuktQgw12SGmS4S1KDDHdJatCiV8ucTaamgIPbuyentUvSGcQzd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDzr4vMR08uIy27WMpRZLGxTN3SWqQ4S5JDTLcJalBhrskNchwl6QGLRruSe5OciLJYz1tFye5L8mPu8eLerbdmeRokieTXD+uwiVJ8xvkzP0LwI7T2u4A7q+qLcD93XOSXAHsAq7s9rkrybqRVStJGsii4V5V3wN+eVrzTmBft74PuLGn/Z6qerGqngKOAttGU6okaVDLnXO/rKqOA3SPl3btG4Bne/rNdG2SpBU06g9U06et+nZMdieZTjI9Ozs74jIk6ey23HB/Lsl6gO7xRNc+A2zq6bcRONbvAFW1t6omq2pyYmJimWVIkvpZbrgfAG7p1m8B7u1p35XkvCSXA1uAQ8OVKElaqkVvHJbkK8zdOeuSJDPAR4CPAfuT3Ao8A9wEUFVHkuwHHgdOArdV1akx1S5Jmsei4V5V751n03Xz9N8D7BmmKEnScPyGqiQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBi36JScDU1GBtC7Uv51iStEyeuUtSgwx3SWqQ4S5JDTLcJalBhrskNcirZQYwdXB7//btB1e0DkkalGfuktQgw12SGtTEtEzf7wDNM5UiSWcDz9wlqUGGuyQ1yHCXpAYNNeee5GngeeAUcLKqJpNcDPwzsBl4GviLqvqf4cqUJC3FKM7c/6iqtlbVZPf8DuD+qtoC3N89lyStoHFMy+wE9nXr+4Abx/AakqQFDBvuBXw7yYNJdndtl1XVcYDu8dJ+OybZnWQ6yfTs7OyQZUiSeg17nfu1VXUsyaXAfUl+NOiOVbUX2AswOTlZQ9YhSeox1Jl7VR3rHk8AXwe2Ac8lWQ/QPZ4YtkhJ0tIsO9yTvCHJBS+vA38CPAYcAG7put0C3DtskZKkpRlmWuYy4OtJXj7Ol6vqX5L8ANif5FbgGeCm4cuUJC3FssO9qn4KvK1P+y+A64YpSpI0HL+hKkkNauKukGte39tWLnP7y+vL2WcQgx5/XMbx+sv9s5DOYJ65S1KDDHdJapDTMkPo+3+rTvkvf0mrzzN3SWqQ4S5JDTLcJalBhrskNchwl6QGebXMGLzqapnuqpqp7QdXuBJJZyvP3CWpQYa7JDXIcJekBhnuktQgP1BdQX1vV4AftEoaPcN9DTD0JY2a0zKS1CDDXZIa5LTMGvab6ZqpnsZ+bb37zNMu6ezimbskNWhsZ+5JdgB/B6wDPldVHxvXa+kVvzlz7/2QdsozeulsM5ZwT7IO+Afgj4EZ4AdJDlTV4+N4PS1uvnBfavtSjz9uo6p/tV9jtbQ8trPduM7ctwFHq+qnAEnuAXYChvsaM99Nztg+5HEWaZ/3OIt8pjAKowqu1XrDHPfrLmS13gxaeBNa6TGkqkZ/0OTPgR1V9Zfd85uBP6iq23v67AZ2d09/F3hygENfAvx8xOWuVWfLWB1nWxznyvqdqprot2FcZ+7p0/Zb7yJVtRfYu6SDJtNVNTlMYWeKs2WsjrMtjnPtGNfVMjPApp7nG4FjY3otSdJpxhXuPwC2JLk8yWuBXcCBMb2WJOk0Y5mWqaqTSW4H/pW5SyHvrqojIzj0kqZxznBny1gdZ1sc5xoxlg9UJUmry2+oSlKDDHdJatCaCfckO5I8meRokjv6bE+Sv++2P5Lk6kH3XUuGHOfdSU4keWxlq1665Y4zyaYk303yRJIjST6w8tUPbohxvi7JoSQPd+P86MpXP7hhfm+77euS/DDJN1au6uUZ8u/o00keTXI4yfTKVn6aqlr1hbkPXX8CvAl4LfAwcMVpfW4AvsXcNfTXAA8Muu9aWYYZZ7ft7cDVwGOrPZYx/jzXA1d36xcA/9Xiz7N7fn63fi7wAHDNao9pHL+33fa/Ar4MfGO1xzPOsQJPA5es9jiqas2cuf/mdgVV9b/Ay7cr6LUT+GLN+U/gwiTrB9x3rRhmnFTV94BfrmjFy7PscVbV8ap6CKCqngeeADasZPFLMMw4q6pe6Pqc2y1r9eqGoX5vk2wE3gV8biWLXqahxrqWrJVw3wA82/N8hlf/hZ6vzyD7rhXDjPNMMpJxJtkMXMXcWe1aNNQ4u6mKw8AJ4L6qanKcwKeBvwZeGlN9ozTsWAv4dpIHu1usrJq1Eu6L3q5ggT6D7LtWDDPOM8nQ40xyPvBV4INV9esR1jZKQ42zqk5V1VbmvsG9LclbR1veyCx7nEneDZyoqgdHX9ZYDPu7e21VXQ38KXBbkrePsrilWCvhPsjtCubrcybd6mCYcZ5JhhpnknOZC/YvVdXXxljnsEby86yqXwEHgR0jr3A0hhnntcCfJXmauSmOdyT5p/GVOrShfqZV9fLjCeDrzE3zrI7VnvSvuQ8hzgF+ClzOKx9iXHlan3fx2x9iHBp037WyDDPOnu2bWfsfqA7z8wzwReDTqz2OMY9zAriwW3898G/Au1d7TKMe52l9trP2P1Ad5mf6BuCCnvV/Z+7uuKszltX+w+z5A7uBuSsjfgL8Tdf2fuD93XqY+w9AfgI8CkwutO9aXYYc51eA48D/MXf2cOtqj2fU4wT+kLl/4j4CHO6WG1Z7PGMY5+8DP+zG+Rjwt6s9lnH93vYcY82H+5A/0zcx92bwMHBktbPI2w9IUoPWypy7JGmEDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUoP8Hs4SJURE6eAUAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model_score is: 0.032350758632074136\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model_score is: 0.02860636884771137\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model_score is: 0.035931039090865306\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model_score is: 0.0010065635818173996\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model_score is: 0.00020301059329618464\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAOAklEQVR4nO3db4hl9X3H8fcnqzEBCyo72mV36W5hKdVAVZatIJRFW1yqZH1QyxYqS7EsBUMTWgiaJ5k8WPBRMYVKWYx0JWm2Cwm4SEqQbYe00LpZE01crXUbrQ6KO0kaklCwuH77YE7MdXdm58zcP3P3N+8XXO45v/M7537vj5nPnDnn3HNTVUiS2vKR9S5AkjR6hrskNchwl6QGGe6S1CDDXZIadMV6FwCwefPm2rFjx3qXIUmXleeee+6HVTWz1LKpCPcdO3Zw+vTp9S5Dki4rSf57uWUelpGkBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAZNxSdUx2V2dnXtktQK99wlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNah3uCfZlOS7SZ7u5q9L8kySV7vnawf6PpzkbJJXktw1jsIlSctbzZ77p4GXB+YfAk5W1S7gZDdPkhuBA8BNwD7gsSSbRlOuJKmPXuGeZBtwN/D4QPN+4Gg3fRS4d6D9WFW9W1WvAWeBPSOpVpLUS98990eBzwLvD7TdUFVvA3TP13ftW4E3B/rNd20fkuRQktNJTi8sLKy2bknSJawY7knuAc5V1XM9t5kl2uqihqojVbW7qnbPzMz03LQkqY8+e+63A59M8jpwDLgjyZeBd5JsAeiez3X954HtA+tvA94aWcXDmJtbfHhDd0mNWzHcq+rhqtpWVTtYPFH6T1X1x8AJ4GDX7SDwVDd9AjiQ5KokO4FdwKmRVy5JWtYw38T0CHA8yQPAG8B9AFV1Jslx4CXgPeDBqjo/dKWSpN5WFe5VNQfMddM/Au5cpt9h4PCQtUmS1shPqEpSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBl2x3gWM3dzcyn1mZ5eelqTL1Ip77kk+luRUkheSnEnyha79uiTPJHm1e752YJ2Hk5xN8kqSu8b5BiRJF+tzWOZd4I6q+i3gZmBfktuAh4CTVbULONnNk+RG4ABwE7APeCzJpjHULklaxorhXot+3s1e2T0K2A8c7dqPAvd20/uBY1X1blW9BpwF9oyyaEnSpfU6oZpkU5LngXPAM1X1LHBDVb0N0D1f33XfCrw5sPp813bhNg8lOZ3k9MLCwhBvQZJ0oV7hXlXnq+pmYBuwJ8knLtE9S21iiW0eqardVbV7ZmamV7GSpH5WdSlkVf0EmGPxWPo7SbYAdM/num7zwPaB1bYBbw1bqCSpvz5Xy8wkuaab/jjwu8B/ACeAg123g8BT3fQJ4ECSq5LsBHYBp0ZctyTpEvpc574FONpd8fIR4HhVPZ3k34DjSR4A3gDuA6iqM0mOAy8B7wEPVtX58ZQvSVrKiuFeVd8Dblmi/UfAncuscxg4PHR1kqQ18fYDktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ26Yr0LWA+zc3thdqBhbu9i+965yRcjSWPgnrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktSgNu8tMzu7+NzdM2Zs279wWpKmhHvuktQgw12SGmS4S1KDDHdJapDhLkkNWvFqmSTbgSeBXwXeB45U1ReTXAf8A7ADeB34w6r6n26dh4EHgPPAn1fVN8dSfeeiC1bGdZWMJF0m+uy5vwf8ZVX9JnAb8GCSG4GHgJNVtQs42c3TLTsA3ATsAx5LsmkcxUuSlrZiuFfV21X1nW76Z8DLwFZgP3C063YUuLeb3g8cq6p3q+o14CywZ8R1S5IuYVXH3JPsAG4BngVuqKq3YfEPAHB9120r8ObAavNd24XbOpTkdJLTCwsLayhdkrSc3uGe5Grga8Bnquqnl+q6RFtd1FB1pKp2V9XumZmZvmVIknroFe5JrmQx2L9SVV/vmt9JsqVbvgU417XPA9sHVt8GvDWaciVJfawY7kkCfAl4uar+amDRCeBgN30QeGqg/UCSq5LsBHYBp0ZXsiRpJX1uHHY7cD/w/STPd22fAx4Bjid5AHgDuA+gqs4kOQ68xOKVNg9W1flRFy5JWt6K4V5V/8rSx9EB7lxmncPA4SHqkiQNwU+oSlKDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJatAV613ANJmd2wuzS7Qv0SZJ08xw78uEl3QZ8bCMJDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUoBXDPckTSc4leXGg7bokzyR5tXu+dmDZw0nOJnklyV3jKlyStLw+e+5/B+y7oO0h4GRV7QJOdvMkuRE4ANzUrfNYkk0jq1aS1MuK4V5V3wJ+fEHzfuBoN30UuHeg/VhVvVtVrwFngT2jKVWS1Ndaj7nfUFVvA3TP13ftW4E3B/rNd22SpAka9QnVLNFWS3ZMDiU5neT0wsLCiMuQpI1treH+TpItAN3zua59Htg+0G8b8NZSG6iqI1W1u6p2z8zMrLEMSdJS1hruJ4CD3fRB4KmB9gNJrkqyE9gFnBquREnSaq34NXtJvgrsBTYnmQc+DzwCHE/yAPAGcB9AVZ1Jchx4CXgPeLCqzo+pdknSMlYM96r6o2UW3blM/8PA4WGKkiQNZ+N+QfbcXP8+sz36woe/RHtUX6g9jm1uBI6bNjhvPyBJDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDVo495bZhVm5/Yu3b53bqJ1SFJf7rlLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KD/ITqhebmVtd/dnbt7ctNr/Z1V7vuJLc/ze/xcqlBWgP33CWpQYa7JDXIcJekBhnuktQgw12SGuTVMkPwPu+SppV77pLUIMNdkhpkuEtSgwx3SWqQ4S5JDfJqmTHwKhpJ681wn6DZub0wO9DQ/REw9CWNmodlJKlB7rlPgYv26H/RvkSbJPVhuE+x2Vk+OHSz2DDQLkmX4GEZSWrQ2Pbck+wDvghsAh6vqkfG9VobzXJ79B8sW26dVbRLuryNJdyTbAL+Bvg9YB74dpITVfXSOF5PvzSqsJ5d5R+PjWiYbw2Uxm1ce+57gLNV9QOAJMeA/YDhPmXGHTir/SPxofZl1u31uqvrfvFrj6CGXtsfYf+1uFz+07tc6ryUSdeaqhr9RpM/APZV1Z928/cDv11Vnxrocwg41M3+BvBKj01vBn444nJb5Dj151j14zj1M+lx+rWqmllqwbj23LNE24f+ilTVEeDIqjaanK6q3cMUthE4Tv05Vv04Tv1M0ziN62qZeWD7wPw24K0xvZYk6QLjCvdvA7uS7EzyUeAAcGJMryVJusBYDstU1XtJPgV8k8VLIZ+oqjMj2PSqDuNsYI5Tf45VP45TP1MzTmM5oSpJWl9+QlWSGmS4S1KDpibck+xL8kqSs0keWmJ5kvx1t/x7SW7tu25LhhynJ5KcS/LiZKuevLWOU5LtSf45yctJziT59OSrn5whxuljSU4leaEbpy9MvvrJGeb3rlu+Kcl3kzw9saKrat0fLJ50/S/g14GPAi8AN17Q5/eBf2TxGvrbgGf7rtvKY5hx6pb9DnAr8OJ6v5dpHSdgC3BrN/0rwH/687TkOAW4upu+EngWuG2939O0jdPA8r8A/h54elJ1T8ue+we3K6iq/wN+cbuCQfuBJ2vRvwPXJNnSc91WDDNOVNW3gB9PtOL1seZxqqq3q+o7AFX1M+BlYOski5+gYcapqurnXZ8ru0erV2cM9XuXZBtwN/D4JIuelnDfCrw5MD/Pxb9Qy/Xps24rhhmnjWQk45RkB3ALi3ulLRpqnLpDDc8D54BnqspxWrrPo8BngffHVN+SpiXcV7xdwSX69Fm3FcOM00Yy9DgluRr4GvCZqvrpCGubJkONU1Wdr6qbWfwE+p4knxhteVNjzeOU5B7gXFU9N/qyLm1awr3P7QqW67ORbnUwzDhtJEONU5IrWQz2r1TV18dY53obyc9TVf0EmAP2jbzC6TDMON0OfDLJ6ywezrkjyZfHV+qA9T5Z0Z1suAL4AbCTX56wuOmCPnfz4RMWp/qu28pjmHEaWL6D9k+oDvPzFOBJ4NH1fh9TPk4zwDXd9MeBfwHuWe/3NG3jdEGfvUzwhOpUfIdqLXO7giR/1i3/W+AbLJ6RPgv8L/Anl1p3Hd7G2A0zTgBJvsriD9jmJPPA56vqS5N9F+M35DjdDtwPfL87ngzwuar6xgTfwkQMOU5bgKPdF/N8BDheVZO7zG+Chv29Wy/efkCSGjQtx9wlSSNkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QG/T/tS0apdMNnCAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model_score is: 0.027510410438838513\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model_score is: 0.006121217889033317\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model_score is: 0.0010065635818173996\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model_score is: 0.00020301059329618464\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model_score is: 0.034582983664973296\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model_score is: 0.03592332742311696\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model_score is: 0.036090885252058544\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for ind, row in para_dfm.iterrows():\n",
    "    print(f\"The model_score is: {row['model_score']}\")\n",
    "    model_pred = model_list[ind]\n",
    "    X_pred = model_pred.predict(X_val)\n",
    "    mse = np.mean(np.power(X_val.flatten() - X_pred.flatten(), 2))\n",
    "    reconstructions = model_pred.predict(X_val)\n",
    "    val_loss = tf.keras.losses.mae(reconstructions, X_val)\n",
    "    # sns.histplot(x=val_loss,y=y_val.flatten(),hue=y_val.flatten())\n",
    "    # plt.show()\n",
    "    df_tmp = pd.DataFrame({\"val_loss\": val_loss, \"y_val\": y_val.flatten()})\n",
    "    df_tmp_fraud = df_tmp[df_tmp[\"y_val\"] == 1]\n",
    "    df_tmp_non_fraud = df_tmp[df_tmp[\"y_val\"] == 0]\n",
    "    plt.hist(df_tmp_fraud[\"val_loss\"], bins=50, alpha=0.5, label=\"fraud\", color=\"red\",density=True)\n",
    "    plt.hist(df_tmp_non_fraud[\"val_loss\"], bins=50, alpha=0.5, label=\"non_fraud\", color=\"blue\",density=True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the relationship between model_score and other columns, we can find a very significant linear relationship between these columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_performance_diff_sens.plot(x='model_score', y='sensitivity', kind='scatter',title='Sensitivity_model_score')\n",
    "plt.show()\n",
    "df_performance_diff_sens.plot(x='model_score', y='roc', kind='scatter',title='ROC_model_score')\n",
    "plt.show()\n",
    "df_performance_diff_sens.plot(x='model_score', y='accuracy_rate', kind='scatter',title='Accuracy_model_score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use statsmodel to test whether it is significant. We can find the p-value of the model is very low, which means the model is significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statsmodels linear regression betwen model_score and sensitivity\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.944\n",
      "Model:                            OLS   Adj. R-squared:                  0.942\n",
      "Method:                 Least Squares   F-statistic:                     473.0\n",
      "Date:                Wed, 09 Mar 2022   Prob (F-statistic):           4.45e-19\n",
      "Time:                        02:52:04   Log-Likelihood:                 50.843\n",
      "No. Observations:                  30   AIC:                            -97.69\n",
      "Df Residuals:                      28   BIC:                            -94.88\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.4344      0.011     39.328      0.000       0.412       0.457\n",
      "x1            11.9295      0.549     21.748      0.000      10.806      13.053\n",
      "==============================================================================\n",
      "Omnibus:                        0.669   Durbin-Watson:                   2.355\n",
      "Prob(Omnibus):                  0.716   Jarque-Bera (JB):                0.690\n",
      "Skew:                           0.090   Prob(JB):                        0.708\n",
      "Kurtosis:                       2.279   Cond. No.                         65.3\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "Statsmodels linear regression betwen model_score and accuracy_rate\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.910\n",
      "Model:                            OLS   Adj. R-squared:                  0.907\n",
      "Method:                 Least Squares   F-statistic:                     284.7\n",
      "Date:                Wed, 09 Mar 2022   Prob (F-statistic):           3.33e-16\n",
      "Time:                        02:52:04   Log-Likelihood:                 69.099\n",
      "No. Observations:                  30   AIC:                            -134.2\n",
      "Df Residuals:                      28   BIC:                            -131.4\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.7436      0.006    123.717      0.000       0.731       0.756\n",
      "x1            -5.0358      0.298    -16.872      0.000      -5.647      -4.424\n",
      "==============================================================================\n",
      "Omnibus:                        8.099   Durbin-Watson:                   2.188\n",
      "Prob(Omnibus):                  0.017   Jarque-Bera (JB):                6.621\n",
      "Skew:                          -1.102   Prob(JB):                       0.0365\n",
      "Kurtosis:                       3.660   Cond. No.                         65.3\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "-------------------------------------------------------\n",
      "Statsmodels linear regression betwen model_score and roc\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.870\n",
      "Model:                            OLS   Adj. R-squared:                  0.865\n",
      "Method:                 Least Squares   F-statistic:                     187.5\n",
      "Date:                Wed, 09 Mar 2022   Prob (F-statistic):           6.23e-14\n",
      "Time:                        02:52:04   Log-Likelihood:                 78.677\n",
      "No. Observations:                  30   AIC:                            -153.4\n",
      "Df Residuals:                      28   BIC:                            -150.6\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.6445      0.004    147.561      0.000       0.636       0.653\n",
      "x1             2.9701      0.217     13.693      0.000       2.526       3.414\n",
      "==============================================================================\n",
      "Omnibus:                        1.623   Durbin-Watson:                   2.561\n",
      "Prob(Omnibus):                  0.444   Jarque-Bera (JB):                1.261\n",
      "Skew:                           0.293   Prob(JB):                        0.532\n",
      "Kurtosis:                       2.184   Cond. No.                         65.3\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "-------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# linear regression #TODO more linear regression test\n",
    "import statsmodels.api as sm\n",
    "X  = np.array(df_performance_diff_sens['model_score'], dtype=float)\n",
    "y = np.array(df_performance_diff_sens['sensitivity'], dtype=float)\n",
    "X = sm.add_constant(X)\n",
    "print(\"Statsmodels linear regression betwen model_score and sensitivity\")\n",
    "model = sm.OLS(y, X).fit()\n",
    "print(model.summary())\n",
    "\n",
    "X = np.array(df_performance_diff_sens['model_score'], dtype=float)\n",
    "y = np.array(df_performance_diff_sens['accuracy_rate'], dtype=float)\n",
    "X = sm.add_constant(X)\n",
    "print(\"Statsmodels linear regression betwen model_score and accuracy_rate\")\n",
    "model = sm.OLS(y, X).fit()\n",
    "print(model.summary())\n",
    "print('-------------------------------------------------------')\n",
    "\n",
    "X = np.array(df_performance_diff_sens['model_score'], dtype=float)\n",
    "y = np.array(df_performance_diff_sens['roc'], dtype=float)\n",
    "X = sm.add_constant(X)\n",
    "print(\"Statsmodels linear regression betwen model_score and roc\")\n",
    "model = sm.OLS(y, X).fit()\n",
    "print(model.summary())\n",
    "print('-------------------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 8\n",
    "Based on the results of the previous question, we can use the model_score to select the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get the index of largest model_score row\n",
    "para_dfm_max_index = para_dfm[para_dfm[\"model_score\"]==max(para_dfm[\"model_score\"])].index[0]\n",
    "# get the loss function of the best model\n",
    "def create_plot(log,limit=None):\n",
    "    if limit:\n",
    "    # plt.plot(log.history['accuracy'],label = \"training accuracy\",color='green')\n",
    "        plt.plot(log.history['loss'][-limit:],label = \"training loss\",color='darkgreen')\n",
    "        # plt.plot(log.history['val_accuracy'], label = \"validation accuracy\",color='grey')\n",
    "        plt.plot(log.history['val_loss'][-limit:], label = \"validation loss\",color='darkblue')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.plot(log.history['loss'],label = \"training loss\",color='darkgreen')\n",
    "        plt.plot(log.history['val_loss'], label = \"validation loss\",color='darkblue')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "create_plot(log_list[para_dfm_max_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_best = model_list[int(para_dfm_max_index)]\n",
    "autoencoder_best.save('models/autoencoder_best.h5')\n",
    "autoencoder_best.save_weights('weights/autoencoder_best_weights.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to reset the weight and train the model again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_weights(model, weights=None):\n",
    "    \"\"\"Randomly permute the weights in `model`, or the given `weights`.\n",
    "\n",
    "    This is a fast approximation of re-initializing the weights of a model.\n",
    "\n",
    "    Assumes weights are distributed independently of the dimensions of the weight tensors\n",
    "      (i.e., the weights have the same distribution along each dimension).\n",
    "\n",
    "    :param Model model: Modify the weights of the given model.\n",
    "    :param list(ndarray) weights: The model's weights will be replaced by a random permutation of these weights.\n",
    "      If `None`, permute the model's current weights.\n",
    "    \"\"\"\n",
    "    if weights is None:\n",
    "        weights = model.get_weights()\n",
    "    weights = [np.random.permutation(w.flat).reshape(w.shape) for w in weights]\n",
    "    # Faster, but less random: only permutes along the first dimension\n",
    "    # weights = [np.random.permutation(w) for w in weights]\n",
    "    model.set_weights(weights)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0417\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 0s 813us/step - loss: 0.0384 - val_loss: 0.0308\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 0s 815us/step - loss: 0.0292 - val_loss: 0.0265\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 0s 811us/step - loss: 0.0237 - val_loss: 0.0216\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 0s 826us/step - loss: 0.0212 - val_loss: 0.0209\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 0s 820us/step - loss: 0.0207 - val_loss: 0.0206\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 0s 814us/step - loss: 0.0205 - val_loss: 0.0204\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 0s 826us/step - loss: 0.0203 - val_loss: 0.0203\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 0s 934us/step - loss: 0.0201 - val_loss: 0.0201\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 0s 841us/step - loss: 0.0200 - val_loss: 0.0200\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 0s 845us/step - loss: 0.0198 - val_loss: 0.0197\n",
      "Epoch 12/100\n",
      "285/285 [==============================] - 0s 866us/step - loss: 0.0196 - val_loss: 0.0194\n",
      "Epoch 13/100\n",
      "285/285 [==============================] - 0s 889us/step - loss: 0.0191 - val_loss: 0.0189\n",
      "Epoch 14/100\n",
      "285/285 [==============================] - 0s 835us/step - loss: 0.0188 - val_loss: 0.0188\n",
      "Epoch 15/100\n",
      "285/285 [==============================] - 0s 811us/step - loss: 0.0186 - val_loss: 0.0185\n",
      "Epoch 16/100\n",
      "285/285 [==============================] - 0s 810us/step - loss: 0.0184 - val_loss: 0.0183\n",
      "Epoch 17/100\n",
      "285/285 [==============================] - 0s 815us/step - loss: 0.0182 - val_loss: 0.0182\n",
      "Epoch 18/100\n",
      "285/285 [==============================] - 0s 853us/step - loss: 0.0180 - val_loss: 0.0180\n",
      "Epoch 19/100\n",
      "285/285 [==============================] - 0s 823us/step - loss: 0.0177 - val_loss: 0.0177\n",
      "Epoch 20/100\n",
      "285/285 [==============================] - 0s 892us/step - loss: 0.0176 - val_loss: 0.0175\n",
      "Epoch 21/100\n",
      "285/285 [==============================] - 0s 990us/step - loss: 0.0174 - val_loss: 0.0174\n",
      "Epoch 22/100\n",
      "285/285 [==============================] - 0s 854us/step - loss: 0.0172 - val_loss: 0.0172\n",
      "Epoch 23/100\n",
      "285/285 [==============================] - 0s 916us/step - loss: 0.0171 - val_loss: 0.0171\n",
      "Epoch 24/100\n",
      "285/285 [==============================] - 0s 801us/step - loss: 0.0169 - val_loss: 0.0170\n",
      "Epoch 25/100\n",
      "285/285 [==============================] - 0s 783us/step - loss: 0.0168 - val_loss: 0.0169\n",
      "Epoch 26/100\n",
      "285/285 [==============================] - 0s 886us/step - loss: 0.0167 - val_loss: 0.0168\n",
      "Epoch 27/100\n",
      "285/285 [==============================] - 0s 847us/step - loss: 0.0166 - val_loss: 0.0168\n",
      "Epoch 28/100\n",
      "285/285 [==============================] - 0s 872us/step - loss: 0.0166 - val_loss: 0.0167\n",
      "Epoch 29/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0165 - val_loss: 0.0166\n",
      "Epoch 30/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0165 - val_loss: 0.0166\n",
      "Epoch 31/100\n",
      "285/285 [==============================] - 0s 829us/step - loss: 0.0165 - val_loss: 0.0166\n",
      "Epoch 32/100\n",
      "285/285 [==============================] - 0s 839us/step - loss: 0.0164 - val_loss: 0.0166\n",
      "Epoch 33/100\n",
      "285/285 [==============================] - 0s 832us/step - loss: 0.0163 - val_loss: 0.0165\n",
      "Epoch 34/100\n",
      "285/285 [==============================] - 0s 818us/step - loss: 0.0163 - val_loss: 0.0162\n",
      "Epoch 35/100\n",
      "285/285 [==============================] - 0s 808us/step - loss: 0.0152 - val_loss: 0.0149\n",
      "Epoch 36/100\n",
      "285/285 [==============================] - 0s 842us/step - loss: 0.0146 - val_loss: 0.0129\n",
      "Epoch 37/100\n",
      "285/285 [==============================] - 0s 833us/step - loss: 0.0123 - val_loss: 0.0118\n",
      "Epoch 38/100\n",
      "285/285 [==============================] - 0s 822us/step - loss: 0.0118 - val_loss: 0.0115\n",
      "Epoch 39/100\n",
      "285/285 [==============================] - 0s 837us/step - loss: 0.0116 - val_loss: 0.0114\n",
      "Epoch 40/100\n",
      "285/285 [==============================] - 0s 884us/step - loss: 0.0115 - val_loss: 0.0113\n",
      "Epoch 41/100\n",
      "285/285 [==============================] - 0s 908us/step - loss: 0.0113 - val_loss: 0.0111\n",
      "Epoch 42/100\n",
      "285/285 [==============================] - 0s 861us/step - loss: 0.0112 - val_loss: 0.0110\n",
      "Epoch 43/100\n",
      "285/285 [==============================] - 0s 883us/step - loss: 0.0110 - val_loss: 0.0109\n",
      "Epoch 44/100\n",
      "285/285 [==============================] - 0s 885us/step - loss: 0.0110 - val_loss: 0.0108\n",
      "Epoch 45/100\n",
      "285/285 [==============================] - 0s 859us/step - loss: 0.0109 - val_loss: 0.0108\n",
      "Epoch 46/100\n",
      "285/285 [==============================] - 0s 817us/step - loss: 0.0108 - val_loss: 0.0107\n",
      "Epoch 47/100\n",
      "285/285 [==============================] - 0s 826us/step - loss: 0.0107 - val_loss: 0.0106\n",
      "Epoch 48/100\n",
      "285/285 [==============================] - 0s 828us/step - loss: 0.0107 - val_loss: 0.0106\n",
      "Epoch 49/100\n",
      "285/285 [==============================] - 0s 843us/step - loss: 0.0106 - val_loss: 0.0105\n",
      "Epoch 50/100\n",
      "285/285 [==============================] - 0s 860us/step - loss: 0.0106 - val_loss: 0.0105\n",
      "Epoch 51/100\n",
      "285/285 [==============================] - 0s 868us/step - loss: 0.0105 - val_loss: 0.0104\n",
      "Epoch 52/100\n",
      "285/285 [==============================] - 0s 828us/step - loss: 0.0105 - val_loss: 0.0104\n",
      "Epoch 53/100\n",
      "285/285 [==============================] - 0s 869us/step - loss: 0.0104 - val_loss: 0.0103\n",
      "Epoch 54/100\n",
      "285/285 [==============================] - 0s 934us/step - loss: 0.0104 - val_loss: 0.0103\n",
      "Epoch 55/100\n",
      "285/285 [==============================] - 0s 817us/step - loss: 0.0104 - val_loss: 0.0103\n",
      "Epoch 56/100\n",
      "285/285 [==============================] - 0s 818us/step - loss: 0.0103 - val_loss: 0.0103\n",
      "Epoch 57/100\n",
      "285/285 [==============================] - 0s 948us/step - loss: 0.0103 - val_loss: 0.0102\n",
      "Epoch 58/100\n",
      "285/285 [==============================] - 0s 775us/step - loss: 0.0100 - val_loss: 0.0096\n",
      "Epoch 59/100\n",
      "285/285 [==============================] - 0s 770us/step - loss: 0.0097 - val_loss: 0.0095\n",
      "Epoch 60/100\n",
      "285/285 [==============================] - 0s 815us/step - loss: 0.0096 - val_loss: 0.0095\n",
      "Epoch 61/100\n",
      "285/285 [==============================] - 0s 782us/step - loss: 0.0096 - val_loss: 0.0095\n",
      "Epoch 62/100\n",
      "285/285 [==============================] - 0s 797us/step - loss: 0.0096 - val_loss: 0.0094\n",
      "Epoch 63/100\n",
      "285/285 [==============================] - 0s 808us/step - loss: 0.0096 - val_loss: 0.0094\n",
      "Epoch 64/100\n",
      "285/285 [==============================] - 0s 810us/step - loss: 0.0095 - val_loss: 0.0094\n",
      "Epoch 65/100\n",
      "285/285 [==============================] - 0s 817us/step - loss: 0.0095 - val_loss: 0.0094\n",
      "Epoch 66/100\n",
      "285/285 [==============================] - 0s 794us/step - loss: 0.0095 - val_loss: 0.0094\n",
      "Epoch 67/100\n",
      "285/285 [==============================] - 0s 804us/step - loss: 0.0095 - val_loss: 0.0094\n",
      "Epoch 68/100\n",
      "285/285 [==============================] - 0s 846us/step - loss: 0.0094 - val_loss: 0.0093\n",
      "Epoch 69/100\n",
      "285/285 [==============================] - 0s 816us/step - loss: 0.0094 - val_loss: 0.0094\n",
      "Epoch 70/100\n",
      "285/285 [==============================] - 0s 882us/step - loss: 0.0094 - val_loss: 0.0093\n",
      "Epoch 71/100\n",
      "285/285 [==============================] - 0s 857us/step - loss: 0.0094 - val_loss: 0.0094\n",
      "Epoch 72/100\n",
      "285/285 [==============================] - 0s 851us/step - loss: 0.0090 - val_loss: 0.0042\n",
      "Epoch 73/100\n",
      "285/285 [==============================] - 0s 974us/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 74/100\n",
      "285/285 [==============================] - 0s 859us/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 75/100\n",
      "285/285 [==============================] - 0s 880us/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 76/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 77/100\n",
      "285/285 [==============================] - 0s 2ms/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 78/100\n",
      "285/285 [==============================] - 0s 954us/step - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 79/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 80/100\n",
      "285/285 [==============================] - 0s 960us/step - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 81/100\n",
      "285/285 [==============================] - 0s 893us/step - loss: 0.0028 - val_loss: 0.0029\n",
      "Epoch 82/100\n",
      "285/285 [==============================] - 0s 885us/step - loss: 0.0028 - val_loss: 0.0029\n",
      "Epoch 83/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0028 - val_loss: 0.0029\n",
      "Epoch 84/100\n",
      "285/285 [==============================] - 0s 886us/step - loss: 0.0028 - val_loss: 0.0029\n",
      "Epoch 85/100\n",
      "285/285 [==============================] - 0s 905us/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 86/100\n",
      "285/285 [==============================] - 0s 933us/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 87/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 88/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 89/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 90/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 91/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 92/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 93/100\n",
      "285/285 [==============================] - 0s 926us/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 94/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 95/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 96/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 97/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 98/100\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 99/100\n",
      "285/285 [==============================] - 0s 824us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 100/100\n",
      "285/285 [==============================] - 0s 783us/step - loss: 0.0026 - val_loss: 0.0028\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "# reset the all the weight of autoencoder model\n",
    "autoencoder_best = shuffle_weights(autoencoder_best)\n",
    "log = autoencoder_best.fit(x=X_train, y=X_train, epochs=100, validation_data=(X_val, X_val), callbacks=[early_stopping_cb])\n",
    "\n",
    "create_plot(log,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7627197039777983\n"
     ]
    }
   ],
   "source": [
    "# Calculate the roc of the model\n",
    "roc = roc_auc_score(y_val.flatten(), val_loss)\n",
    "print(roc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reconstruction_error</th>\n",
       "      <th>True_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002763</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002763</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002763</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.002763</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002763</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1132</th>\n",
       "      <td>0.002763</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1133</th>\n",
       "      <td>0.002763</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1134</th>\n",
       "      <td>0.002763</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1135</th>\n",
       "      <td>0.002763</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1136</th>\n",
       "      <td>0.002763</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1137 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Reconstruction_error  True_class\n",
       "0                 0.002763         0.0\n",
       "1                 0.002763         0.0\n",
       "2                 0.002763         0.0\n",
       "3                 0.002763         0.0\n",
       "4                 0.002763         0.0\n",
       "...                    ...         ...\n",
       "1132              0.002763         1.0\n",
       "1133              0.002763         1.0\n",
       "1134              0.002763         1.0\n",
       "1135              0.002763         1.0\n",
       "1136              0.002763         1.0\n",
       "\n",
       "[1137 rows x 2 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate reconstruction error of the retrained model\n",
    "X_pred = autoencoder_best.predict(X_val)\n",
    "mse = np.mean(np.power(X_val.flatten() - X_pred.flatten(), 2))\n",
    "error_df = pd.DataFrame({'Reconstruction_error': mse, 'True_class': y_val.flatten()})\n",
    "error_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set the threshold for fraud\n",
    "We are going to use three method to set the threshold for fraud:\n",
    "1. Use the mean of the reconstruction error plus one standard deviation as the threshold\n",
    "2. Set the threshold to the minimum of the reconstruction error of fraud cases\n",
    "3. Set the threshold to the minimize the cost function we mentioned above, which is 10*FN + FP\n",
    "\n",
    "If it is real case, we would recommend to use the third method. Because it can have company to lower the cost.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1\n",
    "Use the mean of the reconstruction error plus one standard deviation as the threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold:  0.10469958166591908\n"
     ]
    }
   ],
   "source": [
    "threshold = np.mean(val_loss) + np.std(val_loss)\n",
    "print(\"Threshold: \", threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix is :\n",
      "[[915 166]\n",
      " [ 33  23]]\n",
      "Accuracy rate is 0.8249780123131046\n",
      "Sensitivity is 0.4107142857142857\n"
     ]
    }
   ],
   "source": [
    "# pred y based on the threshold\n",
    "pred_y = np.where(val_loss > threshold, 1, 0)\n",
    "cm = confusion_matrix(y_val.flatten(), pred_y)\n",
    "print(f\"Confusion matrix is :\" )\n",
    "print(cm)\n",
    "accuracy_rate = (cm[0,0] + cm[1,1])/np.sum(cm)\n",
    "print(f\"Accuracy rate is {accuracy_rate}\")\n",
    "# calculate the sensitivity \n",
    "sensitivity = cm[1,1]/(cm[1,1] + cm[1,0])\n",
    "print(f\"Sensitivity is {sensitivity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2\n",
    "Set the threshold to the minimum of the reconstruction error of fraud cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAARbklEQVR4nO3da4xc5X3H8e8fr81iMBfZCwWvXRvhJDVSSOhC3BulTVOMqUCVWtVOGwQushxB5bZKG1e9CaV9UfWiKMKJZRFD6cVulaBAqQ2t1NK8SJ2wtAnBJmAXCB5DxNoJSUtCfPv3xUySZZidOTs745199P1IK82Z8zxzfrb2/HT2zMw5kZlIkua+s2Y7gCSpNyx0SSqEhS5JhbDQJakQFrokFWJotja8ZMmSXLFixWxtXpLmpCeffPJoZo60Wjdrhb5ixQrGx8dna/OSNCdFxFenWucpF0kqhIUuSYWw0CWpELN2Dl2Seu3EiRPUajXeeOON2Y4yY8PDw4yOjjJ//vzKcyx0ScWo1WosWrSIFStWEBGzHadrmcmxY8eo1WqsXLmy8ryOp1wiYmdEvBoRT0+xPiLiYxFxKCKeioirp5FbknrmjTfeYPHixXO6zAEigsWLF0/7L40q59DvB9a2WX8jsKrxswn4xLQSSFIPzfUy/55u/h0dCz0zPwt8vc2QW4AHsm4fcGFEXDrtJJKkGenFOfSlwOFJy7XGc680D4yITdSP4lm+fHkPNl221/95Z9dzc+jsruad9e3Xut5m1/JU91PPPq+7iadPd73NbsXJ73Y99/Q55/cwSTXnrf3AGd9mr439yb9y9P+O9+z1lpy3gPE/eF/HcY8++ihbtmzh1KlT3HHHHWzduvVN6zOTLVu2sGfPHhYuXMj999/P1VfP/Gx1Lz622OrvgpZ3zcjMHZk5lpljIyMtv7kqST3TyzKv+nqnTp3izjvvZO/evRw4cIBdu3Zx4MCBN43Zu3cvBw8e5ODBg+zYsYMPfvCDPcnXi0KvAcsmLY8CL/fgdSVpzvnCF77AFVdcweWXX86CBQtYv349Dz300JvGPPTQQ9x6661EBGvWrOG1117jlVfeclJj2npR6A8DtzY+7bIG+GZmzjyZJM1BR44cYdmyHxzjjo6OcuTIkWmP6UbHc+gRsQu4HlgSETXgj4H5AJm5HdgDrAMOAd8Gbp9xKkmao1rdp7n5EytVxnSjY6Fn5oYO6xO4c8ZJJKkAo6OjHD78g8+J1Go1LrvssmmP6YbXcpGkHrrmmms4ePAgL7zwAsePH2f37t3cfPPNbxpz880388ADD5CZ7Nu3jwsuuIBLL535p7396r+kYi05b0HPP7bYydDQEPfccw833HADp06dYuPGjVx55ZVs374dgM2bN7Nu3Tr27NnDFVdcwcKFC7nvvvt6ks9Cl1SsKp8Z74d169axbt26Nz23efPm7z+OCLZt29bz7XrKRZIKYaFLUiEsdEkqhIUuSYWw0CWpEBa6JBXCjy1KKtefr4LXX+3d6517MfzOwbZDNm7cyCOPPMLFF1/M00+/9UZv/bp0LniELqlkvSzziq9322238eijj065vl+XzgWP0AfauTdtnO0Ikqbpuuuu48UXX5xy/VSXzu3FV/89QpekM6hfl84FC12Szqh+XToXLHRJOqP6delcsNAl6Yzq16VzwTdFJZXs3It7/7HFDjZs2MDjjz/O0aNHGR0d5e677+bEiRNAfy+dCxa6pJJ1+Mx4P+zatavt+n5dOhc85SJJxbDQJakQFrqkorT6WOBc1M2/w0KXVIzh4WGOHTs250s9Mzl27BjDw8PTmuebopKKMTo6Sq1WY2JiYrajzNjw8DCjo6PTmmOhSyrG/PnzWbly5WzHmDWecpGkQljoklQIC12SCmGhS1IhLHRJKoSFLkmFsNAlqRCVCj0i1kbEsxFxKCK2tlh/QUT8U0R8KSL2R8TtvY8qSWqnY6FHxDxgG3AjsBrYEBGrm4bdCRzIzKuA64G/jIgFPc4qSWqjyhH6tcChzHw+M48Du4FbmsYksCjqN8Y7D/g6cLKnSSVJbVUp9KXA4UnLtcZzk90D/AjwMvBlYEtmnm5+oYjYFBHjETFewrUWJGmQVCn0Vrejbr6U2Q3AF4HLgHcB90TE+W+ZlLkjM8cyc2xkZGSaUSVJ7VQp9BqwbNLyKPUj8cluBx7MukPAC8A7ehNRklRFlUJ/AlgVESsbb3SuBx5uGvMS8F6AiLgEeDvwfC+DSpLa63j53Mw8GRF3AY8B84Cdmbk/IjY31m8HPgLcHxFfpn6K5sOZebSPuSVJTSpdDz0z9wB7mp7bPunxy8DP9zaaJGk6/KaoJBXCQpekQljoklQIC12SCmGhS1IhLHRJKoSFLkmFsNAlqRAWuiQVwkKXpEJY6JJUCAtdkgphoUtSISx0SSqEhS5JhbDQJakQFrokFcJCl6RCWOiSVAgLXZIKYaFLUiEsdEkqhIUuSYWw0CWpEBa6JBXCQpekQljoklQIC12SCmGhS1IhLHRJKkSlQo+ItRHxbEQcioitU4y5PiK+GBH7I+I/ehtTktTJUKcBETEP2Aa8D6gBT0TEw5l5YNKYC4GPA2sz86WIuLhPeSVJU6hyhH4tcCgzn8/M48Bu4JamMe8HHszMlwAy89XexpQkdVKl0JcChyct1xrPTfY24KKIeDwinoyIW1u9UERsiojxiBifmJjoLrEkqaUqhR4tnsum5SHgR4GbgBuAP4yIt71lUuaOzBzLzLGRkZFph5UkTa3jOXTqR+TLJi2PAi+3GHM0M18HXo+IzwJXAc/1JKUkqaMqR+hPAKsiYmVELADWAw83jXkI+KmIGIqIhcB7gGd6G1WS1E7HI/TMPBkRdwGPAfOAnZm5PyI2N9Zvz8xnIuJR4CngNHBvZj7dz+CSpDeLzObT4WfG2NhYjo+Pz8q2JWmuiognM3Os1Tq/KSpJhbDQJakQFrokFcJCl6RCWOiSVAgLXZIKYaFLUiEsdEkqhIUuSYWw0CWpEBa6JBXCQpekQljoklQIC12SCmGhS1IhLHRJKoSFLkmFsNAlqRAWuiQVwkKXpEJY6JJUCAtdkgphoUtSISx0SSqEhS5JhbDQJakQFrokFcJCl6RCWOiSVAgLXZIKYaFLUiEqFXpErI2IZyPiUERsbTPumog4FRG/1LuIkqQqOhZ6RMwDtgE3AquBDRGxeopxfwY81uuQkqTOqhyhXwscysznM/M4sBu4pcW43wA+Dbzaw3ySpIqqFPpS4PCk5Vrjue+LiKXALwLb271QRGyKiPGIGJ+YmJhuVklSG1UKPVo8l03LHwU+nJmn2r1QZu7IzLHMHBsZGakYUZJUxVCFMTVg2aTlUeDlpjFjwO6IAFgCrIuIk5n5mV6ElCR1VqXQnwBWRcRK4AiwHnj/5AGZufJ7jyPifuARy1ySzqyOhZ6ZJyPiLuqfXpkH7MzM/RGxubG+7XlzSdKZUeUInczcA+xpeq5lkWfmbTOPJUmaLr8pKkmFsNAlqRAWuiQVwkKXpEJY6JJUCAtdkgphoUtSISx0SSqEhS5JhbDQJakQFrokFcJCl6RCWOiSVAgLXZIKYaFLUiEsdEkqhIUuSYWw0CWpEBa6JBXCQpekQljoklQIC12SCmGhS1IhLHRJKoSFLkmFsNAlqRAWuiQVwkKXpEJY6JJUCAtdkgpRqdAjYm1EPBsRhyJia4v1vxoRTzV+PhcRV/U+qiSpnY6FHhHzgG3AjcBqYENErG4a9gLw05n5TuAjwI5eB5UktVflCP1a4FBmPp+Zx4HdwC2TB2Tm5zLzG43FfcBob2NKkjqpUuhLgcOTlmuN56by68DeVisiYlNEjEfE+MTERPWUkqSOqhR6tHguWw6M+Bnqhf7hVuszc0dmjmXm2MjISPWUkqSOhiqMqQHLJi2PAi83D4qIdwL3Ajdm5rHexJMkVVXlCP0JYFVErIyIBcB64OHJAyJiOfAg8IHMfK73MSVJnXQ8Qs/MkxFxF/AYMA/YmZn7I2JzY/124I+AxcDHIwLgZGaO9S+2JKlZZLY8Hd53Y2NjOT4+PivblqS5KiKenOqA2W+KSlIhLHRJKoSFLkmFsNAlqRAWuiQVwkKXpEJY6JJUCAtdkgphoUtSISx0SSqEhS5JhbDQJakQFrokFcJCl6RCWOiSVAgLXZIKYaFLUiGq3CR64Fx5z/Ndzz3na890NW/461/teptnTTzb1byTl13V9TbnvfGt7iaePtn1Nk+fvaireScWXdL9NoeGu5r3nUve1vU2V1xyWVfzVi881f02z+1u7nnzT3e9ze+cjK7mLZrf/V3Qhs7qbu5Z3UUF4Jffc1FX8/5h3ze63uavrOlum514hC5JhbDQJakQFrokFcJCl6RCWOiSVAgLXZIKYaFLUiEsdEkqhIUuSYWw0CWpEBa6JBXCQpekQljoklSISoUeEWsj4tmIOBQRW1usj4j4WGP9UxFxde+jSpLa6VjoETEP2AbcCKwGNkTE6qZhNwKrGj+bgE/0OKckqYMqR+jXAocy8/nMPA7sBm5pGnML8EDW7QMujIhLe5xVktRGlRtcLAUOT1quAe+pMGYp8MrkQRGxifoRPMuXL59u1u/bf9flXc+FmcyVpLp+3aRiJqocobe6F0jzbUWqjCEzd2TmWGaOjYyMVMknSaqoSqHXgGWTlkeBl7sYI0nqoyqF/gSwKiJWRsQCYD3wcNOYh4FbG592WQN8MzNfaX4hSVL/dDyHnpknI+Iu4DFgHrAzM/dHxObG+u3AHmAdcAj4NnB7/yJLklqp8qYombmHemlPfm77pMcJ3NnbaJKk6fCbopJUCAtdkgphoUtSISx0SSpE1N/PnIUNR0wAX53BSywBjvYozplg3v4yb3/NpbxzKStMP+8PZ2bLb2bOWqHPVESMZ+bYbOeoyrz9Zd7+mkt551JW6G1eT7lIUiEsdEkqxFwu9B2zHWCazNtf5u2vuZR3LmWFHuads+fQJUlvNpeP0CVJk1joklSIgSv0md6QOiLmRcR/R8Qjg543Ii6MiE9FxFci4pmI+LEBz/tbEbE/Ip6OiF0RMTwAed8REf8ZEd+NiA9NZ+4g5Y2IZRHx743fg/0RsWWQ805aP2j7W7vfh0Hc39rlnf7+lpkD80P98rz/Q/0+cQuALwGrm8asA/ZSv0vSGuDzTet/G/h74JFBzwv8NXBH4/EC4MJBzUv9loIvAOc0lv8RuG0A8l4MXAP8KfCh6cwdsLyXAlc3Hi8CnhvkvJPWD9r+NmXeAd3fpvp96Gp/G7Qj9BndkDoiRoGbgHsHPW9EnA9cB3wSIDOPZ+Zrg5q3sW4IOCcihoCF9P+uVB3zZuarmfkEcGK6cwcpb2a+kpn/1Xj8v8Az1HfqgcwLg7m/TZV3UPe3dv+/dLG/DVqhT3Wz6apjPgr8LnC6T/mazSTv5cAEcF/jT9Z7I+LcfoZtk6XjmMw8AvwF8BL1m39/MzP/pY9Zp8xyBuZ2qyfbjIgVwLuBz/cm1pRmmvejDN7+NpVB3d9a6nZ/G7RC7/qG1BHxC8Crmflk72NNaSY30B4CrgY+kZnvBl4H+n2edyb/vxdRP7pYCVwGnBsRv9bjfM0q3Xy8D3O7NeNtRsR5wKeB38zMb/UkVZvNtXiuUt4B3t+mMqj7W+uJXe5vg1boM7kh9U8AN0fEi9T/tPnZiPjb/kVtm6XKmBpQy8zvHYV9ivovXD/NJO/PAS9k5kRmngAeBH68j1nbZen33G7NaJsRMZ96mf9dZj7Y42ytzCTvoO5v7eYO4v42la72t0Er9K5vSJ2Zv5eZo5m5ojHv3zKz30eQM8n7NeBwRLy9Me69wIFBzUv9T781EbEwIqKR95kByNuPud3qepuN/9NPAs9k5l/1MeNkXecd4P2tpQHe36bS3f7Wz3d5u/mh/imL56i/O/z7jec2A5sbjwPY1lj/ZWCsxWtczxl4132meYF3AePAU8BngIsGPO/dwFeAp4G/Ac4egLw/RP1I6FvAa43H5081d1DzAj9J/c/xp4AvNn7WDWreptcYpP2t3e/DIO5v7fJOe3/zq/+SVIhBO+UiSeqShS5JhbDQJakQFrokFcJCl6RCWOiSVAgLXZIK8f/7hPjnsQVRtwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show the distribution of the model_score\n",
    "import seaborn as sns\n",
    "sns.histplot(x=val_loss,y=y_val.flatten(),hue=y_val.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold:  0.07054938492779454\n"
     ]
    }
   ],
   "source": [
    "# get the threshold of the model_score\n",
    "df_temp = pd.DataFrame({'Reconstruction_error': val_loss, 'True_class': y_val.flatten()})\n",
    "df_temp_fraud = df_temp[df_temp['True_class']==1]\n",
    "threshold = df_temp_fraud[\"Reconstruction_error\"].min()\n",
    "print(\"Threshold: \", threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix is :\n",
      "[[423 658]\n",
      " [  0  56]]\n",
      "Accuracy rate is 0.4212840809146878\n",
      "Sensitivity is 1.0\n"
     ]
    }
   ],
   "source": [
    "# pred y based on the threshold\n",
    "pred_y = np.where(val_loss >= threshold, 1, 0)\n",
    "cm = confusion_matrix(y_val.flatten(), pred_y)\n",
    "print(f\"Confusion matrix is :\" )\n",
    "print(cm)\n",
    "accuracy_rate = (cm[0,0] + cm[1,1])/np.sum(cm)\n",
    "print(f\"Accuracy rate is {accuracy_rate}\")\n",
    "# calculate the sensitivity \n",
    "sensitivity = cm[1,1]/(cm[1,1] + cm[1,0])\n",
    "print(f\"Sensitivity is {sensitivity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 3\n",
    "Set the threshold to the minimize the cost function we mentioned above, which is 10*FN + FP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the cost function\n",
    "def calculate_cost(fn,fp):\n",
    "    return 100*fn+fp\n",
    "\n",
    "cost_lost = {}\n",
    "for i in np.linspace(0,0.1,100):\n",
    "    pred_y = np.where(val_loss > i, 1, 0)\n",
    "    cm = confusion_matrix(y_val.flatten(), pred_y)\n",
    "    fn,fp = cm[1][0],cm[0][1]\n",
    "    # cost_lost[\"Threshold: \"+str(i)] = calculate_cost(fn,fp)\n",
    "    cost_lost[i] = calculate_cost(fn,fp)\n",
    "\n",
    "threshold = min(cost_lost, key=cost_lost.get)\n",
    "print(\"Threshold: \", threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix is :\n",
      "[[423 658]\n",
      " [  0  56]]\n",
      "Accuracy rate is 0.4212840809146878\n",
      "Sensitivity is 1.0\n"
     ]
    }
   ],
   "source": [
    "# pred y based on the threshold\n",
    "pred_y = np.where(val_loss >= threshold, 1, 0)\n",
    "cm = confusion_matrix(y_val.flatten(), pred_y)\n",
    "print(f\"Confusion matrix is :\" )\n",
    "print(cm)\n",
    "accuracy_rate = (cm[0,0] + cm[1,1])/np.sum(cm)\n",
    "print(f\"Accuracy rate is {accuracy_rate}\")\n",
    "# calculate the sensitivity \n",
    "sensitivity = cm[1,1]/(cm[1,1] + cm[1,0])\n",
    "print(f\"Sensitivity is {sensitivity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7627197039777983\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "627f9b2e5272ed3cf653ffd46ee5493b7b24a386103372a1710032d6985d4cd7"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
